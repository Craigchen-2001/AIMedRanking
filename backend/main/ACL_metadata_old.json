[
  {
    "id": "acl2025_temp_1290",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Follow-up Question Generation For Enhanced Patient-Provider Conversations",
    "authors": [
      "Joseph Gatto",
      "Parker Seegmiller",
      "Timothy E. Burdick",
      "Inas S. Khayal",
      "Sarah DeLozier",
      "Sarah Masud Preum"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Follow-up question generation is an essential feature of dialogue systems as it can reduce conversational ambiguity and enhance modeling complex interactions. Conversational contexts often pose core NLP challenges such as (i) extracting relevant information buried in fragmented data sources, and (ii) modeling parallel thought processes. These two challenges occur frequently in medical dialogue as a doctor asks questions based not only on patient utterances but also their prior EHR data and current diagnostic hypotheses. Asking medical questions in asynchronous conversations compounds these issues as doctors can only rely on static EHR information to motivate follow-up questions.To address these challenges, we introduce FollowupQ, a novel framework for enhancing asynchronous medical conversation. FollowupQ is a multi-agent framework that processes patient messages and EHR data to generate personalized follow-up questions, clarifying patient-reported medical conditions. FollowupQ reduces requisite provider follow-up communications by 34%. It also improves performance by 17% and 5% on real and synthetic data, respectively. We also release the first public dataset of asynchronous medical messages with linked EHR data alongside 2,300 follow-up questions written by clinical experts for the wider NLP research community.",
    "keywords": "N/A",
    "pdf_url": "https://arxiv.org/pdf/2503.17509",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title, \"Follow-up Question Generation For Enhanced Patient-Provider Conversations,\" clearly implies relevance to healthcare. The paper likely focuses on improving patient-provider interactions, which is a healthcare-specific task. Such conversations are integral to clinical settings for diagnosis, treatment planning, and patient understanding. The generation of follow-up questions suggests an AI-driven solution supporting patient engagement or communication, directly aligning with Healthcare AI applications. Even in the absence of an abstract or keywords, the explicit reference to \"patient-provider conversations\" provides sufficient evidence for classification under Healthcare AI.",
    "prompt_tokens": 22492,
    "completion_tokens": 217,
    "total_tokens": 22709,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "EHR/EMR Predictive Modeling"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (GPT, LLaMA)"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "Clinician-in-the-loop Systems"
    },
    "method": "Multi-agent framework; Differential diagnostic agents; Message clarification agents",
    "application": "Follow-up question generation – Patient-Provider Communication",
    "code_link": "N/A",
    "dataset_name": [
      "FollowupBench-FB Real",
      "FB-Synth"
    ],
    "is_public": false
  },
  {
    "id": "2024.acl-long.484",
    "year": 2024,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "ProtLLM: An Interleaved Protein-Language LLM with Protein-as-Word Pre-Training",
    "authors": [
      "Le Zhuo",
      "Zewen Chi",
      "Minghao Xu",
      "Heyan Huang",
      "Jianan Zhao",
      "Heqi Zheng",
      "Conghui He",
      "Xian-Ling Mao",
      "Wentao Zhang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We propose ProtLLM, a versatile cross-modal large language model (LLM) for both protein-centric and protein-language tasks. ProtLLM features a unique dynamic protein mounting mechanism, enabling it to handle complex inputs where the natural language text is interspersed with an arbitrary number of proteins. Besides, we propose the protein-as-word language modeling approach to train ProtLLM. By developing a specialized protein vocabulary, we equip the model with the capability to predict not just natural language but also proteins from a vast pool of candidates. Additionally, we construct a large-scale interleaved protein-text dataset, named InterPT, for pre-training. This dataset comprehensively encompasses both (1) structured data sources like protein annotations and (2) unstructured data sources like biological research papers, thereby endowing ProtLLM with crucial knowledge for understanding proteins. We evaluate ProtLLM on classic supervised protein-centric tasks and explore its novel protein-language applications. Experimental results demonstrate that ProtLLM not only achieves superior performance against protein-specialized baselines on protein-centric tasks but also induces zero-shot and in-context learning capabilities on protein-language tasks.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2024.acl-long.484.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract describes ProtLLM, a large language model specifically designed for protein-centric and protein-language tasks, highlighting its application to biological and biomedical research. The model is trained with a dataset that includes structured protein annotations and unstructured biological research papers, suggesting a focus on molecular-level biomedical data. Additionally, ProtLLM is evaluated on tasks that involve understanding proteins, which is central to biomedical research areas such as drug discovery, protein design, and genomics. These topics are explicitly relevant to the Biomedicine AI domain due to their potential implications for understanding diseases and developing therapeutic interventions. While healthcare applications (e.g., clinical decision support) are not explicitly mentioned, the focus on proteins strongly aligns with Biomedicine AI.",
    "prompt_tokens": 41117,
    "completion_tokens": 212,
    "total_tokens": 41329,
    "Topic Axis I": {
      "MainTopic": "Computational Genomics & Multi-Omics",
      "SubTopic": "Transcriptomics"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Masked autoencoder"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Transformer-based models (LLaMA-7b); Protein-as-word pretraining",
    "application": "Protein-protein interaction prediction; Protein sequence modeling",
    "code_link": "https://github.com/ProtLLM/ProtLLM",
    "dataset_name": [
      "PubMed",
      "UniProt",
      "STRING",
      "Mol-Instructions"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_1079",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "CAMI: A Counselor Agent Supporting Motivational Interviewing through State Inference and Topic Exploration",
    "authors": [
      "Yizhe Yang",
      "Palakorn Achananuparp",
      "Heyan Huang",
      "Jing Jiang",
      "Phey Ling KIT",
      "Nicholas Gabriel Lim",
      "Cameron Tan Shi Ern",
      "Ee-Peng Lim"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Conversational counselor agents have become essential tools for addressing the rising demand for scalable and accessible mental health support. This paper introduces CAMI, a novel automated counselor agent grounded in Motivational Interviewing (MI) -- a client-centered counseling approach designed to address ambivalence and facilitate behavior change. CAMI employs a novel STAR framework, consisting of client's state inference, motivation topic exploration, and response generation modules, leveraging large language models (LLMs). These components work together to evoke change talk, aligning with MI principles and improving counseling outcomes for clients from diverse backgrounds. We evaluate CAMI's performance through both automated and manual evaluations, utilizing simulated clients to assess MI skill competency, client's state inference accuracy, topic exploration proficiency, and overall counseling success. Results show that CAMI not only outperforms several state-of-the-art methods but also shows more realistic counselor-like behavior. Additionally, our ablation study underscores the critical roles of state inference and topic exploration in achieving this performance.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.1024.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title mentions \"CAMI: A Counselor Agent Supporting Motivational Interviewing,\" which implies the application of AI to counseling and mental health-related support. Motivational interviewing is a psychological technique often used to address behavioral health issues, such as substance abuse or chronic health condition management. Although the abstract and keywords are not provided, the emphasis on counseling and state inference suggests relevance to Healthcare AI, specifically in the domain of mental health support and therapeutic tools leveraging AI.",
    "prompt_tokens": 22447,
    "completion_tokens": 204,
    "total_tokens": 22651,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "LLM prompting; state inference and topic exploration; ranking-based response generation",
    "application": "Motivational interviewing-based counseling",
    "code_link": "https://github.com/IzzetYoung/CAMI",
    "dataset_name": [
      "AnnoMI"
    ],
    "is_public": true
  },
  {
    "id": "2024.acl-long.39",
    "year": 2024,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "DocLens: Multi-aspect Fine-grained Evaluation for Medical Text Generation",
    "authors": [
      "Yiqing Xie",
      "Sheng Zhang",
      "Hao Cheng",
      "Pengfei Liu",
      "Zelalem Gero",
      "Cliff Wong",
      "Tristan Naumann",
      "Hoifung Poon",
      "Carolyn Rose"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Medical text generation aims to assist with administrative work and highlight salient information to support decision-making.To reflect the specific requirements of medical text, in this paper, we propose a set of metrics to evaluate the completeness, conciseness, and attribution of the generated text at a fine-grained level. The metrics can be computed by various types of evaluators including instruction-following (both proprietary and open-source) and supervised entailment models. We demonstrate the effectiveness of the resulting framework, DocLens, with three evaluators on three tasks: clinical note generation, radiology report summarization, and patient question summarization. A comprehensive human study shows that DocLens exhibits substantially higher agreement with the judgments of medical experts than existing metrics. The results also highlight the need to improve open-source evaluators and suggest potential directions. We released the code at https://github.com/yiqingxyq/DocLens.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2024.acl-long.39.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses \"medical text generation\" tasks, specifically focusing on clinical note generation, radiology report summarization, and patient question summarization. These tasks are directly related to Healthcare AI as they aim to support decision-making and administrative work in medical contexts. The evaluation framework, DocLens, is tailored for assessing medical text, reflecting its relevance to healthcare applications. Thus, the focus on medical-specific requirements and tasks strongly aligns with the Healthcare AI domain.",
    "prompt_tokens": 22327,
    "completion_tokens": 227,
    "total_tokens": 22554,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (GPT)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Representation learning; Claim Recall Evaluation; Instruction-following models; Supervised entailment models",
    "application": "Clinical note generation; Radiology report summarization; Patient question summarization",
    "code_link": "https://github.com/yiqingxyq/DocLens",
    "dataset_name": [
      "ACI-BENCH",
      "MIMIC-III",
      "MeQSum"
    ],
    "is_public": true
  },
  {
    "id": "2021.acl-long.390",
    "year": 2021,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Few-Shot Text Ranking with Meta Adapted Synthetic Weak Supervision",
    "authors": [
      "Si Sun",
      "Yingzhuo Qian",
      "Zhenghao Liu",
      "Chenyan Xiong",
      "Kaitao Zhang",
      "Jie Bao",
      "Zhiyuan Liu",
      "Paul Bennett"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The effectiveness of Neural Information Retrieval (Neu-IR) often depends on a large scale of in-domain relevance training signals, which are not always available in real-world ranking scenarios. To democratize the benefits of Neu-IR, this paper presents MetaAdaptRank, a domain adaptive learning method that generalizes Neu-IR models from label-rich source domains to few-shot target domains. Drawing on source-domain massive relevance supervision, MetaAdaptRank contrastively synthesizes a large number of weak supervision signals for target domains and meta-learns to reweight these synthetic “weak” data based on their benefits to the target-domain ranking accuracy of Neu-IR models. Experiments on three TREC benchmarks in the web, news, and biomedical domains show that MetaAdaptRank significantly improves the few-shot ranking accuracy of Neu-IR models. Further analyses indicate that MetaAdaptRank thrives from both its contrastive weak data synthesis and meta-reweighted data selection. The code and data of this paper can be obtained from https://github.com/thunlp/MetaAdaptRank.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2021.acl-long.390.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract mentions experiments conducted on TREC benchmarks, including the biomedical domain. While the paper primarily discusses a domain adaptation method for neural information retrieval, the inclusion of a biomedical-specific dataset implies relevance to Biomedicine AI. This suggests the method could be applied to tasks involving biomedical data or literature, making the paper relevant to the Biomedicine AI domain. Although the healthcare-specific context is not explicitly discussed, the focus on biomedical datasets makes the classification appropriate.",
    "prompt_tokens": 59848,
    "completion_tokens": 271,
    "total_tokens": 60119,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Digital Health & Wearable Sensor Data"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Meta-learning; Contrastive synthesis",
    "application": "Information retrieval – Biomedical literature",
    "code_link": "https://github.com/thunlp/MetaAdaptRank",
    "dataset_name": [
      "TREC-COVID",
      "ClueWeb09-B",
      "Robust04"
    ],
    "is_public": true
  },
  {
    "id": "2021.acl-long.384",
    "year": 2021,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Generating SOAP Notes from Doctor-Patient Conversations Using Modular Summarization Techniques",
    "authors": [
      "Kundan Krishna",
      "Sopan Khosla",
      "Jeffrey Bigham",
      "Zachary C. Lipton"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Following each patient visit, physicians draft long semi-structured clinical summaries called SOAP notes. While invaluable to clinicians and researchers, creating digital SOAP notes is burdensome, contributing to physician burnout. In this paper, we introduce the first complete pipelines to leverage deep summarization models to generate these notes based on transcripts of conversations between physicians and patients. After exploring a spectrum of methods across the extractive-abstractive spectrum, we propose Cluster2Sent, an algorithm that (i) extracts important utterances relevant to each summary section; (ii) clusters together related utterances; and then (iii) generates one summary sentence per cluster. Cluster2Sent outperforms its purely abstractive counterpart by 8 ROUGE-1 points, and produces significantly more factual and coherent sentences as assessed by expert human evaluators. For reproducibility, we demonstrate similar benefits on the publicly available AMI dataset. Our results speak to the benefits of structuring summaries into sections and annotating supporting evidence when constructing summarization corpora.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2021.acl-long.384.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper clearly falls within the domain of Healthcare AI as it addresses the automation of generating SOAP notes, which are clinical summaries created by physicians during patient visits. The abstract explicitly mentions that the work is based on \"transcripts of conversations between physicians and patients,\" a strong indicator of relevance to healthcare. Furthermore, the aim of reducing physician burnout and improving clinical documentation processes aligns directly with Healthcare AI goals. The reference to SOAP notes, a crucial artifact in clinical workflows, confirms its application in healthcare-specific tasks.",
    "prompt_tokens": 22687,
    "completion_tokens": 215,
    "total_tokens": 22902,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (T5, section-conditioned pointer-generator models)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Section-conditioned pointer-generator networks; T5 encoder-decoder model",
    "application": "SOAP notes generation from doctor-patient conversations",
    "code_link": "https://github.com/acmi-lab/modular-summarization",
    "dataset_name": [
      "Abridge AI medical dataset",
      "AMI corpus"
    ],
    "is_public": true
  },
  {
    "id": "2024.acl-long.533",
    "year": 2024,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "To Generate or to Retrieve? On the Effectiveness of Artificial Contexts for Medical Open-Domain Question Answering",
    "authors": [
      "Giacomo Frisoni",
      "Alessio Cocchieri",
      "Alex Presepi",
      "Gianluca Moro",
      "Zaiqiao Meng"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Medical open-domain question answering demands substantial access to specialized knowledge. Recent efforts have sought to decouple knowledge from model parameters, counteracting architectural scaling and allowing for training on common low-resource hardware. The retrieve-then-read paradigm has become ubiquitous, with model predictions grounded on relevant knowledge pieces from external repositories such as PubMed, textbooks, and UMLS. An alternative path, still under-explored but made possible by the advent of domain-specific large language models, entails constructing artificial contexts through prompting. As a result, “to generate or to retrieve” is the modern equivalent of Hamlet’s dilemma. This paper presents MedGENIE, the first generate-then-read framework for multiple-choice question answering in medicine. We conduct extensive experiments on MedQA-USMLE, MedMCQA, and MMLU, incorporating a practical perspective by assuming a maximum of 24GB VRAM. MedGENIE sets a new state-of-the-art in the open-book setting of each testbed, allowing a small-scale reader to outcompete zero-shot closed-book 175B baselines while using up to 706x fewer parameters. Our findings reveal that generated passages are more effective than retrieved ones in attaining higher accuracy.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2024.acl-long.533.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on medical open-domain question answering, explicitly targeting specialized medical knowledge and utilizing datasets such as MedQA-USMLE and MedMCQA, which are relevant to medical exams and clinical understanding. The frequent references to medical contexts, specialized knowledge repositories (e.g., PubMed, textbooks, UMLS), and applications in medicine strongly indicate relevance to Healthcare AI. The goal of improving performance on medical multiple-choice question answering tasks further underscores the healthcare-specific utility of the framework presented in the paper.",
    "prompt_tokens": 21857,
    "completion_tokens": 230,
    "total_tokens": 22087,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Retrieve-then-read; In-context learning; Fine-tuned small language models (SLMs)",
    "application": "Medical open-domain question answering",
    "code_link": "https://github.com/disi-unibo-nlp/medgenie",
    "dataset_name": [
      "MedQA-USMLE",
      "MedMCQA",
      "MMLU-Medical"
    ],
    "is_public": true
  },
  {
    "id": "2024.acl-long.240",
    "year": 2024,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Missci: Reconstructing Fallacies in Misrepresented Science",
    "authors": [
      "Max Glockner",
      "Yufang Hou",
      "Preslav Nakov",
      "Iryna Gurevych"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Health-related misinformation on social networks can lead to poor decision-making and real-world dangers. Such misinformation often misrepresents scientific publications and cites them as “proof” to gain perceived credibility. To effectively counter such claims automatically, a system must explain how the claim was falsely derived from the cited publication. Current methods for automated fact-checking or fallacy detection neglect to assess the (mis)used evidence in relation to misinformation claims, which is required to detect the mismatch between them. To address this gap, we introduce Missci, a novel argumentation theoretical model for fallacious reasoning together with a new dataset for real-world misinformation detection that misrepresents biomedical publications. Unlike previous fallacy detection datasets, Missci (i) focuses on implicit fallacies between the relevant content of the cited publication and the inaccurate claim, and (ii) requires models to verbalize the fallacious reasoning in addition to classifying it. We present Missci as a dataset to test the critical reasoning abilities of large language models (LLMs), that are required to reconstruct real-world fallacious arguments, in a zero-shot setting. We evaluate two representative LLMs and the impact of different levels of detail about the fallacy classes provided to the LLM via prompts. Our experiments and human evaluation show promising results for GPT 4, while also demonstrating the difficulty of this task.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2024.acl-long.240.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly addresses health-related misinformation on social networks, with a focus on countering false claims that misrepresent biomedical publications. The mention of \"misrepresented biomedical publications\" directly ties the research to the domain of Biomedicine AI. Additionally, the system (Missci) aims to detect and explain fallacious reasoning in claims related to health and biomedical literature, which suggests relevance to both healthcare and biomedical contexts. While the paper primarily explores fallacy detection, its application is anchored in the biomedical and healthcare domain, justifying the classification as Biomedicine AI.",
    "prompt_tokens": 22160,
    "completion_tokens": 223,
    "total_tokens": 22383,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "N/A"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (GPT)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Transformer-based models (GPT-4, LLaMA-2); Chain-of-Thought (CoT) prompting",
    "application": "Fallacious reasoning reconstruction – Misrepresented scientific arguments",
    "code_link": "https://github.com/UKPLab/acl2024-missci",
    "dataset_name": [
      "MISSCI"
    ],
    "is_public": true
  },
  {
    "id": "2023.acl-long.138",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Can NLI Provide Proper Indirect Supervision for Low-resource Biomedical Relation Extraction?",
    "authors": [
      "Jiashu Xu",
      "Mingyu Derek Ma",
      "Muhao Chen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Two key obstacles in biomedical relation extraction (RE) are the scarcity of annotations and the prevalence of instances without explicitly pre-defined labels due to low annotation coverage. Existing approaches, which treat biomedical RE as a multi-class classification task, often result in poor generalization in low-resource settings and do not have the ability to make selective prediction on unknown cases but give a guess from seen relations, hindering the applicability of those approaches. We present NBR, which converts biomedical RE as natural language inference formulation through indirect supervision. By converting relations to natural language hypotheses, NBR is capable of exploiting semantic cues to alleviate annotation scarcity. By incorporating a ranking-based loss that implicitly calibrates abstinent instances, NBR learns a clearer decision boundary and is instructed to abstain on uncertain instances. Extensive experiments on three widely-used biomedical RE benchmarks, namely ChemProt, DDI and GAD, verify the effectiveness of NBR in both full-set and low-resource regimes. Our analysis demonstrates that indirect supervision benefits biomedical RE even when a domain gap exists, and combining NLI knowledge with biomedical knowledge leads to the best performance gains.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.138.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This paper focuses on \"biomedical relation extraction (RE),\" specifically addressing challenges in data scarcity and annotation coverage within the biomedical domain. The abstract explicitly mentions biomedical benchmarks such as ChemProt, DDI, and GAD, which are widely used in the field for tasks involving extraction of relationships related to drugs, chemicals, and diseases. The approach (NBR) leverages natural language inference (NLI) to incorporate semantic and domain-specific (biomedical) knowledge. Given the focus on improving information extraction relevant to biomedical research, this paper clearly falls under the domain of Biomedicine AI.",
    "prompt_tokens": 22106,
    "completion_tokens": 223,
    "total_tokens": 22329,
    "Topic Axis I": {
      "MainTopic": "Computational Genomics & Multi-Omics",
      "SubTopic": "new-Biomedical relation extraction for gene-disease and drug-drug interactions"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Semantic representation learning for relations"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Natural Language Inference reformulation; Ranking-based loss; Fine-tuning on general NLI datasets",
    "application": "Biomedical relation extraction tasks",
    "code_link": "https://github.com/luka-group/NLI_as_Indirect_Supervision",
    "dataset_name": [
      "ChemProt",
      "DDI",
      "GAD"
    ],
    "is_public": true
  },
  {
    "id": "2023.acl-long.886",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "DICE: Data-Efficient Clinical Event Extraction with Generative Models",
    "authors": [
      "Mingyu Derek Ma",
      "Alexander Taylor",
      "Wei Wang",
      "Nanyun Peng"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Event extraction for the clinical domain is an under-explored research area. The lack of training data along with the high volume of domain-specific terminologies with vague entity boundaries makes the task especially challenging. In this paper, we introduce DICE, a robust and data-efficient generative model for clinical event extraction. DICE frames event extraction as a conditional generation problem and introduces a contrastive learning objective to accurately decide the boundaries of biomedical mentions. DICE also trains an auxiliary mention identification task jointly with event extraction tasks to better identify entity mention boundaries, and further introduces special markers to incorporate identified entity mentions as trigger and argument candidates for their respective tasks. To benchmark clinical event extraction, we compose MACCROBAT-EE, the first clinical event extraction dataset with argument annotation, based on an existing clinical information extraction dataset MACCROBAT. Our experiments demonstrate state-of-the-art performances of DICE for clinical and news domain event extraction, especially under low data settings.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.886.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly focuses on \"clinical event extraction,\" which directly pertains to analyzing clinical data within healthcare contexts. Terms such as \"lack of training data,\" \"domain-specific terminologies,\" and \"clinical information extraction dataset MACCROBAT\" strongly suggest it is rooted in medical or healthcare applications. Furthermore, the paper benchmarks its method using a clinical dataset and discusses challenges in biomedical mention boundaries, which are relevant to healthcare AI and biomedicine AI for tasks like understanding patient records or extracting medical insights. The generative model DICE is designed specifically for \"clinical domain\" event extraction, indicating a targeted application in healthcare or medical informatics.",
    "prompt_tokens": 60666,
    "completion_tokens": 325,
    "total_tokens": 60991,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "T5-based generative text-to-text model; Mention identification; Scheduled sampling; Contrastive learning",
    "application": "Clinical event extraction – medical NLP",
    "code_link": "https://derek.ma/DICE",
    "dataset_name": [
      "MACCROBAT-EE",
      "ACE05"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0366",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Tracking Life’s Ups and Downs: Mining Life Events from Social Media Posts for Mental Health Analysis",
    "authors": [
      "Minghao Lv",
      "Siyuan Chen",
      "Haoan Jin",
      "Minghao Yuan",
      "Qianqian Ju",
      "Yujia Peng",
      "Kenny Q. Zhu",
      "Mengyue Wu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Social media platforms possess considerable potential in the realm of exploring mental health. Previous research has indicated that major life events can greatly impact individuals’ mental health. However, due to the complexity and ambiguity nature of life events, shedding its light on social media data is quite challenging. In this paper, we are dedicated to uncovering life events mentioned in posts on social media. We hereby provide a carefully-annotated social media event dataset, PsyEvent, which encompasses 12 major life event categories that are likely to occur in everyday life. This dataset is human-annotated under iterative procedure and boasts a high level of quality. Furthermore, by applying the life events extracted from posts to downstream tasks such as early risk detection of depression and suicide risk prediction, we have observed a considerable improvement in performance. This suggests that extracting life events from social media can be beneficial for the analysis of individuals’ mental health.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.345.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title of the paper, \"Tracking Life’s Ups and Downs: Mining Life Events from Social Media Posts for Mental Health Analysis,\" suggests relevance to Healthcare AI, as it focuses on analyzing life events for mental health purposes. The phrase \"Mental Health Analysis\" directly indicates a healthcare-related application. Mental health is a significant domain within healthcare, and utilizing social media posts for such analysis implies an AI-driven approach to understanding or monitoring mental health outcomes, which aligns with Healthcare AI objectives. While the abstract and keywords are unavailable, the explicit mention of \"mental health\" is sufficient to infer relevance to this domain.",
    "prompt_tokens": 22521,
    "completion_tokens": 226,
    "total_tokens": 22747,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (RoBERTa, BERT, Qwen2-7B)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-Life event-based contextual explanations"
    },
    "method": "Transformer-based models (RoBERTa, BERT, Qwen2-7B); Life event detection; Semantic embedding",
    "application": "Depression risk detection; Suicide risk prediction",
    "code_link": "N/A",
    "dataset_name": [
      "ERD dataset",
      "Suicide Risk Prediction dataset",
      "PsyEvent dataset"
    ],
    "is_public": false
  },
  {
    "id": "acl2025_temp_1078",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Structural Reasoning Improves Molecular Understanding of LLM",
    "authors": [
      "Yunhui Jang",
      "Jaehyung Kim",
      "Sungsoo Ahn"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Recently, large language models (LLMs) have shown significant progress, approaching human perception levels. In this work, we demonstrate that despite these advances, LLMs still struggle to reason using molecular structural information. This gap is critical because many molecular properties, including functional groups, depend heavily on such structural details. To address this limitation, we propose an approach that sketches molecular structures for reasoning. Specifically, we introduce Molecular Structural Reasoning (MSR) framework to enhance the understanding of LLMs by explicitly incorporating the key structural features. We present two frameworks for scenarios where the target molecule is known or unknown. We verify that our MSR improves molecular understanding through extensive experiments.",
    "keywords": "N/A",
    "pdf_url": "https://arxiv.org/pdf/2410.05610",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title \"Structural Reasoning Improves Molecular Understanding of LLM\" suggests the paper involves molecular understanding, which is a core aspect of biomedicine. While there is no abstract or keywords provided to clarify further, the term \"molecular understanding\" implies relevance to biomedical research, likely in the context of analyzing molecular structures (e.g., proteins, RNA, or other biological entities). This aligns with applications such as drug discovery, protein design, or other tasks fundamental to Biomedicine AI. Without explicit details, the inference is based on the specific focus on molecular-level reasoning.",
    "prompt_tokens": 22426,
    "completion_tokens": 209,
    "total_tokens": 22635,
    "Topic Axis I": {
      "MainTopic": "Drug Discovery & Development",
      "SubTopic": "De Novo Molecule Design"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Diffusion Models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Molecular Structural Reasoning (MSR)",
    "application": "Molecular representation inference and generation",
    "code_link": "https://github.com/yunhuijang/MSR",
    "dataset_name": [
      "ChEBI-20",
      "L+M"
    ],
    "is_public": true
  },
  {
    "id": "2020.acl-main.286",
    "year": 2020,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Towards Interpretable Clinical Diagnosis with Bayesian Network Ensembles Stacked on Entity-Aware CNNs",
    "authors": [
      "Jun Chen",
      "Xiaoya Dai",
      "Quan Yuan",
      "Chao Lu",
      "Haifeng Huang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The automatic text-based diagnosis remains a challenging task for clinical use because it requires appropriate balance between accuracy and interpretability. In this paper, we attempt to propose a solution by introducing a novel framework that stacks Bayesian Network Ensembles on top of Entity-Aware Convolutional Neural Networks (CNN) towards building an accurate yet interpretable diagnosis system. The proposed framework takes advantage of the high accuracy and generality of deep neural networks as well as the interpretability of Bayesian Networks, which is critical for AI-empowered healthcare. The evaluation conducted on the real Electronic Medical Record (EMR) documents from hospitals and annotated by professional doctors proves that, the proposed framework outperforms the previous automatic diagnosis methods in accuracy performance and the diagnosis explanation of the framework is reasonable.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2020.acl-main.286.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly addresses the challenging task of “automatic text-based diagnosis,” which is a medical application relevant to Healthcare AI. It proposes a framework combining Bayesian Network Ensembles and Entity-Aware CNNs to enhance both accuracy and interpretability in clinical diagnosis tasks, a core aspect of AI in healthcare. The use of \"real Electronic Medical Record (EMR) documents\" and the annotation by professional doctors further affirms that this work directly applies to a clinical, health-oriented domain. Thus, the paper falls under the Healthcare AI domain based on its focus on improving clinical diagnosis.",
    "prompt_tokens": 22262,
    "completion_tokens": 302,
    "total_tokens": 22564,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Inherently Interpretable Models"
    },
    "method": "Entity-aware Convolutional Neural Networks (ECNN); Bayesian Network Ensembles",
    "application": "Disease classification – EMR documents",
    "code_link": "https://github.com/PaddlePaddle/Research/tree/master/KG/ACL2020_SignOrSymptom_Relationship",
    "dataset_name": [
      "Gynaecology EMR dataset",
      "Respiration EMR dataset"
    ],
    "is_public": true
  },
  {
    "id": "2022.acl-long.210",
    "year": 2022,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "KenMeSH: Knowledge-enhanced End-to-end Biomedical Text Labelling",
    "authors": [
      "Xindi Wang",
      "Robert Mercer",
      "Frank Rudzicz"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Currently, Medical Subject Headings (MeSH) are manually assigned to every biomedical article published and subsequently recorded in the PubMed database to facilitate retrieving relevant information. With the rapid growth of the PubMed database, large-scale biomedical document indexing becomes increasingly important. MeSH indexing is a challenging task for machine learning, as it needs to assign multiple labels to each article from an extremely large hierachically organized collection. To address this challenge, we propose KenMeSH, an end-to-end model that combines new text features and a dynamic knowledge-enhanced mask attention that integrates document features with MeSH label hierarchy and journal correlation features to index MeSH terms. Experimental results show the proposed method achieves state-of-the-art performance on a number of measures.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2022.acl-long.210.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly discusses the use of AI for Medical Subject Headings (MeSH) indexing, a task central to biomedical research and literature organization. MeSH terms are used to classify and retrieve biomedical articles in PubMed, which is a database foundational to biomedical sciences. The abstract also mentions the integration of document features with MeSH label hierarchy and journal correlation, both of which are highly relevant to biomedicine. Furthermore, the model aims to facilitate large-scale biomedical document indexing—a clear application in Biomedicine AI. The focus on biomedical text labeling reinforces the direct connection to biomedicine and healthcare.",
    "prompt_tokens": 22480,
    "completion_tokens": 227,
    "total_tokens": 22707,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "new-Multi-label text classification"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Graph Convolutional Neural Networks (GCN); Knowledge-enhanced mask attention; Bidirectional Long Short-Term Memory (biLSTM)",
    "application": "MeSH indexing – Biomedical literature annotations",
    "code_link": "https://github.com/xdwang0726/KenMeSH",
    "dataset_name": [
      "PMC Open Access Subset",
      "MEDLINE Collection"
    ],
    "is_public": true
  },
  {
    "id": "2020.acl-main.723",
    "year": 2020,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "A Prioritization Model for Suicidality Risk Assessment",
    "authors": [
      "Han-Chin Shing",
      "Philip Resnik",
      "Douglas Oard"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We reframe suicide risk assessment from social media as a ranking problem whose goal is maximizing detection of severely at-risk individuals given the time available. Building on measures developed for resource-bounded document retrieval, we introduce a well founded evaluation paradigm, and demonstrate using an expert-annotated test collection that meaningful improvements over plausible cascade model baselines can be achieved using an approach that jointly ranks individuals and their social media posts.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2020.acl-main.723.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses a prioritization model for assessing suicidality risk, which is a critical healthcare and clinical concern. Suicide risk assessment directly pertains to healthcare as it involves efforts to mitigate mental health crises, often requiring intervention from healthcare professionals. The abstract suggests the model leverages social media data to detect severely at-risk individuals, which aligns with applications in healthcare AI for mental health monitoring and intervention. The emphasis on maximizing detection of at-risk individuals indicates a focus on improving health outcomes. Although explicit healthcare-related keywords are missing, the context provided strongly points to relevance in the healthcare domain.",
    "prompt_tokens": -1,
    "completion_tokens": -1,
    "total_tokens": -1,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Hierarchical Attention Networks (HAN)"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "Clinician-in-the-loop Systems"
    },
    "method": "Hierarchical Attention Network (3HAN); Hierarchical Time-Biased Gain (hTBG) evaluation metric; Logistic Regression baseline",
    "application": "Suicidality risk prioritization – Social media posts",
    "code_link": "https://github.com/sidenver/hTBG",
    "dataset_name": [
      "University of Maryland Reddit Suicidality Dataset v2",
      "CROWDSOURCE",
      "EXPERT",
      "WEAK SUPERVISION"
    ],
    "is_public": true
  },
  {
    "id": "2024.acl-long.134",
    "year": 2024,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "VerifiNER: Verification-augmented NER via Knowledge-grounded Reasoning with Large Language Models",
    "authors": [
      "Seoyeon Kim",
      "Kwangwook Seo",
      "Hyungjoo Chae",
      "Jinyoung Yeo",
      "Dongha Lee"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Recent approaches in domain-specific named entity recognition (NER), such as biomedical NER, have shown remarkable advances. However, they still lack of faithfulness, producing erroneous predictions. We assume that knowledge of entities can be useful in verifying the correctness of the predictions. Despite the usefulness of knowledge, resolving such errors with knowledge is nontrivial, since the knowledge itself does not directly indicate the ground-truth label. To this end, we propose VerifiNER, a post-hoc verification framework that identifies errors from existing NER methods using knowledge and revises them into more faithful predictions. Our framework leverages the reasoning abilities of large language models to adequately ground on knowledge and the contextual information in the verification process. We validate effectiveness of VerifiNER through extensive experiments on biomedical datasets. The results suggest that VerifiNER can successfully verify errors from existing models as a model-agnostic approach. Further analyses on out-of-domain and low-resource settings show the usefulness of VerifiNER on real-world applications.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2024.acl-long.134.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper specifically discusses domain-specific named entity recognition (NER) in the biomedical field, as mentioned in the abstract. It references \"biomedical NER\" and evaluates its effectiveness on biomedical datasets, which strongly ties the work to applications in Biomedicine AI. Additionally, the mention of \"out-of-domain and low-resource settings\" suggests practical applications in real-world biomedical contexts. These factors indicate the paper's relevance to Biomedicine AI.",
    "prompt_tokens": 22426,
    "completion_tokens": 189,
    "total_tokens": 22615,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Knowledge-grounded reasoning",
    "application": "Named entity recognition – biomedical domain",
    "code_link": "https://github.com/emseoyk/VerifiNER",
    "dataset_name": [
      "GENIA",
      "BC5CDR"
    ],
    "is_public": true
  },
  {
    "id": "2023.acl-long.853",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "DisorBERT: A Double Domain Adaptation Model for Detecting Signs of Mental Disorders in Social Media",
    "authors": [
      "Mario Ezra Aragón",
      "A. Pastor López-Monroy",
      "Luis C. González",
      "David E. Losada",
      "Manuel Montes-y-Gómez"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Mental disorders affect millions of people worldwide and cause interference with their thinking and behavior. Through the past years, awareness created by health campaigns and other sources motivated the study of these disorders using information extracted from social media platforms. In this work, we aim to contribute to the study of these disorders and to the understanding of how mental problems reflect on social media. To achieve this goal, we propose a double-domain adaptation of a language model. First, we adapted the model to social media language, and then, we adapted it to the mental health domain. In both steps, we incorporated a lexical resource to guide the masking process of the language model and, therefore, to help it in paying more attention to words related to mental disorders. We have evaluated our model in the detection of signs of three major mental disorders: Anorexia, Self-harm, and Depression. Results are encouraging as they show that the proposed adaptation enhances the classification performance and yields competitive results against state-of-the-art methods.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.853.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly focuses on detecting signs of mental disorders (Anorexia, Self-harm, and Depression) using a language model adapted to social media and the mental health domain. Mental disorders are healthcare-related conditions, and their detection contributes to the broader field of Healthcare AI. The mention of \"mental health domain\" and \"understanding how mental problems reflect on social media\" indicates relevance to healthcare applications, particularly in mental health assessment and diagnostics. Therefore, the study aligns with the Healthcare AI domain as it aims to improve mental health outcomes through computational methods.",
    "prompt_tokens": 22148,
    "completion_tokens": 211,
    "total_tokens": 22359,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Disentangled Representation Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Transformer-based models (BERT); Lexicon-enhanced masking",
    "application": "Risk prediction – Social media mental health tasks",
    "code_link": "N/A",
    "dataset_name": [
      "Reddit corpus (Kim et al., 2019)",
      "Mental health datasets from subreddits",
      "eRisk collections"
    ],
    "is_public": false
  },
  {
    "id": "2021.acl-long.387",
    "year": 2021,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Writing by Memorizing: Hierarchical Retrieval-based Medical Report Generation",
    "authors": [
      "Xingyi Yang",
      "Muchao Ye",
      "Quanzeng You",
      "Fenglong Ma"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Medical report generation is one of the most challenging tasks in medical image analysis. Although existing approaches have achieved promising results, they either require a predefined template database in order to retrieve sentences or ignore the hierarchical nature of medical report generation. To address these issues, we propose MedWriter that incorporates a novel hierarchical retrieval mechanism to automatically extract both report and sentence-level templates for clinically accurate report generation. MedWriter first employs the Visual-Language Retrieval (VLR) module to retrieve the most relevant reports for the given images. To guarantee the logical coherence between generated sentences, the Language-Language Retrieval (LLR) module is introduced to retrieve relevant sentences based on the previous generated description. At last, a language decoder fuses image features and features from retrieved reports and sentences to generate meaningful medical reports. We verified the effectiveness of our model by automatic evaluation and human evaluation on two datasets, i.e., Open-I and MIMIC-CXR.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2021.acl-long.387.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly addresses medical report generation, which is a task inherently tied to Healthcare AI and Biomedicine AI. Terms such as \"medical report generation,\" \"medical image analysis,\" \"clinically accurate report generation,\" and the datasets Open-I and MIMIC-CXR (both widely used in healthcare-related AI research) strongly indicate relevance to the Healthcare AI domain. The hierarchical retrieval mechanism is applied specifically to improve the clinical accuracy and coherence of medical reports, further emphasizing its focus on healthcare and biomedical applications.",
    "prompt_tokens": 22281,
    "completion_tokens": 217,
    "total_tokens": 22498,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Other Imaging Modalities"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Vision Foundation Models (VFMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Hierarchical retrieval; Hierarchical language decoding; Multi-query attention",
    "application": "Medical report generation - radiology (X-ray)",
    "code_link": "N/A",
    "dataset_name": [
      "Open-i",
      "MIMIC-CXR"
    ],
    "is_public": false
  },
  {
    "id": "2023.acl-long.305",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Clinical Note Owns its Hierarchy: Multi-Level Hypergraph Neural Networks for Patient-Level Representation Learning",
    "authors": [
      "Nayeon Kim",
      "Yinhua Piao",
      "Sun Kim"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Leveraging knowledge from electronic health records (EHRs) to predict a patient’s condition is essential to the effective delivery of appropriate care. Clinical notes of patient EHRs contain valuable information from healthcare professionals, but have been underused due to their difficult contents and complex hierarchies. Recently, hypergraph-based methods have been proposed for document classifications. Directly adopting existing hypergraph methods on clinical notes cannot sufficiently utilize the hierarchy information of the patient, which can degrade clinical semantic information by (1) frequent neutral words and (2) hierarchies with imbalanced distribution. Thus, we propose a taxonomy-aware multi-level hypergraph neural network (TM-HGNN), where multi-level hypergraphs assemble useful neutral words with rare keywords via note and taxonomy level hyperedges to retain the clinical semantic information. The constructed patient hypergraphs are fed into hierarchical message passing layers for learning more balanced multi-level knowledge at the note and taxonomy levels. We validate the effectiveness of TM-HGNN by conducting extensive experiments with MIMIC-III dataset on benchmark in-hospital-mortality prediction.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.305.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper clearly pertains to Healthcare AI as it focuses on leveraging clinical notes from electronic health records (EHRs), a cornerstone dataset in healthcare. Specifically, it aims to predict patient outcomes (in-hospital mortality) based on clinical data using a novel taxonomy-aware hypergraph neural network (TM-HGNN). The use of the MIMIC-III dataset, which is widely recognized as a healthcare dataset, and the task of improving patient-level representation learning, strongly anchors this research in the Healthcare AI domain. Concepts like \"clinical notes,\" \"patient EHRs,\" and \"in-hospital-mortality prediction\" are explicit references to clinical and healthcare-specific contexts.",
    "prompt_tokens": 22600,
    "completion_tokens": 245,
    "total_tokens": 22845,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Graph Representation Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-Taxonomy-level semantic information for patient representation learning"
    },
    "method": "Taxonomy-aware Multi-level Hypergraph Neural Networks (TM-HGNN); Hierarchical Message Passing; Multi-level hypergraph construction; Graph Representation Learning",
    "application": "In-hospital mortality prediction – ICU",
    "code_link": "https://github.com/ny1031/TM-HGNN",
    "dataset_name": [
      "MIMIC-III"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_1319",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Delta-KNN: Improving Demonstration Selection in In-Context Learning for Alzheimer’s Disease Detection",
    "authors": [
      "Chuyuan Li",
      "Raymond Li",
      "Thalia S. Field",
      "Giuseppe Carenini"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Alzheimer’s Disease (AD) is a progressive neurodegenerative disorder that leads to dementia, and early intervention can greatly benefit from analyzing linguistic abnormalities. In this work, we explore the potential of Large Language Models as health assistants for AD diagnosis from patient-generated text using in-context learning (ICL), where tasks are defined through a few input-output examples. Empirical results reveal that conventional ICL methods, such as similarity-based selection, perform poorly for AD diagnosis, likely due to the inherent complexity of this task. To address this, we introduce Delta-KNN, a novel demonstration selection strategy that enhances ICL performance. Our method leverages a delta score to assess the relative gains of each training example, coupled with a KNN-based retriever that dynamically selects optimal “representatives” for a given input.Experiments on two AD detection datasets across three models demonstrate that Delta-KNN consistently outperforms existing ICL baselines. Notably, when using the Llama-3.1 model, our approach achieves new state-of-the-art results, surpassing even supervised classifiers.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.1253.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title explicitly mentions Alzheimer’s Disease detection, which is a healthcare and biomedical application focused on diagnosing a neurodegenerative condition. Alzheimer's detection is a widely researched topic in Healthcare AI, involving tasks like disease diagnosis, clinical decision support, or analyzing biomarkers. Additionally, the mention of “demonstration selection in in-context learning” suggests the use of advanced AI techniques tailored for this medical application. Hence, the paper falls within the Healthcare AI/Biomedicine AI domain.",
    "prompt_tokens": 21844,
    "completion_tokens": 219,
    "total_tokens": 22063,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "new-In-context Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Delta-KNN; In-context Learning strategies; embedding-based retrievers",
    "application": "Alzheimer's Disease detection using Cookie Theft picture descriptions",
    "code_link": "https://github.com/chuyuanli/Delta-KNN/",
    "dataset_name": [
      "ADReSS",
      "Canary"
    ],
    "is_public": true
  },
  {
    "id": "2020.acl-main.520",
    "year": 2020,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "An Effective Transition-based Model for Discontinuous NER",
    "authors": [
      "Xiang Dai",
      "Sarvnaz Karimi",
      "Ben Hachey",
      "Cecile Paris"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Unlike widely used Named Entity Recognition (NER) data sets in generic domains, biomedical NER data sets often contain mentions consisting of discontinuous spans. Conventional sequence tagging techniques encode Markov assumptions that are efficient but preclude recovery of these mentions. We propose a simple, effective transition-based model with generic neural encoding for discontinuous NER. Through extensive experiments on three biomedical data sets, we show that our model can effectively recognize discontinuous mentions without sacrificing the accuracy on continuous mentions.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2020.acl-main.520.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on Named Entity Recognition (NER) methods specifically applied to biomedical datasets, which frequently contain discontinuous spans. The term \"biomedical NER datasets\" and references to mentions within these datasets clearly indicate a focus on processing structured biomedical data, which is an essential task in the Biomedicine AI domain. NER in this context is often used to extract clinically relevant information such as drug mentions, biomarkers, or disease entities, making it directly relevant to Biomedicine AI. The use of domain-specific datasets reinforces the connection to biomedical applications.",
    "prompt_tokens": 22466,
    "completion_tokens": 228,
    "total_tokens": 22694,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Transition-based models; attention mechanism",
    "application": "Named entity recognition (NER) – biomedical domain",
    "code_link": "https://github.com/daixiangau/acl2020-transition-discontinuous-ner",
    "dataset_name": [
      "CADEC",
      "ShARe 13",
      "ShARe 14"
    ],
    "is_public": true
  },
  {
    "id": "2021.acl-long.219",
    "year": 2021,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "A Neural Transition-based Joint Model for Disease Named Entity Recognition and Normalization",
    "authors": [
      "Zongcheng Ji",
      "Tian Xia",
      "Mei Han",
      "Jing Xiao"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Disease is one of the fundamental entities in biomedical research. Recognizing such entities from biomedical text and then normalizing them to a standardized disease vocabulary offer a tremendous opportunity for many downstream applications. Previous studies have demonstrated that joint modeling of the two sub-tasks has superior performance than the pipelined counterpart. Although the neural joint model based on multi-task learning framework has achieved state-of-the-art performance, it suffers from the boundary inconsistency problem due to the separate decoding procedures. Moreover, it ignores the rich information (e.g., the text surface form) of each candidate concept in the vocabulary, which is quite essential for entity normalization. In this work, we propose a neural transition-based joint model to alleviate these two issues. We transform the end-to-end disease recognition and normalization task as an action sequence prediction task, which not only jointly learns the model with shared representations of the input, but also jointly searches the output by state transitions in one search space. Moreover, we introduce attention mechanisms to take advantage of the text surface form of each candidate concept for better normalization performance. Experimental results conducted on two publicly available datasets show the effectiveness of the proposed method.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2021.acl-long.219.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper primarily focuses on disease named entity recognition and normalization, which are fundamental tasks in biomedical text processing. The abstract explicitly mentions \"disease,\" \"biomedical research,\" and \"standardized disease vocabulary,\" indicating direct relevance to biomedicine. Furthermore, the proposed method addresses \"end-to-end disease recognition and normalization,\" which is a task strongly relevant to both biomedical and healthcare AI applications. The paper also mentions leveraging text surface forms of disease concepts, highlighting its focus on improving disease-related analysis in a biomedical context.",
    "prompt_tokens": 22307,
    "completion_tokens": 219,
    "total_tokens": 22526,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Inherently Interpretable Models"
    },
    "method": "Neural Transition-Based Joint Model; Attention Mechanisms; Beam Search Optimization",
    "application": "Disease named entity recognition and normalization – Biomedical text",
    "code_link": "N/A",
    "dataset_name": [
      "NCBI disease corpus",
      "BioCreative V CDR task corpus"
    ],
    "is_public": false
  },
  {
    "id": "acl2025_temp_0615",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "HyKGE: A Hypothesis Knowledge Graph Enhanced RAG Framework for Accurate and Reliable Medical LLMs Responses",
    "authors": [
      "Xinke Jiang",
      "Ruizhe Zhang",
      "Yongxin Xu",
      "Rihong Qiu",
      "Yue Fang",
      "Zhiyuan Wang",
      "Jinyi Tang",
      "Hongxin Ding",
      "Xu Chu",
      "Junfeng Zhao",
      "Yasha Wang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In this paper, we investigate the retrieval-augmented generation (RAG) based on Knowledge Graphs (KGs) to improve the accuracy and reliability of Large Language Models (LLMs). Recent approaches suffer from insufficient and repetitive knowledge retrieval, tedious and time-consuming query parsing, and monotonous knowledge utilization. To this end, we develop a Hypothesis Knowledge Graph Enhanced (HyKGE) framework, which leverages LLMs' powerful reasoning capacity to compensate for the incompleteness of user queries, optimizes the interaction process with LLMs, and provides diverse retrieved knowledge. Specifically, HyKGE explores the zero-shot capability and the rich knowledge of LLMs with Hypothesis Outputs to extend feasible exploration directions in the KGs, as well as the carefully curated prompt to enhance the density and efficiency of LLMs' responses. Furthermore, we introduce the HO Fragment Granularity-aware Rerank Module to filter out noise while ensuring the balance between diversity and relevance in retrieved knowledge. Experiments on two Chinese medical multiple-choice question datasets and one Chinese open-domain medical Q&A dataset with two LLM turbos demonstrate the superiority of HyKGE in terms of accuracy and explainability.",
    "keywords": "N/A",
    "pdf_url": "https://arxiv.org/pdf/2312.15883",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title, \"HyKGE: A Hypothesis Knowledge Graph Enhanced RAG Framework for Accurate and Reliable Medical LLMs Responses,\" explicitly mentions \"medical LLMs responses,\" which indicates a focus on clinical or healthcare-related tasks. The inclusion of phrases like \"medical\" signifies the application of AI to a health context, likely involving tasks such as providing accurate medical information or decision support. The use of a \"Hypothesis Knowledge Graph\" further suggests the framework is designed to enhance reasoning or understanding within a biomedical or clinical domain. Therefore, it falls within the Healthcare AI / Biomedicine AI domain.",
    "prompt_tokens": 41091,
    "completion_tokens": 286,
    "total_tokens": 41377,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs): Foundation models for clinical text, dialogue, and biomedical literature"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Retrieval-augmented generation (RAG); Zero-shot reasoning capabilities; Hypothesis knowledge graph-enhanced extraction",
    "application": "medical question answering tasks",
    "code_link": "N/A",
    "dataset_name": [
      "CMB-Exam",
      "CMB-Clin"
    ],
    "is_public": false
  },
  {
    "id": "2023.acl-long.739",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Continual Contrastive Finetuning Improves Low-Resource Relation Extraction",
    "authors": [
      "Wenxuan Zhou",
      "Sheng Zhang",
      "Tristan Naumann",
      "Muhao Chen",
      "Hoifung Poon"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Relation extraction (RE), which has relied on structurally annotated corpora for model training, has been particularly challenging in low-resource scenarios and domains. Recent literature has tackled low-resource RE by self-supervised learning, where the solution involves pretraining the entity pair embedding by RE-based objective and finetuning on labeled data by classification-based objective. However, a critical challenge to this approach is the gap in objectives, which prevents the RE model from fully utilizing the knowledge in pretrained representations. In this paper, we aim at bridging the gap and propose to pretrain and finetune the RE model using consistent objectives of contrastive learning. Since in this kind of representation learning paradigm, one relation may easily form multiple clusters in the representation space, we further propose a multi-center contrastive loss that allows one relation to form multiple clusters to better align with pretraining. Experiments on two document-level RE datasets, BioRED and Re-DocRED, demonstrate the effectiveness of our method. Particularly, when using 1% end-task training data, our method outperforms PLM-based RE classifier by 10.5% and 6.1% on the two datasets, respectively.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.739.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper is focused on improving relation extraction techniques on datasets such as BioRED, which is explicitly related to biomedical research, and Re-DocRED, a dataset likely containing information relevant to domains like medicine. The mention of \"document-level RE datasets\" with terms specifically tied to biomedical applications (e.g., \"BioRED\") indicates a focus on extracting relations that could potentially be used for improving biomedical knowledge extraction or healthcare applications. While the core methodological contribution involves contrastive learning, its application to biomedical datasets justifies its relevance to Biomedicine AI.",
    "prompt_tokens": 22328,
    "completion_tokens": 219,
    "total_tokens": 22547,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Inherently Interpretable Models"
    },
    "method": "Multi-center contrastive loss (MCCL); kNN-based inference; continual contrastive finetuning",
    "application": "Relation extraction – Biomedical domain",
    "code_link": "N/A",
    "dataset_name": [
      "BioRED",
      "Re-DocRED",
      "PubTator Central"
    ],
    "is_public": false
  },
  {
    "id": "2022.acl-long.175",
    "year": 2022,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Generating Scientific Claims for Zero-Shot Scientific Fact Checking",
    "authors": [
      "Dustin Wright",
      "David Wadden",
      "Kyle Lo",
      "Bailey Kuehl",
      "Arman Cohan",
      "Isabelle Augenstein",
      "Lucy Lu Wang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Automated scientific fact checking is difficult due to the complexity of scientific language and a lack of significant amounts of training data, as annotation requires domain expertise. To address this challenge, we propose scientific claim generation, the task of generating one or more atomic and verifiable claims from scientific sentences, and demonstrate its usefulness in zero-shot fact checking for biomedical claims. We propose CLAIMGEN-BART, a new supervised method for generating claims supported by the literature, as well as KBIN, a novel method for generating claim negations. Additionally, we adapt an existing unsupervised entity-centric method of claim generation to biomedical claims, which we call CLAIMGEN-ENTITY. Experiments on zero-shot fact checking demonstrate that both CLAIMGEN-ENTITY and CLAIMGEN-BART, coupled with KBIN, achieve up to 90% performance of fully supervised models trained on manually annotated claims and evidence. A rigorous evaluation study demonstrates significant improvement in generated claim and negation quality over existing baselines",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2022.acl-long.175.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly focuses on \"zero-shot fact checking for biomedical claims,\" indicating a clear application to the Biomedicine AI domain. The methods proposed (CLAIMGEN-BART and CLAIMGEN-ENTITY) are tailored to process scientific claims related to biomedicine, as evidenced by the mention of \"biomedical claims\" and \"literature-supported claims.\" Additionally, the task of scientific claim generation and negation directly ties into biomedical research, which often involves verifying the validity of scientific claims and evidence in medical or biological contexts. Although healthcare applications are not directly mentioned, the focus on biomedical language and fact-checking strongly aligns this work with Biomedicine AI.",
    "prompt_tokens": 22233,
    "completion_tokens": 243,
    "total_tokens": 22476,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Scientific claim generation; Knowledge Base Informed Negations (KBIN); Text infilling with BART; Named entity recognition (NER); Zero-shot scientific fact-checking",
    "application": "Scientific claim generation – biomedical domain",
    "code_link": "https://github.com/allenai/scientific-claim-generation",
    "dataset_name": [
      "SciFact",
      "MedMentions"
    ],
    "is_public": true
  },
  {
    "id": "2023.acl-long.881",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Human-in-the-loop Evaluation for Early Misinformation Detection: A Case Study of COVID-19 Treatments",
    "authors": [
      "Ethan Mendes",
      "Yang Chen",
      "Wei Xu",
      "Alan Ritter"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We present a human-in-the-loop evaluation framework for fact-checking novel misinformation claims and identifying social media messages that support them. Our approach extracts check-worthy claims, which are aggregated and ranked for review. Stance classifiers are then used to identify tweets supporting novel misinformation claims, which are further reviewed to determine whether they violate relevant policies. To demonstrate the feasibility of our approach, we develop a baseline system based on modern NLP methods for human-in-the-loop fact-checking in the domain of COVID-19 treatments. We make our data and detailed annotation guidelines available to support the evaluation of human-in-the-loop systems that identify novel misinformation directly from raw user-generated content.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.881.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper involves the development of a human-in-the-loop fact-checking framework specifically applied to misinformation about COVID-19 treatments, which are inherently health-related topics. Phrases such as \"COVID-19 treatments,\" \"novel misinformation claims,\" and the identification of misinformation directly from social media content suggest a focus on health and biomedicine, particularly in the context of public health communication and disease management. Although the methods are grounded in NLP, their application directly pertains to healthcare by targeting misinformation about medical treatments, making it relevant to the Healthcare AI domain.",
    "prompt_tokens": 22402,
    "completion_tokens": 232,
    "total_tokens": 22634,
    "Topic Axis I": {
      "MainTopic": "Population Health & Computational Epidemiology",
      "SubTopic": "Public Health Surveillance"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (RoBERTa, T5, CT-BERT)"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "Human-AI Collaborative Performance"
    },
    "method": "Claim Extraction; Question-Answering Models; Stance Classification; Human-in-the-loop evaluations",
    "application": "COVID-19 misinformation detection",
    "code_link": "N/A",
    "dataset_name": [
      "Twitter COVID-19 Event Extraction dataset",
      "W-NUT 2020 COVID-19 event extraction shared task"
    ],
    "is_public": false
  },
  {
    "id": "acl2025_temp_0572",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Knowledge-Augmented Multimodal Clinical Rationale Generation for Disease Diagnosis with Small Language Models",
    "authors": [
      "Shuai Niu",
      "Jing Ma",
      "Hongzhan Lin",
      "Liang Bai",
      "Zhihua Wang",
      "Richard Yi Da Xu",
      "Yunya Song",
      "Xian Yang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Interpretation is critical for disease diagnosis, but existing models struggle to balance predictive accuracy with human-understandable rationales. While large language models (LLMs) offer strong reasoning abilities, their clinical use is limited by high computational costs and restricted multimodal reasoning ability. Small language models (SLMs) are efficient but lack advanced reasoning for integrating multimodal medical data. In addition, both LLMs and SLMs lack domain knowledge for trustworthy reasoning. Therefore, we propose ClinRaGen, enhancing SLMs by leveraging LLM-derived reasoning ability via rationale distillation and domain knowledge injection for trustworthy multimodal rationale generation. Key innovations include a sequential rationale distillation framework that equips SLMs with LLM-comparable multimodal reasoning abilities, and a knowledge-augmented attention mechanism that jointly unifies multimodal representation from time series and textual data in the same encoding space, enabling it to be naturally interpreted by SLMs while incorporating domain knowledge for reliable rationale generation. Experiments on real-world medical datasets show that ClinRaGen achieves state-of-the-art performance in disease diagnosis and rationale generation, demonstrating the effectiveness of combining LLM-driven reasoning with knowledge augmentation for improved interpretability.",
    "keywords": "N/A",
    "pdf_url": "https://arxiv.org/pdf/2411.07611",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title “Knowledge-Augmented Multimodal Clinical Rationale Generation for Disease Diagnosis with Small Language Models” contains strong indicators of relevance to the Healthcare AI domain. Specifically, the phrases \"clinical rationale generation\" and \"disease diagnosis\" directly point to applications in healthcare, particularly in aiding clinical decision-making processes. The focus on \"small language models\" suggests an AI-driven approach tailored for medical or clinical tasks, further supporting its classification under Healthcare AI. While there is no abstract or keywords available, the title alone provides sufficient information to infer its healthcare relevance.",
    "prompt_tokens": 22228,
    "completion_tokens": 230,
    "total_tokens": 22458,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "EHR/EMR Predictive Modeling"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Knowledge-augmented rationale distillation; Chain-of-Thought reasoning; Retrieval-Augmented Generation",
    "application": "Disease diagnosis; clinical rationale generation",
    "code_link": "https://github.com/Healthcare-Data-Mining-Laboratory/ClinRaGen",
    "dataset_name": [
      "MIMIC-III",
      "MIMIC-IV"
    ],
    "is_public": true
  },
  {
    "id": "2021.acl-long.234",
    "year": 2021,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Competence-based Multimodal Curriculum Learning for Medical Report Generation",
    "authors": [
      "Fenglin Liu",
      "Shen Ge",
      "Xian Wu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Medical report generation task, which targets to produce long and coherent descriptions of medical images, has attracted growing research interests recently. Different from the general image captioning tasks, medical report generation is more challenging for data-driven neural models. This is mainly due to 1) the serious data bias and 2) the limited medical data. To alleviate the data bias and make best use of available data, we propose a Competence-based Multimodal Curriculum Learning framework (CMCL). Specifically, CMCL simulates the learning process of radiologists and optimizes the model in a step by step manner. Firstly, CMCL estimates the difficulty of each training instance and evaluates the competence of current model; Secondly, CMCL selects the most suitable batch of training instances considering current model competence. By iterating above two steps, CMCL can gradually improve the model’s performance. The experiments on the public IU-Xray and MIMIC-CXR datasets show that CMCL can be incorporated into existing models to improve their performance.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2021.acl-long.234.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper specifically addresses the medical report generation task for radiological images, which is a healthcare application. Terms like \"medical images,\" \"medical report generation,\" and datasets such as \"IU-Xray\" and \"MIMIC-CXR\" strongly indicate relevance to Healthcare AI, as the focus is on improving performance in tasks directly useful to radiologists and healthcare professionals. Additionally, the methodology proposed (Competence-based Multimodal Curriculum Learning) is applied within the medical imaging context, further confirming the paper's applicability to Healthcare AI.",
    "prompt_tokens": 22416,
    "completion_tokens": 219,
    "total_tokens": 22635,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Radiology"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Data-Efficient Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-CMCL explanation approach in alleviating data bias in medical report generation"
    },
    "method": "Competence-based multimodal curriculum learning; CNN-HLSTM; visual & semantic attention",
    "application": "Medical report generation – chest X-ray analysis",
    "code_link": "N/A",
    "dataset_name": [
      "MIMIC-CXR",
      "IU-Xray"
    ],
    "is_public": false
  },
  {
    "id": "2024.acl-long.324",
    "year": 2024,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "ProtT3: Protein-to-Text Generation for Text-based Protein Understanding",
    "authors": [
      "Zhiyuan Liu",
      "An Zhang",
      "Hao Fei",
      "Enzhi Zhang",
      "Xiang Wang",
      "Kenji Kawaguchi",
      "Tat-Seng Chua"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Language Models (LMs) excel in understanding textual descriptions of proteins, as evident in biomedical question-answering tasks. However, their capability falters with raw protein data, such as amino acid sequences, due to a deficit in pretraining on such data. Conversely, Protein Language Models (PLMs) can understand and convert protein data into high-quality representations, but struggle to process texts. To address their limitations, we introduce ProtT3, a framework for Protein-to-Text Generation for Text-based Protein Understanding. ProtT3 empowers an LM to understand protein sequences of amino acids by incorporating a PLM as its protein understanding module, enabling effective protein-to-text generation. This collaboration between PLM and LM is facilitated by a cross-modal projector (i.e., Q-Former) that bridges the modality gap between the PLM’s representation space and the LM’s input space. Unlike previous studies focusing on protein property prediction and protein-text retrieval, we delve into the largely unexplored field of protein-to-text generation. To facilitate comprehensive benchmarks and promote future research, we establish quantitative evaluations for protein-text modeling tasks, including protein captioning, protein question-answering, and protein-text retrieval. Our experiments show that ProtT3 substantially surpasses current baselines, with ablation studies further highlighting the efficacy of its core components. Our code is available at https://github.com/acharkq/ProtT3.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2024.acl-long.324.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses the development of ProtT3, a framework that facilitates protein-to-text generation and improves the understanding of amino acid sequences through text-based modeling. This is directly relevant to biomedicine as it involves advancements in protein language modeling, which is crucial in contexts such as drug discovery, protein property prediction, and molecular modeling. Understanding and interpreting protein sequences accurately has significant implications for biomedical research, particularly in areas like genomics, protein design for therapeutics, and biomarker identification. Though the abstract does not explicitly mention healthcare applications, the references to protein understanding tasks (e.g., protein captioning and protein question-answering) strongly align with biomedicine AI objectives.",
    "prompt_tokens": 21779,
    "completion_tokens": 231,
    "total_tokens": 22010,
    "Topic Axis I": {
      "MainTopic": "Computational Genomics & Multi-Omics",
      "SubTopic": "Proteomics & Protein Structure"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Cross-modal projector; protein language models (PLM); Q-Former model adapter",
    "application": "Protein-to-text generation – protein annotation",
    "code_link": "https://github.com/acharkq/ProtT3",
    "dataset_name": [
      "Swiss-Prot",
      "ProteinKG25",
      "PDB-QA"
    ],
    "is_public": true
  },
  {
    "id": "2022.acl-long.572",
    "year": 2022,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "A Comparison of Strategies for Source-Free Domain Adaptation",
    "authors": [
      "Xin Su",
      "Yiyun Zhao",
      "Steven Bethard"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Data sharing restrictions are common in NLP, especially in the clinical domain, but there is limited research on adapting models to new domains without access to the original training data, a setting known as source-free domain adaptation. We take algorithms that traditionally assume access to the source-domain training data—active learning, self-training, and data augmentation—and adapt them for source free domain adaptation. Then we systematically compare these different strategies across multiple tasks and domains. We find that active learning yields consistent gains across all SemEval 2021 Task 10 tasks and domains, but though the shared task saw successful self-trained and data augmented models, our systematic comparison finds these strategies to be unreliable for source-free domain adaptation.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2022.acl-long.572.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract references \"data sharing restrictions\" in the \"clinical domain,\" which strongly indicates relevance to healthcare or biomedicine. This suggests that the source-free domain adaptation strategies have been applied or considered in contexts involving clinical data, which aligns with Healthcare AI. Additionally, the focus on domain adaptation techniques is crucial in handling sensitive health-related datasets where data sharing is restricted, further supporting its relevance to the field.",
    "prompt_tokens": 60787,
    "completion_tokens": 248,
    "total_tokens": 61035,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "new-Source-Free Domain Adaptation"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "new-Domain Performance under Shift"
    },
    "method": "Self-training; Active Learning; Data Augmentation",
    "application": "Domain adaptation for semantic processing",
    "code_link": "https://github.com/xinsu626/SourceFreeDomainAdaptation",
    "dataset_name": [
      "SHARP Seed",
      "i2b2 2010",
      "MIMIC III",
      "SemEval 2018 Task 6",
      "Food security reports"
    ],
    "is_public": true
  },
  {
    "id": "2020.acl-main.719",
    "year": 2020,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Rationalizing Medical Relation Prediction from Corpus-level Statistics",
    "authors": [
      "Zhen Wang",
      "Jennifer Lee",
      "Simon Lin",
      "Huan Sun"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Nowadays, the interpretability of machine learning models is becoming increasingly important, especially in the medical domain. Aiming to shed some light on how to rationalize medical relation prediction, we present a new interpretable framework inspired by existing theories on how human memory works, e.g., theories of recall and recognition. Given the corpus-level statistics, i.e., a global co-occurrence graph of a clinical text corpus, to predict the relations between two entities, we first recall rich contexts associated with the target entities, and then recognize relational interactions between these contexts to form model rationales, which will contribute to the final prediction. We conduct experiments on a real-world public clinical dataset and show that our framework can not only achieve competitive predictive performance against a comprehensive list of neural baseline models, but also present rationales to justify its prediction. We further collaborate with medical experts deeply to verify the usefulness of our model rationales for clinical decision making.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2020.acl-main.719.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper clearly pertains to the medical domain based on its focus on \"medical relation prediction\" and its application to a \"real-world public clinical dataset.\" The abstract describes a framework designed to improve the interpretability of predictions in a medical context by leveraging corpus-level statistics from clinical text. Additionally, the involvement of \"medical experts\" to assess the usefulness of the model's rationales for \"clinical decision making\" strongly ties the research to Healthcare AI. These factors demonstrate its direct application to healthcare and justify the classification as part of the Healthcare AI domain.",
    "prompt_tokens": 21970,
    "completion_tokens": 219,
    "total_tokens": 22189,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Graph Representation Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Graph embedding; self-attention mechanism; relational learning",
    "application": "Relation prediction – Clinical knowledge bases",
    "code_link": "https://github.com/zhenwang9102/X-MedRELA",
    "dataset_name": [
      "Medical co-occurrence graph (20 million clinical notes)"
    ],
    "is_public": true
  },
  {
    "id": "2020.acl-main.282",
    "year": 2020,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "HyperCore: Hyperbolic and Co-graph Representation for Automatic ICD Coding",
    "authors": [
      "Pengfei Cao",
      "Yubo Chen",
      "Kang Liu",
      "Jun Zhao",
      "Shengping Liu",
      "Weifeng Chong"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The International Classification of Diseases (ICD) provides a standardized way for classifying diseases, which endows each disease with a unique code. ICD coding aims to assign proper ICD codes to a medical record. Since manual coding is very laborious and prone to errors, many methods have been proposed for the automatic ICD coding task. However, most of existing methods independently predict each code, ignoring two important characteristics: Code Hierarchy and Code Co-occurrence. In this paper, we propose a Hyperbolic and Co-graph Representation method (HyperCore) to address the above problem. Specifically, we propose a hyperbolic representation method to leverage the code hierarchy. Moreover, we propose a graph convolutional network to utilize the code co-occurrence. Experimental results on two widely used datasets demonstrate that our proposed model outperforms previous state-of-the-art methods.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2020.acl-main.282.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on automatic ICD coding, where ICD refers to the International Classification of Diseases—a globally standardized system integral to healthcare. The task involves assigning disease codes to medical records, which directly pertains to clinical data analysis and healthcare management. Furthermore, the abstract mentions leveraging “medical record” data and improving methods that support this healthcare-specific process, reinforcing its classification within Healthcare AI. Both \"code hierarchy\" and \"code co-occurrence\" are discussed as important features related to disease data structure and utilization, which aligns closely with healthcare applications.",
    "prompt_tokens": 40708,
    "completion_tokens": 243,
    "total_tokens": 40951,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Graph Representation Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Hyperbolic representation learning; Graph convolutional network (GCN)",
    "application": "Medical classification - automatic ICD coding",
    "code_link": "N/A",
    "dataset_name": [
      "MIMIC-III full",
      "MIMIC-III 50",
      "MIMIC-II"
    ],
    "is_public": false
  },
  {
    "id": "2024.acl-long.708",
    "year": 2024,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "From Sights to Insights: Towards Summarization of Multimodal Clinical Documents",
    "authors": [
      "Akash Ghosh",
      "Mohit Tomar",
      "Abhisek Tiwari",
      "Sriparna Saha",
      "Jatin Salve",
      "Setu Sinha"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The advancement of Artificial Intelligence is pivotal in reshaping healthcare, enhancing diagnostic precision, and facilitating personalized treatment strategies. One major challenge for healthcare professionals is quickly navigating through long clinical documents to provide timely and effective solutions. Doctors often struggle to draw quick conclusions from these extensive documents. To address this issue and save time for healthcare professionals, an effective summarization model is essential. Most current models assume the data is only text-based. However, patients often include images of their medical conditions in clinical documents. To effectively summarize these multimodal documents, we introduce EDI-Summ, an innovative Image-Guided Encoder-Decoder Model. This model uses modality-aware contextual attention on the encoder and an image cross-attention mechanism on the decoder, enhancing the BART base model to create detailed visual-guided summaries. We have tested our model extensively on three multimodal clinical benchmarks involving multimodal question and dialogue summarization tasks. Our analysis demonstrates that EDI-Summ outperforms state-of-the-art large language and vision-aware models in these summarization tasks. Disclaimer: The work includes vivid medical illustrations, depicting the essential aspects of the subject matter.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2024.acl-long.708.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly focuses on summarizing multimodal clinical documents, which are central to the healthcare domain. It highlights the challenge faced by healthcare professionals in navigating extensive clinical documents for timely decision-making, a task directly linked to Healthcare AI. The proposed model, EDI-Summ, incorporates both text and images (e.g., medical conditions or illustrations) to generate summaries, emphasizing its application to clinical workflows, including multimodal question and dialogue summarization tasks. Further, testing on multimodal clinical benchmarks solidifies its relevance to Healthcare AI as it targets improving efficiency in clinical contexts.",
    "prompt_tokens": 22026,
    "completion_tokens": 245,
    "total_tokens": 22271,
    "Topic Axis I": {
      "MainTopic": "Healthcare Systems & Operations",
      "SubTopic": "Hospital Operations Management"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Inherently Interpretable Models"
    },
    "method": "Multimodal context-aware self-attention; Image cross-attention; Transformer-based models (BART)",
    "application": "clinical document summarization with text and image modalities",
    "code_link": "https://github.com/AkashGhosh/From-Sights-to-Insights-Towards-Summarization-of-Multimodal-Clinical-Documents",
    "dataset_name": [
      "MMQS",
      "MMCQS",
      "MM_CliConSummation"
    ],
    "is_public": true
  },
  {
    "id": "2020.acl-main.335",
    "year": 2020,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Biomedical Entity Representations with Synonym Marginalization",
    "authors": [
      "Mujeen Sung",
      "Hwisang Jeon",
      "Jinhyuk Lee",
      "Jaewoo Kang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Biomedical named entities often play important roles in many biomedical text mining tools. However, due to the incompleteness of provided synonyms and numerous variations in their surface forms, normalization of biomedical entities is very challenging. In this paper, we focus on learning representations of biomedical entities solely based on the synonyms of entities. To learn from the incomplete synonyms, we use a model-based candidate selection and maximize the marginal likelihood of the synonyms present in top candidates. Our model-based candidates are iteratively updated to contain more difficult negative samples as our model evolves. In this way, we avoid the explicit pre-selection of negative samples from more than 400K candidates. On four biomedical entity normalization datasets having three different entity types (disease, chemical, adverse reaction), our model BioSyn consistently outperforms previous state-of-the-art models almost reaching the upper bound on each dataset.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2020.acl-main.335.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly focuses on \"biomedical named entities,\" which are crucial in biomedical text mining. The abstract mentions entity normalization for biomedical categories such as \"disease, chemical, adverse reaction,\" indicating a clear application in biomedicine. Additionally, its focus on learning representations of biomedical entities aligns with key goals in Biomedicine AI, such as improving data analysis in health-related research. These factors strongly situate the paper within the Biomedicine AI domain.",
    "prompt_tokens": 22045,
    "completion_tokens": 216,
    "total_tokens": 22261,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Core Methodological Contributions",
      "SubTopic": "Data-Centric & Privacy-Enhancing AI"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Synonym Marginalization; BioBERT-based representation learning; Iterative Candidate Retrieval",
    "application": "Biomedical entity normalization",
    "code_link": "https://github.com/dmis-lab/BioSyn",
    "dataset_name": [
      "NCBI Disease Corpus",
      "BC5CDR Disease",
      "BC5CDR Chemical",
      "TAC2017ADR"
    ],
    "is_public": true
  },
  {
    "id": "2023.acl-long.896",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "DrBERT: A Robust Pre-trained Model in French for Biomedical and Clinical domains",
    "authors": [
      "Yanis Labrak",
      "Adrien Bazoge",
      "Richard Dufour",
      "Mickael Rouvier",
      "Emmanuel Morin",
      "Béatrice Daille",
      "Pierre-Antoine Gourraud"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In recent years, pre-trained language models (PLMs) achieve the best performance on a wide range of natural language processing (NLP) tasks. While the first models were trained on general domain data, specialized ones have emerged to more effectively treat specific domains. In this paper, we propose an original study of PLMs in the medical domain on French language. We compare, for the first time, the performance of PLMs trained on both public data from the web and private data from healthcare establishments. We also evaluate different learning strategies on a set of biomedical tasks. In particular, we show that we can take advantage of already existing biomedical PLMs in a foreign language by further pre-train it on our targeted data. Finally, we release the first specialized PLMs for the biomedical field in French, called DrBERT, as well as the largest corpus of medical data under free license on which these models are trained.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.896.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on pre-trained language models (PLMs) tailored to the biomedical domain in French, as indicated by phrases like \"medical domain on French language\" and \"specialized PLMs for the biomedical field.\" The abstract mentions evaluation on biomedical tasks and the use of medical data for training, which directly ties to healthcare and biomedicine applications of AI. Furthermore, the release of specialized PLMs named DrBERT specifically for the biomedical domain underscores its connection to Biomedicine AI.",
    "prompt_tokens": 42079,
    "completion_tokens": 282,
    "total_tokens": 42361,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "new-Biomedical Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Transformer-based models (RoBERTa); continual pre-training",
    "application": "Biomedical language modeling – French medical NLP tasks",
    "code_link": "https://drbert.univ-avignon.fr/",
    "dataset_name": [
      "NACHOS",
      "MUSCA-DET",
      "QUAERO French Medical Corpus",
      "FrenchMedMCQA"
    ],
    "is_public": true
  },
  {
    "id": "2021.acl-long.140",
    "year": 2021,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Named Entity Recognition with Small Strongly Labeled and Large Weakly Labeled Data",
    "authors": [
      "Haoming Jiang",
      "Danqing Zhang",
      "Tianyu Cao",
      "Bing Yin",
      "Tuo Zhao"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Weak supervision has shown promising results in many natural language processing tasks, such as Named Entity Recognition (NER). Existing work mainly focuses on learning deep NER models only with weak supervision, i.e., without any human annotation, and shows that by merely using weakly labeled data, one can achieve good performance, though still underperforms fully supervised NER with manually/strongly labeled data. In this paper, we consider a more practical scenario, where we have both a small amount of strongly labeled data and a large amount of weakly labeled data. Unfortunately, we observe that weakly labeled data does not necessarily improve, or even deteriorate the model performance (due to the extensive noise in the weak labels) when we train deep NER models over a simple or weighted combination of the strongly labeled and weakly labeled data. To address this issue, we propose a new multi-stage computational framework – NEEDLE with three essential ingredients: (1) weak label completion, (2) noise-aware loss function, and (3) final fine-tuning over the strongly labeled data. Through experiments on E-commerce query NER and Biomedical NER, we demonstrate that NEEDLE can effectively suppress the noise of the weak labels and outperforms existing methods. In particular, we achieve new SOTA F1-scores on 3 Biomedical NER datasets: BC5CDR-chem 93.74, BC5CDR-disease 90.69, NCBI-disease 92.28.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2021.acl-long.140.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly mentions its application in Biomedical Named Entity Recognition (NER), which involves identifying entities such as diseases and chemicals in biomedical texts. Furthermore, the abstract highlights results on datasets like BC5CDR-chem, BC5CDR-disease, and NCBI-disease, which are standard datasets in biomedical research for tasks related to disease and chemical entity extraction. These tasks are directly relevant to Biomedicine AI as they support applications in biomedical information extraction and research, which are essential for understanding diseases and healthcare-related data.",
    "prompt_tokens": 22189,
    "completion_tokens": 231,
    "total_tokens": 22420,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Biomedical Named Entity Recognition"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (BERT, RoBERTa, CRF)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Inherently Interpretable Models"
    },
    "method": "Transformer-based models (BERT, RoBERTa, CRF); Noise-aware loss function; Weak supervision",
    "application": "Biomedical named entity recognition",
    "code_link": "N/A",
    "dataset_name": [
      "BC5CDR-Chem",
      "BC5CDR-Disease",
      "NCBI-Disease"
    ],
    "is_public": false
  },
  {
    "id": "2020.acl-main.137",
    "year": 2020,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "In Layman’s Terms: Semi-Open Relation Extraction from Scientific Texts",
    "authors": [
      "Ruben Kruiper",
      "Julian Vincent",
      "Jessica Chen-Burger",
      "Marc Desmulliez",
      "Ioannis Konstas"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Information Extraction (IE) from scientific texts can be used to guide readers to the central information in scientific documents. But narrow IE systems extract only a fraction of the information captured, and Open IE systems do not perform well on the long and complex sentences encountered in scientific texts. In this work we combine the output of both types of systems to achieve Semi-Open Relation Extraction, a new task that we explore in the Biology domain. First, we present the Focused Open Biological Information Extraction (FOBIE) dataset and use FOBIE to train a state-of-the-art narrow scientific IE system to extract trade-off relations and arguments that are central to biology texts. We then run both the narrow IE system and a state-of-the-art Open IE system on a corpus of 10K open-access scientific biological texts. We show that a significant amount (65%) of erroneous and uninformative Open IE extractions can be filtered using narrow IE extractions. Furthermore, we show that the retained extractions are significantly more often informative to a reader.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2020.acl-main.137.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper introduces a new information extraction approach tailored to the Biology domain, as evidenced by the mention of the \"Focused Open Biological Information Extraction (FOBIE) dataset\" and efforts to extract \"trade-off relations and arguments central to biology texts.\" The focus on scientific biological texts and the specific application to biological information extraction strongly aligns with tasks in the Biomedicine AI domain. Although there is no explicit mention of healthcare applications or datasets, the narrow scope within biology suggests it supports biomedical research, making it relevant to Biomedicine AI.",
    "prompt_tokens": 40700,
    "completion_tokens": 254,
    "total_tokens": 40954,
    "Topic Axis I": {
      "MainTopic": "Computational Genomics & Multi-Omics",
      "SubTopic": "Transcriptomics"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Disentangled Representation Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Inherently Interpretable Models"
    },
    "method": "Span-based Relation Extraction",
    "application": "TRADE-OFF relation extraction in scientific biological texts",
    "code_link": "https://github.com/rubenkruiper/FOBIE",
    "dataset_name": [
      "FOBIE dataset"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0798",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "MolRAG: Unlocking the Power of Large Language Models for Molecular Property Prediction",
    "authors": [
      "Ziting Xian",
      "Jiawei Gu",
      "Lingbo Li",
      "Eran Segal",
      "Shangsong Liang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Recent LLMs exhibit limited effectiveness on molecular property prediction task due to the semantic gap between molecular representations and natural language, as well as the lack of domain-specific knowledge. To address these challenges, we propose MolRAG, a Retrieval-Augmented Generation framework integrating Chain-of-Thought reasoning for molecular property prediction. MolRAG operates by retrieving structurally analogous molecules as contextual references to guide stepwise knowledge reasoning through chemical structure-property relationships. This dual mechanism synergizes molecular similarity analysis with structured inference, while generating human-interpretable rationales grounded in domain knowledge. Experimental results show MolRAG outperforms pre-trained LLMs on four datasets, and even matches supervised methods, achieving performance gains of 1.1%–45.7% over direct prediction approaches, demonstrating versatile effectiveness. Our code is available at https://github.com/AcaciaSin/MolRAG.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.755.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title “MolRAG: Unlocking the Power of Large Language Models for Molecular Property Prediction” suggests that the paper focuses on leveraging large language models for molecular property prediction, which aligns with tasks in biomedicine AI. Molecular property prediction is often relevant to biomedical research as it can contribute to areas like drug discovery, protein design, and therapeutic development. These applications typically aim to improve healthcare outcomes or enable advancements in biomedical understanding. The absence of an abstract or keywords does not change the inference made based on the title's strong implication of biomedicine-related research.",
    "prompt_tokens": 22587,
    "completion_tokens": 274,
    "total_tokens": 22861,
    "Topic Axis I": {
      "MainTopic": "Drug Discovery & Development",
      "SubTopic": "new-Molecular Property Prediction"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Retrieval-augmented generation (RAG)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Chain-of-Thought reasoning; Morgan Fingerprint; Similarity-based reasoning; Retrieval-augmented generation",
    "application": "Molecular Property Prediction for Drug Discovery",
    "code_link": "https://github.com/AcaciaSin/MolRAG",
    "dataset_name": [
      "MoleculeNet",
      "Tox21",
      "ToxCast",
      "BBBP",
      "Lipo",
      "ESOL",
      "FreeSolv",
      "CYP450",
      "HIV",
      "MUV",
      "BACE"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0029",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "A Survey on Foundation Language Models for Single-cell Biology",
    "authors": [
      "Fan Zhang",
      "Hao Chen",
      "Zhihong Zhu",
      "Ziheng Zhang",
      "Zhenxi Lin",
      "Ziyue Qiao",
      "Yefeng Zheng",
      "Xian Wu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The recent advancements in language models have significantly catalyzed progress in computational biology. A growing body of research strives to construct unified foundation models for single-cell biology, with language models serving as the cornerstone. In this paper, we systematically review the developments in foundation language models designed specifically for single-cell biology. Our survey offers a thorough analysis of various incarnations of single-cell foundation language models, viewed through the lens of both pre-trained language models (PLMs) and large language models (LLMs). This includes an exploration of data tokenization strategies, pre-training/tuning paradigms, and downstream single-cell data analysis tasks. Additionally, we discuss the current challenges faced by these pioneering works and speculate on future research directions. Overall, this survey provides a comprehensive overview of the existing single-cell foundation language models, paving the way for future research endeavors.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.26.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title explicitly mentions \"Single-cell Biology,\" which is a domain within biomedical research. Furthermore, \"Foundation Language Models\" indicates the use of advanced machine learning techniques to address challenges in this area. Single-cell biology involves the study of individual cells, often for applications such as understanding disease mechanisms or discovering biomarkers. Thus, the paper falls squarely into the category of Biomedicine AI based on its focus on a highly relevant biomedical domain and the use of AI models to support this research area.",
    "prompt_tokens": 21923,
    "completion_tokens": 226,
    "total_tokens": 22149,
    "Topic Axis I": {
      "MainTopic": "Computational Genomics & Multi-Omics",
      "SubTopic": "Transcriptomics"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs): Foundation models for biomedical data modalities"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Transformer-based models (scGPT, scELMo)",
    "application": "Gene expression prediction – Transcriptomics",
    "code_link": "N/A",
    "dataset_name": [
      "CELL×GENE",
      "hECA-10M",
      "Human Cell Landscape",
      "COVID-19 integration dataset",
      "Immune Human dataset"
    ],
    "is_public": false
  },
  {
    "id": "acl2025_temp_0571",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "PKAG-DDI: Pairwise Knowledge-Augmented Language Model for Drug-Drug Interaction Event Text Generation",
    "authors": [
      "Ziyan Wang",
      "Zhankun Xiong",
      "Feng Huang",
      "Wen Zhang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Drug-drug interactions (DDIs) arise when multiple drugs are administered concurrently. Accurately predicting the specific mechanisms underlying DDIs (named DDI events or DDIEs) is critical for the safe clinical use of drugs. DDIEs are typically represented as textual descriptions. However, most computational methods focus more on predicting the DDIE class label over generating human-readable natural language increasing clinicians' interpretation costs. Furthermore, current methods overlook the fact that each drug assumes distinct biological functions in a DDI, which, when used as input context, can enhance the understanding of the DDIE process and benefit DDIE generation by the language model (LM). In this work, we propose a novel pairwise knowledge-augmented generative method (termed PKAG-DDI) for DDIE text generation. It consists of a pairwise knowledge selector efficiently injecting structural information between drugs bidirectionally and simultaneously to select pairwise biological functions from the knowledge set, and a pairwise knowledge integration strategy that matches and integrates the selected biological functions into the LM. Experiments on two professional datasets show that PKAG-DDI outperforms existing methods in DDIE text generation, especially in challenging inductive scenarios, indicating its practicality and generalization.",
    "keywords": "N/A",
    "pdf_url": "https://arxiv.org/pdf/2507.19011",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title \"PKAG-DDI: Pairwise Knowledge-Augmented Language Model for Drug-Drug Interaction Event Text Generation\" explicitly mentions drug-drug interaction (DDI), which is highly relevant to biomedicine and healthcare. Drug-drug interactions are a critical concern in clinical practice, pharmacology, and therapeutic decision-making. The development of a language model to generate DDI-related event texts suggests an application aimed at improving understanding and communication about pharmaceutical safety, which falls under the Biomedicine AI domain.",
    "prompt_tokens": 22038,
    "completion_tokens": 220,
    "total_tokens": 22258,
    "Topic Axis I": {
      "MainTopic": "Drug Discovery & Development",
      "SubTopic": "new-Drug-Drug Interaction Event Text Generation"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "new-Retrieval-Augmented Generation"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-Biological Function Integration with LM"
    },
    "method": "Pairwise Knowledge-Augmented Generative Model; Pairwise Knowledge Selector; Pairwise Knowledge Integration",
    "application": "Drug-drug interaction event text generation",
    "code_link": "https://github.com/wzy-Sarah/PKAG-DDI",
    "dataset_name": [
      "MecDDI",
      "DDInter2.0"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0674",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Improving Medical Large Vision-Language Models with Abnormal-Aware Feedback",
    "authors": [
      "Yucheng Zhou",
      "Lingran Song",
      "Jianbing Shen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Existing Medical Large Vision-Language Models (Med-LVLMs), encapsulating extensive medical knowledge, demonstrate excellent capabilities in understanding medical images. However, there remain challenges in visual localization in medical images, which is crucial for abnormality detection and interpretation. To address these issues, we propose a novel UMed-LVLM designed to unveil medical abnormalities. Specifically, we collect a Medical Abnormalities Unveiling (MAU) dataset and propose a two-stage training method for UMed-LVLM training. To collect MAU dataset, we propose a prompt method utilizing the GPT-4V to generate diagnoses based on identified abnormal areas in medical images. Moreover, the two-stage training method includes Abnormal-Aware Instruction Tuning and Abnormal-Aware Rewarding, comprising Relevance Reward, Abnormal Localization Reward and Vision Relevance Reward. Experimental results demonstrate that our UMed-LVLM significantly outperforms existing Med-LVLMs in identifying and understanding medical abnormalities, achieving a 58% improvement over the baseline. In addition, this work shows that enhancing the abnormality detection capabilities of Med-LVLMs significantly improves their understanding of medical images and generalization capability. Our code and data release at URL.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.636.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title \"Improving Medical Large Vision-Language Models with Abnormal-Aware Feedback\" explicitly mentions the development of vision-language models for medical applications. The term \"Medical\" in the context of AI models suggests a direct focus on healthcare or clinical-related tasks, likely involving the analysis of medical images or data for abnormality detection, which is a core aspect of Healthcare AI and Biomedicine AI. Additionally, \"Abnormal-Aware Feedback\" implies the use of AI for detecting abnormalities, likely in medical contexts such as imaging or diagnostics.",
    "prompt_tokens": 22038,
    "completion_tokens": 217,
    "total_tokens": 22255,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Other Imaging Modalities"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Vision Foundation Models (VFMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Prompt Method; Abnormal-aware instruction tuning; Abnormal-aware rewarding",
    "application": "Medical image abnormality detection and diagnosis text generation",
    "code_link": "N/A",
    "dataset_name": [
      "DeepLesion",
      "KidneyStone",
      "NIH",
      "TBX11K",
      "KVASIR"
    ],
    "is_public": false
  },
  {
    "id": "acl2025_temp_1436",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Query-driven Document-level Scientific Evidence Extraction from Biomedical Studies",
    "authors": [
      "Massimiliano Pronesti",
      "Joao H Bettencourt-Silva",
      "Paul Flanagan",
      "Alessandra Pascale",
      "Oisín Redmond",
      "Anya Belz",
      "Yufang Hou"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Extracting scientific evidence from biomedical studies for clinical research questions (e.g., Does stem cell transplantation improve quality of life in patients with medically refractory Crohn's disease compared to placebo?) is a crucial step in synthesising biomedical evidence. In this paper, we focus on the task of document-level scientific evidence extraction for clinical questions with conflicting evidence. To support this task, we create a dataset called CochraneForest, leveraging forest plots from Cochrane systematic reviews. It comprises 202 annotated forest plots, associated clinical research questions, full texts of studies, and study-specific conclusions. Building on CochraneForest, we propose URCA (Uniform Retrieval Clustered Augmentation), a retrieval-augmented generation framework designed to tackle the unique challenges of evidence extraction. Our experiments show that URCA outperforms the best existing methods by up to 10.3% in F1 score on this task. However, the results also underscore the complexity of CochraneForest, establishing it as a challenging testbed for advancing automated evidence synthesis systems.",
    "keywords": "N/A",
    "pdf_url": "https://arxiv.org/pdf/2505.06186",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title, \"Query-driven Document-level Scientific Evidence Extraction from Biomedical Studies,\" explicitly mentions \"Biomedical Studies,\" which indicates a focus on extracting evidence from research in the biomedical domain. This aligns with the Biomedicine AI category as it likely involves the application of AI techniques to analyze biomedical research data and extract relevant scientific evidence. While the abstract and keywords are not provided, the title alone strongly suggests relevance to biomedical research, justifying a \"Yes\" classification.",
    "prompt_tokens": 22119,
    "completion_tokens": 217,
    "total_tokens": 22336,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Retrieval-Augmented Generation (RAG)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Retrieval-augmented generation (RAG); Clustering-based synthesis",
    "application": "Scientific evidence extraction – clinical research questions",
    "code_link": "N/A",
    "dataset_name": [
      "COCHRANEFOREST",
      "PubMedQA",
      "MedQA-US"
    ],
    "is_public": false
  },
  {
    "id": "2023.acl-long.416",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "MDACE: MIMIC Documents Annotated with Code Evidence",
    "authors": [
      "Hua Cheng",
      "Rana Jafari",
      "April Russell",
      "Russell Klopfer",
      "Edmond Lu",
      "Benjamin Striner",
      "Matthew Gormley"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We introduce a dataset for evidence/rationale extraction on an extreme multi-label classification task over long medical documents. One such task is Computer-Assisted Coding (CAC) which has improved significantly in recent years, thanks to advances in machine learning technologies. Yet simply predicting a set of final codes for a patient encounter is insufficient as CAC systems are required to provide supporting textual evidence to justify the billing codes. A model able to produce accurate and reliable supporting evidence for each code would be a tremendous benefit. However, a human annotated code evidence corpus is extremely difficult to create because it requires specialized knowledge. In this paper, we introduce MDACE, the first publicly available code evidence dataset, which is built on a subset of the MIMIC-III clinical records. The dataset – annotated by professional medical coders – consists of 302 Inpatient charts with 3,934 evidence spans and 52 Profee charts with 5,563 evidence spans. We implemented several evidence extraction methods based on the EffectiveCAN model (Liu et al., 2021) to establish baseline performance on this dataset. MDACE can be used to evaluate code evidence extraction methods for CAC systems, as well as the accuracy and interpretability of deep learning models for multi-label classification. We believe that the release of MDACE will greatly improve the understanding and application of deep learning technologies for medical coding and document classification.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.416.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper is directly relevant to Healthcare AI as it discusses improving computer-assisted coding (CAC), a critical task in healthcare documentation and billing. The use of the MIMIC-III dataset and the references to \"clinical records,\" \"Inpatient charts,\" \"Profee charts,\" and \"medical coders\" strongly tie the research to healthcare-specific tasks. Furthermore, the objective of extracting supporting textual evidence for billing codes is explicitly linked to healthcare applications, meeting the criteria for Healthcare AI.",
    "prompt_tokens": 41178,
    "completion_tokens": 205,
    "total_tokens": 41383,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "EffectiveCAN; supervised attention; CNN tagging",
    "application": "code evidence extraction for diagnosis and procedure codes",
    "code_link": "https://github.com/3mcloud/MDACE",
    "dataset_name": [
      "MDACE",
      "MIMIC-III"
    ],
    "is_public": true
  },
  {
    "id": "2021.acl-long.127",
    "year": 2021,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Stance Detection in COVID-19 Tweets",
    "authors": [
      "Kyle Glandt",
      "Sarthak Khanal",
      "Yingjie Li",
      "Doina Caragea",
      "Cornelia Caragea"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The prevalence of the COVID-19 pandemic in day-to-day life has yielded large amounts of stance detection data on social media sites, as users turn to social media to share their views regarding various issues related to the pandemic, e.g. stay at home mandates and wearing face masks when out in public. We set out to make use of this data by collecting the stance expressed by Twitter users, with respect to topics revolving around the pandemic. We annotate a new stance detection dataset, called COVID-19-Stance. Using this newly annotated dataset, we train several established stance detection models to ascertain a baseline performance for this specific task. To further improve the performance, we employ self-training and domain adaptation approaches to take advantage of large amounts of unlabeled data and existing stance detection datasets. The dataset, code, and other resources are available on GitHub.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2021.acl-long.127.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on stance detection in COVID-19 tweets, which involves analyzing public opinions on health-related topics such as 'stay at home mandates' and 'wearing face masks.' COVID-19 is a global health crisis, and understanding public stance on these topics can inform healthcare policies and communication strategies. While the methodology centers around social media data, the application and context are health-related, implying relevance to Healthcare AI. Thus, the paper aligns with healthcare applications in AI.",
    "prompt_tokens": -1,
    "completion_tokens": -1,
    "total_tokens": -1,
    "Topic Axis I": {
      "MainTopic": "Population Health & Computational Epidemiology",
      "SubTopic": "Public Health Surveillance"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (BERT, COVID-Twitter-BERT)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Model Performance Benchmarking"
    },
    "method": "BERT; COVID-Twitter-BERT; BiLSTM; CNN; Self-training with Noisy Student; Dual-view Attention Network (DAN)",
    "application": "Stance detection – COVID-19 tweets",
    "code_link": "https://github.com/kglandt/stance-detection-in-covid-19-tweets",
    "dataset_name": [
      "COVID-19-Stance",
      "SemEval2016 Task 6"
    ],
    "is_public": true
  },
  {
    "id": "2022.acl-long.461",
    "year": 2022,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Leveraging Task Transferability to Meta-learning for Clinical Section Classification with Limited Data",
    "authors": [
      "Zhuohao Chen",
      "Jangwon Kim",
      "Ram Bhakta",
      "Mustafa Sir"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Identifying sections is one of the critical components of understanding medical information from unstructured clinical notes and developing assistive technologies for clinical note-writing tasks. Most state-of-the-art text classification systems require thousands of in-domain text data to achieve high performance. However, collecting in-domain and recent clinical note data with section labels is challenging given the high level of privacy and sensitivity. The present paper proposes an algorithmic way to improve the task transferability of meta-learning-based text classification in order to address the issue of low-resource target data. Specifically, we explore how to make the best use of the source dataset and propose a unique task transferability measure named Normalized Negative Conditional Entropy (NNCE). Leveraging the NNCE, we develop strategies for selecting clinical categories and sections from source task data to boost cross-domain meta-learning accuracy. Experimental results show that our task selection strategies improve section classification accuracy significantly compared to meta-learning algorithms.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2022.acl-long.461.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly focuses on \"clinical section classification\" within unstructured clinical notes, which is a Healthcare AI task. It aims to improve understanding of medical information through meta-learning algorithms, addressing challenges specific to clinical contexts such as privacy and limited annotated datasets. Phrases like \"clinical note-writing tasks,\" \"medical information,\" and \"section classification accuracy\" firmly place the paper in the domain of Healthcare AI, as it contributes to advancing assistive technologies for healthcare documentation and analysis.",
    "prompt_tokens": 41145,
    "completion_tokens": 295,
    "total_tokens": 41440,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "new-Task transferability measurement"
    },
    "method": "Meta-learning; Reptile; Normalized Negative Conditional Entropy",
    "application": "clinical section classification – low-resource scenarios",
    "code_link": "https://github.com/huggingface/pytorch-pretrained-BERT",
    "dataset_name": [
      "MIMIC-III"
    ],
    "is_public": true
  },
  {
    "id": "2021.acl-long.457",
    "year": 2021,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "SMedBERT: A Knowledge-Enhanced Pre-trained Language Model with Structured Semantics for Medical Text Mining",
    "authors": [
      "Taolin Zhang",
      "Zerui Cai",
      "Chengyu Wang",
      "Minghui Qiu",
      "Bite Yang",
      "Xiaofeng He"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Recently, the performance of Pre-trained Language Models (PLMs) has been significantly improved by injecting knowledge facts to enhance their abilities of language understanding. For medical domains, the background knowledge sources are especially useful, due to the massive medical terms and their complicated relations are difficult to understand in text. In this work, we introduce SMedBERT, a medical PLM trained on large-scale medical corpora, incorporating deep structured semantic knowledge from neighbours of linked-entity. In SMedBERT, the mention-neighbour hybrid attention is proposed to learn heterogeneous-entity information, which infuses the semantic representations of entity types into the homogeneous neighbouring entity structure. Apart from knowledge integration as external features, we propose to employ the neighbors of linked-entities in the knowledge graph as additional global contexts of text mentions, allowing them to communicate via shared neighbors, thus enrich their semantic representations. Experiments demonstrate that SMedBERT significantly outperforms strong baselines in various knowledge-intensive Chinese medical tasks. It also improves the performance of other tasks such as question answering, question matching and natural language inference.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2021.acl-long.457.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses SMedBERT, a pre-trained language model specifically designed for medical text mining, which involves enhancing language understanding in medical contexts through structured semantics and knowledge graphs. Key phrases like \"medical domains,\" \"massive medical terms,\" \"complicated relations difficult to understand in text,\" and its application in \"knowledge-intensive Chinese medical tasks\" (e.g., question answering, question matching, natural language inference in medical settings) indicate that the research is directly focused on applications in the medical and healthcare domain. This places the paper squarely within the Healthcare AI / Biomedicine AI category, as it aims to improve computational tools for understanding and leveraging medical text and knowledge.",
    "prompt_tokens": 22262,
    "completion_tokens": 265,
    "total_tokens": 22527,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-structured semantics knowledge injection"
    },
    "method": "Transformer-based models (BERT), Knowledge-enhanced language models; Hybrid attention mechanism",
    "application": "entity relation extraction – medical domain",
    "code_link": "N/A",
    "dataset_name": [
      "DXY-NER",
      "DXY-RE",
      "CHIP-RE",
      "cMedQANER",
      "cMedQQ",
      "cMedQNLI",
      "WebMedQA",
      "cMedQA"
    ],
    "is_public": false
  },
  {
    "id": "acl2025_temp_0463",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Can Large Language Models Accurately Generate Answer Keys for Health-related Questions?",
    "authors": [
      "Davis Bartels",
      "Deepak Gupta",
      "Dina Demner-Fushman"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The evaluation of text generated by LLMs remains a challenge for question answering, retrieval augmented generation (RAG), summarization, and many other natural language processing tasks. Evaluating the factuality of LLM generated responses is particularly important in medical question answering, where the stakes are high. One method of evaluating the factuality of text is through the use of information nuggets (answer keys). Nuggets are text representing atomic facts that may be used by an assessor to make a binary decision as to whether the fact represented by said nugget is contained in an answer. Although manual nugget extraction is expensive and time-consuming, recent RAG shared task evaluations have explored automating the nuggetization of text with LLMs. In this work, we explore several approaches to nugget generation for medical question answering and evaluate their alignment with expert human nugget generation. We find providing an example and extracting nuggets from an answer to be the best approach to nuggetization. While, overall, we found the capabilities of LLMs to distill atomic facts limited, Llama 3.3 performed the best out of the models we tested.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-short.28.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title specifically asks about generating answer keys for health-related questions, indicating a focus on addressing health-specific problems using large language models. While the abstract and keywords are unavailable, the explicit mention of \"health-related questions\" in the title suggests relevance to the Healthcare AI or Biomedicine AI domain, as it implies applications within a medical or healthcare context.",
    "prompt_tokens": 22274,
    "completion_tokens": 195,
    "total_tokens": 22469,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Causal Inference & Reasoning",
      "SubTopic": "Causal Representation Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Representation learning; retrieval-augmented generation (RAG)",
    "application": "Medical fact evaluation; Question answering",
    "code_link": "N/A",
    "dataset_name": [
      "BioGen 2024",
      "TREC 2024"
    ],
    "is_public": false
  },
  {
    "id": "2023.acl-long.577",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Understanding Client Reactions in Online Mental Health Counseling",
    "authors": [
      "Anqi Li",
      "Lizhi Ma",
      "Yaling Mei",
      "Hongliang He",
      "Shuai Zhang",
      "Huachuan Qiu",
      "Zhenzhong Lan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Communication success relies heavily on reading participants’ reactions. Such feedback is especially important for mental health counselors, who must carefully consider the client’s progress and adjust their approach accordingly. However, previous NLP research on counseling has mainly focused on studying counselors’ intervention strategies rather than their clients’ reactions to the intervention. This work aims to fill this gap by developing a theoretically grounded annotation framework that encompasses counselors’ strategies and client reaction behaviors. The framework has been tested against a large-scale, high-quality text-based counseling dataset we collected over the past two years from an online welfare counseling platform. Our study show how clients react to counselors’ strategies, how such reactions affect the final counseling outcomes, and how counselors can adjust their strategies in response to these reactions. We also demonstrate that this study can help counselors automatically predict their clients’ states.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.577.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper addresses the application of NLP to mental health counseling, discussing the development of frameworks to analyze client reactions and improve counseling outcomes. Mental health counseling is directly tied to healthcare, as it involves understanding and improving individuals' psychological well-being—a critical component of health. The study’s focus on predicting client states further underscores its relevance to Healthcare AI, as this prediction informs interventions aimed at improving health outcomes for clients in an online counseling setting. This aligns with the broader scope of Healthcare AI applications in patient monitoring and personalized treatment strategies.",
    "prompt_tokens": 41003,
    "completion_tokens": 205,
    "total_tokens": 41208,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (RoBERTa)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Pre-trained language models; supervised learning",
    "application": "Client behavior classification – Mental health counseling",
    "code_link": " https://github.com/dll-wu/Client-Reactions",
    "dataset_name": [
      "PsyQA",
      "Althoff et al. mental health corpus"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_1580",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Less is More: Explainable and Efficient ICD Code Prediction with Clinical Entities",
    "authors": [
      "James Douglas",
      "Yidong Gan",
      "Ben Hachey",
      "Jonathan K. Kummerfeld"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Clinical coding, assigning standardized codes to medical notes, is critical for epidemiological research, hospital planning, and reimbursement. Neural coding models generally process entire discharge summaries, which are often lengthy and contain information that is not relevant to coding. We propose an approach that combines Named Entity Recognition (NER) and Assertion Classification (AC) to filter for clinically important content before supervised code prediction. On MIMIC-IV, a standard evaluation dataset, our approach achieves near-equivalent performance to a state-of-the-art full-text baseline while using only 22% of the content and reducing training time by over half. Additionally, mapping model attention to complete entity spans yields coherent, clinically meaningful explanations, capturing coding-relevant modifiers such as acuity and laterality. We release a newly annotated NER+AC dataset for MIMIC-IV, designed specifically for ICD coding. Our entity-centric approach lays a foundation for more transparent and cost-effective assisted coding.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.1489.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title \"Less is More: Explainable and Efficient ICD Code Prediction with Clinical Entities\" directly references \"ICD Code Prediction,\" which is indicative of a healthcare-related application. ICD (International Classification of Diseases) codes are used in clinical settings for disease classification and medical billing. The mention of \"Clinical Entities\" further reinforces that the paper deals with healthcare data and tasks, likely focusing on improving clinical predictions or decision-making. This aligns with the domain of Healthcare AI.",
    "prompt_tokens": 22052,
    "completion_tokens": 224,
    "total_tokens": 22276,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Transformer-based models (RoBERTa-PM); Named Entity Recognition (NER); Assertion Classification (AC); InputXGrad",
    "application": "ICD coding – structured patient notes",
    "code_link": "N/A",
    "dataset_name": [
      "MIMIC-IV",
      "i2b2"
    ],
    "is_public": false
  },
  {
    "id": "2023.acl-long.588",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Annotating Mentions Alone Enables Efficient Domain Adaptation for Coreference Resolution",
    "authors": [
      "Nupoor Gandhi",
      "Anjalie Field",
      "Emma Strubell"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Although recent neural models for coreference resolution have led to substantial improvements on benchmark datasets, it remains a challenge to successfully transfer these models to new target domains containing many out-of-vocabulary spans and requiring differing annotation schemes. Typical approaches involve continued training on annotated target-domain data, but obtaining annotations is costly and time-consuming. In this work, we show that adapting mention detection is the key component to successful domain adaptation of coreference models, rather than antecedent linking. We also show annotating mentions alone is nearly twice as fast as annotating full coreference chains. Based on these insights, we propose a method for efficiently adapting coreference models, which includes a high-precision mention detection objective and requires only mention annotations in the target domain. Extensive evaluation across three English coreference datasets: CoNLL-2012 (news/conversation), i2b2/VA (medical notes), and child welfare notes, reveals that our approach facilitates annotation-efficient transfer and results in a 7-14% improvement in average F1 without increasing annotator time.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.588.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract explicitly mentions the application of coreference resolution models to \"i2b2/VA (medical notes),\" which is a well-known dataset derived from electronic health records and patient medical notes. This dataset is clearly tied to healthcare data and tasks related to medical language processing, an integral part of healthcare AI. Additionally, adapting mention detection for medical notes aligns with efforts in healthcare-specific natural language processing, making the research relevant to Healthcare AI. There is no mention of tasks or datasets outside health-related contexts that would disqualify this association.",
    "prompt_tokens": 22291,
    "completion_tokens": 228,
    "total_tokens": 22519,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "EHR/EMR Predictive Modeling"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Algorithmic Fairness & Bias Mitigation"
    },
    "method": "SpanBERT-based neural coreference resolution; high-precision mention pruning; auxiliary mention detection objective",
    "application": "Coreference model adaptation – domain-specific texts",
    "code_link": "https://github.com/nupoorgandhi/data-eff-coref",
    "dataset_name": [
      "OntoNotes",
      "i2b2/VA Shared-Task",
      "Child Welfare Case Notes (CN)"
    ],
    "is_public": true
  },
  {
    "id": "2024.acl-long.419",
    "year": 2024,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "MARS: Meaning-Aware Response Scoring for Uncertainty Estimation in Generative LLMs",
    "authors": [
      "Yavuz Faruk Bakman",
      "Duygu Nur Yaldiz",
      "Baturalp Buyukates",
      "Chenyang Tao",
      "Dimitrios Dimitriadis",
      "Salman Avestimehr"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Generative Large Language Models (LLMs) are widely utilized for their excellence in various tasks. However, their tendency to produce inaccurate or misleading outputs poses a potential risk, particularly in high-stakes environments. Therefore, estimating the correctness of generative LLM outputs is an important task for enhanced reliability. Uncertainty Estimation (UE) in generative LLMs is an evolving domain, where SOTA probability-based methods commonly employ length-normalized scoring. In this work, we propose Meaning-Aware Response Scoring (MARS) as an alternative to length-normalized scoring for UE methods. MARS is a novel scoring function that considers the semantic contribution of each token in the generated sequence in the context of the question. We demonstrate that integrating MARS into UE methods results in a universal and significant improvement in UE performance. We conduct experiments using three distinct closed-book question-answering datasets across five popular pre-trained LLMs. Lastly, we validate the efficacy of MARS on a Medical QA dataset. Code can be found here.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2024.acl-long.419.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper specifically validates its proposed Meaning-Aware Response Scoring (MARS) method on a Medical QA dataset, indicating a direct application in the healthcare domain. Although the majority of the abstract focuses on general Uncertainty Estimation (UE) in generative LLMs, the explicit reference to using a medical dataset suggests relevance to Healthcare AI. Validating methods in a healthcare or medical context typically implies an interest in improving the reliability of AI systems for tasks related to healthcare or biomedicine, making this paper relevant to the domain.",
    "prompt_tokens": 21713,
    "completion_tokens": 214,
    "total_tokens": 21927,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Algorithmic Fairness & Bias Mitigation"
    },
    "method": "Meaning-Aware Response Scoring (MARS); Uncertainty Estimation (UE) methods",
    "application": "Medical question answering – LLM generated responses",
    "code_link": "https://github.com/Ybakman/LLM_Uncertainty",
    "dataset_name": [
      "MedMCQA"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0677",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Exploring Compositional Generalization of Multimodal LLMs for Medical Imaging",
    "authors": [
      "Zhenyang Cai",
      "Junying Chen",
      "Rongsheng Wang",
      "Weihong Wang",
      "Yonglin Deng",
      "Dingjie Song",
      "Yize Chen",
      "Zixu Zhang",
      "Benyou Wang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Medical imaging provides essential visual insights for diagnosis, and multimodal large language models (MLLMs) are increasingly utilized for its analysis due to their strong generalization capabilities; however, the underlying factors driving this generalization remain unclear. Current research suggests that multi-task training outperforms single-task as different tasks can benefit each other, but they often overlook the internal relationships within these tasks. To analyze this phenomenon, we attempted to employ compositional generalization (CG), which refers to the models' ability to understand novel combinations by recombining learned elements, as a guiding framework. Since medical images can be precisely defined by Modality, Anatomical area, and Task, naturally providing an environment for exploring CG, we assembled 106 medical datasets to create Med-MAT for comprehensive experiments. The experiments confirmed that MLLMs can use CG to understand unseen medical images and identified CG as one of the main drivers of the generalization observed in multi-task training. Additionally, further studies demonstrated that CG effectively supports datasets with limited data and confirmed that MLLMs can achieve CG across classification and detection tasks, underscoring its broader generalization potential.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.639.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title mentions \"Exploring Compositional Generalization of Multimodal LLMs for Medical Imaging,\" which clearly indicates a focus on medical imaging – a critical domain in Healthcare AI. Medical imaging is used for tasks such as disease diagnosis, treatment planning, and patient health monitoring, directly linking the paper to healthcare applications. Additionally, the use of multimodal LLMs (large language models) suggests the utilization of AI methods optimized for clinical or diagnostic tasks involving complex medical data. Even without an abstract or keywords, the explicit reference to \"medical imaging\" strongly supports relevance to Healthcare AI.",
    "prompt_tokens": 22095,
    "completion_tokens": 187,
    "total_tokens": 22282,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Ophthalmology"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Transformer-based models",
    "application": "Disease classification",
    "code_link": "N/A",
    "dataset_name": [
      "RFMiD 2.0",
      "Adam Dataset",
      "APTOS 2019 Blindness",
      "DRIMDB"
    ],
    "is_public": false
  },
  {
    "id": "2023.acl-long.549",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Automated Metrics for Medical Multi-Document Summarization Disagree with Human Evaluations",
    "authors": [
      "Lucy Lu Wang",
      "Yulia Otmakhova",
      "Jay DeYoung",
      "Thinh Hung Truong",
      "Bailey Kuehl",
      "Erin Bransom",
      "Byron Wallace"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Evaluating multi-document summarization (MDS) quality is difficult. This is especially true in the case of MDS for biomedical literature reviews, where models must synthesize contradicting evidence reported across different documents. Prior work has shown that rather than performing the task, models may exploit shortcuts that are difficult to detect using standard n-gram similarity metrics such as ROUGE. Better automated evaluation metrics are needed, but few resources exist to assess metrics when they are proposed. Therefore, we introduce a dataset of human-assessed summary quality facets and pairwise preferences to encourage and support the development of better automated evaluation methods for literature review MDS. We take advantage of community submissions to the Multi-document Summarization for Literature Review (MSLR) shared task to compile a diverse and representative sample of generated summaries. We analyze how automated summarization evaluation metrics correlate with lexical features of generated summaries, to other automated metrics including several we propose in this work, and to aspects of human-assessed summary quality. We find that not only do automated metrics fail to capture aspects of quality as assessed by humans, in many cases the system rankings produced by these metrics are anti-correlated with rankings according to human annotators.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.549.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on the evaluation of multi-document summarization systems specifically for biomedical literature reviews, as indicated by the phrase \"MDS for biomedical literature reviews\" in the abstract. This suggests that the research is concerned with synthesizing information from biomedical research documents. Additionally, the reference to \"biomedical literature reviews\" highlights its direct relevance to the Biomedicine AI domain, as it involves summarizing and making sense of medical or biological research findings, a critical task in supporting healthcare and biomedical research applications.",
    "prompt_tokens": 22537,
    "completion_tokens": 216,
    "total_tokens": 22753,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Transformer-based models; BART; Longformer Encoder-Decoder; Self-Supervised learning",
    "application": "Medical multi-document summarization",
    "code_link": "https://github.com/allenai/mslr-annotated-dataset",
    "dataset_name": [
      "Cochrane",
      "MS^2"
    ],
    "is_public": true
  },
  {
    "id": "2021.acl-long.82",
    "year": 2021,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Robust Knowledge Graph Completion with Stacked Convolutions and a Student Re-Ranking Network",
    "authors": [
      "Justin Lovelace",
      "Denis Newman-Griffis",
      "Shikhar Vashishth",
      "Jill Fain Lehman",
      "Carolyn Rosé"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Knowledge Graph (KG) completion research usually focuses on densely connected benchmark datasets that are not representative of real KGs. We curate two KG datasets that include biomedical and encyclopedic knowledge and use an existing commonsense KG dataset to explore KG completion in the more realistic setting where dense connectivity is not guaranteed. We develop a deep convolutional network that utilizes textual entity representations and demonstrate that our model outperforms recent KG completion methods in this challenging setting. We find that our model’s performance improvements stem primarily from its robustness to sparsity. We then distill the knowledge from the convolutional network into a student network that re-ranks promising candidate entities. This re-ranking stage leads to further improvements in performance and demonstrates the effectiveness of entity re-ranking for KG completion.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2021.acl-long.82.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper mentions the development of two curated KG datasets, one of which includes \"biomedical knowledge,\" explicitly linking this research to the field of biomedicine. The model's robustness to sparsity could benefit sparsely connected biomedical datasets often encountered in tasks like drug discovery or molecular biology. Additionally, the exploration of approaches for knowledge graph completion in a biomedical context suggests applications in analyzing or integrating knowledge relevant to healthcare or biomedicine. Thus, the paper is relevant to Biomedicine AI.",
    "prompt_tokens": 41221,
    "completion_tokens": 325,
    "total_tokens": 41546,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "EHR/EMR Predictive Modeling"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Disentangled Representation Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Deep convolutional architecture; Knowledge distillation; Entity re-ranking; BERT-based entity embedding",
    "application": "Knowledge graph completion – biomedical and commonsense domains",
    "code_link": "https://github.com/justinlovelace/robust-kg-completion",
    "dataset_name": [
      "SNOMED CT Core",
      "CN-100K",
      "FB15k-237",
      "FB15k-237-Sparse"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_1347",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "RADAR: Enhancing Radiology Report Generation with Supplementary Knowledge Injection",
    "authors": [
      "Wenjun Hou",
      "Yi Cheng",
      "Kaishuai Xu",
      "Heng Li",
      "Yan Hu",
      "Wenjie Li",
      "Jiang Liu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in various domains, including radiology report generation. Previous approaches have attempted to utilize multimodal LLMs for this task, enhancing their performance through the integration of domain-specific knowledge retrieval. However, these approaches often overlook the knowledge already embedded within the LLMs, leading to redundant information integration. To address this limitation, we propose Radar, a framework for enhancing radiology report generation with supplementary knowledge injection. Radar improves report generation by systematically leveraging both the internal knowledge of an LLM and externally retrieved information. Specifically, it first extracts the model’s acquired knowledge that aligns with expert image-based classification outputs. It then retrieves relevant supplementary knowledge to further enrich this information. Finally, by aggregating both sources, Radar generates more accurate and informative radiology reports. Extensive experiments on MIMIC-CXR, CheXpert-Plus, and IU X-ray demonstrate that our model outperforms state-of-the-art LLMs in both language quality and clinical accuracy",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.1279.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title \"RADAR: Enhancing Radiology Report Generation with Supplementary Knowledge Injection\" indicates the paper focuses on radiology, which is explicitly tied to medical imaging and healthcare. The task of radiology report generation inherently supports clinical workflows, such as diagnosis and treatment planning. Keywords like “radiology” and “report generation” strongly indicate that the work is within the Healthcare AI domain, as it applies AI to a healthcare-specific task involving medical imaging. Even though the abstract and keywords are not provided, the domain-specific term \"radiology\" is sufficient to classify this as Healthcare AI.",
    "prompt_tokens": 21738,
    "completion_tokens": 207,
    "total_tokens": 21945,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Radiology"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Multimodal LLM; Knowledge extraction; Supplementary knowledge injection",
    "application": "Radiology report generation",
    "code_link": "https://github.com/wjhou/Radar",
    "dataset_name": [
      "MIMIC-CXR",
      "CHEXPERT-PLUS",
      "IU X-RAY"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0703",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "ReflecTool: Towards Reflection-Aware Tool-Augmented Clinical Agents",
    "authors": [
      "Yusheng Liao",
      "Shuyang Jiang",
      "Yanfeng Wang",
      "Yu Wang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Large Language Models (LLMs) have shown promising potential in the medical domain, assisting with tasks like clinical note generation and patient communication. However, current LLMs are limited to text-based communication, hindering their ability to interact with diverse forms of information in clinical environments. Despite clinical agents succeeding in diverse signal interaction, they are oriented to a single clinical scenario and hence fail for broader applications. To evaluate clinical agents holistically, we propose ClinicalAgent Bench (CAB), a comprehensive medical agent benchmark consisting of 18 tasks across five key realistic clinical dimensions. Building on this, we introduce ReflectTool, a novel framework that excels at utilizing domain-specific tools within two stages. The first optimization stage progressively enlarges a long-term memory by saving successful solving processes and tool-wise experience of agents in a tiny pre-defined training set. In the following inference stage, ReflectTool can search for supportive successful demonstrations from already built long-term memory to guide the tool selection strategy, and a verifier improves the tool usage according to the tool-wise experience with two verification methods–iterative refinement and candidate selection. Extensive experiments on CAB demonstrate that ReflectTool surpasses the pure LLMs with more than 10 points and the well-established agent-based methods with 3 points, highlighting its adaptability and effectiveness in solving complex clinical tasks. Our code and datasets are available at https://github.com/BlueZeros/ReflecTool.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.663.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title \"ReflecTool: Towards Reflection-Aware Tool-Augmented Clinical Agents\" includes the term \"Clinical Agents,\" which is a strong indicator that the work pertains to healthcare or clinical applications. The phrase \"reflection-aware\" and \"tool-augmented\" suggest the development of AI systems designed to assist in clinical contexts, potentially enhancing decision-making or providing support to healthcare professionals. Although no abstract or keywords were provided, the explicit mention of \"clinical\" strongly implies a focus on Healthcare AI. Consequently, the paper is classified as relevant to the domain.",
    "prompt_tokens": 22431,
    "completion_tokens": 287,
    "total_tokens": 22718,
    "Topic Axis I": {
      "MainTopic": "Healthcare Systems & Operations",
      "SubTopic": "Hospital Operations Management"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Tool-Augmented Framework; Long-term Memory; Iterative Refinement; Candidate Selection",
    "application": "Agent-based Task Optimization – Clinical environments",
    "code_link": "https://github.com/BlueZeros/ReflecTool",
    "dataset_name": [
      "CAB",
      "MIMIC-III",
      "eICU",
      "PubMedQA",
      "BioASQ",
      "MedQA",
      "MedHalt-Rht",
      "MedVQA-Halt",
      "EHR-Halt",
      "LongHalt"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0717",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "MEDDxAgent: A Unified Modular Agent Framework for Explainable Automatic Differential Diagnosis",
    "authors": [
      "Daniel Philip Rose",
      "Chia-Chien Hung",
      "Marco Lepri",
      "Israa Alqassem",
      "Kiril Gashteovski",
      "Carolin Lawrence"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Differential Diagnosis (DDx) is a fundamental yet complex aspect of clinical decision-making, in which physicians iteratively refine a ranked list of possible diseases based on symptoms, antecedents, and medical knowledge. While recent advances in large language models (LLMs) have shown promise in supporting DDx, existing approaches face key limitations, including single-dataset evaluations, isolated optimization of components, unrealistic assumptions about complete patient profiles, and single-attempt diagnosis. We introduce a Modular Explainable DDx Agent (MEDDxAgent) framework designed for interactive DDx, where diagnostic reasoning evolves through iterative learning, rather than assuming a complete patient profile is accessible. MEDDxAgent integrates three modular components: (1) an orchestrator (DDxDriver), (2) a history taking simulator, and (3) two specialized agents for knowledge retrieval and diagnosis strategy. To ensure robust evaluation, we introduce a comprehensive DDx benchmark covering respiratory, skin, and rare diseases. We analyze single-turn diagnostic approaches and demonstrate the importance of iterative refinement when patient profiles are not available at the outset. Our broad evaluation demonstrates that MEDDxAgent achieves over 10% accuracy improvements in interactive DDx across both large and small LLMs, while offering critical explainability into its diagnostic reasoning process.",
    "keywords": "N/A",
    "pdf_url": "https://arxiv.org/pdf/2502.19175",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title \"MEDDxAgent: A Unified Modular Agent Framework for Explainable Automatic Differential Diagnosis\" explicitly mentions \"differential diagnosis,\" which is a core task in healthcare and clinical settings. The reference to \"diagnosis\" strongly indicates relevance to Healthcare AI, as the paper likely discusses AI methods for automating or assisting in medical diagnosis processes. Additionally, the focus on explainability further aligns with the necessity for transparency in medical applications, where understanding AI-driven decisions is critical for clinical trust and applicability. Without an abstract or keywords, the title alone provides sufficient evidence to classify this paper under Healthcare AI.",
    "prompt_tokens": 21868,
    "completion_tokens": 225,
    "total_tokens": 22093,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Disentangled Representation Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Iterative refinement; Modular agent framework; Chain-of-thought reasoning; Few-shot dynamic adaptation",
    "application": "Interactive differential diagnosis",
    "code_link": "https://github.com/nec-research/meddxagent",
    "dataset_name": [
      "DDxPlus",
      "iCRAFT-MD",
      "RareBench"
    ],
    "is_public": true
  },
  {
    "id": "2021.acl-long.119",
    "year": 2021,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "A Gradually Soft Multi-Task and Data-Augmented Approach to Medical Question Understanding",
    "authors": [
      "Khalil Mrini",
      "Franck Dernoncourt",
      "Seunghyun Yoon",
      "Trung Bui",
      "Walter Chang",
      "Emilia Farcas",
      "Ndapa Nakashole"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Users of medical question answering systems often submit long and detailed questions, making it hard to achieve high recall in answer retrieval. To alleviate this problem, we propose a novel Multi-Task Learning (MTL) method with data augmentation for medical question understanding. We first establish an equivalence between the tasks of question summarization and Recognizing Question Entailment (RQE) using their definitions in the medical domain. Based on this equivalence, we propose a data augmentation algorithm to use just one dataset to optimize for both tasks, with a weighted MTL loss. We introduce gradually soft parameter-sharing: a constraint for decoder parameters to be close, that is gradually loosened as we move to the highest layer. We show through ablation studies that our proposed novelties improve performance. Our method outperforms existing MTL methods across 4 datasets of medical question pairs, in ROUGE scores, RQE accuracy and human evaluation. Finally, we show that our method fares better than single-task learning under 4 low-resource settings.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2021.acl-long.119.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper directly focuses on improving the task of medical question understanding, which is clearly a healthcare-specific application. Phrases such as “users of medical question answering systems” and “definitions in the medical domain” indicate the work's relevance to Healthcare AI. Additionally, the use of datasets involving \"medical question pairs\" and evaluation metrics like Recognizing Question Entailment (RQE) for medical queries further solidifies its connection to the healthcare domain, as it aims to enhance systems supporting medical decision-making and patient communication.",
    "prompt_tokens": 22344,
    "completion_tokens": 242,
    "total_tokens": 22586,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (GPT, LLaMA)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "N/A"
    },
    "method": "Simultaneous Multi-Task Learning; Gradually soft parameter-sharing method; BART large architecture",
    "application": "Medical question understanding",
    "code_link": "https://github.com/KhalilMrini/Medical-Question-Understanding",
    "dataset_name": [
      "MeQSum",
      "HealthCareMagic",
      "iCliniq",
      "MEDIQA RQE"
    ],
    "is_public": true
  },
  {
    "id": "2024.acl-long.234",
    "year": 2024,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "InfoLossQA: Characterizing and Recovering Information Loss in Text Simplification",
    "authors": [
      "Jan Trienes",
      "Sebastian Joseph",
      "Jörg Schlötterer",
      "Christin Seifert",
      "Kyle Lo",
      "Wei Xu",
      "Byron Wallace",
      "Junyi Jessy Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Text simplification aims to make technical texts more accessible to laypeople but often results in deletion of information and vagueness. This work proposes InfoLossQA, a framework to characterize and recover simplification-induced information loss in form of question-and-answer (QA) pairs. Building on the theory of Questions Under Discussion, the QA pairs are designed to help readers deepen their knowledge of a text. First, we collect a dataset of 1,000 linguist-curated QA pairs derived from 104 LLM simplifications of English medical study abstracts. Our analyses of this data reveal that information loss occurs frequently, and that the QA pairs give a high-level overview of what information was lost. Second, we devise two methods for this task: end-to-end prompting of open-source and commercial language models, and a natural language inference pipeline. With a novel evaluation framework considering the correctness of QA pairs and their linguistic suitability, our expert evaluation reveals that models struggle to reliably identify information loss and applying similar standards as humans at what constitutes information loss.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2024.acl-long.234.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on assessing and mitigating information loss in text simplifications of English medical study abstracts. The application domain is explicitly tied to \"medical study abstracts,\" which are indicative of a biomedical research context. By analyzing and recovering lost information in these simplified texts, the framework has direct implications for improving the accessibility and understanding of medical research, which aligns with the goals of Biomedicine AI. Additionally, the paper's reference to \"LLM simplifications of English medical study abstracts\" highlights its relevance to healthcare and biomedical communication. Thus, the paper belongs to the Biomedicine AI domain.",
    "prompt_tokens": 60209,
    "completion_tokens": 284,
    "total_tokens": 60493,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Randomized Controlled Trials"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (GPT-4, LLaMA)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Question generation using GPT models; Natural Language Inference pipeline",
    "application": "Information loss detection – Randomized Controlled Trials",
    "code_link": "https://Together.AI",
    "dataset_name": [
      "INFOLOSSQA",
      "RCT abstracts",
      "manual validation dataset"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0058",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "PsyDT: Using LLMs to Construct the Digital Twin of Psychological Counselor with Personalized Counseling Style for Psychological Counseling",
    "authors": [
      "Haojie Xie",
      "Yirong Chen",
      "Xiaofen Xing",
      "Jingkai Lin",
      "Xiangmin Xu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Currently, large language models (LLMs) have made significant progress in the field of psychological counseling. However, existing mental health LLMs overlook a critical issue where they do not consider the fact that different psychological counselors exhibit different personal styles, including linguistic style and therapy techniques, etc. As a result, these LLMs fail to satisfy the individual needs of clients who seek different counseling styles. To help bridge this gap, we propose PsyDT, a novel framework using LLMs to construct the Digital Twin of Psychological counselor with personalized counseling style. Compared to the time-consuming and costly approach of collecting a large number of real-world counseling cases to create a specific counselor's digital twin, our framework offers a faster and more cost-effective solution. To construct PsyDT, we utilize dynamic one-shot learning by using GPT-4 to capture counselor's unique counseling style, mainly focusing on linguistic style and therapy techniques. Subsequently, using existing single-turn long-text dialogues with client's questions, GPT-4 is guided to synthesize multi-turn dialogues of specific counselor. Finally, we fine-tune the LLMs on the synthetic dataset, PsyDTCorpus, to achieve the digital twin of psychological counselor with personalized counseling style. Experimental results indicate that our proposed PsyDT framework can synthesize multi-turn dialogues that closely resemble real-world counseling cases and demonstrate better performance compared to other baselines, thereby show that our framework can effectively construct the digital twin of psychological counselor with a specific counseling style.",
    "keywords": "N/A",
    "pdf_url": "https://arxiv.org/pdf/2412.13660",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper, titled \"PsyDT: Using LLMs to Construct the Digital Twin of Psychological Counselor with Personalized Counseling Style for Psychological Counseling,\" relates to the development of a digital twin of a psychological counselor using large language models (LLMs). The focus is on psychological counseling, which is a healthcare-specific application aimed at mental health and well-being. Psychological counseling falls under the realm of healthcare, and the implementation of personalized counseling styles aligns with healthcare AI objectives of enhancing therapy and patient care. Thus, this paper is classified within the Healthcare AI domain.",
    "prompt_tokens": 21716,
    "completion_tokens": 227,
    "total_tokens": 21943,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "Human-AI Collaborative Performance"
    },
    "method": "Multi-turn instruction fine-tuning (MIFT); GPT-4-based linguistic style and therapy synthesis",
    "application": "Mental health counseling dialogue generation",
    "code_link": "https://github.com/scutcyr/SoulChat2.0",
    "dataset_name": [
      "SoulChatCorpus",
      "PsyDTCorpus"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0104",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "AfriMed-QA: A Pan-African, Multi-Specialty, Medical Question-Answering Benchmark Dataset",
    "authors": [
      "Charles Nimo",
      "Tobi Olatunji",
      "Abraham Toluwase Owodunni",
      "Tassallah Abdullahi",
      "Emmanuel Ayodele",
      "Mardhiyah Sanni",
      "Ezinwanne C. Aka",
      "Folafunmi Omofoye",
      "Foutse Yuehgoh",
      "Timothy Faniran",
      "Bonaventure F. P. Dossou",
      "Moshood O. Yekini",
      "Jonas Kemp",
      "Katherine A Heller",
      "Jude Chidubem Omeke",
      "Chidi Asuzu MD",
      "Naome A Etori",
      "Aïmérou Ndiaye",
      "Ifeoma Okoh",
      "Evans Doe Ocansey",
      "Wendy Kinara",
      "Michael Best",
      "Irfan Essa",
      "Stephen Edward Moore",
      "Chris Fourie",
      "Mercy Nyamewaa Asiedu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Recent advancements in large language model(LLM) performance on medical multiple choice question (MCQ) benchmarks have stimulated interest from healthcare providers and patients globally. Particularly in low-and middle-income countries (LMICs) facing acute physician shortages and lack of specialists, LLMs offer a potentially scalable pathway to enhance healthcare access and reduce costs. However, their effectiveness in the Global South, especially across the African continent, remains to be established. In this work, we introduce AfriMed-QA, the first large scale Pan-African English multi-specialty medical Question-Answering (QA) dataset, 15,000 questions (open and closed-ended) sourced from over 60 medical schools across 16 countries, covering 32 medical specialties. We further evaluate 30 LLMs across multiple axes including correctness and demographic bias. Our findings show significant performance variation across specialties and geographies, MCQ performance clearly lags USMLE (MedQA). We find that biomedical LLMs underperform general models and smaller edge-friendly LLMs struggle to achieve a passing score. Interestingly, human evaluations show a consistent consumer preference for LLM answers and explanations when compared with clinician answers.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.96.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title of the paper, \"AfriMed-QA: A Pan-African, Multi-Specialty, Medical Question-Answering Benchmark Dataset,\" explicitly suggests a focus on medical question-answering. The use of terms such as \"Medical\" and \"Question-Answering\" indicates a healthcare-related application. Additionally, the development of a benchmark dataset specifically for medical contexts strongly ties this work to Healthcare AI, as such datasets are foundational to training and evaluating AI models for healthcare or clinical tasks. The regional focus (\"Pan-African\") and multi-specialty aspects also suggest relevance to diverse healthcare domains within the medical field.",
    "prompt_tokens": 22207,
    "completion_tokens": 247,
    "total_tokens": 22454,
    "Topic Axis I": {
      "MainTopic": "Healthcare Systems & Operations",
      "SubTopic": "Clinical Trial Optimization"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (GPT, LLaMA)"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Transformer-based models (GPT-4, LLaMA); quest inference evaluation; BERTScore; Rouge-L; QuestEval",
    "application": "Medical question-answering – Consumer queries; Multiple-choice questions – Pan-African healthcare",
    "code_link": "https://huggingface.co/datasets/intronhealth/afrimedqa_v2",
    "dataset_name": [
      "AfriMed-QA"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0892",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "LLMs Can Simulate Standardized Patients via Agent Coevolution",
    "authors": [
      "Zhuoyun Du",
      "LujieZheng",
      "Renjun Hu",
      "Yuyang Xu",
      "Xiawei Li",
      "Ying Sun",
      "Wei Chen",
      "Jian Wu",
      "Haolei Cai",
      "Haochao Ying"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Training medical personnel using standardized patients (SPs) remains a complex challenge, requiring extensive domain expertise and role-specific practice. Previous research on Large Language Model (LLM)-based SPs mostly focuses on improving data retrieval accuracy or adjusting prompts through human feedback. However, this focus has overlooked the critical need for patient agents to learn a standardized presentation pattern that transforms data into human-like patient responses through unsupervised simulations. To address this gap, we propose EvoPatient, a novel simulated patient framework in which a patient agent and doctor agents simulate the diagnostic process through multi-turn dialogues, simultaneously gathering experience to improve the quality of both questions and answers, ultimately enabling human doctor training. Extensive experiments on various cases demonstrate that, by providing only overall SP requirements, our framework improves over existing reasoning methods by more than 10 percent in requirement alignment and better human preference, while achieving an optimal balance of resource consumption after evolving over 200 cases for 10 hours, with excellent generalizability.",
    "keywords": "N/A",
    "pdf_url": "https://arxiv.org/pdf/2412.11716",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title, \"LLMs Can Simulate Standardized Patients via Agent Coevolution,\" suggests that the paper involves using large language models (LLMs) to simulate standardized patients. Standardized patients are commonly used in medical education and clinical training to simulate real-life patient interactions. This indicates a direct application of AI in a healthcare-related context, specifically in medical training and simulation. The use of LLMs in this way aligns with the Healthcare AI category, as it involves improving healthcare education and potentially clinical outcomes through AI-driven simulations.",
    "prompt_tokens": 22236,
    "completion_tokens": 208,
    "total_tokens": 22444,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "Human-AI Collaborative Performance"
    },
    "method": "Multi-agent coevolution; Generative model; retrieval and alignment strategies",
    "application": "Simulating standardized patients and improving human doctor training",
    "code_link": "https://github.com/ZJUMAI/EvoPatient",
    "dataset_name": [
      "MTSamples",
      "MIMIC II"
    ],
    "is_public": true
  },
  {
    "id": "2024.acl-long.393",
    "year": 2024,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Enhancing EEG-to-Text Decoding through Transferable Representations from Pre-trained Contrastive EEG-Text Masked Autoencoder",
    "authors": [
      "Jiaqi Wang",
      "Zhenxi Song",
      "Zhengyu Ma",
      "Xipeng Qiu",
      "Min Zhang",
      "Zhiguo Zhang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Reconstructing natural language from non-invasive electroencephalography (EEG) holds great promise as a language decoding technology for brain-computer interfaces (BCIs). However, EEG-based language decoding is still in its nascent stages, facing several technical issues such as: 1) Absence of a hybrid strategy that can effectively integrate cross-modality (between EEG and text) self-learning with intra-modality self-reconstruction of EEG features or textual sequences; 2) Under-utilization of large language models (LLMs) to enhance EEG-based language decoding. To address above issues, we propose the Contrastive EEG-Text Masked Autoencoder (CET-MAE), a novel model that orchestrates compound self-supervised learning across and within EEG and text through a dedicated multi-stream encoder. Furthermore, we develop a framework called E2T-PTR (EEG-to-Text decoding using Pretrained Transferable Representations), which leverages pre-trained modules alongside the EEG stream from CET-MAE and further enables an LLM (specifically BART) to decode text from EEG sequences. Comprehensive experiments conducted on the popular text-evoked EEG database, ZuCo, demonstrate the superiority of E2T-PTR, which outperforms the baseline framework in ROUGE-1 F1 and BLEU-4 scores by 8.34% and 32.21%, respectively. Our proposed pre-trained EEG-Text model shows the potential to improve downstream tasks involving EEG and text. This opens up promising avenues for its application in inner speech BCI paradigms, meriting further investigation.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2024.acl-long.393.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper addresses EEG-to-text decoding and proposes a model optimized for decoding natural language from EEG signals, which are non-invasive brain signals commonly used in neuroscience and clinical contexts. EEG decoding has significant implications for brain-computer interfaces (BCIs), particularly in healthcare, where it can aid in communication for individuals with speech disabilities or neurological disorders. The abstract explicitly mentions applications in \"inner speech BCI paradigms,\" which are directly relevant to healthcare and assistive technologies. Additionally, EEG is frequently used in medical and biomedical research, reinforcing the relevance to the Biomedicine AI domain. The focus on pre-trained models and language decoding further supports the potential for therapeutic or clinical applications in neuroscience and related health fields.",
    "prompt_tokens": 41264,
    "completion_tokens": 229,
    "total_tokens": 41493,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Physiological Time Series Analysis"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Diffusion Models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Contrastive learning; Masked autoencoder",
    "application": "EEG-to-text generation",
    "code_link": "https://huggingface.co/facebook/bart-large",
    "dataset_name": [
      "ZuCo v1.0",
      "ZuCo v2.0"
    ],
    "is_public": true
  },
  {
    "id": "2022.acl-long.116",
    "year": 2022,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Domain Knowledge Transferring for Pre-trained Language Model via Calibrated Activation Boundary Distillation",
    "authors": [
      "Dongha Choi",
      "HongSeok Choi",
      "Hyunju Lee"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Since the development and wide use of pretrained language models (PLMs), several approaches have been applied to boost their performance on downstream tasks in specific domains, such as biomedical or scientific domains. Additional pre-training with in-domain texts is the most common approach for providing domain-specific knowledge to PLMs. However, these pre-training methods require considerable in-domain data and training resources and a longer training time. Moreover, the training must be re-performed whenever a new PLM emerges. In this study, we propose a domain knowledge transferring (DoKTra) framework for PLMs without additional in-domain pretraining. Specifically, we extract the domain knowledge from an existing in-domain pretrained language model and transfer it to other PLMs by applying knowledge distillation. In particular, we employ activation boundary distillation, which focuses on the activation of hidden neurons. We also apply an entropy regularization term in both teacher training and distillation to encourage the model to generate reliable output probabilities, and thus aid the distillation. By applying the proposed DoKTra framework to downstream tasks in the biomedical, clinical, and financial domains, our student models can retain a high percentage of teacher performance and even outperform the teachers in certain tasks. Our code is available at https://github.com/DMCB-GIST/DoKTra.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2022.acl-long.116.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses applying domain knowledge transfer to downstream tasks in specific domains, including biomedical and clinical domains. This directly implicates relevance to Biomedicine AI and potentially Healthcare AI, as these domains encompass tasks related to medicine and clinical applications. Keywords and phrases like \"biomedical,\" \"clinical,\" \"domain knowledge,\" and \"downstream tasks\" suggest that the research has clear applications in analyzing and improving AI's performance in medical and healthcare-related fields.",
    "prompt_tokens": 22516,
    "completion_tokens": 226,
    "total_tokens": 22742,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Knowledge distillation; Activation boundary distillation; Confidence penalty regularization; Entropy penalty",
    "application": "Biomedical and clinical classification tasks",
    "code_link": "https://github.com/DMCB-GIST/DoKTra",
    "dataset_name": [
      "ChemProt",
      "GAD",
      "DDI",
      "i2b2",
      "HoC"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_1140",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Can LLMs Understand Unvoiced Speech? Exploring EMG-to-Text Conversion with LLMs",
    "authors": [
      "Payal Mohapatra",
      "Akash Pandey",
      "Xiaoyuan Zhang",
      "Qi Zhu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Unvoiced electromyography (EMG) is an effective communication tool for individuals unable to produce vocal speech. However, most prior methods rely on paired voiced and unvoiced EMG signals, along with speech data, for EMG-to-text conversion, which is not practical for such individuals. Given the rise of large language models (LLMs) in speech recognition, we explore their potential to understand unvoiced speech. To this end, we address the challenge of learning from unvoiced EMG alone and propose a novel EMG adaptor module that maps EMG features into an LLM's input space, achieving an average word error rate (WER) of 0.49 on a closed-vocabulary unvoiced EMG-to-text task. Even with a conservative data availability of just six minutes, our approach improves performance over specialized models by nearly 20%. While LLMs have been shown to be extendable to new language modalities -- such as audio -- understanding articulatory biosignals like unvoiced EMG remains more challenging. This work takes a crucial first step toward enabling LLMs to comprehend unvoiced speech using surface EMG.",
    "keywords": "N/A",
    "pdf_url": "https://arxiv.org/pdf/2506.00304",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper's title, \"Can LLMs Understand Unvoiced Speech? Exploring EMG-to-Text Conversion with LLMs,\" suggests that it involves converting electromyographic (EMG) signals into text using large language models (LLMs). Although the abstract and keywords are unavailable, EMG is commonly used in medical or clinical contexts, such as speech prosthetics, patient rehabilitation, or assistive technologies for individuals with speech impairments (e.g., patients with ALS, strokes, or other disorders affecting communication). This potential application in healthcare and assistive devices indicates relevance to the Healthcare AI and Biomedicine AI domains. Specifically, leveraging EMG for unvoiced speech could represent a healthcare tool for improving communication and quality of life for patients.",
    "prompt_tokens": 21960,
    "completion_tokens": 239,
    "total_tokens": 22199,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Physiological Time Series Analysis"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "LSTM-based models; Fine-tuned LLMs (Llama-3B)",
    "application": "EMG-to-text conversion",
    "code_link": "https://github.com/payalmohapatra/SilentSpeechLLM",
    "dataset_name": [
      "CSL-EMG_Array",
      "Gaddy Closed Vocabulary Dataset"
    ],
    "is_public": true
  },
  {
    "id": "2021.acl-long.322",
    "year": 2021,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Learning Language and Multimodal Privacy-Preserving Markers of Mood from Mobile Data",
    "authors": [
      "Paul Pu Liang",
      "Terrance Liu",
      "Anna Cai",
      "Michal Muszynski",
      "Ryo Ishii",
      "Nick Allen",
      "Randy Auerbach",
      "David Brent",
      "Ruslan Salakhutdinov",
      "Louis-Philippe Morency"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Mental health conditions remain underdiagnosed even in countries with common access to advanced medical care. The ability to accurately and efficiently predict mood from easily collectible data has several important implications for the early detection, intervention, and treatment of mental health disorders. One promising data source to help monitor human behavior is daily smartphone usage. However, care must be taken to summarize behaviors without identifying the user through personal (e.g., personally identifiable information) or protected (e.g., race, gender) attributes. In this paper, we study behavioral markers of daily mood using a recent dataset of mobile behaviors from adolescent populations at high risk of suicidal behaviors. Using computational models, we find that language and multimodal representations of mobile typed text (spanning typed characters, words, keystroke timings, and app usage) are predictive of daily mood. However, we find that models trained to predict mood often also capture private user identities in their intermediate representations. To tackle this problem, we evaluate approaches that obfuscate user identity while remaining predictive. By combining multimodal representations with privacy-preserving learning, we are able to push forward the performance-privacy frontier.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2021.acl-long.322.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly addresses the prediction of daily mood using data derived from smartphone usage, with the goal of improving the detection, intervention, and treatment of mental health disorders. Mental health is a critical aspect of healthcare, as evidenced by phrases like \"early detection, intervention, and treatment of mental health disorders\" and \"adolescent populations at high risk of suicidal behaviors.\" Additionally, the focus on privacy-preserving machine learning to protect user identity while monitoring behaviors supports the development of healthcare-related AI tools meant to operate practically in sensitive medical contexts. Although the dataset involves mobile behaviors rather than traditional clinical data, the overall aim aligns strongly with Healthcare AI, particularly within the domain of mental health monitoring and prevention.",
    "prompt_tokens": 22534,
    "completion_tokens": 233,
    "total_tokens": 22767,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Digital Health & Wearable Sensor Data"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Differential Privacy"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Multimodal models; Support Vector Machines (SVM); Multilayer Perceptron (MLP); Noisy Identity MLP (NI-MLP)",
    "application": "Mood prediction – adolescents at high risk for suicide",
    "code_link": "https://github.com/huggingface",
    "dataset_name": [
      "Mobile Assessment for the Prediction of Suicide (MAPS)"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_1418",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "CheXalign: Preference fine-tuning in chest X-ray interpretation models without human feedback",
    "authors": [
      "Dennis Hein",
      "Zhihong Chen",
      "Sophie Ostmeier",
      "Justin Xu",
      "Maya Varma",
      "Eduardo Pontes Reis",
      "Arne Edward Michalson MD",
      "Christian Bluethgen",
      "Hyun Joo Shin",
      "Curtis Langlotz",
      "Akshay S Chaudhari"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Radiologists play a crucial role in translating medical images into actionable reports. However, the field faces staffing shortages and increasing workloads. While automated approaches using vision-language models (VLMs) show promise as assistants, they require exceptionally high accuracy. Most current VLMs in radiology rely solely on supervised fine-tuning. Meanwhile, additional preference fine-tuning in the post-training pipeline has become standard practice in the general domain. The challenge in radiology lies in the prohibitive cost of obtaining radiologist feedback at scale. To address this challenge, we propose an automated pipeline for preference feedback, focusing on chest X-ray radiology report generation (RRG). Specifically, our method leverages publicly available datasets containing pairs of images and radiologist-written reference reports with reference-based metrics, or Judges, eliminating the need for *additional radiologist feedback*. We investigate reward overoptimization via length exploitation in this setting and introduce a length-controlled version of the GREEN score. Our best-performing setup achieves state-of-the-art CheXbert scores on the MIMIC-CXR dataset for the RRG task while on average maintaining robust performance across six additional image perception and reasoning tasks.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.1342.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title \"CheXalign: Preference fine-tuning in chest X-ray interpretation models without human feedback\" indicates that the paper pertains to chest X-ray interpretation, which is a medical imaging task fundamental to healthcare applications for diagnosing and monitoring various thoracic conditions (e.g., pneumonia, lung cancer). \"Preference fine-tuning\" refers to improving model performance, potentially in decision-making or ranking interpretation results relevant to clinical contexts. Chest X-rays are a common diagnostic tool in healthcare, making this paper clearly relevant to the Healthcare AI domain.",
    "prompt_tokens": 22272,
    "completion_tokens": 232,
    "total_tokens": 22504,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Radiology"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Vision Foundation Models (VFMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "DPO; LC-DPO; IPO; KTO; ORPO",
    "application": "Radiology report generation",
    "code_link": "https://github.com/StanfordMIMI/CheXalign",
    "dataset_name": [
      "MIMIC-CXR",
      "CheXpert Plus",
      "RSNA",
      "SIIM",
      "OpenI",
      "SLAKE",
      "Rad-Restruct"
    ],
    "is_public": true
  },
  {
    "id": "2024.acl-long.230",
    "year": 2024,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Transferable Embedding Inversion Attack: Uncovering Privacy Risks in Text Embeddings without Model Queries",
    "authors": [
      "Yu-Hsiang Huang",
      "Yuche Tsai",
      "Hsiang Hsiao",
      "Hong-Yi Lin",
      "Shou-De Lin"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "This study investigates the privacy risks associated with text embeddings, focusing on the scenario where attackers cannot access the original embedding model. Contrary to previous research requiring direct model access, we explore a more realistic threat model by developing a transfer attack method. This approach uses a surrogate model to mimic the victim model’s behavior, allowing the attacker to infer sensitive information from text embeddings without direct access. Our experiments across various embedding models and a clinical dataset demonstrate that our transfer attack significantly outperforms traditional methods, revealing the potential privacy vulnerabilities in embedding technologies and emphasizing the need for enhanced security measures.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2024.acl-long.230.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract explicitly mentions the use of a \"clinical dataset\" in the experiments, which ties the research to the healthcare or biomedical domain. While the core focus of the paper is on text embedding privacy risks and transfer attacks, the use of clinical data highlights potential implications for sensitive healthcare-related information privacy. The relevance to healthcare AI lies in the privacy concerns surrounding text embeddings applied in clinical or healthcare contexts, where safeguarding sensitive data is critical.",
    "prompt_tokens": 22102,
    "completion_tokens": 219,
    "total_tokens": 22321,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Differential Privacy"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Adversarial training; embedding inversion; surrogate modeling",
    "application": "Sensitive information recovery from embeddings",
    "code_link": "N/A",
    "dataset_name": [
      "MIMIC-III",
      "QNLI",
      "IMDB",
      "AG News",
      "PersonaChat"
    ],
    "is_public": false
  },
  {
    "id": "acl2025_temp_1424",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Online Iterative Self-Alignment for Radiology Report Generation",
    "authors": [
      "Ting Xiao",
      "Lei Shi",
      "Yang Zhang",
      "HaoFeng Yang",
      "Zhe Wang",
      "Chenjia Bai"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Radiology Report Generation (RRG) is an important research topic for relieving radiologist' heavy workload. Existing RRG models mainly rely on supervised fine-tuning (SFT) based on different model architectures using data pairs of radiological images and corresponding radiologist-annotated reports. Recent research has shifted focus to post-training improvements, aligning RRG model outputs with human preferences using reinforcement learning (RL). However, the limited data coverage of high-quality annotated data poses risks of overfitting and generalization. This paper proposes a novel Online Iterative Self-Alignment (OISA) method for RRG that consists of four stages: self-generation of diverse data, self-evaluation for multi-objective preference data,self-alignment for multi-objective optimization and self-iteration for further improvement. Our approach allows for generating varied reports tailored to specific clinical objectives, enhancing the overall performance of the RRG model iteratively. Unlike existing methods, our frame-work significantly increases data quality and optimizes performance through iterative multi-objective optimization. Experimental results demonstrate that our method surpasses previous approaches, achieving state-of-the-art performance across multiple evaluation metrics.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.1348.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title \"Online Iterative Self-Alignment for Radiology Report Generation\" explicitly mentions radiology, a core medical domain. The paper appears to focus on generating radiology reports, which are essential in clinical workflows for disease diagnosis and understanding patient conditions. This task indicates direct applicability to Healthcare AI, as radiology report generation is a healthcare-specific application involving medical imaging and natural language processing to improve physician efficiency and patient outcomes. While abstract and keywords are unavailable, radiology is inherently part of healthcare.",
    "prompt_tokens": 22373,
    "completion_tokens": 205,
    "total_tokens": 22578,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Radiology"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Preference optimization; Multi-objective direct preference optimization; Self-evaluation; Self-alignment",
    "application": "Radiology report generation",
    "code_link": "N/A",
    "dataset_name": [
      "MIMIC-CXR",
      "IU-Xray"
    ],
    "is_public": false
  },
  {
    "id": "acl2025_temp_0048",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Aligning AI Research with the Needs of Clinical Coding Workflows: Eight Recommendations Based on US Data Analysis and Critical Review",
    "authors": [
      "Yidong Gan",
      "Maciej Rybinski",
      "Ben Hachey",
      "Jonathan K. Kummerfeld"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Clinical coding is crucial for healthcare billing and data analysis. Manual clinical coding is labour-intensive and error-prone, which has motivated research towards full automation of the process. However, our analysis, based on US English electronic health records and automated coding research using these records, shows that widely used evaluation methods are not aligned with real clinical contexts. For example, evaluations that focus on the top 50 most common codes are an oversimplification, as there are thousands of codes used in practice. This position paper aims to align AI coding research more closely with practical challenges of clinical coding. Based on our analysis, we offer eight specific recommendations, suggesting ways to improve current evaluation methods. Additionally, we propose new AI-based methods beyond automated coding, suggesting alternative approaches to assist clinical coders in their workflows.",
    "keywords": "N/A",
    "pdf_url": "https://arxiv.org/pdf/2412.18043",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title explicitly mentions \"Aligning AI Research with the Needs of Clinical Coding Workflows,\" which points to a focus on healthcare-specific applications. The reference to \"clinical coding workflows\" suggests a direct connection to healthcare processes, as clinical coding is a fundamental part of managing and analyzing Electronic Health Records (EHR), a key aspect of Healthcare AI. Although the abstract and keywords are not provided, the mention of \"clinical\" and \"coding workflows\" strongly imply the paper pertains to the domain of Healthcare AI.",
    "prompt_tokens": 22441,
    "completion_tokens": 212,
    "total_tokens": 22653,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "new-AI for Clinical Workflow Analysis"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "AI for Clinical Decision Support (CDS)"
    },
    "method": "Multilabel classification using pretrained language models (PLM-ICD) incorporating domain-specific pretraining and segment pooling",
    "application": "Automated diagnostic and procedural ICD coding from clinical text",
    "code_link": "N/A",
    "dataset_name": [
      "MIMIC-III",
      "MIMIC-IV"
    ],
    "is_public": false
  },
  {
    "id": "2021.acl-long.120",
    "year": 2021,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Leveraging Type Descriptions for Zero-shot Named Entity Recognition and Classification",
    "authors": [
      "Rami Aly",
      "Andreas Vlachos",
      "Ryan McDonald"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "A common issue in real-world applications of named entity recognition and classification (NERC) is the absence of annotated data for the target entity classes during training. Zero-shot learning approaches address this issue by learning models from classes with training data that can predict classes without it. This paper presents the first approach for zero-shot NERC, introducing novel architectures that leverage the fact that textual descriptions for many entity classes occur naturally. We address the zero-shot NERC specific challenge that the not-an-entity class is not well defined as different entity classes are considered in training and testing. For evaluation, we adapt two datasets, OntoNotes and MedMentions, emulating the difficulty of real-world zero-shot learning by testing models on the rarest entity classes. Our proposed approach outperforms baselines adapted from machine reading comprehension and zero-shot text classification. Furthermore, we assess the effect of different class descriptions for this task.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2021.acl-long.120.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper evaluates zero-shot named entity recognition and classification (NERC) methods on datasets including MedMentions, which is a biomedical dataset containing entity mentions from medical literature. This indicates the methodology has relevance and potential applications in the biomedical domain. Additionally, MedMentions focuses on identifying and classifying biomedical entities, such as diseases, drugs, or anatomical terms, which aligns with tasks in Biomedicine AI. Thus, the paper's focus and evaluation clearly intersect with biomedical applications, justifying a classification as Biomedicine AI.",
    "prompt_tokens": 22196,
    "completion_tokens": 236,
    "total_tokens": 22432,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "new-Named Entity Recognition with entity type descriptions for transfer learning"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (BERT, SMXM)"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "new-Collaborative entity description refinement"
    },
    "method": "Entity masking; Transformer-based models (BERT, SMXM); Self-supervised learning",
    "application": "Named Entity Recognition Classification (NERC) – Zero-Shot learning evaluation",
    "code_link": "N/A",
    "dataset_name": [
      "OntoNotes-ZS",
      "MedMentions-ZS"
    ],
    "is_public": false
  },
  {
    "id": "2022.acl-long.15",
    "year": 2022,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Discriminative Marginalized Probabilistic Neural Method for Multi-Document Summarization of Medical Literature",
    "authors": [
      "Gianluca Moro",
      "Luca Ragazzi",
      "Lorenzo Valgimigli",
      "Davide Freddi"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Although current state-of-the-art Transformer-based solutions succeeded in a wide range for single-document NLP tasks, they still struggle to address multi-input tasks such as multi-document summarization. Many solutions truncate the inputs, thus ignoring potential summary-relevant contents, which is unacceptable in the medical domain where each information can be vital. Others leverage linear model approximations to apply multi-input concatenation, worsening the results because all information is considered, even if it is conflicting or noisy with respect to a shared background. Despite the importance and social impact of medicine, there are no ad-hoc solutions for multi-document summarization. For this reason, we propose a novel discriminative marginalized probabilistic method (DAMEN) trained to discriminate critical information from a cluster of topic-related medical documents and generate a multi-document summary via token probability marginalization. Results prove we outperform the previous state-of-the-art on a biomedical dataset for multi-document summarization of systematic literature reviews. Moreover, we perform extensive ablation studies to motivate the design choices and prove the importance of each module of our method.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2022.acl-long.15.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper is directly relevant to the Biomedicine AI domain, as it addresses multi-document summarization specifically for medical literature, with a focus on systematic literature reviews. Systematic reviews are critical in medical research to consolidate evidence for clinical practice, and the paper highlights the importance of not ignoring any potential summary-relevant content due to the high stakes in the medical domain. The explicit reference to medical literature and systematic reviews, which are foundational in evidence-based medicine, strongly aligns this paper with Biomedicine AI.",
    "prompt_tokens": 22207,
    "completion_tokens": 209,
    "total_tokens": 22416,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Systematic literature reviews – multi-document summarization of medical studies"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Token probability marginalization; BERT-based method; BART model",
    "application": "Multi-document summarization – system literature reviews",
    "code_link": "https://disi-unibo-nlp.github.io/projects/damen",
    "dataset_name": [
      "MS2"
    ],
    "is_public": true
  },
  {
    "id": "2021.acl-long.109",
    "year": 2021,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "CLIP: A Dataset for Extracting Action Items for Physicians from Hospital Discharge Notes",
    "authors": [
      "James Mullenbach",
      "Yada Pruksachatkun",
      "Sean Adler",
      "Jennifer Seale",
      "Jordan Swartz",
      "Greg McKelvey",
      "Hui Dai",
      "Yi Yang",
      "David Sontag"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Continuity of care is crucial to ensuring positive health outcomes for patients discharged from an inpatient hospital setting, and improved information sharing can help. To share information, caregivers write discharge notes containing action items to share with patients and their future caregivers, but these action items are easily lost due to the lengthiness of the documents. In this work, we describe our creation of a dataset of clinical action items annotated over MIMIC-III, the largest publicly available dataset of real clinical notes. This dataset, which we call CLIP, is annotated by physicians and covers 718 documents representing 100K sentences. We describe the task of extracting the action items from these documents as multi-aspect extractive summarization, with each aspect representing a type of action to be taken. We evaluate several machine learning models on this task, and show that the best models exploit in-domain language model pre-training on 59K unannotated documents, and incorporate context from neighboring sentences. We also propose an approach to pre-training data selection that allows us to explore the trade-off between size and domain-specificity of pre-training datasets for this task.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2021.acl-long.109.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper is clearly relevant to Healthcare AI as it focuses on extracting clinical action items from hospital discharge notes—a task directly tied to improving continuity of care and patient outcomes, which are critical aspects of healthcare. The dataset, CLIP, is derived from MIMIC-III, a well-known medical dataset of clinical notes, further solidifying its relevance to the healthcare domain. Additionally, the abstract mentions \"physicians,\" \"clinical action items,\" and \"hospital discharge notes,\" which are explicitly linked to healthcare contexts. The proposed methods also aim to improve actionable communication between caregivers, which is a key application in healthcare settings. Thus, the paper falls firmly within the Healthcare AI domain.",
    "prompt_tokens": 22006,
    "completion_tokens": 230,
    "total_tokens": 22236,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Pretraining on in-domain data; BERT-based sentence classification; Context-based representation learning; Sentence-level multi-label classification",
    "application": "clinical action item extraction – ICU discharge notes",
    "code_link": "https://github.com/asappresearch/clip",
    "dataset_name": [
      "MIMIC-III",
      "CLIP"
    ],
    "is_public": true
  },
  {
    "id": "2022.acl-long.329",
    "year": 2022,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Rewire-then-Probe: A Contrastive Recipe for Probing Biomedical Knowledge of Pre-trained Language Models",
    "authors": [
      "Zaiqiao Meng",
      "Fangyu Liu",
      "Ehsan Shareghi",
      "Yixuan Su",
      "Charlotte Collins",
      "Nigel Collier"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Knowledge probing is crucial for understanding the knowledge transfer mechanism behind the pre-trained language models (PLMs). Despite the growing progress of probing knowledge for PLMs in the general domain, specialised areas such as the biomedical domain are vastly under-explored. To facilitate this, we release a well-curated biomedical knowledge probing benchmark, MedLAMA, constructed based on the Unified Medical Language System (UMLS) Metathesaurus. We test a wide spectrum of state-of-the-art PLMs and probing approaches on our benchmark, reaching at most 3% of acc@10. While highlighting various sources of domain-specific challenges that amount to this underwhelming performance, we illustrate that the underlying PLMs have a higher potential for probing tasks. To achieve this, we propose Contrastive-Probe, a novel self-supervised contrastive probing approach, that adjusts the underlying PLMs without using any probing data. While Contrastive-Probe pushes the acc@10 to 28%, the performance gap still remains notable. Our human expert evaluation suggests that the probing performance of our Contrastive-Probe is still under-estimated as UMLS still does not include the full spectrum of factual knowledge. We hope MedLAMA and Contrastive-Probe facilitate further developments of more suited probing techniques for this domain. Our code and dataset are publicly available at https://github.com/cambridgeltl/medlama.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2022.acl-long.329.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly discusses a probing benchmark called \"MedLAMA\" constructed based on the Unified Medical Language System (UMLS) Metathesaurus, which is a resource widely used in the biomedical domain. Additionally, the paper highlights challenges associated with probing biomedical knowledge from pre-trained language models (PLMs) and introduces a novel method, Contrastive-Probe, to improve the probing of biomedical knowledge. The references to \"biomedical knowledge probing,\" \"Unified Medical Language System,\" and \"domain-specific challenges\" directly align with the Biomedicine AI domain. These factors confirm the paper’s relevance to Biomedicine AI.",
    "prompt_tokens": 22364,
    "completion_tokens": 225,
    "total_tokens": 22589,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-Contrastive Probing Techniques for Biomedical NLP domains"
    },
    "method": "Self-supervised contrastive probing approach",
    "application": "Knowledge probing of biomedical pre-trained language models using MedLAMA benchmark",
    "code_link": "https://github.com/cambridgeltl/medlama",
    "dataset_name": [
      "UMLS MedLAMA"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0061",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Automatic detection of dyslexia based on eye movements during reading in Russian",
    "authors": [
      "Anna Laurinavichyute",
      "Anastasiya Lopukhina",
      "David Robert Reich"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Dyslexia, a common learning disability, requires an early diagnosis. However, current screening tests are very time- and resource-consuming. We present an LSTM that aims to automatically classify dyslexia based on eye movements recorded during natural readingcombined with basic demographic information and linguistic features. The proposed model reaches an AUC of 0.93 and outperforms thestate-of-the-art model by 7 %. We report several ablation studies demonstrating that the fixation features matter the most for classification.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-short.5.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper titled \"Automatic detection of dyslexia based on eye movements during reading in Russian\" implies an application of AI to identify dyslexia, a neurodevelopmental disorder with implications for health and education. Dyslexia detection is closely tied to healthcare as it involves understanding and diagnosing a condition that affects reading ability and brain functioning. Eye movement data during reading can be interpreted as neurobiological signals relevant to detecting and potentially managing dyslexia, aligning this work with the Healthcare AI domain.",
    "prompt_tokens": 21118,
    "completion_tokens": 215,
    "total_tokens": 21333,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Physiological Time Series Analysis"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "BiLSTM; Demographic features; Eye-movement features",
    "application": "Dyslexia classification using eye movements – Russian language",
    "code_link": "https://github.com/annlaurin/Rus_dyslex_classification",
    "dataset_name": [
      "Child Russian Sentence Corpus",
      "Russian National Corpus",
      "Readability Test"
    ],
    "is_public": true
  },
  {
    "id": "2021.acl-long.525",
    "year": 2021,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Learning Latent Structures for Cross Action Phrase Relations in Wet Lab Protocols",
    "authors": [
      "Chaitanya Kulkarni",
      "Jany Chan",
      "Eric Fosler-Lussier",
      "Raghu Machiraju"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Wet laboratory protocols (WLPs) are critical for conveying reproducible procedures in biological research. They are composed of instructions written in natural language describing the step-wise processing of materials by specific actions. This process flow description for reagents and materials synthesis in WLPs can be captured by material state transfer graphs (MSTGs), which encode global temporal and causal relationships between actions. Here, we propose methods to automatically generate a MSTG for a given protocol by extracting all action relationships across multiple sentences. We also note that previous corpora and methods focused primarily on local intra-sentence relationships between actions and entities and did not address two critical issues: (i) resolution of implicit arguments and (ii) establishing long-range dependencies across sentences. We propose a new model that incrementally learns latent structures and is better suited to resolving inter-sentence relations and implicit arguments. This model draws upon a new corpus WLP-MSTG which was created by extending annotations in the WLP corpora for inter-sentence relations and implicit arguments. Our model achieves an F1 score of 54.53% for temporal and causal relations in protocols from our corpus, which is a significant improvement over previous models - DyGIE++:28.17%; spERT:27.81%. We make our annotated WLP-MSTG corpus available to the research community.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2021.acl-long.525.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on analyzing and structuring wet laboratory protocols (WLPs), which are fundamental to biological research. These protocols involve material synthesis and processing, as well as annotations for temporal and causal relationships between actions, suggesting relevance to experimental biomedicine. The creation of material state transfer graphs (MSTGs) aids in understanding and replicating biological experiments, which is critical for advancing biomedical research. While the paper does not explicitly state applications in healthcare or clinical domains, the emphasis on protocols for biological experimentation aligns strongly with the Biomedicine AI domain, as these methods can contribute to areas like drug discovery, molecular biology, or experimental therapeutics indirectly.",
    "prompt_tokens": 22221,
    "completion_tokens": 202,
    "total_tokens": 22423,
    "Topic Axis I": {
      "MainTopic": "Healthcare Systems & Operations",
      "SubTopic": "Clinical Trial Optimization"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Graph Representation Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Inherently Interpretable Models"
    },
    "method": "Multi-head relational graph convolutional networks; Relational convolutions",
    "application": "Temporal and causal relation extraction – Wet lab protocols",
    "code_link": "N/A",
    "dataset_name": [
      "WLP-MSTG Corpus",
      "WLP Corpus",
      "WNUT 2020"
    ],
    "is_public": false
  },
  {
    "id": "acl2025_temp_1586",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "DDxTutor: Clinical Reasoning Tutoring System with Differential Diagnosis-Based Structured Reasoning",
    "authors": [
      "Qian Wu",
      "Zheyao Gao",
      "Longfei Gou",
      "Qi Dou"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Clinical diagnosis education requires students to master both systematic reasoning processes and comprehensive medical knowledge. While recent advances in Large Language Models (LLMs) have enabled various medical educational applications, these systems often provide direct answers that could reduce students’ cognitive engagement and lead to fragmented learning. Motivated by these challenges, we propose DDxTutor, a framework that follows differential diagnosis principles to decompose clinical reasoning into teachable components. It consists of a structured reasoning module that analyzes clinical clues and synthesizes diagnostic conclusions, and an interactive dialogue framework that guides students through this process. To enable such tutoring, we construct DDxReasoning, a dataset of 933 clinical cases with fine-grained diagnostic steps verified by doctors. Our experiments demonstrate that fine-tuned LLMs achieve strong performance in generating structured teaching references and conducting interactive diagnostic tutoring dialogues. Human evaluation by medical educators and students validates the framework’s potential and effectiveness for clinical diagnosis education. Our project is available at https://github.com/med-air/DDxTutor.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.1495.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title mentions \"Clinical Reasoning Tutoring System with Differential Diagnosis-Based Structured Reasoning,\" which emphasizes structured clinical reasoning based on differential diagnosis. Differential diagnosis is a fundamental process in medical practice used to identify conditions and diseases. This strongly indicates relevance to Healthcare AI, as the paper aims to support clinical decision-making, likely through an AI system designed for healthcare applications focused on diagnosis and reasoning tasks.",
    "prompt_tokens": 22202,
    "completion_tokens": 207,
    "total_tokens": 22409,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Local analysis and global synthesis; structured differential diagnosis reasoning; GPT-4o generation",
    "application": "Interactive diagnostic tutoring system development",
    "code_link": "N/A",
    "dataset_name": [
      "DDxReasoning Dataset",
      "MedQA"
    ],
    "is_public": false
  },
  {
    "id": "2024.acl-long.386",
    "year": 2024,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "ChiMed-GPT: A Chinese Medical Large Language Model with Full Training Regime and Better Alignment to Human Preferences",
    "authors": [
      "Yuanhe Tian",
      "Ruyi Gan",
      "Yan Song",
      "Jiaxing Zhang",
      "Yongdong Zhang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Recently, the increasing demand for superior medical services has highlighted the discrepancies in the medical infrastructure. With big data, especially texts, forming the foundation of medical services, there is an exigent need for effective natural language processing (NLP) solutions tailored to the healthcare domain. Conventional approaches leveraging pre-trained models present promising results in this domain and current large language models (LLMs) offer advanced foundation for medical text processing. However, most medical LLMs are trained only with supervised fine-tuning (SFT), even though it efficiently empowers LLMs to understand and respond to medical instructions but is ineffective in learning domain knowledge and aligning with human preference. In this work, we propose ChiMed-GPT, a new benchmark LLM designed explicitly for Chinese medical domain, and undergoes a comprehensive training regime with pre-training, SFT, and RLHF. Evaluations on tasks including information extraction, question answering, and dialogue generation demonstrate ChiMed-GPT’s superior performance over general domain LLMs. Furthermore, we analyze possible biases through prompting ChiMed-GPT to perform attitude scales regarding discrimination of patients, so as to contribute to further responsible development of LLMs in the medical domain.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2024.acl-long.386.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper clearly belongs to the Healthcare AI domain as it introduces ChiMed-GPT, a large language model specifically tailored to the Chinese medical domain. The abstract highlights its application to medical tasks such as information extraction, question answering, and dialogue generation, which are critical for healthcare-related NLP. Furthermore, the paper discusses its ability to align responses with human preferences in the medical domain and evaluates biases related to patient discrimination, further underscoring its focus on healthcare-specific use cases. These factors strongly indicate relevance to Healthcare AI.",
    "prompt_tokens": 21967,
    "completion_tokens": 254,
    "total_tokens": 22221,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (GPT, LLaMA)"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Algorithmic Fairness & Bias Mitigation"
    },
    "method": "Reinforcement learning from human feedback (RLHF); Supervised fine-tuning (SFT); Data augmentation",
    "application": "Medical classification and dialogue generation",
    "code_link": "https://github.com/synlp/ChiMed-GPT",
    "dataset_name": [
      "CMD (Pre-train)",
      "ChiMed",
      "CMD (SFT)",
      "MC",
      "MedDialog",
      "CMD (Reward)",
      "Safety-Prompts"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_1547",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Spurious Correlations and Beyond: Understanding and Mitigating Shortcut Learning in SDOH Extraction with Large Language Models",
    "authors": [
      "Fardin Ahsan Sakib",
      "Ziwei Zhu",
      "Karen Trister Grace",
      "Meliha Yetisgen",
      "Ozlem Uzuner"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Social determinants of health (SDOH) extraction from clinical text is critical for downstream healthcare analytics. Although large language models (LLMs) have shown promise, they may rely on superficial cues leading to spurious predictions. Using the MIMIC portion of the SHAC (Social History Annotation Corpus) dataset and focusing on drug status extraction as a case study, we demonstrate that mentions of alcohol or smoking can falsely induce models to predict current/past drug use where none is present, while also uncovering concerning gender disparities in model performance. We further evaluate mitigation strategies—such as prompt engineering and chain-of-thought reasoning—to reduce these false positives, providing insights into enhancing LLM reliability in health domains.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-short.86.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title, \"Spurious Correlations and Beyond: Understanding and Mitigating Shortcut Learning in SDOH Extraction with Large Language Models,\" implies relevance to healthcare AI due to the focus on \"SDOH,\" which refers to Social Determinants of Health. SDOHs are crucial factors in healthcare outcomes and clinical applications. The paper likely discusses the use of large language models to extract healthcare-relevant information, specifically related to social factors impacting health, and addresses methodological challenges like shortcut learning in this context. These characteristics firmly place the paper in the Healthcare AI domain.",
    "prompt_tokens": 22049,
    "completion_tokens": 246,
    "total_tokens": 22295,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Prompt Engineering"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "AI for Clinical Decision Support (CDS)"
    },
    "method": "Chain-of-Thought (CoT) prompting; warning-based strategies; in-context learning",
    "application": "Social determinants of health (SDOH) extraction; drug status time classification",
    "code_link": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/MODEL_CARD.md",
    "dataset_name": [
      "MIMIC-III",
      "SHAC"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0315",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "NGQA: A Nutritional Graph Question Answering Benchmark for Personalized Health-aware Nutritional Reasoning",
    "authors": [
      "Zheyuan Zhang",
      "Yiyang Li",
      "Nhi Ha Lan Le",
      "Zehong Wang",
      "Tianyi Ma",
      "Vincent Galassi",
      "Keerthiram Murugesan",
      "Nuno Moniz",
      "Werner Geyer",
      "Nitesh V Chawla",
      "Chuxu Zhang",
      "Yanfang Ye"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Diet plays a critical role in human health, yet tailoring dietary reasoning to individual health conditions remains a major challenge. Nutrition Question Answering (QA) has emerged as a popular method for addressing this problem. However, current research faces two critical limitations. On one hand, the absence of datasets involving user-specific medical information severely limits \textit{personalization}. This challenge is further compounded by the wide variability in individual health needs. On the other hand, while large language models (LLMs), a popular solution for this task, demonstrate strong reasoning abilities, they struggle with the domain-specific complexities of personalized healthy dietary reasoning, and existing benchmarks fail to capture these challenges. To address these gaps, we introduce the Nutritional Graph Question Answering (NGQA) benchmark, the first graph question answering dataset designed for personalized nutritional health reasoning. NGQA leverages data from the National Health and Nutrition Examination Survey (NHANES) and the Food and Nutrient Database for Dietary Studies (FNDDS) to evaluate whether a food is healthy for a specific user, supported by explanations of the key contributing nutrients. The benchmark incorporates three question complexity settings and evaluates reasoning across three downstream tasks. Extensive experiments with LLM backbones and baseline models demonstrate that the NGQA benchmark effectively challenges existing models. In sum, NGQA addresses a critical real-world problem while advancing GraphQA research with a novel domain-specific benchmark.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.296.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title mentions \"Nutritional Graph Question Answering\" and \"Personalized Health-aware Nutritional Reasoning,\" which strongly implies that the paper is focused on health-related applications, specifically personalized nutrition and health-aware decision-making. Although the abstract and keywords are unavailable, the title indicates a clear connection to healthcare and nutrition, which falls under the domain of Healthcare AI. Tasks involving personalized nutritional reasoning align with personalized medicine and health monitoring objectives, indicating relevance to this domain.",
    "prompt_tokens": 21383,
    "completion_tokens": 198,
    "total_tokens": 21581,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "Human-AI Collaborative Performance"
    },
    "method": "Graph Retrieval Augmented Generation (Graph-RAG)",
    "application": "personalized healthy nutrition intake question answering",
    "code_link": "N/A",
    "dataset_name": [
      "NHANES",
      "Food and Nutrient Database for Dietary Studies (FNDDS)"
    ],
    "is_public": false
  },
  {
    "id": "acl2025_temp_1157",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Boosting LLM’s Molecular Structure Elucidation with Knowledge Enhanced Tree Search Reasoning",
    "authors": [
      "Xiang Zhuang",
      "Bin Wu",
      "Jiyu Cui",
      "Kehua Feng",
      "Xiaotong Li",
      "Huabin Xing",
      "Keyan Ding",
      "Qiang Zhang",
      "Huajun Chen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Molecular structure elucidation involves deducing a molecule’s structure from various types of spectral data, which is crucial in chemical experimental analysis. While large language models (LLMs) have shown remarkable proficiency in analyzing and reasoning through complex tasks, they still encounter substantial challenges in molecular structure elucidation. We identify that these challenges largely stem from LLMs’ limited grasp of specialized chemical knowledge. In this work, we introduce a Knowledge-enhanced reasoning framework for Molecular Structure Elucidation (K-MSE), leveraging Monte Carlo Tree Search for test-time scaling as a plugin. Specifically, we construct an external molecular substructure knowledge base to extend the LLMs’ coverage of the chemical structure space. Furthermore, we design a specialized molecule-spectrum scorer to act as a reward model for the reasoning process, addressing the issue of inaccurate solution evaluation in LLMs. Experimental results show that our approach significantly boosts performance, particularly gaining more than 20% improvement on both GPT-4o-mini and GPT-4o.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.1100.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title \"Boosting LLM’s Molecular Structure Elucidation with Knowledge Enhanced Tree Search Reasoning\" indicates a focus on molecular structure elucidation, which is a key task in biomedical research, particularly in drug discovery and molecular biology. Although the abstract and keywords are not provided, the reference to \"molecular structure\" strongly suggests relevance to biomedical AI, as understanding molecular structures typically aids in applications like designing new drugs, studying biochemical interactions, or developing therapeutic agents. These tasks are firmly within the scope of biomedicine AI.",
    "prompt_tokens": 22065,
    "completion_tokens": 214,
    "total_tokens": 22279,
    "Topic Axis I": {
      "MainTopic": "Drug Discovery & Development",
      "SubTopic": "Target Identification & Validation"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Monte Carlo Tree Search; Transformer-based models (GPT-4o, GPT-4o-mini)",
    "application": "Molecular structure elucidation – chemical experimental analysis",
    "code_link": "https://github.com/HICAI-ZJU/K-MSE",
    "dataset_name": [
      "MolPuzzle"
    ],
    "is_public": true
  },
  {
    "id": "2024.acl-long.227",
    "year": 2024,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Multi-Level Feedback Generation with Large Language Models for Empowering Novice Peer Counselors",
    "authors": [
      "Alicja Chaszczewicz",
      "Raj Shah",
      "Ryan Louie",
      "Bruce Arnow",
      "Robert Kraut",
      "Diyi Yang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Realistic practice and tailored feedback are key processes for training peer counselors with clinical skills. However, existing mechanisms of providing feedback largely rely on human supervision. Peer counselors often lack mechanisms to receive detailed feedback from experienced mentors, making it difficult for them to support the large number of people with mental health issues who use peer counseling. Our work aims to leverage large language models to provide contextualized and multi-level feedback to empower peer counselors, especially novices, at scale. To achieve this, we co-design with a group of senior psychotherapy supervisors to develop a multi-level feedback taxonomy, and then construct a publicly available dataset with comprehensive feedback annotations of 400 emotional support conversations. We further design a self-improvement method on top of large language models to enhance the automatic generation of feedback. Via qualitative and quantitative evaluation with domain experts, we demonstrate that our method minimizes the risk of potentially harmful and low-quality feedback generation which is desirable in such high-stakes scenarios.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2024.acl-long.227.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on leveraging large language models (LLMs) to provide feedback for training peer counselors in delivering emotional support. Emotional support and peer counseling are directly related to mental health, which falls under the broader domain of healthcare. The abstract highlights that the system is designed in collaboration with senior psychotherapy supervisors, further reinforcing its clinical context. Since mental health is a critical aspect of healthcare, and the intervention aims to empower counselors supporting individuals with mental health issues, the paper relates to Healthcare AI and is classified as relevant to this domain.",
    "prompt_tokens": 22288,
    "completion_tokens": 219,
    "total_tokens": 22507,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (GPT, LLaMA)"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "Clinician-in-the-loop Systems"
    },
    "method": "Transformer-based models (Llama-2); Self-improvement via forecasting",
    "application": "Contextualized feedback generation – Peer counseling",
    "code_link": "https://github.com/SALT-NLP/counseling-feedback",
    "dataset_name": [
      "ESConv",
      "FeedbackESConv"
    ],
    "is_public": true
  },
  {
    "id": "2020.acl-main.141",
    "year": 2020,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Reasoning with Latent Structure Refinement for Document-Level Relation Extraction",
    "authors": [
      "Guoshun Nan",
      "Zhijiang Guo",
      "Ivan Sekulic",
      "Wei Lu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Document-level relation extraction requires integrating information within and across multiple sentences of a document and capturing complex interactions between inter-sentence entities. However, effective aggregation of relevant information in the document remains a challenging research question. Existing approaches construct static document-level graphs based on syntactic trees, co-references or heuristics from the unstructured text to model the dependencies. Unlike previous methods that may not be able to capture rich non-local interactions for inference, we propose a novel model that empowers the relational reasoning across sentences by automatically inducing the latent document-level graph. We further develop a refinement strategy, which enables the model to incrementally aggregate relevant information for multi-hop reasoning. Specifically, our model achieves an F1 score of 59.05 on a large-scale document-level dataset (DocRED), significantly improving over the previous results, and also yields new state-of-the-art results on the CDR and GDA dataset. Furthermore, extensive analyses show that the model is able to discover more accurate inter-sentence relations.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2020.acl-main.141.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract mentions the use of the proposed model on datasets like CDR and GDA, which are biomedical datasets focusing on tasks such as extracting relationships between chemicals, diseases, and genes. These are directly related to biomedicine and healthcare research. Additionally, the problem of document-level relation extraction is pertinent for understanding biomedical literature, where multi-hop reasoning is often necessary to analyze complex interactions such as gene-disease associations or drug-disease relationships. This strongly indicates the paper's relevance to Biomedicine AI.",
    "prompt_tokens": 41716,
    "completion_tokens": 227,
    "total_tokens": 41943,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Graph Representation Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-Latent Structure Reasoning"
    },
    "method": "Latent Structure Refinement (LSR); Graph Neural Networks (GNN)",
    "application": "document-level relation extraction",
    "code_link": "https://github.com/nanguoshun/LSR",
    "dataset_name": [
      "DocRED",
      "CDR",
      "GDA"
    ],
    "is_public": true
  },
  {
    "id": "2021.acl-long.122",
    "year": 2021,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Factuality Assessment as Modal Dependency Parsing",
    "authors": [
      "Jiarui Yao",
      "Haoling Qiu",
      "Jin Zhao",
      "Bonan Min",
      "Nianwen Xue"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "As the sources of information that we consume everyday rapidly diversify, it is becoming increasingly important to develop NLP tools that help to evaluate the credibility of the information we receive. A critical step towards this goal is to determine the factuality of events in text. In this paper, we frame factuality assessment as a modal dependency parsing task that identifies the events and their sources, formally known as conceivers, and then determine the level of certainty that the sources are asserting with respect to the events. We crowdsource the first large-scale data set annotated with modal dependency structures that consists of 353 Covid-19 related news articles, 24,016 events, and 2,938 conceivers. We also develop the first modal dependency parser that jointly extracts events, conceivers and constructs the modal dependency structure of a text. We evaluate the joint model against a pipeline model and demonstrate the advantage of the joint model in conceiver extraction and modal dependency structure construction when events and conceivers are automatically extracted. We believe the dataset and the models will be a valuable resource for a whole host of NLP applications such as fact checking and rumor detection.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2021.acl-long.122.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on assessing the factuality of events in text with applications such as fact-checking and rumor detection. The dataset described is specific to Covid-19-related news articles, indicating relevance to a healthcare domain, as Covid-19 is a health-related disease. While the methodology may apply to broader domains, the direct focus on Covid-19 and the information surrounding it clearly places the research in the context of public health and healthcare communication. The emphasis on evaluating the credibility of health information makes this paper relevant to Healthcare AI.",
    "prompt_tokens": 21745,
    "completion_tokens": 211,
    "total_tokens": 21956,
    "Topic Axis I": {
      "MainTopic": "N/A",
      "SubTopic": "N/A"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (GPT, BERT)"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Joint learning approach; Transformer-based models; Modal dependency parsing",
    "application": "Event factuality assessment",
    "code_link": "https://github.com/Jryao/modal_dependency",
    "dataset_name": [
      "MDS",
      "FactBank"
    ],
    "is_public": true
  },
  {
    "id": "2022.acl-long.458",
    "year": 2022,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "The AI Doctor Is In: A Survey of Task-Oriented Dialogue Systems for Healthcare Applications",
    "authors": [
      "Mina Valizadeh",
      "Natalie Parde"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Task-oriented dialogue systems are increasingly prevalent in healthcare settings, and have been characterized by a diverse range of architectures and objectives. Although these systems have been surveyed in the medical community from a non-technical perspective, a systematic review from a rigorous computational perspective has to date remained noticeably absent. As a result, many important implementation details of healthcare-oriented dialogue systems remain limited or underspecified, slowing the pace of innovation in this area. To fill this gap, we investigated an initial pool of 4070 papers from well-known computer science, natural language processing, and artificial intelligence venues, identifying 70 papers discussing the system-level implementation of task-oriented dialogue systems for healthcare applications. We conducted a comprehensive technical review of these papers, and present our key findings including identified gaps and corresponding recommendations.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2022.acl-long.458.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly focuses on task-oriented dialogue systems designed for healthcare applications, as stated in the title and abstract. It discusses healthcare settings and addresses specific implementations of AI systems tailored for healthcare-related tasks, emphasizing their impact on \"medical community\" applications. While the keywords are not provided, the abstract highlights relevance to \"healthcare applications\" and gaps that slow innovation in this area, which strongly ties the paper to the Healthcare AI domain.",
    "prompt_tokens": 22384,
    "completion_tokens": 198,
    "total_tokens": 22582,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (GPT, LLaMA)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "End-to-End Dialogue System Architecture",
    "application": "Diagnosis; Monitoring; Patient Assistance – Healthcare Dialogue Systems",
    "code_link": "N/A",
    "dataset_name": [
      "N/A"
    ],
    "is_public": false
  },
  {
    "id": "2021.acl-long.485",
    "year": 2021,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "An End-to-End Progressive Multi-Task Learning Framework for Medical Named Entity Recognition and Normalization",
    "authors": [
      "Baohang Zhou",
      "Xiangrui Cai",
      "Ying Zhang",
      "Xiaojie Yuan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Medical named entity recognition (NER) and normalization (NEN) are fundamental for constructing knowledge graphs and building QA systems. Existing implementations for medical NER and NEN are suffered from the error propagation between the two tasks. The mispredicted mentions from NER will directly influence the results of NEN. Therefore, the NER module is the bottleneck of the whole system. Besides, the learnable features for both tasks are beneficial to improving the model performance. To avoid the disadvantages of existing models and exploit the generalized representation across the two tasks, we design an end-to-end progressive multi-task learning model for jointly modeling medical NER and NEN in an effective way. There are three level tasks with progressive difficulty in the framework. The progressive tasks can reduce the error propagation with the incremental task settings which implies the lower level tasks gain the supervised signals other than errors from the higher level tasks to improve their performances. Besides, the context features are exploited to enrich the semantic information of entity mentions extracted by NER. The performance of NEN profits from the enhanced entity mention features. The standard entities from knowledge bases are introduced into the NER module for extracting corresponding entity mentions correctly. The empirical results on two publicly available medical literature datasets demonstrate the superiority of our method over nine typical methods.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2021.acl-long.485.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on medical named entity recognition (NER) and normalization (NEN), which are explicitly described as fundamental tasks for constructing knowledge graphs and building QA systems in the medical domain. The term \"medical literature datasets\" confirms its healthcare and biomedical relevance, as it suggests the application of AI models to health-related data sources. Additionally, the discussion of standard entities from knowledge bases and semantic information related to entity mentions further indicates the paper's focus on health-specific information extraction and organization, which ties directly to Healthcare AI and Biomedicine AI domains.",
    "prompt_tokens": 22102,
    "completion_tokens": 237,
    "total_tokens": 22339,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (e.g., BERT, BioBERT)"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Progressive multi-task learning; attention mechanism; BERT-based feature extraction",
    "application": "Medical named entity recognition (NER) and normalization (NEN)",
    "code_link": "https://github.com/zhoubaohang/E2EMERN",
    "dataset_name": [
      "NCBI",
      "BC5CDR"
    ],
    "is_public": true
  },
  {
    "id": "2024.acl-long.62",
    "year": 2024,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "InstructProtein: Aligning Human and Protein Language via Knowledge Instruction",
    "authors": [
      "Zeyuan Wang",
      "Qiang Zhang",
      "Keyan Ding",
      "Ming Qin",
      "Xiang Zhuang",
      "Xiaotong Li",
      "Huajun Chen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Large Language Models (LLMs) have revolutionized the field of natural language processing, but they fall short in comprehending biological sequences such as proteins. To address this challenge, we propose InstructProtein, an innovative LLM that possesses bidirectional generation capabilities in both human and protein languages: (i) taking a protein sequence as input to predict its textual function description and (ii) using natural language to prompt protein sequence generation. To achieve this, we first pre-train an LLM on both protein and natural language corpora, enabling it to comprehend individual languages. Then supervised instruction tuning is employed to facilitate the alignment of these two distinct languages. Herein, we introduce a knowledge graph-based instruction generation framework to construct a high-quality instruction dataset, addressing the annotation imbalance and the absence of instructional signals in the existing protein-text corpus. In particular, the instructions inherit the structural relations between proteins and function annotations in knowledge graphs, which empowers our model to engage in the causal modeling of protein functions, akin to the chain-of-thought processes in natural languages. Extensive experiments on bidirectional protein-text generation tasks show that InstructProtein outperforms state-of-the-art LLMs by a large margin.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2024.acl-long.62.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly discusses protein sequence analysis and generation, which is a key area of biomedical research. Concepts such as \"protein sequence,\" \"function prediction,\" and \"causal modeling of protein functions\" are directly related to understanding molecular-level data in biomedicine. Furthermore, the use of a knowledge graph-based framework for protein function annotation aligns with efforts in drug discovery, molecular modeling, and therapeutic protein design—all relevant to Biomedicine AI. While the paper does not mention healthcare applications explicitly, the focus on aligning human and protein languages has clear implications for biomedical tasks, such as designing functional proteins for therapeutic use.",
    "prompt_tokens": 40803,
    "completion_tokens": 250,
    "total_tokens": 41053,
    "Topic Axis I": {
      "MainTopic": "Computational Genomics & Multi-Omics",
      "SubTopic": "Proteomics & Protein Structure"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Diffusion Models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Multimodal Language Model; Knowledge Graph-based Instruction tuning; Chain-of-thought reasoning; Knowledge representation with causal modeling (KCM)",
    "application": "Protein sequence design",
    "code_link": "https://github.com/HICAI-ZJU/InstructProtein",
    "dataset_name": [
      "Gene Ontology (GO)",
      "InterPro",
      "UniProtKB"
    ],
    "is_public": true
  },
  {
    "id": "2023.acl-long.225",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Knowledge-enhanced Mixed-initiative Dialogue System for Emotional Support Conversations",
    "authors": [
      "Yang Deng",
      "Wenxuan Zhang",
      "Yifei Yuan",
      "Wai Lam"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Unlike empathetic dialogues, the system in emotional support conversations (ESC) is expected to not only convey empathy for comforting the help-seeker, but also proactively assist in exploring and addressing their problems during the conversation. In this work, we study the problem of mixed-initiative ESC where the user and system can both take the initiative in leading the conversation. Specifically, we conduct a novel analysis on mixed-initiative ESC systems with a tailor-designed schema that divides utterances into different types with speaker roles and initiative types. Four emotional support metrics are proposed to evaluate the mixed-initiative interactions. The analysis reveals the necessity and challenges of building mixed-initiative ESC systems. In the light of this, we propose a knowledge-enhanced mixed-initiative framework (KEMI) for ESC, which retrieves actual case knowledge from a large-scale mental health knowledge graph for generating mixed-initiative responses. Experimental results on two ESC datasets show the superiority of KEMI in both content-preserving evaluation and mixed initiative related analyses.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.225.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses the development of a mixed-initiative dialogue system for emotional support conversations (ESC), which includes assisting users in exploring and addressing their problems, an application directly relevant to mental health—a key aspect of Healthcare AI. Additionally, the use of a mental health knowledge graph further emphasizes the paper’s focus on healthcare-related tasks. Emotional support and mental health applications fall under the scope of Healthcare AI as they involve enhancing psychological well-being and providing supportive interventions. Furthermore, the system addresses challenges specific to emotional support dialogues, a critical area in digital health interventions.",
    "prompt_tokens": 21838,
    "completion_tokens": 213,
    "total_tokens": 22051,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Digital Health & Wearable Sensor Data"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "Human-AI Collaborative Performance"
    },
    "method": "Seq2Seq learning; multi-task learning; BlenderBot-based model; retrieval-augmented generation",
    "application": "Emotional support conversation system for mixed-initiative interaction",
    "code_link": "https://huggingface.co/facebook/blenderbot_small-90M",
    "dataset_name": [
      "ESConv",
      "MI"
    ],
    "is_public": true
  },
  {
    "id": "2023.acl-long.741",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "UniCoRN: Unified Cognitive Signal ReconstructioN bridging cognitive signals and human language",
    "authors": [
      "Nuwa Xi",
      "Sendong Zhao",
      "Haochun Wang",
      "Chi Liu",
      "Bing Qin",
      "Ting Liu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Decoding text stimuli from cognitive signals (e.g. fMRI) enhances our understanding of the human language system, paving the way for building versatile Brain-Computer Interface. However, existing studies largely focus on decoding individual word-level fMRI volumes from a restricted vocabulary, which is far too idealized for real-world application. In this paper, we propose fMRI2text, the first open-vocabulary task aiming to bridge fMRI time series and human language. Furthermore, to explore the potential of this new task, we present a baseline solution, UniCoRN: the Unified Cognitive Signal ReconstructioN for Brain Decoding. By reconstructing both individual time points and time series, UniCoRN establishes a robust encoder for cognitive signals (fMRI & EEG). Leveraging a pre-trained language model as decoder, UniCoRN proves its efficacy in decoding coherent text from fMRI series across various split settings. Our model achieves a 34.77% BLEU score on fMRI2text, and a 37.04% BLEU when generalized to EEG-to-text decoding, thereby surpassing the former baseline. Experimental results indicate the feasibility of decoding consecutive fMRI volumes, and the effectiveness of decoding different cognitive signals using a unified structure.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.741.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses decoding text stimuli from cognitive signals such as fMRI and EEG, which are commonly used in neuroscience and biomedical research. fMRI and EEG are explicitly mentioned as cognitive signals, and these modalities are frequently applied in domains like brain-computer interfaces, neurological research, and investigation of brain activity related to language processing. These topics are closely tied to Biomedicine AI where understanding brain function, cognitive systems, and neurological health is central. While the paper does not explicitly mention healthcare or clinical applications, the focus on reconstructing human language from brain signals suggests potential implications for medical research, such as aiding patients with neurological disorders or enhancing neuroprosthetic technologies.",
    "prompt_tokens": 22192,
    "completion_tokens": 197,
    "total_tokens": 22389,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Physiological Time Series Analysis"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Inherently Interpretable Models"
    },
    "method": "Multi-layer transformer encoder; Representation learning",
    "application": "Text decoding – fMRI time-series",
    "code_link": "N/A",
    "dataset_name": [
      "Narratives",
      "ZuCo1.0"
    ],
    "is_public": false
  },
  {
    "id": "2021.acl-long.488",
    "year": 2021,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Joint Biomedical Entity and Relation Extraction with Knowledge-Enhanced Collective Inference",
    "authors": [
      "Tuan Lai",
      "Heng Ji",
      "ChengXiang Zhai",
      "Quan Hung Tran"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Compared to the general news domain, information extraction (IE) from biomedical text requires much broader domain knowledge. However, many previous IE methods do not utilize any external knowledge during inference. Due to the exponential growth of biomedical publications, models that do not go beyond their fixed set of parameters will likely fall behind. Inspired by how humans look up relevant information to comprehend a scientific text, we present a novel framework that utilizes external knowledge for joint entity and relation extraction named KECI (Knowledge-Enhanced Collective Inference). Given an input text, KECI first constructs an initial span graph representing its initial understanding of the text. It then uses an entity linker to form a knowledge graph containing relevant background knowledge for the the entity mentions in the text. To make the final predictions, KECI fuses the initial span graph and the knowledge graph into a more refined graph using an attention mechanism. KECI takes a collective approach to link mention spans to entities by integrating global relational information into local representations using graph convolutional networks. Our experimental results show that the framework is highly effective, achieving new state-of-the-art results in two different benchmark datasets: BioRelEx (binding interaction detection) and ADE (adverse drug event extraction). For example, KECI achieves absolute improvements of 4.59% and 4.91% in F1 scores over the state-of-the-art on the BioRelEx entity and relation extraction tasks",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2021.acl-long.488.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly addresses information extraction from biomedical text, which requires the integration of domain-specific knowledge such as binding interactions and adverse drug event extraction. It mentions external background knowledge from a knowledge graph and benchmarks on datasets like BioRelEx (binding interaction detection) and ADE (adverse drug event extraction), both of which focus on biomedical information and drug-related phenomena. This situates the work clearly within the Biomedicine AI domain, as it directly enhances the understanding and extraction of biomedical entities and relations.",
    "prompt_tokens": 22231,
    "completion_tokens": 215,
    "total_tokens": 22446,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Graph Representation Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "Clinician-in-the-loop Systems"
    },
    "method": "Graph Convolutional Networks; Transformer-based models (SciBERT); Attention Mechanisms",
    "application": "Entity and relation extraction – biomedical text",
    "code_link": "https://github.com/laituan245/bio_relex",
    "dataset_name": [
      "BioRelEx",
      "ADE"
    ],
    "is_public": true
  },
  {
    "id": "2022.acl-long.131",
    "year": 2022,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "GPT-D: Inducing Dementia-related Linguistic Anomalies by Deliberate Degradation of Artificial Neural Language Models",
    "authors": [
      "Changye Li",
      "David Knopman",
      "Weizhe Xu",
      "Trevor Cohen",
      "Serguei Pakhomov"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Deep learning (DL) techniques involving fine-tuning large numbers of model parameters have delivered impressive performance on the task of discriminating between language produced by cognitively healthy individuals, and those with Alzheimer’s disease (AD). However, questions remain about their ability to generalize beyond the small reference sets that are publicly available for research. As an alternative to fitting model parameters directly, we propose a novel method by which a Transformer DL model (GPT-2) pre-trained on general English text is paired with an artificially degraded version of itself (GPT-D), to compute the ratio between these two models’ perplexities on language from cognitively healthy and impaired individuals. This technique approaches state-of-the-art performance on text data from a widely used “Cookie Theft” picture description task, and unlike established alternatives also generalizes well to spontaneous conversations. Furthermore, GPT-D generates text with characteristics known to be associated with AD, demonstrating the induction of dementia-related linguistic anomalies. Our study is a step toward better understanding of the relationships between the inner workings of generative neural language models, the language that they produce, and the deleterious effects of dementia on human speech and language characteristics.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2022.acl-long.131.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly focuses on Alzheimer’s disease (AD), a neurodegenerative condition relevant to healthcare and biomedicine. It discusses using deep learning (specifically Transformer models) to analyze linguistic anomalies indicative of AD, a task directly tied to health outcomes and disease diagnosis. The study leverages language production as a biomarker for cognitive impairment due to dementia, which fits within the Healthcare AI or Biomedicine AI domain. Additionally, the mention of improving understanding of dementia-related effects aligns with neuroscience and medical applications.",
    "prompt_tokens": 22034,
    "completion_tokens": 230,
    "total_tokens": 22264,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Paired perplexity ratio; Transformer-based models (GPT-2, GPT-D); Saliency visualization",
    "application": "linguistic anomaly detection – dementia",
    "code_link": "https://github.com/LinguisticAnomalies/hammer-nets",
    "dataset_name": [
      "ADReSS",
      "DementiaBank",
      "CCC"
    ],
    "is_public": true
  },
  {
    "id": "2021.acl-long.463",
    "year": 2021,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Automatic ICD Coding via Interactive Shared Representation Networks with Self-distillation Mechanism",
    "authors": [
      "Tong Zhou",
      "Pengfei Cao",
      "Yubo Chen",
      "Kang Liu",
      "Jun Zhao",
      "Kun Niu",
      "Weifeng Chong",
      "Shengping Liu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The ICD coding task aims at assigning codes of the International Classification of Diseases in clinical notes. Since manual coding is very laborious and prone to errors, many methods have been proposed for the automatic ICD coding task. However, existing works either ignore the long-tail of code frequency or the noisy clinical notes. To address the above issues, we propose an Interactive Shared Representation Network with Self-Distillation Mechanism. Specifically, an interactive shared representation network targets building connections among codes while modeling the co-occurrence, consequently alleviating the long-tail problem. Moreover, to cope with the noisy text issue, we encourage the model to focus on the clinical note’s noteworthy part and extract valuable information through a self-distillation learning mechanism. Experimental results on two MIMIC datasets demonstrate the effectiveness of our method.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2021.acl-long.463.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on the task of assigning International Classification of Diseases (ICD) codes to clinical notes, which is a healthcare-specific application. The abstract strongly emphasizes the relevance to healthcare, mentioning the use of clinical notes and addressing the labor-intensive task of manual ICD coding, which is directly associated with healthcare and medical record-keeping. Furthermore, the paper evaluates its method on the MIMIC datasets, which are widely recognized healthcare datasets containing electronic health records (EHR). These factors confirm the paper’s alignment with the Healthcare AI domain.",
    "prompt_tokens": 22250,
    "completion_tokens": 213,
    "total_tokens": 22463,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Multi-scale convolutional encoder; Shared attention; Self-distillation learning; Transformer-based models",
    "application": "ICD Code Prediction – Clinical Notes",
    "code_link": "https://github.com/tongzhou21/ISD",
    "dataset_name": [
      "MIMIC-II",
      "MIMIC-III"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_1403",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Data-Constrained Synthesis of Training Data for De-Identification",
    "authors": [
      "Thomas Vakili",
      "Aron Henriksson",
      "Hercules Dalianis"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Many sensitive domains -- such as the clinical domain -- lack widely available datasets due to privacy risks. The increasing generative capabilities of large language models (LLMs) have made synthetic datasets a viable path forward. In this study, we domain-adapt LLMs to the clinical domain and generate synthetic clinical texts that are machine-annotated with tags for personally identifiable information using capable encoder-based NER models. The synthetic corpora are then used to train synthetic NER models. The results show that training NER models using synthetic corpora incurs only a small drop in predictive performance. The limits of this process are investigated in a systematic ablation study -- using both Swedish and Spanish data. Our analysis shows that smaller datasets can be sufficient for domain-adapting LLMs for data synthesis. Instead, the effectiveness of this process is almost entirely contingent on the performance of the machine-annotating NER models trained using the original data.",
    "keywords": "N/A",
    "pdf_url": "https://arxiv.org/pdf/2502.14677",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title, “Data-Constrained Synthesis of Training Data for De-Identification,” strongly suggests an application relevant to Healthcare AI. De-identification is a critical process used in handling healthcare datasets like electronic health records (EHRs) to protect patient privacy. This aligns with healthcare-specific tasks and the development of tools for managing sensitive patient data. While the abstract and keywords are missing, the concept of training data synthesis for de-identification is a common issue in healthcare AI when dealing with clinical or patient-related datasets. Thus, reasonable inference supports this classification.",
    "prompt_tokens": 22371,
    "completion_tokens": 211,
    "total_tokens": 22582,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Differential Privacy"
    },
    "method": "Autoregressive language modeling; domain adaptation via fine-tuned LLMs; NER models for machine annotation",
    "application": "PII detection – clinical text",
    "code_link": "N/A",
    "dataset_name": [
      "SEPR PHI",
      "MEDDOCAN"
    ],
    "is_public": false
  },
  {
    "id": "2023.acl-long.350",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "CoAD: Automatic Diagnosis through Symptom and Disease Collaborative Generation",
    "authors": [
      "Huimin Wang",
      "Wai Chung Kwan",
      "Kam-Fai Wong",
      "Yefeng Zheng"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Automatic diagnosis (AD), a critical application of AI in healthcare, employs machine learning techniques to assist doctors in gathering patient symptom information for precise disease diagnosis. The Transformer-based method utilizes an input symptom sequence, predicts itself through auto-regression, and employs the hidden state of the final symptom to determine the disease. Despite its simplicity and superior performance demonstrated, a decline in disease diagnosis accuracy is observed caused by 1) a mismatch between symptoms observed during training and generation, and 2) the effect of different symptom orders on disease prediction. To address the above obstacles, we introduce the CoAD, a novel disease and symptom collaborative generation framework, which incorporates several key innovations to improve AD: 1) aligning sentence-level disease labels with multiple possible symptom inquiry steps to bridge the gap between training and generation; 2) expanding symptom labels for each sub-sequence of symptoms to enhance annotation and eliminate the effect of symptom order; 3) developing a repeated symptom input schema to effectively and efficiently learn the expanded disease and symptom labels. We evaluate the CoAD framework using four datasets, including three public and one private, and demonstrate that it achieves an average 2.3% improvement over previous state-of-the-art results in automatic disease diagnosis. For reproducibility, we release the code and data at https://github.com/KwanWaiChung/coad.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.350.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly focuses on \"Automatic Diagnosis (AD)\" in healthcare, as described in the abstract. It uses AI, specifically a Transformer-based method, to predict diseases based on symptom inquiry, an application directly relevant to clinical decision support and healthcare tasks. Terms such as \"precise disease diagnosis,\" \"hidden state of the final symptom to determine the disease,\" and the evaluation against several datasets (including one private healthcare dataset) further solidify its relevance to Healthcare AI. The objectives and innovations outlined in the paper are clearly aimed at improving the accuracy and efficiency of AI systems in a medical context.",
    "prompt_tokens": 22302,
    "completion_tokens": 201,
    "total_tokens": 22503,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Sequential Decision Making & Reinforcement Learning",
      "SubTopic": "Dynamic Treatment Regimes"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "AI for Clinical Decision Support (CDS)"
    },
    "method": "Transformer-based models; Sequence generation; d-labeler alignment; s-label augmentation; Reinforcement Learning",
    "application": "Automatic disease diagnosis",
    "code_link": "https://github.com/KwanWaiChung/coad",
    "dataset_name": [
      "Dxy",
      "MuZhi",
      "MuZhi-2",
      "Ped"
    ],
    "is_public": true
  },
  {
    "id": "2024.acl-long.558",
    "year": 2024,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models",
    "authors": [
      "Yilin Wen",
      "Zifeng Wang",
      "Jimeng Sun"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Large language models (LLMs) have achieved remarkable performance in natural language understanding and generation tasks. However, they often suffer from limitations such as difficulty in incorporating new knowledge, generating hallucinations, and explaining their reasoning process. To address these challenges, we propose a novel prompting pipeline, named MindMap, that leverages knowledge graphs (KGs) to enhance LLMs’ inference and transparency. Our method enables LLMs to comprehend KG inputs and infer with a combination of implicit and external knowledge. Moreover, our method elicits the mind map of LLMs, which reveals their reasoning pathways based on the ontology of knowledge. We evaluate our method on diverse question & answering tasks, especially in medical domains, and show significant improvements over baselines. We also introduce a new hallucination evaluation benchmark and analyze the effects of different components of our method. Our results demonstrate the effectiveness and robustness of our method in merging knowledge from LLMs and KGs for combined inference.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2024.acl-long.558.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract explicitly mentions \"question & answering tasks, especially in medical domains,\" which implies the application of the proposed method (MindMap) in healthcare or biomedicine contexts. Additionally, the challenges addressed, such as hallucinations and reasoning transparency, are directly relevant to ensuring reliability in medical AI applications. While the broader methodology involves knowledge graphs and language models, the inclusion of medical domains as a primary evaluation area strongly suggests a focus on Healthcare AI or Biomedicine AI.",
    "prompt_tokens": 21624,
    "completion_tokens": 209,
    "total_tokens": 21833,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Retrieval-augmented generation; Knowledge graph augmentation; Language model fine-tuning",
    "application": "Medical question answering",
    "code_link": "https://github.com/wyl-willing/MindMap",
    "dataset_name": [
      "GenMedGPT-5k",
      "CMCQA",
      "ExplainCPE"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_1370",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Automated Structured Radiology Report Generation",
    "authors": [
      "Jean-Benoit Delbrouck",
      "Justin Xu",
      "Johannes Moll",
      "Alois Thomas",
      "Zhihong Chen",
      "Maya Varma",
      "Asfandyar Azhar",
      "Sophie Ostmeier",
      "Andrew Johnston",
      "Eduardo Pontes Reis",
      "Christian Bluethgen",
      "Mohamed S Muneer",
      "Kelvin Zhenghao Li",
      "Curtis Langlotz"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Automated radiology report generation from chest X-ray (CXR) images has the potential to improve clinical efficiency and reduce radiologists’ workload. However, most datasets, including the publicly available MIMIC-CXR and CheXpert Plus, consist entirely of free-form reports, which are inherently variable and unstructured. This variability poses challenges for both generation and evaluation: existing models struggle to produce consistent, clinically meaningful reports, and standard evaluation metrics fail to capture the nuances of radiological interpretation. To address this, we introduce Structured Radiology Report Generation (SRRG), a new task that reformulates free-text radiology reports into a standardized format, ensuring clarity, consistency, and structured clinical reporting. We create a novel dataset by restructuring reports using large language models (LLMs) following strict structured reporting desiderata. Additionally, we introduce SRR-BERT, a fine-grained disease classification model trained on 55 labels, enabling more precise and clinically informed evaluation of structured reports. To assess report quality, we propose F1-SRR-BERT, a metric that leverages SRR-BERT’s hierarchical disease taxonomy to bridge the gap between free-text variability and structured clinical reporting. We validate our dataset through a reader study conducted by five board-certified radiologists and extensive benchmarking experiments.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.1301.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title \"Automated Structured Radiology Report Generation\" strongly indicates relevance to Healthcare AI as it pertains to the automation of radiology report creation. Radiology reports are a core aspect of clinical practice and involve medical imaging analysis, which is directly linked to healthcare. Although an abstract and keywords are unavailable, the title alone clearly reflects healthcare-specific tasks involving diagnostic data and clinical reporting, making it clearly within the domain of Healthcare AI.",
    "prompt_tokens": 22313,
    "completion_tokens": 221,
    "total_tokens": 22534,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Radiology"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Structured Radiology Report Generation; Fine-grained Disease Classification with SRR-BERT",
    "application": "Radiology report generation – Chest X-ray",
    "code_link": "https://stanford-aimi.github.io/srrg.html",
    "dataset_name": [
      "MIMIC-CXR",
      "CheXpert Plus"
    ],
    "is_public": true
  },
  {
    "id": "2024.acl-long.766",
    "year": 2024,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Multistage Collaborative Knowledge Distillation from a Large Language Model for Semi-Supervised Sequence Generation",
    "authors": [
      "Jiachen Zhao",
      "Wenlong Zhao",
      "Andrew Drozdov",
      "Benjamin Rozonoyer",
      "Md Arafat Sultan",
      "Jay-Yoon Lee",
      "Mohit Iyyer",
      "Andrew McCallum"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We study semi-supervised sequence generation tasks, where the few labeled examples are too scarce to finetune a model, and meanwhile, few-shot prompted large language models (LLMs) exhibit room for improvement. In this paper, we present the discovery that a student model distilled from a few-shot prompted LLM can commonly generalize better than its teacher to unseen examples on such tasks. We find that the student is able to learn a general pattern from the high-quality pseudolabels produced by the teacher during knowledge distillation (KD), and favorably not a general pattern from the low-quality pseudolabels. Leveraging this discovery, we propose a new method, Multistage Collaborative Knowledge Distillation from an LLM (MCKD), for these tasks. MCKD first few-shot prompts an LLM to produce pseudolabels for unlabeled data. Then at each stage of an iterative KD process, a new pair of students is trained on disjoint partitions of the pseudolabeled data, and produces new and improved pseudolabels for their unseen partitions. We conduct extensive experiments on four syntactic and semantic parsing datasets and show the effectiveness of MCKD for low-resource semi-supervised sequence generation. On CRAFT biomedical parsing, for example, 3-stage MCKD with 50 labeled examples outperforms an LLM teacher and vanilla KD by 7.5% and 3.7% parsing F1, respectively, and matches the performance of supervised finetuning with 500 labeled examples.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2024.acl-long.766.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract mentions the use of the proposed method, MCKD, on multiple syntactic and semantic parsing datasets, including \"CRAFT biomedical parsing.\" The CRAFT corpus pertains to biomedical literature annotations, making it directly relevant to the Biomedicine AI domain. The fact that this dataset is explicitly mentioned indicates an application of the method in a biomedical context, specifically parsing biomedical text. While the method itself is general, its demonstrated effectiveness in biomedical parsing makes this paper relevant to Biomedicine AI.",
    "prompt_tokens": 21970,
    "completion_tokens": 240,
    "total_tokens": 22210,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Multistage Collaborative Knowledge Distillation (MCKD); Few-shot LLM prompting; Knowledge distillation (KD)",
    "application": "Sequence generation – Parsing tasks",
    "code_link": "https://github.com/andotalao24/Multistage-Collaborative-Knowledge-Distillation",
    "dataset_name": [
      "CRAFT",
      "ATIS",
      "PTB",
      "Snips"
    ],
    "is_public": true
  },
  {
    "id": "2021.acl-long.489",
    "year": 2021,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Fine-grained Information Extraction from Biomedical Literature based on Knowledge-enriched Abstract Meaning Representation",
    "authors": [
      "Zixuan Zhang",
      "Nikolaus Parulian",
      "Heng Ji",
      "Ahmed Elsayed",
      "Skatje Myers",
      "Martha Palmer"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Biomedical Information Extraction from scientific literature presents two unique and non-trivial challenges. First, compared with general natural language texts, sentences from scientific papers usually possess wider contexts between knowledge elements. Moreover, comprehending the fine-grained scientific entities and events urgently requires domain-specific background knowledge. In this paper, we propose a novel biomedical Information Extraction (IE) model to tackle these two challenges and extract scientific entities and events from English research papers. We perform Abstract Meaning Representation (AMR) to compress the wide context to uncover a clear semantic structure for each complex sentence. Besides, we construct the sentence-level knowledge graph from an external knowledge base and use it to enrich the AMR graph to improve the model’s understanding of complex scientific concepts. We use an edge-conditioned graph attention network to encode the knowledge-enriched AMR graph for biomedical IE tasks. Experiments on the GENIA 2011 dataset show that the AMR and external knowledge have contributed 1.8% and 3.0% absolute F-score gains respectively. In order to evaluate the impact of our approach on real-world problems that involve topic-specific fine-grained knowledge elements, we have also created a new ontology and annotated corpus for entity and event extraction for the COVID-19 scientific literature, which can serve as a new benchmark for the biomedical IE community.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2021.acl-long.489.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper falls into the Biomedicine AI domain, as it focuses on extracting \"scientific entities and events\" from biomedical literature, specifically English research papers. The abstract explicitly mentions its application to biomedical challenges, such as understanding \"fine-grained scientific entities and events\" that require \"domain-specific background knowledge.\" Additionally, the use of the GENIA 2011 dataset, which is well-known in the biomedical IE community, and the creation of a new corpus related to \"COVID-19 scientific literature\" reinforces the paper's relevance to biomedicine. These aspects clearly place the paper within the Biomedicine AI domain.",
    "prompt_tokens": 22230,
    "completion_tokens": 215,
    "total_tokens": 22445,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Abstract Meaning Representation (AMR); Graph Attention Network (GAT)",
    "application": "Biomedical information extraction – scientific literature",
    "code_link": "https://github.com/zhangzx-uiuc/Knowledge-AMR",
    "dataset_name": [
      "GENIA 2011",
      "COVID-19 scientific literature dataset"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_1238",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Asclepius: A Spectrum Evaluation Benchmark for Medical Multi-Modal Large Language Models",
    "authors": [
      "Jie Liu",
      "Wenxuan Wang",
      "SU Yihang",
      "Jingyuan Huang",
      "Yudi Zhang",
      "Cheng-Yi Li",
      "Wenting Chen",
      "Xiaohan Xing",
      "Kao-Jung Chang",
      "Linlin Shen",
      "Michael R. Lyu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The significant breakthroughs of Medical Multi-Modal Large Language Models (Med-MLLMs) renovate modern healthcare with robust information synthesis and medical decision support. However, these models are often evaluated on benchmarks that are unsuitable for the Med-MLLMs due to the complexity of real-world diagnostics across diverse specialties. To address this gap, we introduce Asclepius, a novel Med-MLLM benchmark that comprehensively assesses Med-MLLMs in terms of: distinct medical specialties (cardiovascular, gastroenterology, etc.) and different diagnostic capacities (perception, disease analysis, etc.). Grounded in 3 proposed core principles, Asclepius ensures a comprehensive evaluation by encompassing 15 medical specialties, stratifying into 3 main categories and 8 sub-categories of clinical tasks, and exempting overlap with existing VQA dataset. We further provide an in-depth analysis of 6 Med-MLLMs and compare them with 3 human specialists, providing insights into their competencies and limitations in various medical contexts. Our work not only advances the understanding of Med-MLLMs' capabilities but also sets a precedent for future evaluations and the safe deployment of these models in clinical environments.",
    "keywords": "N/A",
    "pdf_url": "https://arxiv.org/pdf/2402.11217",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title explicitly mentions \"Medical Multi-Modal Large Language Models,\" strongly indicating that the paper is focused on applications of AI in the medical domain. The use of \"Asclepius\" (a reference to the Greek god of medicine) further supports the healthcare relevance. The paper likely evaluates large language models tailored to handle multi-modal medical data, which is directly relevant to Healthcare AI or Biomedicine AI. While no abstract or keywords are provided, the context and focus on medical AI align with the criteria for this classification.",
    "prompt_tokens": 22300,
    "completion_tokens": 216,
    "total_tokens": 22516,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Radiology"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Vision Foundation Models (VFMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Multi-modal fusion for medical question-answering and report generation; multi-specialty evaluation",
    "application": "Radiology report generation",
    "code_link": "https://asclepius-med.github.io/",
    "dataset_name": [
      "MIMIC-CXR",
      "DeepDRiD"
    ],
    "is_public": true
  },
  {
    "id": "2024.acl-long.93",
    "year": 2024,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "HealMe: Harnessing Cognitive Reframing in Large Language Models for Psychotherapy",
    "authors": [
      "Mengxi Xiao",
      "Qianqian Xie",
      "Ziyan Kuang",
      "Zhicheng Liu",
      "Kailai Yang",
      "Min Peng",
      "Weiguang Han",
      "Jimin Huang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Large Language Models (LLMs) can play a vital role in psychotherapy by adeptly handling the crucial task of cognitive reframing and overcoming challenges such as shame, distrust, therapist skill variability, and resource scarcity. Previous LLMs in cognitive reframing mainly converted negative emotions to positive ones, but these approaches have limited efficacy, often not promoting clients’ self-discovery of alternative perspectives. In this paper, we unveil the Helping and Empowering through Adaptive Language in Mental Enhancement (HealMe) model. This novel cognitive reframing therapy method effectively addresses deep-rooted negative thoughts and fosters rational, balanced perspectives. Diverging from traditional LLM methods, HealMe employs empathetic dialogue based on psychotherapeutic frameworks. It systematically guides clients through distinguishing circumstances from feelings, brainstorming alternative viewpoints, and developing empathetic, actionable suggestions. Moreover, we adopt the first comprehensive and expertly crafted psychological evaluation metrics, specifically designed to rigorously assess the performance of cognitive reframing, in both AI-simulated dialogues and real-world therapeutic conversations. Experimental results show that our model outperforms others in terms of empathy, guidance, and logical coherence, demonstrating its effectiveness and potential positive impact on psychotherapy.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2024.acl-long.93.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses the development of the HealMe model, which is specifically tailored for psychotherapy, a clinical and therapeutic application in mental health. The abstract highlights that the model focuses on addressing \"deep-rooted negative thoughts\" and fostering \"rational, balanced perspectives,\" which are core components of mental health therapy. Psychotherapy is a recognized healthcare domain, and the implementation of AI in this context directly relates to healthcare AI. Furthermore, the mention of \"empathetic dialogue based on psychotherapeutic frameworks\" and the use of \"psychological evaluation metrics\" reinforces its relevance to Healthcare AI, as it integrates AI methods to enhance mental health interventions.",
    "prompt_tokens": 22136,
    "completion_tokens": 231,
    "total_tokens": 22367,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "Human-AI Collaborative Performance"
    },
    "method": "Fine-tuned LLaMA2-7B; Empathy-driven dialogue modeling; Cognitive reframing strategy",
    "application": "Mental health support – cognitive reframing therapy",
    "code_link": "https://github.com/elsa66666/HealMe",
    "dataset_name": [
      "Maddela et al. (2023)",
      "Sharma et al. (2023b)"
    ],
    "is_public": true
  },
  {
    "id": "2024.acl-long.823",
    "year": 2024,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "SPZ: A Semantic Perturbation-based Data Augmentation Method with Zonal-Mixing for Alzheimer’s Disease Detection",
    "authors": [
      "FangFang Li",
      "Cheng Huang",
      "PuZhen Su",
      "Jie Yin"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Alzheimer’s Disease (AD), characterized by significant cognitive and functional impairment, necessitates the development of early detection techniques. Traditional diagnostic practices, such as cognitive assessments and biomarker analysis, are often invasive and costly. Deep learning-based approaches for non-invasive AD detection have been explored in recent studies, but the lack of accessible data hinders further improvements in detection performance. To address these challenges, we propose a novel semantic perturbation-based data augmentation method that essentially differs from existing techniques, which primarily rely on explicit data engineering. Our approach generates controlled semantic perturbations to enhance textual representations, aiding the model in identifying AD-specific linguistic patterns, particularly in scenarios with limited data availability. It learns contextual information and dynamically adjusts the perturbation degree for different linguistic features. This enhances the model’s sensitivity to AD-specific linguistic features and its robustness against natural language noise. Experimental results on the ADReSS challenge dataset demonstrate that our approach outperforms other strong and competitive deep learning methods.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2024.acl-long.823.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper is focused on Alzheimer’s Disease (AD) detection, which is explicitly a healthcare-related task as it involves diagnosing a neurological condition. The abstract mentions that the proposed method enhances non-invasive detection through linguistic pattern analysis, which is a clinical application. References to \"disease diagnosis,\" \"biomarkers,\" \"cognitive impairments,\" and the ADReSS challenge dataset strongly indicate relevance to Healthcare AI or Biomedicine AI. Moreover, improving diagnostic accuracy for Alzheimer’s Disease aligns with the goals of healthcare and biomedical research.",
    "prompt_tokens": 22358,
    "completion_tokens": 210,
    "total_tokens": 22568,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Data Augmentation"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Token-level semantic perturbation; BERT-based textual embedding; zonal-mixing augmentation method",
    "application": "Alzheimer’s disease detection from speech transcripts",
    "code_link": "https://github.com/google-research/bert",
    "dataset_name": [
      "ADReSS"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_1616",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Completing A Systematic Review in Hours instead of Months with Interactive AI Agents",
    "authors": [
      "Rui Qiu",
      "Shijie Chen",
      "Yu Su",
      "Po-Yin Yen",
      "Han Wei Shen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Systematic reviews (SRs) are vital for evidence-based practice in high stakes disciplines, such as healthcare, but are often impeded by intensive labors and lengthy processes that can take months to complete. Due to the high demand for domain expertise, existing automatic summarization methods fail to accurately identify relevant studies and generate high-quality summaries. To that end, we introduce InsightAgent, a human-centered interactive AI agent powered by large language models that revolutionize this workflow. InsightAgent partitions a large literature corpus based on semantics and employs a multi-agent design for more focused processing of literature, leading to significant improvement in the quality of generated SRs. InsightAgent also provides intuitive visualizations of the corpus and agent trajectories, allowing users to effortlessly monitor the actions of the agent and provide real-time feedback based on their expertise. Our user studies with 9 medical professionals demonstrate that the visualization and interaction mechanisms can effectively improve the quality of synthesized SRs by 27.2%, reaching 79.7% of human-written quality. At the same time, user satisfaction is improved by 34.4%. With InsightAgent, it only takes a clinician about 1.5 hours, rather than months, to complete a high-quality systematic review.",
    "keywords": "N/A",
    "pdf_url": "https://arxiv.org/pdf/2504.14822",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses completing systematic reviews, which are critical in evidence-based medicine and healthcare. The process of synthesizing research findings to inform clinical decision-making, policy development, or biomedical understanding falls squarely within the domain of Healthcare and Biomedicine AI. The use of interactive AI agents to accelerate systematic review workflows strongly suggests application in healthcare or biomedical fields, as this process often involves reviewing clinical trial data, epidemiological studies, or treatment outcomes.",
    "prompt_tokens": 22282,
    "completion_tokens": 222,
    "total_tokens": 22504,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "Clinician-in-the-loop Systems"
    },
    "method": "Transformer-based models (GPT-4); Multi-agent design; Corpus partitioning; Data visualization",
    "application": "Systematic review generation",
    "code_link": "https://github.com/OSU-NLP-Group/InsightAgent",
    "dataset_name": [
      "PubMed systematic reviews"
    ],
    "is_public": true
  },
  {
    "id": "2020.acl-main.359",
    "year": 2020,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Selecting Backtranslated Data from Multiple Sources for Improved Neural Machine Translation",
    "authors": [
      "Xabier Soto",
      "Dimitar Shterionov",
      "Alberto Poncelas",
      "Andy Way"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Machine translation (MT) has benefited from using synthetic training data originating from translating monolingual corpora, a technique known as backtranslation. Combining backtranslated data from different sources has led to better results than when using such data in isolation. In this work we analyse the impact that data translated with rule-based, phrase-based statistical and neural MT systems has on new MT systems. We use a real-world low-resource use-case (Basque-to-Spanish in the clinical domain) as well as a high-resource language pair (German-to-English) to test different scenarios with backtranslation and employ data selection to optimise the synthetic corpora. We exploit different data selection strategies in order to reduce the amount of data used, while at the same time maintaining high-quality MT systems. We further tune the data selection method by taking into account the quality of the MT systems used for backtranslation and lexical diversity of the resulting corpora. Our experiments show that incorporating backtranslated data from different sources can be beneficial, and that availing of data selection can yield improved performance.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2020.acl-main.359.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly mentions a \"real-world low-resource use-case (Basque-to-Spanish in the clinical domain)\" as part of its experiments. The term \"clinical domain\" strongly indicates relevance to healthcare applications, as it suggests that the developed machine translation systems are being evaluated in a medical or healthcare-related context. Even though the paper's focus is on machine translation techniques, the clinical application aligns the research with the Healthcare AI or Biomedicine AI domain.",
    "prompt_tokens": 41742,
    "completion_tokens": 238,
    "total_tokens": 41980,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "Clinician-in-the-loop Systems"
    },
    "method": "Transformer-based models; Backtranslation method; Feature Decay Algorithm (FDA)",
    "application": "Translation – Clinical texts from Basque to Spanish",
    "code_link": "https://github.com/rsennrich/subword-nmt",
    "dataset_name": [
      "Galdakao-Usansolo EHR Corpus",
      "Bilingual dictionary for clinical term generation"
    ],
    "is_public": true
  },
  {
    "id": "2021.acl-long.139",
    "year": 2021,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "A Systematic Investigation of KB-Text Embedding Alignment at Scale",
    "authors": [
      "Vardaan Pahuja",
      "Yu Gu",
      "Wenhu Chen",
      "Mehdi Bahrami",
      "Lei Liu",
      "Wei-Peng Chen",
      "Yu Su"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Knowledge bases (KBs) and text often contain complementary knowledge: KBs store structured knowledge that can support long range reasoning, while text stores more comprehensive and timely knowledge in an unstructured way. Separately embedding the individual knowledge sources into vector spaces has demonstrated tremendous successes in encoding the respective knowledge, but how to jointly embed and reason with both knowledge sources to fully leverage the complementary information is still largely an open problem. We conduct a large-scale, systematic investigation of aligning KB and text embeddings for joint reasoning. We set up a novel evaluation framework with two evaluation tasks, few-shot link prediction and analogical reasoning, and evaluate an array of KB-text embedding alignment methods. We also demonstrate how such alignment can infuse textual information into KB embeddings for more accurate link prediction on emerging entities and events, using COVID-19 as a case study.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2021.acl-long.139.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract indicates that the study involves integrating knowledge from textual and structured data sources to enhance reasoning and link prediction tasks. The specific mention of a \"COVID-19 case study\" as an application strongly ties this work to healthcare and biomedicine, as COVID-19 research is inherently a biomedical and healthcare-related domain. The study's focus on improving link prediction for emerging entities and events in this context suggests a potential use in biomedical knowledge discovery or healthcare-related reasoning tasks. Therefore, the paper is relevant to Biomedicine AI.",
    "prompt_tokens": 22332,
    "completion_tokens": 207,
    "total_tokens": 22539,
    "Topic Axis I": {
      "MainTopic": "Population Health & Computational Epidemiology",
      "SubTopic": "Public Health Surveillance"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Graph Representation Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Alignment using projection; Skip-gram modeling; Knowledge Graph Embedding (KGE)",
    "application": "Few-shot link prediction; Analogical reasoning tasks",
    "code_link": "https://github.com/dki-lab/joint-kb-text-embedding",
    "dataset_name": [
      "Wikidata",
      "Wikipedia"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0290",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "What is Stigma Attributed to? A Theory-Grounded, Expert-Annotated Interview Corpus for Demystifying Mental-Health Stigma",
    "authors": [
      "Han Meng",
      "Yancan Chen",
      "Yunan Li",
      "YITIAN YANG",
      "Jungup Lee",
      "Renwen Zhang",
      "Yi-Chieh Lee"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Mental-health stigma remains a pervasive social problem that hampers treatment-seeking and recovery. Existing resources for training neural models to finely classify such stigma are limited, relying primarily on social-media or synthetic data without theoretical underpinnings. To remedy this gap, we present an expert-annotated, theory-informed corpus of human-chatbot interviews, comprising 4,141 snippets from 684 participants with documented socio-cultural backgrounds. Our experiments benchmark state-of-the-art neural models and empirically unpack the challenges of stigma detection. This dataset can facilitate research on computationally detecting, neutralizing, and counteracting mental-health stigma. Our corpus is openly available at https://github.com/HanMeng2004/Mental-Health-Stigma-Interview-Corpus.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.272.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title, “What is Stigma Attributed to? A Theory-Grounded, Expert-Annotated Interview Corpus for Demystifying Mental-Health Stigma,” strongly suggests a focus on mental health stigma, which is directly related to healthcare. Additionally, the creation of an \"expert-annotated interview corpus\" implies the use of AI or machine learning methods for analyzing healthcare-related phenomena. While the abstract and keywords are missing, terms such as \"mental health\" and \"stigma\" make it clear that the paper is relevant to Healthcare AI, as mental health is a critical aspect of clinical care and healthcare research.",
    "prompt_tokens": 40947,
    "completion_tokens": 238,
    "total_tokens": 41185,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Transformer-based models (GPT, LLaMA); Fine-tuning; Classification tasks; FlashAttention-2",
    "application": "Mental health stigma detection – Interview corpus",
    "code_link": "https://github.com/HanMeng2004/Mental-Health-Stigma-Interview-Corpus",
    "dataset_name": [
      "Mental-Health-Stigma-Interview-Corpus",
      "Attribution Questionnaire-27"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0284",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Pattern Recognition or Medical Knowledge? The Problem with Multiple-Choice Questions in Medicine",
    "authors": [
      "Maxime Griot",
      "Jean Vanderdonckt",
      "Demet YUKSEL",
      "Coralie Hemptinne"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Large Language Models (LLMs) such as ChatGPT demonstrate significant potential in the medical domain and are often evaluated using multiple-choice questions (MCQs) modeled on exams like the USMLE. However, such benchmarks may overestimate true clinical understanding by rewarding pattern recognition and test-taking heuristics. To investigate this, we created a fictional medical benchmark centered on an imaginary organ, the Glianorex, allowing us to separate memorized knowledge from reasoning ability. We generated textbooks and MCQs in English and French using leading LLMs, then evaluated proprietary, open-source, and domain-specific models in a zero-shot setting. Despite the fictional content, models achieved an average score of 64%, while physicians scored only 27%. Fine-tuned medical models outperformed base models in English but not in French. Ablation and interpretability analyses revealed that models frequently relied on shallow cues, test-taking strategies, and hallucinated reasoning to identify the correct choice. These results suggest that standard MCQ-based evaluations may not effectively measure clinical reasoning and highlight the need for more robust, clinically meaningful assessment methods for LLMs.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.266.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title suggests the paper discusses issues with multiple-choice questions in a medical setting (\"The Problem with Multiple-Choice Questions in Medicine\"). This implies a focus on medical education or clinical evaluation. While the abstract and keywords are unavailable, the inclusion of the term \"Medicine\" in the context of pattern recognition and knowledge assessment strongly indicates relevance to healthcare. Additionally, the phrasing suggests potential implications for AI applications in clinical training or testing, which would align with Healthcare AI.",
    "prompt_tokens": 21810,
    "completion_tokens": 212,
    "total_tokens": 22022,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Other Imaging Modalities"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Safety & Failure Detection"
    },
    "method": "Multi-marginal flow matching; Self-supervised learning; Adaptive question refinement",
    "application": "Medical evaluation and reasoning assessment",
    "code_link": "N/A",
    "dataset_name": [
      "MedMCQA",
      "MultiMedQA",
      "PubMedQA"
    ],
    "is_public": false
  },
  {
    "id": "2020.acl-main.576",
    "year": 2020,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "MIE: A Medical Information Extractor towards Medical Dialogues",
    "authors": [
      "Yuanzhe Zhang",
      "Zhongtao Jiang",
      "Tao Zhang",
      "Shiwan Liu",
      "Jiarun Cao",
      "Kang Liu",
      "Shengping Liu",
      "Jun Zhao"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Electronic Medical Records (EMRs) have become key components of modern medical care systems. Despite the merits of EMRs, many doctors suffer from writing them, which is time-consuming and tedious. We believe that automatically converting medical dialogues to EMRs can greatly reduce the burdens of doctors, and extracting information from medical dialogues is an essential step. To this end, we annotate online medical consultation dialogues in a window-sliding style, which is much easier than the sequential labeling annotation. We then propose a Medical Information Extractor (MIE) towards medical dialogues. MIE is able to extract mentioned symptoms, surgeries, tests, other information and their corresponding status. To tackle the particular challenges of the task, MIE uses a deep matching architecture, taking dialogue turn-interaction into account. The experimental results demonstrate MIE is a promising solution to extract medical information from doctor-patient dialogues.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2020.acl-main.576.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on extracting medical information from doctor-patient dialogues to aid in generating Electronic Medical Records (EMRs), a task directly linked to healthcare. Specifically, it discusses automating the extraction of symptoms, surgeries, tests, and their statuses, which are critical components of clinical diagnosis and treatment documentation. The implementation addresses a specific need within modern medical care systems, positioning the work squarely within the Healthcare AI domain. Key phrases like \"medical dialogues,\" \"EMRs,\" and \"doctors\" emphasize healthcare-specific applications. There is no ambiguity that this research pertains to Healthcare AI.",
    "prompt_tokens": 21779,
    "completion_tokens": 244,
    "total_tokens": 22023,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Bi-LSTM; self-attention mechanism; deep matching model",
    "application": "medical information extraction – clinical dialogues",
    "code_link": "https://github.com/nlpir2020/MIE-ACL-2020",
    "dataset_name": [
      "Chunyu Doctor Dialogue Dataset",
      "2010 i2b2 challenge dataset"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0469",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Are LLMs effective psychological assessors? Leveraging adaptive RAG for interpretable mental health screening through psychometric practice",
    "authors": [
      "Federico Ravenda",
      "Seyed Ali Bahrainian",
      "Andrea Raballo",
      "Antonietta Mira",
      "Noriko Kando"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In psychological practice, standardized questionnaires serve as essential tools for assessing mental health through structured, clinically-validated questions (i.e., items). While social media platforms offer rich data for mental health screening, computational approaches often bypass these established clinical assessment tools in favor of black-box classification. We propose a novel questionnaire-guided screening framework that bridges psychological practice and computational methods through adaptive Retrieval-Augmented Generation (aRAG). Our approach links unstructured social media content and standardized clinical assessments by retrieving relevant posts for each questionnaire item and using Large Language Models (LLMs) to complete validated psychological instruments. Our findings demonstrate two key advantages of questionnaire-guided screening: First, when completing the Beck Depression Inventory-II (BDI-II), our approach matches or outperforms state-of-the-art performance on Reddit-based benchmarks without requiring training data. Second, we show that guiding LLMs through standardized questionnaires yields superior results compared to directly prompting them for depression screening. Additionally, we show as a proof-of-concept how our questionnaire-based methodology successfully extends to self-harm screening.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.440.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper's title strongly suggests relevance to Healthcare AI, as it focuses on leveraging LLMs (Large Language Models) for mental health screening, which is a clear healthcare application. Terms such as \"psychological assessors,\" \"mental health screening,\" and \"psychometric practice\" point directly to clinical applications for assessing and addressing mental health, which falls under the domain of Healthcare AI. Even without an abstract or keywords, the context implies the use of AI in supporting healthcare tasks specific to mental health.",
    "prompt_tokens": 22291,
    "completion_tokens": 228,
    "total_tokens": 22519,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Adaptive Retrieval-Augmented Generation (aRAG)",
    "application": "Psychological questionnaire completion – Depression severity assessment",
    "code_link": "https://github.com/Fede-stack/Adaptive-RAG-for-Psychological-Assessment",
    "dataset_name": [
      "eRisk 2019",
      "eRisk 2020"
    ],
    "is_public": true
  },
  {
    "id": "2023.acl-long.555",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Cognitive Reframing of Negative Thoughts through Human-Language Model Interaction",
    "authors": [
      "Ashish Sharma",
      "Kevin Rushton",
      "Inna Lin",
      "David Wadden",
      "Khendra Lucas",
      "Adam Miner",
      "Theresa Nguyen",
      "Tim Althoff"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "A proven therapeutic technique to overcome negative thoughts is to replace them with a more hopeful “reframed thought.” Although therapy can help people practice and learn this Cognitive Reframing of Negative Thoughts, clinician shortages and mental health stigma commonly limit people’s access to therapy. In this paper, we conduct a human-centered study of how language models may assist people in reframing negative thoughts. Based on psychology literature, we define a framework of seven linguistic attributes that can be used to reframe a thought. We develop automated metrics to measure these attributes and validate them with expert judgements from mental health practitioners. We collect a dataset of 600 situations, thoughts and reframes from practitioners and use it to train a retrieval-enhanced in-context learning model that effectively generates reframed thoughts and controls their linguistic attributes. To investigate what constitutes a “high-quality” reframe, we conduct an IRB-approved randomized field study on a large mental health website with over 2,000 participants. Amongst other findings, we show that people prefer highly empathic or specific reframes, as opposed to reframes that are overly positive. Our findings provide key implications for the use of LMs to assist people in overcoming negative thoughts.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.555.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses how language models can assist in cognitive reframing of negative thoughts, a therapeutic technique widely used in mental health care. The abstract references a study conducted on a large mental health website and includes validation from mental health practitioners, which directly ties the research to healthcare domains, particularly mental health. Additionally, the study's focus on assisting individuals with negative thoughts addresses a health-related application, meeting the definition of Healthcare AI. While it does not mention traditional clinical terms like \"disease diagnosis\" or \"treatment planning,\" the focus on mental health therapy and the role of language models in patient assistance aligns with the broader application of AI in healthcare.",
    "prompt_tokens": 22243,
    "completion_tokens": 235,
    "total_tokens": 22478,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "new-Retrieval-enhanced in-context learning methods for text generation"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "Human-AI Collaborative Performance"
    },
    "method": "Retrieval-enhanced in-context learning; GPT-based multi-label classification; controllable text generation",
    "application": "Cognitive reframing of negative thoughts",
    "code_link": "https://github.com/behavioral-data/Cognitive-Reframing",
    "dataset_name": [
      "Thought Records Dataset",
      "Mental Health America (MHA)"
    ],
    "is_public": true
  },
  {
    "id": "2020.acl-main.748",
    "year": 2020,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "A Generate-and-Rank Framework with Semantic Type Regularization for Biomedical Concept Normalization",
    "authors": [
      "Dongfang Xu",
      "Zeyu Zhang",
      "Steven Bethard"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Concept normalization, the task of linking textual mentions of concepts to concepts in an ontology, is challenging because ontologies are large. In most cases, annotated datasets cover only a small sample of the concepts, yet concept normalizers are expected to predict all concepts in the ontology. In this paper, we propose an architecture consisting of a candidate generator and a list-wise ranker based on BERT. The ranker considers pairings of concept mentions and candidate concepts, allowing it to make predictions for any concept, not just those seen during training. We further enhance this list-wise approach with a semantic type regularizer that allows the model to incorporate semantic type information from the ontology during training. Our proposed concept normalization framework achieves state-of-the-art performance on multiple datasets.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2020.acl-main.748.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on \"biomedical concept normalization,\" explicitly addressing the challenge of linking textual mentions of biomedical concepts to concepts in an ontology. The abstract discusses leveraging semantic type information from ontologies, which are core structures in biomedical informatics. Ontologies are commonly used in fields like genomics, disease classification, and clinical text mining. The phrase \"multiple datasets\" likely refers to standard biomedical datasets. These elements make it evident that the paper is in the domain of Biomedicine AI.",
    "prompt_tokens": 22255,
    "completion_tokens": 227,
    "total_tokens": 22482,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (GPT, LLaMA)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "BERT-based multi-class classifier; BERT-based list-wise classifier; Semantic type regularizer",
    "application": "Medical concept normalization",
    "code_link": "https://github.com/dongfang91/Generate-and-Rank-ConNorm",
    "dataset_name": [
      "AskAPatient",
      "TwADR-L",
      "SMM4H-17",
      "MCN"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0643",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "KokoroChat: A Japanese Psychological Counseling Dialogue Dataset Collected via Role-Playing by Trained Counselors",
    "authors": [
      "Zhiyang Qi",
      "Takumasa Kaneko",
      "Keiko Takamizo",
      "Mariko Ukiyo",
      "Michimasa Inaba"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Generating psychological counseling responses with language models relies heavily on high-quality datasets. Crowdsourced data collection methods require strict worker training, and data from real-world counseling environments may raise privacy and ethical concerns. While recent studies have explored using large language models (LLMs) to augment psychological counseling dialogue datasets, the resulting data often suffers from limited diversity and authenticity. To address these limitations, this study adopts a role-playing approach where trained counselors simulate counselor-client interactions, ensuring high-quality dialogues while mitigating privacy risks. Using this method, we construct KokoroChat, a Japanese psychological counseling dialogue dataset comprising 6,589 long-form dialogues, each accompanied by comprehensive client feedback. Experimental results demonstrate that fine-tuning open-source LLMs with KokoroChat improves both the quality of generated counseling responses and the automatic evaluation of counseling dialogues. The KokoroChat dataset is available at this https URL.",
    "keywords": "N/A",
    "pdf_url": "https://arxiv.org/pdf/2506.01357",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title of the paper, *\"KokoroChat: A Japanese Psychological Counseling Dialogue Dataset Collected via Role-Playing by Trained Counselors\"*, suggests a focus on psychological counseling, which directly relates to mental health—a domain within Healthcare AI. Collecting dialogue data for counseling indicates potential applications in AI systems designed to support or enhance mental health care, such as virtual therapy assistants, diagnostic tools for mental health, or AI-driven interventions. While there is no abstract or keywords available for further analysis, the focus on \"psychological counseling\" inherently ties the dataset and underlying research to healthcare, particularly within the mental health domain.",
    "prompt_tokens": 21999,
    "completion_tokens": 213,
    "total_tokens": 22212,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (GPT, LLaMA)"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "Human-AI Collaborative Performance"
    },
    "method": "Transformer-based models (GPT, LLaMA); Fine-tuning; QLoRA for efficient adaptation",
    "application": "Psychological counseling dialogue response generation and evaluation",
    "code_link": "N/A",
    "dataset_name": [
      "KokoroChat"
    ],
    "is_public": false
  },
  {
    "id": "2022.acl-long.137",
    "year": 2022,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Predicting Intervention Approval in Clinical Trials through Multi-Document Summarization",
    "authors": [
      "Georgios Katsimpras",
      "Georgios Paliouras"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Clinical trials offer a fundamental opportunity to discover new treatments and advance the medical knowledge. However, the uncertainty of the outcome of a trial can lead to unforeseen costs and setbacks. In this study, we propose a new method to predict the effectiveness of an intervention in a clinical trial. Our method relies on generating an informative summary from multiple documents available in the literature about the intervention under study. Specifically, our method first gathers all the abstracts of PubMed articles related to the intervention. Then, an evidence sentence, which conveys information about the effectiveness of the intervention, is extracted automatically from each abstract. Based on the set of evidence sentences extracted from the abstracts, a short summary about the intervention is constructed. Finally, the produced summaries are used to train a BERT-based classifier, in order to infer the effectiveness of an intervention. To evaluate our proposed method, we introduce a new dataset which is a collection of clinical trials together with their associated PubMed articles. Our experiments, demonstrate the effectiveness of producing short informative summaries and using them to predict the effectiveness of an intervention.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2022.acl-long.137.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly focuses on predicting the effectiveness of interventions in clinical trials, which directly ties into \"clinical prediction\" and \"health outcomes,\" making it relevant to Healthcare AI. Furthermore, the method involves gathering abstracts from PubMed articles, a database primarily used for biomedical research, and using these to inform decision-making about medical interventions. These aspects strongly position the work in the Biomedicine AI domain, as it involves AI applied to analyze biomedical literature and clinical trial data to advance healthcare knowledge and practice.",
    "prompt_tokens": 21989,
    "completion_tokens": 213,
    "total_tokens": 22202,
    "Topic Axis I": {
      "MainTopic": "Drug Discovery & Development",
      "SubTopic": "ADMET & Trial Outcome Prediction"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Other Generative Models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Multi-document summarization; BERT-based evidence classifier",
    "application": "clinical trial outcome prediction – intervention approval",
    "code_link": "https://github.com/nneinn/ct_intervention_approval",
    "dataset_name": [
      "ClinicalTrials.gov",
      "PubMed"
    ],
    "is_public": true
  },
  {
    "id": "2021.acl-long.459",
    "year": 2021,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Cross-modal Memory Networks for Radiology Report Generation",
    "authors": [
      "Zhihong Chen",
      "Yaling Shen",
      "Yan Song",
      "Xiang Wan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Medical imaging plays a significant role in clinical practice of medical diagnosis, where the text reports of the images are essential in understanding them and facilitating later treatments. By generating the reports automatically, it is beneficial to help lighten the burden of radiologists and significantly promote clinical automation, which already attracts much attention in applying artificial intelligence to medical domain. Previous studies mainly follow the encoder-decoder paradigm and focus on the aspect of text generation, with few studies considering the importance of cross-modal mappings and explicitly exploit such mappings to facilitate radiology report generation. In this paper, we propose a cross-modal memory networks (CMN) to enhance the encoder-decoder framework for radiology report generation, where a shared memory is designed to record the alignment between images and texts so as to facilitate the interaction and generation across modalities. Experimental results illustrate the effectiveness of our proposed model, where state-of-the-art performance is achieved on two widely used benchmark datasets, i.e., IU X-Ray and MIMIC-CXR. Further analyses also prove that our model is able to better align information from radiology images and texts so as to help generating more accurate reports in terms of clinical indicators.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2021.acl-long.459.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper clearly fits into the Healthcare AI domain as it focuses on automating the generation of radiology reports based on medical imaging, which is an essential task in clinical practice. Specific references to \"medical imaging,\" \"radiology report generation,\" and the use of datasets such as IU X-Ray and MIMIC-CXR, which are widely used in healthcare research, emphasize its relevance to clinical and healthcare contexts. Additionally, its goal to facilitate clinical automation and reduce the burden on radiologists further solidifies its application within Healthcare AI. The cross-modal memory networks aimed at improving alignment between medical images and textual reports also directly support medical diagnosis and treatment planning, aligning it with healthcare-focused AI research.",
    "prompt_tokens": 22493,
    "completion_tokens": 211,
    "total_tokens": 22704,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Radiology"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "AI for Clinical Decision Support (CDS)"
    },
    "method": "Cross-modal memory networks; Transformer-based encoder-decoder",
    "application": "Radiology report generation",
    "code_link": "https://github.com/cuhksz-nlp/R2GenCMN",
    "dataset_name": [
      "IU X-Ray",
      "MIMIC-CXR"
    ],
    "is_public": true
  },
  {
    "id": "2022.acl-long.335",
    "year": 2022,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Textomics: A Dataset for Genomics Data Summary Generation",
    "authors": [
      "Mu-Chun Wang",
      "Zixuan Liu",
      "Sheng Wang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Summarizing biomedical discovery from genomics data using natural languages is an essential step in biomedical research but is mostly done manually. Here, we introduce Textomics, a novel dataset of genomics data description, which contains 22,273 pairs of genomics data matrices and their summaries. Each summary is written by the researchers who generated the data and associated with a scientific paper. Based on this dataset, we study two novel tasks: generating textual summary from a genomics data matrix and vice versa. Inspired by the successful applications of k nearest neighbors in modeling genomics data, we propose a kNN-Vec2Text model to address these tasks and observe substantial improvement on our dataset. We further illustrate how Textomics can be used to advance other applications, including evaluating scientific paper embeddings and generating masked templates for scientific paper understanding. Textomics serves as the first benchmark for generating textual summaries for genomics data and we envision it will be broadly applied to other biomedical and natural language processing applications.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2022.acl-long.335.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses the Textomics dataset, which focuses on summarizing genomics data using natural language. Genomics data is a core component of biomedical research, as it is critical for understanding genetic markers, mutation patterns, and molecular biology related to diseases and therapeutics. Terms like “genomics data,” “biomedical discovery,” and the mention of applications for “scientific paper understanding” strongly indicate its relevance to Biomedicine AI. Additionally, the dataset aims to advance tasks related to biomedical research, making it pertinent to the Biomedicine AI domain.",
    "prompt_tokens": 22391,
    "completion_tokens": 214,
    "total_tokens": 22605,
    "Topic Axis I": {
      "MainTopic": "Computational Genomics & Multi-Omics",
      "SubTopic": "Transcriptomics"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Other Generative Models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-Summary generation from genomics data for enhanced understanding"
    },
    "method": "kNN-Vec2Text; Transformer-based models (T5)",
    "application": "Text generation – Genomics data matrix",
    "code_link": "https://github.com/amos814/Textomics",
    "dataset_name": [
      "Textomics"
    ],
    "is_public": true
  },
  {
    "id": "2020.acl-main.176",
    "year": 2020,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "A Tale of Two Perplexities: Sensitivity of Neural Language Models to Lexical Retrieval Deficits in Dementia of the Alzheimer’s Type",
    "authors": [
      "Trevor Cohen",
      "Serguei Pakhomov"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In recent years there has been a burgeoning interest in the use of computational methods to distinguish between elicited speech samples produced by patients with dementia, and those from healthy controls. The difference between perplexity estimates from two neural language models (LMs) - one trained on transcripts of speech produced by healthy participants and one trained on those with dementia - as a single feature for diagnostic classification of unseen transcripts has been shown to produce state-of-the-art performance. However, little is known about why this approach is effective, and on account of the lack of case/control matching in the most widely-used evaluation set of transcripts (DementiaBank), it is unclear if these approaches are truly diagnostic, or are sensitive to other variables. In this paper, we interrogate neural LMs trained on participants with and without dementia by using synthetic narratives previously developed to simulate progressive semantic dementia by manipulating lexical frequency. We find that perplexity of neural LMs is strongly and differentially associated with lexical frequency, and that using a mixture model resulting from interpolating control and dementia LMs improves upon the current state-of-the-art for models trained on transcript text exclusively.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2020.acl-main.176.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly discusses the diagnostic capabilities of neural language models for distinguishing speech patterns in individuals with dementia, specifically Alzheimer’s disease. The focus on \"diagnostic classification\" and the evaluation of speech samples from participants with dementia versus healthy controls suggests a direct application in Healthcare AI. Additionally, using language models to interrogate and potentially improve diagnostic methods for a medical condition like Alzheimer’s situates the work within the Healthcare AI domain. While the methods are computational, the ultimate aim appears to be medical diagnostics or health-related outcomes, making it relevant to Healthcare AI.",
    "prompt_tokens": 21951,
    "completion_tokens": 212,
    "total_tokens": 22163,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Long Short-Term Memory (LSTM); Interpolation; Evaluation via Leave-One-Out Cross Validation (LOOCV); Pretrained embeddings for skipgram subword",
    "application": "Diagnostic classification – dementia transcription analysis",
    "code_link": "https://github.com/dmlc/gluon-nlp",
    "dataset_name": [
      "DementiaBank"
    ],
    "is_public": true
  },
  {
    "id": "2020.acl-main.2",
    "year": 2020,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Predicting Depression in Screening Interviews from Latent Categorization of Interview Prompts",
    "authors": [
      "Alex Rinaldi",
      "Jean Fox Tree",
      "Snigdha Chaturvedi"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Accurately diagnosing depression is difficult– requiring time-intensive interviews, assessments, and analysis. Hence, automated methods that can assess linguistic patterns in these interviews could help psychiatric professionals make faster, more informed decisions about diagnosis. We propose JLPC, a model that analyzes interview transcripts to identify depression while jointly categorizing interview prompts into latent categories. This latent categorization allows the model to define high-level conversational contexts that influence patterns of language in depressed individuals. We show that the proposed model not only outperforms competitive baselines, but that its latent prompt categories provide psycholinguistic insights about depression.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2020.acl-main.2.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly focuses on diagnosing depression, a clinically recognized mental health disorder, through automated analysis of linguistic patterns in psychiatric screening interviews. Terms such as \"diagnosing depression,\" \"psychiatric professionals,\" and \"screening interviews\" strongly indicate relevance to Healthcare AI, as the research involves aiding clinical professionals in mental health diagnostics. The proposed model (JLPC) also provides psycholinguistic insights related to depression, which is directly tied to healthcare. Therefore, the paper falls within the Healthcare AI domain due to its focus on mental health diagnosis and clinical applications.",
    "prompt_tokens": 22204,
    "completion_tokens": 236,
    "total_tokens": 22440,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (BERT)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-Improved understanding of conversational context using prompts and responses"
    },
    "method": "Joint Latent Prompt Categorization (JLPC); Transformer-based models (BERT); GloVe embeddings",
    "application": "Depression prediction from interview transcripts",
    "code_link": "https://github.com/alexwgr/LatentPromptRelease",
    "dataset_name": [
      "Distress Analysis Interview Corpus (DAIC)"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_1404",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Just a Scratch: Enhancing LLM Capabilities for Self-harm Detection through Intent Differentiation and Emoji Interpretation",
    "authors": [
      "Soumitra Ghosh",
      "Gopendra Vikram Singh",
      "Shambhavi",
      "Sabarna Choudhury",
      "Asif Ekbal"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Self-harm detection on social media is critical for early intervention and mental health support, yet remains challenging due to the subtle, context-dependent nature of such expressions. Identifying self-harm intent aids suicide prevention by enabling timely responses, but current large language models (LLMs) struggle to interpret implicit cues in casual language and emojis. This work enhances LLMs’ comprehension of self-harm by distinguishing intent through nuanced language–emoji interplay. We present the Centennial Emoji Sensitivity Matrix (CESM-100)—a curated set of 100 emojis with contextual self-harm interpretations—and the Self-Harm Identification aNd intent Extraction with Supportive emoji sensitivity (SHINES) dataset, offering detailed annotations for self-harm labels, casual mentions (CMs), and serious intents (SIs). Our unified framework:a) enriches inputs using CESM-100;b) fine-tunes LLMs for multi-task learning—self-harm detection (primary) and CM/SI span detection (auxiliary);c) generate explainable rationales for self-harm predictions. We evaluate the framework on three state-of-the-art LLMs—Llama 3, Mental-Alpaca, and MentalLlama—across zero-shot, few-shot, and fine-tuned scenarios. By coupling intent differentiation with contextual cues, our approach commendably enhances LLM performance in both detection and explanation tasks, effectively addressing the inherent ambiguity in self-harm signals. The SHINES dataset, CESM-100 and codebase are publicly available at: https://www.iitp.ac.in/%7eai-nlp-ml/resources.html#SHINES",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.1330.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper presents a multi-task framework using LLMs for self-harm detection, focusing on distinguishing casual mentions from serious intent via emoji interpretation. It introduces the SHINES dataset and CESM-100 emoji sensitivity matrix, both designed for mental health monitoring and suicide prevention, directly contributing to AI in healthcare for psychological assessment and early intervention.",
    "prompt_tokens": -1,
    "completion_tokens": -1,
    "total_tokens": -1,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Digital Health & Wearable Sensor Data"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Rationale Generation for Mental Health Models"
    },
    "method": "Multi-task fine-tuning; Intent differentiation; Emoji sensitivity modeling (CESM-100); LLM-based rationale generation",
    "application": "Self-harm detection – Social media posts",
    "code_link": "https://www.iitp.ac.in/~ai-nlp-ml/resources.html#SHINES",
    "dataset_name": [
      "SHINES",
      "CESM-100"
    ],
    "is_public": true
  },
  {
    "id": "2022.acl-long.320",
    "year": 2022,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Graph Enhanced Contrastive Learning for Radiology Findings Summarization",
    "authors": [
      "Jinpeng Hu",
      "Zhuo Li",
      "Zhihong Chen",
      "Zhen Li",
      "Xiang Wan",
      "Tsung-Hui Chang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The impression section of a radiology report summarizes the most prominent observation from the findings section and is the most important section for radiologists to communicate to physicians. Summarizing findings is time-consuming and can be prone to error for inexperienced radiologists, and thus automatic impression generation has attracted substantial attention. With the encoder-decoder framework, most previous studies explore incorporating extra knowledge (e.g., static pre-defined clinical ontologies or extra background information). Yet, they encode such knowledge by a separate encoder to treat it as an extra input to their models, which is limited in leveraging their relations with the original findings. To address the limitation, we propose a unified framework for exploiting both extra knowledge and the original findings in an integrated way so that the critical information (i.e., key words and their relations) can be extracted in an appropriate way to facilitate impression generation. In detail, for each input findings, it is encoded by a text encoder and a graph is constructed through its entities and dependency tree. Then, a graph encoder (e.g., graph neural networks (GNNs)) is adopted to model relation information in the constructed graph. Finally, to emphasize the key words in the findings, contrastive learning is introduced to map positive samples (constructed by masking non-key words) closer and push apart negative ones (constructed by masking key words). The experimental results on two datasets, OpenI and MIMIC-CXR, confirm the effectiveness of our proposed method, where the state-of-the-art results are achieved.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2022.acl-long.320.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This paper is directly related to Healthcare AI because it focuses on the automatic generation of the impression section in radiology reports, an application critical to medical decision-making. The task it addresses—summarizing radiology findings to create impressions—is specific to healthcare and involves clinical data such as radiology reports, which are explicitly mentioned in the abstract. Additionally, the use of healthcare-related datasets like MIMIC-CXR and OpenI further confirms the paper’s relevance to the domain. Concepts like \"radiology findings summarization,\" \"clinical ontologies,\" and \"key words extraction in findings\" clearly align with healthcare AI applications.",
    "prompt_tokens": 21851,
    "completion_tokens": 215,
    "total_tokens": 22066,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Radiology"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Graph Representation Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Graph neural networks (GNNs); Contrastive learning",
    "application": "Radiology findings summarization",
    "code_link": "https://github.com/jinpeng01/AIG_CL",
    "dataset_name": [
      "MIMIC-CXR",
      "OpenI"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0281",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "$SECRET$: Semi-supervised Clinical Trial Document Similarity Search",
    "authors": [
      "Trisha Das",
      "Afrah Shafquat",
      "Mandis Beigi",
      "Jacob Aptekar",
      "Jimeng Sun"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Clinical trials are vital for evaluation of safety and efficacy of new treatments. However, clinical trials are resource-intensive, time-consuming and expensive to conduct, where errors in trial design, reduced efficacy, and safety events can result in significant delays, financial losses, and damage to reputation. These risks underline the importance of informed and strategic decisions in trial design to mitigate these risks and improve the chances of a successful trial. Identifying similar historical trials is critical as these trials can provide an important reference for potential pitfalls and challenges including serious adverse events, dosage inaccuracies, recruitment difficulties, patient adherence issues, etc. Addressing these challenges in trial design can lead to development of more effective study protocols with optimized patient safety and trial efficiency. In this paper, we present a novel method to identify similar historical trials by summarizing clinical trial protocols and searching for similar trials based on a query trial's protocol. Our approach significantly outperforms all baselines, achieving up to a 78% improvement in recall@1 and a 53% improvement in precision@1 over the best baseline. We also show that our method outperforms all other baselines in partial trial similarity search and zero-shot patient-trial matching, highlighting its superior utility in these tasks.",
    "keywords": "N/A",
    "pdf_url": "https://arxiv.org/pdf/2505.10780",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title, \"Semi-supervised Clinical Trial Document Similarity Search,\" specifically mentions \"clinical trial,\" which is a strong indicator of relevance to the Healthcare AI domain. Clinical trials are a fundamental component of healthcare and medical research, often used for evaluating treatments and interventions. The term \"document similarity search\" further implies the use of machine learning techniques to process and analyze clinical documents, which is highly relevant to healthcare applications. Even though the abstract and keywords are missing, the context provided in the title alone is sufficient to classify this paper as related to Healthcare AI or Biomedicine AI.",
    "prompt_tokens": 22315,
    "completion_tokens": 200,
    "total_tokens": 22515,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Other Imaging Modalities"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Semi-supervised learning; Question-Answer representation; Local and global contrastive training; BioBERT backbone encoder",
    "application": "Clinical trial document similarity search",
    "code_link": "https://github.com/secret-repository",
    "dataset_name": [
      "TREC2021",
      "Cohrane Reviews"
    ],
    "is_public": true
  },
  {
    "id": "2024.acl-long.199",
    "year": 2024,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Unity in Diversity: Collaborative Pre-training Across Multimodal Medical Sources",
    "authors": [
      "Xiaochen Wang",
      "Junyu Luo",
      "Jiaqi Wang",
      "Yuan Zhong",
      "Xiaokun Zhang",
      "Yaqing Wang",
      "Parminder Bhatia",
      "Cao Xiao",
      "Fenglong Ma"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Although pre-training has become a prevalent approach for addressing various biomedical tasks, the current efficacy of pre-trained models is hindered by their reliance on a limited scope of medical sources. This limitation results in data scarcity during pre-training and restricts the range of applicable downstream tasks. In response to these challenges, we develop MedCSP, a new pre-training strategy designed to bridge the gap between multimodal medical sources. MedCSP employs modality-level aggregation to unify patient data within individual sources. Additionally, leveraging temporal information and diagnosis history, MedCSP effectively captures explicit and implicit correlations between patients across different sources. To evaluate the proposed strategy, we conduct comprehensive experiments, where the experiments are based on 6 modalities from 2 real-world medical data sources, and MedCSP is evaluated on 4 tasks against 19 baselines, marking an initial yet essential step towards cross-source modeling in the medical domain.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2024.acl-long.199.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper primarily focuses on a pre-training strategy designed to unify and analyze multimodal medical data sources (e.g., encompassing \"patient data,\" \"temporal information,\" and \"diagnosis history\"). These terms indicate a focus on leveraging AI for clinical or healthcare-specific applications. Additionally, the evaluation involves real-world medical data and multiple healthcare tasks, which strongly situates the work in the domain of Healthcare AI. By addressing patient data analysis and cross-source data modeling, the research aligns with applications in healthcare and biomedicine.",
    "prompt_tokens": 22042,
    "completion_tokens": 215,
    "total_tokens": 22257,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "EHR/EMR Predictive Modeling"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "Clinician-in-the-loop Systems"
    },
    "method": "Contrastive learning; modality-specific embeddings",
    "application": "Predictive modeling tasks – ICU and readmission prediction",
    "code_link": "https://github.com/XiaochenWang-PSU/MedCSP",
    "dataset_name": [
      "MIMIC-IV",
      "MIMIC-CXR"
    ],
    "is_public": true
  },
  {
    "id": "2020.acl-main.215",
    "year": 2020,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "MultiQT: Multimodal learning for real-time question tracking in speech",
    "authors": [
      "Jakob D. Havtorn",
      "Jan Latko",
      "Joakim Edin",
      "Lars Maaløe",
      "Lasse Borgholt",
      "Lorenzo Belgrano",
      "Nicolai Jacobsen",
      "Regitze Sdun",
      "Željko Agić"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We address a challenging and practical task of labeling questions in speech in real time during telephone calls to emergency medical services in English, which embeds within a broader decision support system for emergency call-takers. We propose a novel multimodal approach to real-time sequence labeling in speech. Our model treats speech and its own textual representation as two separate modalities or views, as it jointly learns from streamed audio and its noisy transcription into text via automatic speech recognition. Our results show significant gains of jointly learning from the two modalities when compared to text or audio only, under adverse noise and limited volume of training data. The results generalize to medical symptoms detection where we observe a similar pattern of improvements with multimodal learning.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2020.acl-main.215.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on a practical task of labeling questions in speech in real time during emergency medical service telephone calls. This task is explicitly framed as part of a decision support system for emergency call-takers, which is a clear healthcare application. Additionally, the mention of “medical symptoms detection” in the abstract further ties the work to healthcare-specific tasks. These references to emergency medical services and symptom detection strongly suggest relevance to Healthcare AI, as the application is directly tied to real-world clinical and emergency response scenarios.",
    "prompt_tokens": 21942,
    "completion_tokens": 207,
    "total_tokens": 22149,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Physiological Time Series Analysis"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "AI for Clinical Decision Support (CDS)"
    },
    "method": "Multimodal learning; convolutional neural networks; sequence labeling",
    "application": "Real-time question tracking in emergency calls",
    "code_link": "N/A",
    "dataset_name": [
      "N/A"
    ],
    "is_public": false
  },
  {
    "id": "acl2025_temp_1570",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Should I Believe in What Medical AI Says? A Chinese Benchmark for Medication Based on Knowledge and Reasoning",
    "authors": [
      "Yue Wu",
      "Yangmin Huang",
      "Qianyun Du",
      "Lixian Lai",
      "Zhiyang He",
      "Jiaxue Hu",
      "Xiaodong Tao"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Large language models (LLMs) show potential in healthcare but often generate hallucinations, especially when handling unfamiliar information. In medication, a systematic benchmark to evaluate model capabilities is lacking, which is critical given the high-risk nature of medical information. This paper introduces a Chinese benchmark aimed at assessing models in medication tasks, focusing on knowledge and reasoning across six datasets: indication, dosage and administration, contraindicated population, mechanisms of action, drug recommendation, and drug interaction. We evaluate eight closed-source and five open-source models to identify knowledge boundaries, providing the first systematic analysis of limitations and risks in proprietary medical models.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-short.91.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title, \"Should I Believe in What Medical AI Says? A Chinese Benchmark for Medication Based on Knowledge and Reasoning,\" explicitly references \"Medical AI\" and discusses its use in a medication-related context. This strongly suggests relevance to Healthcare AI as it involves clinical decision support or reasoning about medical treatments. The focus on knowledge and reasoning further implies that the AI is applied to improve or evaluate medical tasks. While the abstract and keywords are not available, the phrasing in the title alone clearly situates the paper within the domain of Healthcare AI.",
    "prompt_tokens": 21786,
    "completion_tokens": 210,
    "total_tokens": 21996,
    "Topic Axis I": {
      "MainTopic": "Drug Discovery & Development",
      "SubTopic": "Drug Interaction"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Learning under data constraints"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Safety & Failure Detection"
    },
    "method": "Semantic Entropy; Self-Consistency; R-tuning",
    "application": "Medication recommendation and drug interaction tasks",
    "code_link": "https://github.com/LeoCoder33/ChiDrug-benchmark",
    "dataset_name": [
      "ChiDrug Benchmark"
    ],
    "is_public": true
  },
  {
    "id": "2023.acl-long.587",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "What are the Desired Characteristics of Calibration Sets? Identifying Correlates on Long Form Scientific Summarization",
    "authors": [
      "Griffin Adams",
      "Bichlien Nguyen",
      "Jake Smith",
      "Yingce Xia",
      "Shufang Xie",
      "Anna Ostropolets",
      "Budhaditya Deb",
      "Yuan-Jyue Chen",
      "Tristan Naumann",
      "Noémie Elhadad"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Summarization models often generate text that is poorly calibrated to quality metrics because they are trained to maximize the likelihood of a single reference (MLE). To address this, recent work has added a calibration step, which exposes a model to its own ranked outputs to improve relevance or, in a separate line of work, contrasts positive and negative sets to improve faithfulness. While effective, much of this work has focused on how to generate and optimize these sets. Less is known about why one setup is more effective than another. In this work, we uncover the underlying characteristics of effective sets. For each training instance, we form a large, diverse pool of candidates and systematically vary the subsets used for calibration fine-tuning. Each selection strategy targets distinct aspects of the sets, such as lexical diversity or the size of the gap between positive and negatives. On three diverse scientific long-form summarization datasets (spanning biomedical, clinical, and chemical domains), we find, among others, that faithfulness calibration is optimal when the negative sets are extractive and more likely to be generated, whereas for relevance calibration, the metric margin between candidates should be maximized and surprise–the disagreement between model and metric defined candidate rankings–minimized.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.587.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper specifically mentions the application of summarization models to three diverse scientific long-form summarization datasets spanning the biomedical, clinical, and chemical domains. The use of terms like \"biomedical\" and \"clinical\" suggests relevance to biomedicine AI, as these domains are inherently tied to healthcare and biological research. Furthermore, \"faithfulness calibration\" and \"relevance calibration\" in the context of summarization could directly contribute to improving scientific communication and understanding in healthcare and biomedicine research settings.",
    "prompt_tokens": 41036,
    "completion_tokens": 259,
    "total_tokens": 41295,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (GPT, LLaMA)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Transformer-based models",
    "application": "Biomedical text summarization",
    "code_link": "N/A",
    "dataset_name": [
      "MIMIC-CXR",
      "Pubmed"
    ],
    "is_public": false
  },
  {
    "id": "2023.acl-long.593",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "A Cognitive Stimulation Dialogue System with Multi-source Knowledge Fusion for Elders with Cognitive Impairment",
    "authors": [
      "Jiyue Jiang",
      "Sheng Wang",
      "Qintong Li",
      "Lingpeng Kong",
      "Chuan Wu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "When communicating with elders with cognitive impairment, cognitive stimulation (CS) help to maintain the cognitive health of elders. Data sparsity is the main challenge in building CS-based dialogue systems, particularly in the Chinese language. To fill this gap, we construct a Chinese CS conversation (CSConv) dataset, which contains about 2.6K groups of dialogues with therapy principles and emotional support strategy labels. Making chit chat while providing emotional support is overlooked by the majority of existing cognitive dialogue systems. In this paper, we propose a multi-source knowledge fusion method for CS dialogue (CSD), to generate open-ended responses guided by the therapy principle and emotional support strategy. We first use a progressive mask method based on external knowledge to learn encoders as effective classifiers, which is the prerequisite to predict the therapy principle and emotional support strategy of the target response. Then a decoder interacts with the perceived therapy principle and emotional support strategy to generate responses. Extensive experiments conducted on the CSConv dataset demonstrate the effectiveness of the proposed method, while there is still a large space for improvement compared to human performance.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.593.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses a dialogue system aimed at providing cognitive stimulation (CS) for elders with cognitive impairment. Cognitive stimulation is a therapeutic intervention used to maintain cognitive health, particularly relevant for conditions like dementia or Alzheimer’s disease. The focus on improving cognitive health for a vulnerable population aligns with healthcare applications. Additionally, the mention of therapy principles and emotional support strategies further strengthens the connection to healthcare, as these are commonly employed in therapeutic contexts to promote mental and emotional well-being. While the core method is a machine learning application, its explicit focus on aiding individuals with cognitive impairments situates it within the Healthcare AI domain.",
    "prompt_tokens": 22320,
    "completion_tokens": 202,
    "total_tokens": 22522,
    "Topic Axis I": {
      "MainTopic": "Healthcare Systems & Operations",
      "SubTopic": "Digital Health & Wearable Sensor Data"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "Human-AI Collaborative Performance"
    },
    "method": "Progressive Mask Encoder; Multi-source Knowledge Fusion",
    "application": "Dialogue system – Cognitive stimulation",
    "code_link": "https://github.com/jiangjyjy/CSD",
    "dataset_name": [
      "CSConv"
    ],
    "is_public": true
  },
  {
    "id": "2022.acl-long.242",
    "year": 2022,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Multilingual Molecular Representation Learning via Contrastive Pre-training",
    "authors": [
      "Zhihui Guo",
      "Pramod Sharma",
      "Andy Martinez",
      "Liang Du",
      "Robin Abraham"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Molecular representation learning plays an essential role in cheminformatics. Recently, language model-based approaches have gained popularity as an alternative to traditional expert-designed features to encode molecules. However, these approaches only utilize a single molecular language for representation learning. Motivated by the fact that a given molecule can be described using different languages such as Simplified Molecular Line Entry System (SMILES), The International Union of Pure and Applied Chemistry (IUPAC), and The IUPAC International Chemical Identifier (InChI), we propose a multilingual molecular embedding generation approach called MM-Deacon (multilingual molecular domain embedding analysis via contrastive learning). MM-Deacon is pre-trained using SMILES and IUPAC as two different languages on large-scale molecules. We evaluated the robustness of our method on seven molecular property prediction tasks from MoleculeNet benchmark, zero-shot cross-lingual retrieval, and a drug-drug interaction prediction task.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2022.acl-long.242.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on molecular representation learning and mentions specific applications like molecular property prediction and drug-drug interaction prediction. These are crucial tasks in drug discovery and biomedical research, directly aligning with the Biomedicine AI domain. Terms such as \"drug-drug interaction\" and \"MoleculeNet benchmark\" imply relevance to biomedicine, as they relate to understanding chemical properties and interactions for therapeutic purposes. Although the primary focus is on contrastive learning methods, the described applications strongly indicate relevance to biomedicine.",
    "prompt_tokens": 22179,
    "completion_tokens": 265,
    "total_tokens": 22444,
    "Topic Axis I": {
      "MainTopic": "Drug Discovery & Development",
      "SubTopic": "new-Molecular representation learning and drug-drug interaction prediction"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "new-Contrastive learning for molecular representation"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model robustness and uncertainty quantification"
    },
    "method": "Contrastive learning; Transformer-based models (SMILES; IUPAC)",
    "application": "Molecular property prediction; drug-drug interaction prediction; cross-lingual molecule retrieval",
    "code_link": "N/A",
    "dataset_name": [
      "PubChem",
      "MoleculeNet BBBP",
      "ClinTox",
      "HIV",
      "SIDER",
      "ESOL",
      "FreeSolv",
      "Lipophilicity",
      "DDI dataset"
    ],
    "is_public": false
  },
  {
    "id": "acl2025_temp_0334",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "AutoMedEval: Harnessing Language Models for Automatic Medical Capability Evaluation",
    "authors": [
      "Xiechi Zhang",
      "Zetian Ouyang",
      "Linlin Wang",
      "Gerard de Melo",
      "Zhu Cao",
      "Xiaoling Wang",
      "Ya Zhang",
      "Yanfeng Wang",
      "Liang He"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "With the proliferation of large language models (LLMs) in the medical domain, there is increasing demand for improved evaluation techniques to assess their capabilities. However, traditional metrics like F1 and ROUGE, which rely on token overlaps to measure quality, significantly overlook the importance of medical terminology. While human evaluation tends to be more reliable, it can be very costly and may as well suffer from inaccuracies due to limits in human expertise and motivation. Although there are some evaluation methods based on LLMs, their usability in the medical field is limited due to their proprietary nature or lack of expertise. To tackle these challenges, we present AutoMedEval, an open-sourced automatic evaluation model with 13B parameters specifically engineered to measure the question-answering proficiency of medical LLMs. The overarching objective of AutoMedEval is to assess the quality of responses produced by diverse models, aspiring to significantly reduce the dependence on human evaluation. Specifically, we propose a hierarchical training method involving curriculum instruction tuning and an iterative knowledge introspection mechanism, enabling AutoMedEval to acquire professional medical assessment capabilities with limited instructional data. Human evaluations indicate that AutoMedEval surpasses other baselines in terms of correlation with human judgments.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.314.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title \"AutoMedEval: Harnessing Language Models for Automatic Medical Capability Evaluation\" strongly suggests relevance to Healthcare AI or Biomedicine AI. The term \"Medical Capability Evaluation\" implies a focus on healthcare-specific tasks, likely involving the assessment of medical systems, data, or decision-making processes. The use of \"Language Models\" further indicates the application of AI to understand or analyze text or language-based medical information. While there is no abstract or keywords provided, the explicit reference to \"medical\" in the title supports the classification within the Healthcare AI domain.",
    "prompt_tokens": 22175,
    "completion_tokens": 255,
    "total_tokens": 22430,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "Human-AI Collaborative Performance"
    },
    "method": "Hierarchical training approach; retrieval-augmented GPT; iterative knowledge introspection",
    "application": "medical evaluation of AI language models; evaluative scoring tasks",
    "code_link": "https://huggingface.co/chaoyi-wu/MedLLaMA_13B",
    "dataset_name": [
      "Medical-Meadow-Wikidoc"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0485",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Identifying Cellular Niches in Spatial Transcriptomics: An Investigation into the Capabilities of Large Language Models",
    "authors": [
      "Huanhuan Wei",
      "Xiao Luo",
      "Hongyi Yu",
      "Jinping Liang",
      "Luning Yang",
      "Lixing Lin",
      "Alexandra Popa",
      "Xiting Yan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Spatial transcriptomic technologies enable measuring gene expression profile and spatial information of cells in tissues simultaneously. Clustering of captured cells/spots in the spatial transcriptomic data is crucial for understanding tissue niches and uncovering disease-related changes.Current methods to cluster spatial transcriptomic data encounter obstacles, including inefficiency in handling multi-replicate data, lack of prior knowledge incorporation, and producing uninterpretable cluster labels.We introduce a novel approach, LLMiniST, to identify spatial niche using a zero-shot large language models (LLMs) by transforming spatial transcriptomic data into spatial context prompts, leveraging gene expression of neighboring cells/spots, cell type composition, tissue information, and external knowledge. The model was further enhanced using a two-stage fine-tuning strategy for improved generalizability. We also develop a user-friendly annotation tool to accelerate the creation of well-annotated spatial dataset for fine-tuning.Comprehensive method performance evaluations showed that both zero-shot and fine-tunned LLMiniST had superior performance than current non-LLM methods in many circumstances. Notably, the two-stage fine-tuning strategy facilitated substantial cross-subject generalizability. The results demonstrate the feasibility of LLMs for tissue niche identification using spatial transcriptomic data and the potential of LLMs as a scalable solution to efficiently integrate minimal human guidance for improved performance in large-scale datasets.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.455.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title \"Identifying Cellular Niches in Spatial Transcriptomics: An Investigation into the Capabilities of Large Language Models\" suggests that the paper focuses on the application of AI techniques, specifically large language models, in spatial transcriptomics. Spatial transcriptomics is a cutting-edge technology used in biomedical research for analyzing gene expression within tissue samples to identify cellular niches. This strongly aligns with the Biomedicine AI domain as it involves analyzing complex biological data to gain insights into cellular and molecular processes, potentially aiding in disease understanding or therapeutic development.",
    "prompt_tokens": 22236,
    "completion_tokens": 217,
    "total_tokens": 22453,
    "Topic Axis I": {
      "MainTopic": "Computational Genomics & Multi-Omics",
      "SubTopic": "Transcriptomics"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Prompt engineering; Large Language Model fine-tuning",
    "application": "Spatial niche identification – transcriptomics",
    "code_link": "https://github.com/wJDKnight/LLMiniST",
    "dataset_name": [
      "STARmap",
      "MERFISH",
      "Visium"
    ],
    "is_public": true
  },
  {
    "id": "2020.acl-main.613",
    "year": 2020,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Document Translation vs. Query Translation for Cross-Lingual Information Retrieval in the Medical Domain",
    "authors": [
      "Shadi Saleh",
      "Pavel Pecina"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We present a thorough comparison of two principal approaches to Cross-Lingual Information Retrieval: document translation (DT) and query translation (QT). Our experiments are conducted using the cross-lingual test collection produced within the CLEF eHealth information retrieval tasks in 2013–2015 containing English documents and queries in several European languages. We exploit the Statistical Machine Translation (SMT) and Neural Machine Translation (NMT) paradigms and train several domain-specific and task-specific machine translation systems to translate the non-English queries into English (for the QT approach) and the English documents to all the query languages (for the DT approach). The results show that the quality of QT by SMT is sufficient enough to outperform the retrieval results of the DT approach for all the languages. NMT then further boosts translation quality and retrieval quality for both QT and DT for most languages, but still, QT provides generally better retrieval results than DT.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2020.acl-main.613.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper is focused on Cross-Lingual Information Retrieval in the medical domain, as indicated by the title and abstract. It utilizes machine translation systems to improve information retrieval specifically for the CLEF eHealth tasks, which are designed to evaluate information retrieval methods within the healthcare space. The term \"eHealth\" strongly ties the paper's content to healthcare applications, particularly in enabling access to medical information across languages. This suggests relevance to Healthcare AI because the methods are applied to a medical context to improve access to clinical or health-related information, aligning with healthcare-specific tasks like patient information retrieval or healthcare resource accessibility.",
    "prompt_tokens": 22325,
    "completion_tokens": 249,
    "total_tokens": 22574,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (GPT, LLaMA)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Neural Machine Translation (NMT); Statistical Machine Translation (SMT); Back-translation",
    "application": "Cross-Lingual Information Retrieval",
    "code_link": "http://ufal.mff.cuni.cz/ufal_medical_corpus",
    "dataset_name": [
      "CLEF eHealth 2013–2015 Collection",
      "Khresmoi Summary Translation Test Data",
      "Khresmoi Query Translation Test Data",
      "UFAL Medical Corpus"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0719",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "HSCR: Hierarchical Self-Contrastive Rewarding for Aligning Medical Vision Language Models",
    "authors": [
      "Songtao Jiang",
      "Yan Zhang",
      "Yeying Jin",
      "Zhihang Tang",
      "Yangyang Wu",
      "YANG FENG",
      "Jian Wu",
      "Zuozhu Liu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Medical Vision-Language Models (Med-VLMs) have achieved success across various tasks, yet most existing methods overlook the modality misalignment issue that can lead to untrustworthy responses in clinical settings. In this paper, we propose Hierarchical Self-Contrastive Rewarding (HSCR), a novel approach that addresses two critical challenges in Med-VLM alignment: 1) Cost-effective generation of high-quality preference data; 2) Capturing nuanced and context-aware preferences for improved alignment. HSCR first leverages the inherent capability of Med-VLMs to generate dispreferred responses with higher sampling probability. By analyzing output logit shifts after visual token dropout, we identify modality-coupled tokens that induce misalignment and derive an implicit alignment reward function. This function guides token replacement with hallucinated ones during decoding, producing high-quality dispreferred data. Furthermore, HSCR introduces a multi-level preference optimization strategy, which extends beyond traditional adjacent-level optimization by incorporating nuanced implicit preferences, leveraging relative quality in dispreferred data to capture subtle alignment cues for more precise and context-aware optimization. Extensive experiments across multiple medical tasks, including Med-VQA, medical image captioning and instruction following, demonstrate that HSCR not only enhances zero-shot performance but also significantly improves modality alignment and trustworthiness with just 2,000 training entries.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.679.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title \"Hierarchical Self-Contrastive Rewarding for Aligning Medical Vision Language Models\" explicitly refers to the alignment of \"Medical Vision Language Models,\" which strongly suggests a focus on applications in healthcare or biomedicine. Vision-language models are frequently used for tasks involving medical imaging, a key domain in Healthcare AI and Biomedicine AI. The inclusion of the term \"medical\" in the title makes it clear that the paper addresses AI applications relevant to the healthcare or biomedical field. Even without an abstract or keywords, this implies a specific focus on the intersection of machine learning and medicine.",
    "prompt_tokens": 22358,
    "completion_tokens": 254,
    "total_tokens": 22612,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Radiology"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Vision Foundation Models (VFMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Hierarchical Self-Contrastive Rewarding (HSCR); Visual token dropout; Preference optimization",
    "application": "modality alignment and trustworthiness enhancement for Medical Vision-Language Models (Med-VLMs)",
    "code_link": "https://github.com/jiangsongtao/HSCR",
    "dataset_name": [
      "LLaVA-Med",
      "Rad-VQA",
      "SLAKE",
      "PathVQA",
      "PMC-15M"
    ],
    "is_public": true
  },
  {
    "id": "2023.acl-long.382",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Are Experts Needed? On Human Evaluation of Counselling Reflection Generation",
    "authors": [
      "Zixiu Wu",
      "Simone Balloccu",
      "Ehud Reiter",
      "Rim Helaoui",
      "Diego Reforgiato Recupero",
      "Daniele Riboni"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Reflection is a crucial counselling skill where the therapist conveys to the client their interpretation of what the client said. Language models have recently been used to generate reflections automatically, but human evaluation is challenging, particularly due to the cost of hiring experts. Laypeople-based evaluation is less expensive and easier to scale, but its quality is unknown for reflections. Therefore, we explore whether laypeople can be an alternative to experts in evaluating a fundamental quality aspect: coherence and context-consistency. We do so by asking a group of laypeople and a group of experts to annotate both synthetic reflections and human reflections from actual therapists. We find that both laypeople and experts are reliable annotators and that they have moderate-to-strong inter-group correlation, which shows that laypeople can be trusted for such evaluations. We also discover that GPT-3 mostly produces coherent and consistent reflections, and we explore changes in evaluation results when the source of synthetic reflections changes to GPT-3 from the less powerful GPT-2.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.382.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract discusses evaluating automated reflections generated by language models, specifically in the context of counselling. Counselling is a healthcare service related to mental health, which falls under the scope of Healthcare AI. The paper mentions “therapist,” “client,” and “counselling skill,” indicating the application is directly tied to supporting healthcare professionals in delivering mental health services. Furthermore, human evaluation of counsellor-generated reflections has implications for the quality of mental health care delivery, thus making it relevant to Healthcare AI.",
    "prompt_tokens": 22147,
    "completion_tokens": 207,
    "total_tokens": 22354,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Fine-tuning; GPT-2 medium; GPT-3 prompting",
    "application": "Reflection generation – Counseling dialogues",
    "code_link": "https://github.com/uccollab/expert_laypeople_reflection_annotation",
    "dataset_name": [
      "AnnoMI",
      "MITI"
    ],
    "is_public": true
  },
  {
    "id": "2020.acl-main.410",
    "year": 2020,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Clinical Reading Comprehension: A Thorough Analysis of the emrQA Dataset",
    "authors": [
      "Xiang Yue",
      "Bernal Jimenez Gutierrez",
      "Huan Sun"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Machine reading comprehension has made great progress in recent years owing to large-scale annotated datasets. In the clinical domain, however, creating such datasets is quite difficult due to the domain expertise required for annotation. Recently, Pampari et al. (EMNLP’18) tackled this issue by using expert-annotated question templates and existing i2b2 annotations to create emrQA, the first large-scale dataset for question answering (QA) based on clinical notes. In this paper, we provide an in-depth analysis of this dataset and the clinical reading comprehension (CliniRC) task. From our qualitative analysis, we find that (i) emrQA answers are often incomplete, and (ii) emrQA questions are often answerable without using domain knowledge. From our quantitative experiments, surprising results include that (iii) using a small sampled subset (5%-20%), we can obtain roughly equal performance compared to the model trained on the entire dataset, (iv) this performance is close to human expert’s performance, and (v) BERT models do not beat the best performing base model. Following our analysis of the emrQA, we further explore two desired aspects of CliniRC systems: the ability to utilize clinical domain knowledge and to generalize to unseen questions and contexts. We argue that both should be considered when creating future datasets.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2020.acl-main.410.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on the emrQA dataset, which is explicitly designed for machine reading comprehension tasks involving clinical notes. Terms like \"clinical reading comprehension,\" \"clinical notes,\" and \"clinical domain knowledge\" indicate that this research applies AI to the healthcare domain. The usage of clinical data (e.g., electronic medical records, i2b2 annotations) and the focus on improving systems for understanding and answering clinical questions align closely with the definition of Healthcare AI. Additionally, the exploration of domain knowledge utilization and system generalization to unseen clinical contexts further underscores its relevance to medical applications.",
    "prompt_tokens": 22298,
    "completion_tokens": 221,
    "total_tokens": 22519,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (GPT, LLaMA)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Inherently Interpretable Models"
    },
    "method": "Transformer-based models (BERT, ClinicalBERT, BioBERT); Knowledge Incorporation Module (KIM)",
    "application": "Clinical reading comprehension – EMRs",
    "code_link": "https://github.com/xiangyue9607/CliniRC",
    "dataset_name": [
      "emrQA",
      "MIMIC-III"
    ],
    "is_public": true
  },
  {
    "id": "2021.acl-long.301",
    "year": 2021,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "A Neural Model for Joint Document and Snippet Ranking in Question Answering for Large Document Collections",
    "authors": [
      "Dimitris Pappas",
      "Ion Androutsopoulos"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Question answering (QA) systems for large document collections typically use pipelines that (i) retrieve possibly relevant documents, (ii) re-rank them, (iii) rank paragraphs or other snippets of the top-ranked documents, and (iv) select spans of the top-ranked snippets as exact answers. Pipelines are conceptually simple, but errors propagate from one component to the next, without later components being able to revise earlier decisions. We present an architecture for joint document and snippet ranking, the two middle stages, which leverages the intuition that relevant documents have good snippets and good snippets come from relevant documents. The architecture is general and can be used with any neural text relevance ranker. We experiment with two main instantiations of the architecture, based on POSIT-DRMM (PDRMM) and a BERT-based ranker. Experiments on biomedical data from BIOASQ show that our joint models vastly outperform the pipelines in snippet retrieval, the main goal for QA, with fewer trainable parameters, also remaining competitive in document retrieval. Furthermore, our joint PDRMM-based model is competitive with BERT-based models, despite using orders of magnitude fewer parameters. These claims are also supported by human evaluation on two test batches of BIOASQ. To test our key findings on another dataset, we modified the Natural Questions dataset so that it can also be used for document and snippet retrieval. Our joint PDRMM-based model again outperforms the corresponding pipeline in snippet retrieval on the modified Natural Questions dataset, even though it performs worse than the pipeline in document retrieval. We make our code and the modified Natural Questions dataset publicly available.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2021.acl-long.301.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on question answering (QA) systems within the context of large document collections, specifically evaluating the methodology on biomedical data from the BIOASQ dataset. The BIOASQ dataset is well-known for its application in biomedical question answering, which addresses tasks related to retrieving and understanding biomedical research. Given the explicit mention of \"biomedical data\" and the application to BIOASQ, the paper falls squarely in the Biomedicine AI domain. Additionally, the inclusion of experiments targeting systems for document and snippet retrieval related to medical research strongly ties the work to biomedical applications. While the paper emphasizes methodology, the focus on biomedical QA demonstrates direct relevance to Biomedicine AI.",
    "prompt_tokens": 22111,
    "completion_tokens": 217,
    "total_tokens": 22328,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "PDRMM; BERT-based ranker; Neural pipelines and joint models",
    "application": "Snippet retrieval – Question answering on biomedical data",
    "code_link": "http://nlp.cs.aueb.gr/publications.html",
    "dataset_name": [
      "BIOASQ",
      "Natural Questions"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_1177",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "VITAL: A New Dataset for Benchmarking Pluralistic Alignment in Healthcare",
    "authors": [
      "Anudeex Shetty",
      "Amin Beheshti",
      "Mark Dras",
      "Usman Naseem"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Alignment techniques have become central to ensuring that Large Language Models (LLMs) generate outputs consistent with human values. However, existing alignment paradigms often model an averaged or monolithic preference, failing to account for the diversity of perspectives across cultures, demographics, and communities. This limitation is particularly critical in health-related scenarios, where plurality is essential due to the influence of culture, religion, personal values, and conflicting opinions. Despite progress in pluralistic alignment, no prior work has focused on health, likely due to the unavailability of publicly available datasets. To address this gap, we introduce VITAL, a new benchmark dataset comprising 13.1K value-laden situations and 5.4K multiple-choice questions focused on health, designed to assess and benchmark pluralistic alignment methodologies. Through extensive evaluation of eight LLMs of varying sizes, we demonstrate that existing pluralistic alignment techniques fall short in effectively accommodating diverse healthcare beliefs, underscoring the need for tailored AI alignment in specific domains. This work highlights the limitations of current approaches and lays the groundwork for developing health-specific alignment solutions.",
    "keywords": "N/A",
    "pdf_url": "https://arxiv.org/pdf/2502.13775",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title mentions \"VITAL: A New Dataset for Benchmarking Pluralistic Alignment in Healthcare,\" which explicitly references a healthcare-specific dataset. The term \"pluralistic alignment\" likely pertains to aligning diverse perspectives or methods in a healthcare context, which fits within the domain of Healthcare AI. Even though an abstract and keywords are not provided, the clear mention of \"Healthcare\" in the title strongly suggests relevance to clinical or health-related applications.",
    "prompt_tokens": 21836,
    "completion_tokens": 221,
    "total_tokens": 22057,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Causal Inference & Reasoning",
      "SubTopic": "Causal Representation Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Algorithmic Fairness & Bias Mitigation"
    },
    "method": "Pluralistic alignment; Mixture of Experts (MoE); Modular Pluralism (ModPlural); Prompting-based alignment",
    "application": "Evaluating large language models' alignment for pluralistic medical scenarios",
    "code_link": "https://github.com/anudeex/VITAL.git",
    "dataset_name": [
      "VITAL"
    ],
    "is_public": true
  },
  {
    "id": "2022.acl-long.109",
    "year": 2022,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Differentiable Multi-Agent Actor-Critic for Multi-Step Radiology Report Summarization",
    "authors": [
      "Sanjeev Kumar Karn",
      "Ning Liu",
      "Hinrich Schuetze",
      "Oladimeji Farri"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The IMPRESSIONS section of a radiology report about an imaging study is a summary of the radiologist’s reasoning and conclusions, and it also aids the referring physician in confirming or excluding certain diagnoses. A cascade of tasks are required to automatically generate an abstractive summary of the typical information-rich radiology report. These tasks include acquisition of salient content from the report and generation of a concise, easily consumable IMPRESSIONS section. Prior research on radiology report summarization has focused on single-step end-to-end models – which subsume the task of salient content acquisition. To fully explore the cascade structure and explainability of radiology report summarization, we introduce two innovations. First, we design a two-step approach: extractive summarization followed by abstractive summarization. Second, we additionally break down the extractive part into two independent tasks: extraction of salient (1) sentences and (2) keywords. Experiments on English radiology reports from two clinical sites show our novel approach leads to a more precise summary compared to single-step and to two-step-with-single-extractive-process baselines with an overall improvement in F1 score of 3-4%.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2022.acl-long.109.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper clearly addresses a healthcare-specific task, namely the summarization of radiology reports. Radiology reports are integral to medical imaging and clinical decision-making, as evidenced by the description of the \"IMPRESSIONS\" section being crucial for confirming or excluding diagnoses. The abstract mentions \"radiologist's reasoning,\" \"referring physician,\" and \"radiology report summarization,\" which directly connect the work to clinical healthcare applications. The methodology involves AI techniques (multi-agent actor-critic) applied in the healthcare domain, establishing its relevance to Healthcare AI.",
    "prompt_tokens": 22365,
    "completion_tokens": 232,
    "total_tokens": 22597,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Radiology"
    },
    "Topic Axis II": {
      "MainTopic": "Sequential Decision Making & Reinforcement Learning",
      "SubTopic": "Reinforcement Learning for Clinical Policy"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Differentiable Multi-agent Actor-Critic (DiMAC) RL learning method; multi-agent reinforcement learning; extractive summarization; abstractive summarization",
    "application": "Radiology report summarization – abstraction and extraction",
    "code_link": "N/A",
    "dataset_name": [
      "Radiology reports from Princeton Radiology, Princeton",
      "University of Colorado Health"
    ],
    "is_public": false
  },
  {
    "id": "2020.acl-main.570",
    "year": 2020,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Amalgamation of protein sequence, structure and textual information for improving protein-protein interaction identification",
    "authors": [
      "Pratik Dutta",
      "Sriparna Saha"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "An in-depth exploration of protein-protein interactions (PPI) is essential to understand the metabolism in addition to the regulations of biological entities like proteins, carbohydrates, and many more. Most of the recent PPI tasks in BioNLP domain have been carried out solely using textual data. In this paper, we argue that incorporating multimodal cues can improve the automatic identification of PPI. As a first step towards enabling the development of multimodal approaches for PPI identification, we have developed two multi-modal datasets which are extensions and multi-modal versions of two popular benchmark PPI corpora (BioInfer and HRPD50). Besides, existing textual modalities, two new modalities, 3D protein structure and underlying genomic sequence, are also added to each instance. Further, a novel deep multi-modal architecture is also implemented to efficiently predict the protein interactions from the developed datasets. A detailed experimental analysis reveals the superiority of the multi-modal approach in comparison to the strong baselines including unimodal approaches and state-of the-art methods over both the generated multi-modal datasets. The developed multi-modal datasets are available for use at https://github.com/sduttap16/MM_PPI_NLP.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2020.acl-main.570.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper falls under the Biomedicine AI domain as it focuses on improving the identification of protein-protein interactions (PPI), which is directly relevant to understanding metabolism and the regulation of biological entities. This has significant implications for biomedical research, particularly in areas like genomics and protein modeling. Specific phrases such as \"protein-protein interactions,\" \"genomic sequence,\" and \"3D protein structure\" are strong indicators of relevance to biomedicine. While the abstract does not mention direct applications in healthcare (e.g., diagnostics or therapeutics), the focus on biological systems and multimodal datasets for analyzing proteins situates it firmly within the scope of Biomedicine AI.",
    "prompt_tokens": 22300,
    "completion_tokens": 259,
    "total_tokens": 22559,
    "Topic Axis I": {
      "MainTopic": "Computational Genomics & Multi-Omics",
      "SubTopic": "Multi-Omics Integration"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (BioBERT); Capsule Network; Graph Convolutional Neural Networks (GCNN); Self-attention mechanism"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods – Visualizations for attention mechanisms"
    },
    "method": "BioBERT; BiLSTM; Capsule network; Graph Convolutional Neural Networks (GCNN); Self-attention mechanism",
    "application": "Protein-protein interaction identification",
    "code_link": "https://github.com/sduttap16/MM_PPI_NLP",
    "dataset_name": [
      "BioInfer",
      "HRPD50"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0490",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Focus on What Matters: Enhancing Medical Vision-Language Models with Automatic Attention Alignment Tuning",
    "authors": [
      "Aofei Chang",
      "Le Huang",
      "Alex James Boyd",
      "Parminder Bhatia",
      "Taha Kass-Hout",
      "Cao Xiao",
      "Fenglong Ma"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Medical Large Vision-Language Models (Med-LVLMs) often exhibit suboptimal attention distribution on visual inputs, leading to hallucinated or inaccurate outputs. Existing methods primarily rely on inference-time interventions, which are limited in attention adaptation or require additional supervision. To address this, we propose A3Tune, a novel fine-tuning framework for Automatic Attention Alignment Tuning. ATune leverages zero-shot weak labels from SAM, refines them into prompt-aware labels using BioMedCLIP, and then selectively modifies visually-critical attention heads to improve alignment while minimizing interference. Additionally, we introduce a A3MoE module, enabling adaptive parameter selection for attention tuning across diverse prompts and images. Extensive experiments on medical VQA and report generation benchmarks show that A3Tune outperforms state-of-the-art baselines, achieving enhanced attention distributions and performance in Med-LVLMs.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.460.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title \"Focus on What Matters: Enhancing Medical Vision-Language Models with Automatic Attention Alignment Tuning\" indicates a clear focus on medical applications, specifically the development or enhancement of vision-language models for medical use. Vision-language models are AI tools designed to process and interpret visual and textual data, and the inclusion of \"medical\" in the title strongly ties the research to the Healthcare AI domain. While there is no abstract or keywords provided, the title alone suggests relevance because it implies that these models are tailored for medical tasks, such as interpreting medical imaging or biomedical texts—common in both Healthcare AI and Biomedicine AI contexts.",
    "prompt_tokens": 22359,
    "completion_tokens": 236,
    "total_tokens": 22595,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Radiology"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Vision-language pretraining"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Inherently Interpretable Models"
    },
    "method": "Fine-tuning framework; attention alignment tuning; Mixture-of-Experts model",
    "application": "Medical VQA and medical report generation",
    "code_link": "https://github.com/Aofei-Chang/A3Tune",
    "dataset_name": [
      "SLAKE",
      "VQA-RAD",
      "PathVQA",
      "IU-Xray",
      "MIMIC-CXR",
      "OmniMedVQA"
    ],
    "is_public": true
  },
  {
    "id": "2021.acl-long.275",
    "year": 2021,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Nested Named Entity Recognition via Explicitly Excluding the Influence of the Best Path",
    "authors": [
      "Yiran Wang",
      "Hiroyuki Shindo",
      "Yuji Matsumoto",
      "Taro Watanabe"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "This paper presents a novel method for nested named entity recognition. As a layered method, our method extends the prior second-best path recognition method by explicitly excluding the influence of the best path. Our method maintains a set of hidden states at each time step and selectively leverages them to build a different potential function for recognition at each level. In addition, we demonstrate that recognizing innermost entities first results in better performance than the conventional outermost entities first scheme. We provide extensive experimental results on ACE2004, ACE2005, and GENIA datasets to show the effectiveness and efficiency of our proposed method.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2021.acl-long.275.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract mentions experimental results on the GENIA dataset, which is a well-known dataset in the biomedical domain. GENIA specifically includes biomedical literature annotations, indicating that the proposed nested named entity recognition method has applications in processing biomedical data. While the ACE2004 and ACE2005 datasets are more general, the inclusion of the GENIA dataset aligns the paper with Biomedicine AI, as it focuses on the extraction of entities from biomedical text, which is a key task in biomedical research and applications like drug discovery or literature mining.",
    "prompt_tokens": 41323,
    "completion_tokens": 215,
    "total_tokens": 41538,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Novel nested NER algorithms; Sequential labeling; Multi-level encoding scheme; CRF sequential labeling",
    "application": "Nested named entity recognition",
    "code_link": "https://github.com/speedcell4/nersted",
    "dataset_name": [
      "ACE2004",
      "ACE2005",
      "GENIA"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0651",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Enhancing Safe and Controllable Protein Generation via Knowledge Preference Optimization",
    "authors": [
      "Yuhao Wang",
      "Keyan Ding",
      "Kehua Feng",
      "Zeyuan Wang",
      "Ming Qin",
      "Xiaotong Li",
      "Qiang Zhang",
      "Huajun Chen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Protein language models have emerged as powerful tools for sequence generation, offering substantial advantages in functional optimization and *denovo* design. However, these models also present significant risks of generating harmful protein sequences, such as those that enhance viral transmissibility or evade immune responses. These concerns underscore critical biosafety and ethical challenges. To address these issues, we propose a Knowledge-guided Preference Optimization (KPO) framework that integrates prior knowledge via a Protein Safety Knowledge Graph. This framework utilizes an efficient graph pruning strategy to identify preferred sequences and employs reinforcement learning to minimize the risk of generating harmful proteins. Experimental results demonstrate that KPO effectively reduces the likelihood of producing hazardous sequences while maintaining high functionality, offering a robust safety assurance framework for applying generative models in biotechnology.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.616.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title, \"Enhancing Safe and Controllable Protein Generation via Knowledge Preference Optimization,\" directly implies the focus is on protein generation, which is a critical aspect of biomedical research. Proteins play a fundamental role in biological functions and are often studied for drug discovery, therapeutic development, and molecular biology applications. The phrase \"safe and controllable\" suggests a focus on optimizing protein design or synthesis in a way that could be important for biomedicine, particularly for therapeutic purposes. Although the abstract and keywords are not available, the context strongly aligns with Biomedicine AI due to its emphasis on protein-related tasks that are central to biomedical research and applications.",
    "prompt_tokens": 21908,
    "completion_tokens": 200,
    "total_tokens": 22108,
    "Topic Axis I": {
      "MainTopic": "Computational Genomics & Multi-Omics",
      "SubTopic": "Proteomics & Protein Structure"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Other Generative Models"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Safety & Failure Detection"
    },
    "method": "Direct Preference Optimization; Graph Pruning",
    "application": "Protein generation – Biosafety assurance",
    "code_link": "https://github.com/huggingface/trl",
    "dataset_name": [
      "UniProt",
      "Swiss-Prot"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0178",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Retrieve to Explain: Evidence-driven Predictions for Explainable Drug Target Identification",
    "authors": [
      "Ravi Patel",
      "Angus Brayne",
      "Rogier Hintzen",
      "Daniel Jaroslawicz",
      "Georgiana Neculae",
      "Dane S. Corneil"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Language models hold incredible promise for enabling scientific discovery by synthesizing massive research corpora. Many complex scientific research questions have multiple plausible answers, each supported by evidence of varying strength. However, existing language models lack the capability to quantitatively and faithfully compare answer plausibility in terms of supporting evidence. To address this, we introduce Retrieve to Explain (R2E), a retrieval-based model that scores and ranks all possible answers to a research question based on evidence retrieved from a document corpus. The architecture represents each answer only in terms of its supporting evidence, with the answer itself masked. This allows us to extend feature attribution methods such as Shapley values, to transparently attribute answer scores to supporting evidence at inference time. The architecture also allows incorporation of new evidence without retraining, including non-textual data modalities templated into natural language. We developed R2E for the challenging scientific discovery task of drug target identification, a human-in-the-loop process where failures are extremely costly and explainability paramount. When predicting whether drug targets will subsequently be confirmed as efficacious in clinical trials, R2E not only matches non-explainable literature-based models but also surpasses a genetics-based target identification approach used throughout the pharmaceutical industry.",
    "keywords": "N/A",
    "pdf_url": "https://arxiv.org/pdf/2402.04068",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title \"Retrieve to Explain: Evidence-driven Predictions for Explainable Drug Target Identification\" explicitly mentions \"drug target identification,\" which falls under the domain of Biomedicine AI. Drug target identification is a critical component of biomedical research, particularly in drug discovery and therapeutic development. The phrase \"evidence-driven predictions\" further implies the use of data-centric AI methods to improve decision-making in a biological or medical context. These elements strongly indicate relevance to Biomedicine AI.",
    "prompt_tokens": 21940,
    "completion_tokens": 217,
    "total_tokens": 22157,
    "Topic Axis I": {
      "MainTopic": "Drug Discovery & Development",
      "SubTopic": "Target Identification & Validation"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Retrieval-augmented generation; Shapley value explanations; Retrieval-based reasoning",
    "application": "Drug target identification and prediction of clinical trial efficacy outcomes",
    "code_link": "https://github.com/BenevolentAI/r2e-evaluation-data",
    "dataset_name": [
      "Held-out Biomedical Literature",
      "Gene Description Facts",
      "Clinical Trial Outcomes"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0434",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "LLM as Entity Disambiguator for Biomedical Entity-Linking",
    "authors": [
      "Christophe Ye",
      "Cassie S. Mitchell"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Entity linking involves normalizing a mention in medical text to a unique identifier in a knowledge base, such as UMLS or MeSH. Most entity linkers follow a two-stage process: first, a candidate generation step selects high-quality candidates, and then a named entity disambiguation phase determines the best candidate for final linking. This study demonstrates that leveraging a large language model (LLM) as an entity disambiguator significantly enhances entity linking models’ accuracy and recall. Specifically, the LLM disambiguator achieves remarkable improvements when applied to alias-matching entity linking methods. Without any fine-tuning, our approach establishes a new state-of-the-art (SOTA), surpassing previous methods on multiple prevalent biomedical datasets by up to 16 points in accuracy. We released our code on GitHub at https://github.com/ChristopheYe/llm_disambiguator",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-short.25.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title \"LLM as Entity Disambiguator for Biomedical Entity-Linking\" explicitly mentions \"Biomedical Entity-Linking,\" which is a task closely related to the domain of Biomedicine AI. Entity disambiguation in the biomedical context typically involves processing and linking biomedical terms, entities, or concepts (e.g., genes, proteins, diseases) to standardized biomedical databases or ontologies, a crucial step in biomedical text-mining and research. The inference of using a large language model (LLM) for such a task further ties this paper to the field of Biomedicine AI. Even in the absence of an abstract and keywords, the phrasing in the title is sufficient evidence of relevance.",
    "prompt_tokens": 21944,
    "completion_tokens": 242,
    "total_tokens": 22186,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "LLM-based entity disambiguation; candidate entity ranking",
    "application": "biomedical entity disambiguation – knowledge bases (UMLS, MeSH)",
    "code_link": "https://github.com/ChristopheYe/llm_disambiguator",
    "dataset_name": [
      "NCBI-Disease",
      "GNormPlus",
      "NLM-Chem",
      "NLM-Gene",
      "Medmentions-ST21PV"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_1104",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "PsyDial: A Large-scale Long-term Conversational Dataset for Mental Health Support",
    "authors": [
      "Huachuan Qiu",
      "Zhenzhong Lan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Dialogue systems for mental health counseling aim to alleviate client distress and assist individuals in navigating personal challenges. Developing effective conversational agents for psychotherapy requires access to high-quality, real-world, long-term client-counselor interaction data, which is difficult to obtain due to privacy concerns. Although removing personally identifiable information is feasible, this process is labor-intensive. To address these challenges, we propose a novel privacy-preserving data reconstruction method that reconstructs real-world client-counselor dialogues while mitigating privacy concerns. We apply the RMRR (Retrieve, Mask, Reconstruct, Refine) method, which facilitates the creation of the privacy-preserving PsyDial dataset, with an average of 37.8 turns per dialogue. Extensive analysis demonstrates that PsyDial effectively reduces privacy risks while maintaining dialogue diversity and conversational exchange. To fairly and reliably evaluate the performance of models fine-tuned on our dataset, we manually collect 101 dialogues from professional counseling books. Experimental results show that models fine-tuned on PsyDial achieve improved psychological counseling performance, outperforming various baseline models. A user study involving counseling experts further reveals that our LLM-based counselor provides higher-quality responses. Code, data, and models are available at https://github.com/qiuhuachuan/PsyDial, serving as valuable resources for future advancements in AI psychotherapy.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.1049.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title of the paper, \"PsyDial: A Large-scale Long-term Conversational Dataset for Mental Health Support,\" explicitly mentions \"Mental Health Support,\" which falls under the domain of Healthcare AI. The focus on conversational datasets tailored for mental health likely involves applications relevant to patient care, such as therapeutic interactions, psychological counseling, or monitoring mental health outcomes—all of which align with Healthcare AI. Even though the abstract and keywords are unavailable, the emphasis on mental health strongly ties the work to clinical and healthcare applications.",
    "prompt_tokens": 41394,
    "completion_tokens": 291,
    "total_tokens": 41685,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "Human-AI Collaborative Performance"
    },
    "method": "RMRR (Retrieve, Mask, Reconstruct, Refine) method; Supervised Fine-Tuning",
    "application": "Long-term psychotherapy dialogue reconstruction",
    "code_link": "https://github.com/qiuhuachuan/PsyDial",
    "dataset_name": [
      "PsyDial"
    ],
    "is_public": true
  },
  {
    "id": "2023.acl-long.681",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "A Simple and Flexible Modeling for Mental Disorder Detection by Learning from Clinical Questionnaires",
    "authors": [
      "Hoyun Song",
      "Jisu Shin",
      "Huije Lee",
      "Jong Park"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Social media is one of the most highly sought resources for analyzing characteristics of the language by its users. In particular, many researchers utilized various linguistic features of mental health problems from social media. However, existing approaches to detecting mental disorders face critical challenges, such as the scarcity of high-quality data or the trade-off between addressing the complexity of models and presenting interpretable results grounded in expert domain knowledge. To address these challenges, we design a simple but flexible model that preserves domain-based interpretability. We propose a novel approach that captures the semantic meanings directly from the text and compares them to symptom-related descriptions. Experimental results demonstrate that our model outperforms relevant baselines on various mental disorder detection tasks. Our detailed analysis shows that the proposed model is effective at leveraging domain knowledge, transferable to other mental disorders, and providing interpretable detection results.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.681.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper introduces a simple yet interpretable model for detecting mental disorders using language data and symptom descriptions derived from clinical questionnaires. It bridges clinical diagnostic criteria (DSM-5) and NLP, focusing on depression, bipolar disorder, anxiety, and borderline personality disorder detection from social media text. This clearly aligns with AI for mental health, a key subdomain of Healthcare AI.",
    "prompt_tokens": -1,
    "completion_tokens": -1,
    "total_tokens": -1,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Siamese Neural Networks"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Symptom-based Model Interpretation"
    },
    "method": "Multi-Head Siamese Network (MHS); Symptom-based representation learning; Domain-knowledge integration from DSM-5; BERT/RoBERTa contextualized embeddings",
    "application": "Mental disorder detection – Social media text",
    "code_link": "https://github.com/HoyunSong/acl23-multi-head-siamese-mental-illness",
    "dataset_name": [
      "Reddit Mental Disorder Datasets (r/depression, r/bipolar, r/anxiety, r/bpd)",
      "RSDD",
      "eRisk2018"
    ],
    "is_public": true
  },
  {
    "id": "2021.acl-long.372",
    "year": 2021,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "A Span-Based Model for Joint Overlapped and Discontinuous Named Entity Recognition",
    "authors": [
      "Fei Li",
      "ZhiChao Lin",
      "Meishan Zhang",
      "Donghong Ji"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Research on overlapped and discontinuous named entity recognition (NER) has received increasing attention. The majority of previous work focuses on either overlapped or discontinuous entities. In this paper, we propose a novel span-based model that can recognize both overlapped and discontinuous entities jointly. The model includes two major steps. First, entity fragments are recognized by traversing over all possible text spans, thus, overlapped entities can be recognized. Second, we perform relation classification to judge whether a given pair of entity fragments to be overlapping or succession. In this way, we can recognize not only discontinuous entities, and meanwhile doubly check the overlapped entities. As a whole, our model can be regarded as a relation extraction paradigm essentially. Experimental results on multiple benchmark datasets (i.e., CLEF, GENIA and ACE05) show that our model is highly competitive for overlapped and discontinuous NER.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2021.acl-long.372.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper's abstract explicitly mentions the use of the model on benchmark datasets such as GENIA, which is a biomedical dataset commonly used for tasks involving biomedical text analysis. Additionally, the focus on named entity recognition (NER) for overlapped and discontinuous entities has applications in biomedical research, particularly in recognizing complex biomedical terms, entities, or relations from scientific literature. While the abstract does not directly reference healthcare or clinical tasks, the inclusion of biomedical-specific datasets and the implications for biomedical text processing strongly align with the Biomedicine AI domain.",
    "prompt_tokens": 22155,
    "completion_tokens": 248,
    "total_tokens": 22403,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "BERT-based span representation; Dependency-guided graph convolutional network (GCN)",
    "application": "Named Entity Recognition (NER) – clinical text",
    "code_link": "https://github.com/foxlf823/sodner",
    "dataset_name": [
      "ShARe/CLEF eHealth Evaluation Lab 2013",
      "SemEval 2014 Task 7",
      "CADEC",
      "GENIA",
      "ACE05"
    ],
    "is_public": true
  },
  {
    "id": "2022.acl-long.350",
    "year": 2022,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "The patient is more dead than alive: exploring the current state of the multi-document summarisation of the biomedical literature",
    "authors": [
      "Yulia Otmakhova",
      "Karin Verspoor",
      "Timothy Baldwin",
      "Jey Han Lau"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Although multi-document summarisation (MDS) of the biomedical literature is a highly valuable task that has recently attracted substantial interest, evaluation of the quality of biomedical summaries lacks consistency and transparency. In this paper, we examine the summaries generated by two current models in order to understand the deficiencies of existing evaluation approaches in the context of the challenges that arise in the MDS task. Based on this analysis, we propose a new approach to human evaluation and identify several challenges that must be overcome to develop effective biomedical MDS systems.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2022.acl-long.350.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on multi-document summarization (MDS) of biomedical literature, which is explicitly a task within the Biomedicine AI domain. The abstract highlights that the study addresses the challenges in generating and evaluating summaries of biomedical content. The emphasis on \"biomedical literature\" strongly ties the paper to the Biomedicine AI field, as MDS in this context would involve processing and synthesizing information relevant to biomedical and clinical research. While the paper does not explicitly mention specific healthcare tasks, its direct focus on biomedical literature aligns it with Biomedicine AI.",
    "prompt_tokens": 22509,
    "completion_tokens": 306,
    "total_tokens": 22815,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Transformer-based models (BART, Longformer)",
    "application": "Medical multi-document summarization",
    "code_link": "N/A",
    "dataset_name": [
      "N/A"
    ],
    "is_public": false
  },
  {
    "id": "2022.acl-long.79",
    "year": 2022,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Doctor Recommendation in Online Health Forums via Expertise Learning",
    "authors": [
      "Xiaoxin Lu",
      "Yubo Zhang",
      "Jing Li",
      "Shi Zong"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Huge volumes of patient queries are daily generated on online health forums, rendering manual doctor allocation a labor-intensive task. To better help patients, this paper studies a novel task of doctor recommendation to enable automatic pairing of a patient to a doctor with relevant expertise. While most prior work in recommendation focuses on modeling target users from their past behavior, we can only rely on the limited words in a query to infer a patient’s needs for privacy reasons. For doctor modeling, we study the joint effects of their profiles and previous dialogues with other patients and explore their interactions via self-learning. The learned doctor embeddings are further employed to estimate their capabilities of handling a patient query with a multi-head attention mechanism. For experiments, a large-scale dataset is collected from Chunyu Yisheng, a Chinese online health forum, where our model exhibits the state-of-the-art results, outperforming baselines only consider profiles and past dialogues to characterize a doctor.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2022.acl-long.79.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This paper clearly falls within the Healthcare AI domain as it addresses the task of automatic doctor recommendation in online health forums, which is directly relevant to healthcare. The abstract specifies the goal of pairing patients with doctors based on their expertise, which is a clinical application. The research involves modeling patient queries to infer healthcare needs and analyzing doctor profiles and dialogues, further highlighting its relevance to healthcare-specific applications. Additionally, it discusses helping patients on a platform dedicated to health-related issues, solidifying its place in Healthcare AI.",
    "prompt_tokens": 22113,
    "completion_tokens": 208,
    "total_tokens": 22321,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (GPT)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Transformer-based models (BERT); Multi-head attention",
    "application": "Doctor recommendation – online health forums",
    "code_link": "https://github.com/polyusmart/Doctor-Recommendation",
    "dataset_name": [
      "Chunyu Yisheng"
    ],
    "is_public": true
  },
  {
    "id": "2021.acl-long.165",
    "year": 2021,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "COVID-Fact: Fact Extraction and Verification of Real-World Claims on COVID-19 Pandemic",
    "authors": [
      "Arkadiy Saakyan",
      "Tuhin Chakrabarty",
      "Smaranda Muresan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We introduce a FEVER-like dataset COVID-Fact of 4,086 claims concerning the COVID-19 pandemic. The dataset contains claims, evidence for the claims, and contradictory claims refuted by the evidence. Unlike previous approaches, we automatically detect true claims and their source articles and then generate counter-claims using automatic methods rather than employing human annotators. Along with our constructed resource, we formally present the task of identifying relevant evidence for the claims and verifying whether the evidence refutes or supports a given claim. In addition to scientific claims, our data contains simplified general claims from media sources, making it better suited for detecting general misinformation regarding COVID-19. Our experiments indicate that COVID-Fact will provide a challenging testbed for the development of new systems and our approach will reduce the costs of building domain-specific datasets for detecting misinformation.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2021.acl-long.165.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on identifying, verifying, and extracting facts about the COVID-19 pandemic, which directly pertains to healthcare and public health. The construction of the COVID-Fact dataset explicitly involves extracting claims related to COVID-19, a health-related context, and verifying misinformation surrounding the pandemic. The tasks of fact verification and misinformation detection are within the healthcare domain because they aim to address health-related information integrity, critical for public safety and medical awareness during a pandemic. Furthermore, the reference to \"scientific claims\" and \"general misinformation regarding COVID-19\" aligns closely with public health and biomedicine AI efforts that analyze and verify health-related information.",
    "prompt_tokens": 22271,
    "completion_tokens": 227,
    "total_tokens": 22498,
    "Topic Axis I": {
      "MainTopic": "Population Health & Computational Epidemiology",
      "SubTopic": "Public Health Surveillance"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Self-supervised learning; BERT and RoBERTa; SBERT-based sentence embedding",
    "application": "Fact verification – COVID claims",
    "code_link": "https://github.com/asaakyan/covidfact",
    "dataset_name": [
      "COVID-Fact",
      "SciFact",
      "Fever"
    ],
    "is_public": true
  },
  {
    "id": "2024.acl-long.459",
    "year": 2024,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "FactPICO: Factuality Evaluation for Plain Language Summarization of Medical Evidence",
    "authors": [
      "Sebastian Joseph",
      "Lily Chen",
      "Jan Trienes",
      "Hannah Göke",
      "Monika Coers",
      "Wei Xu",
      "Byron Wallace",
      "Junyi Jessy Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Plain language summarization with LLMs can be useful for improving textual accessibility of technical content. But how factual are these summaries in a high-stakes domain like medicine? This paper presents FactPICO, a factuality benchmark for plain language summarization of medical texts describing randomized controlled trials (RCTs), which are the basis of evidence-based medicine and can directly inform patient treatment. FactPICO consists of 345 plain language summaries of RCT abstracts generated from three LLMs (i.e., GPT-4, Llama-2, and Alpaca), with fine-grained evaluation and natural language rationales from experts. We assess the factuality of critical elements of RCTs in those summaries: Populations, Interventions, Comparators, Outcomes (PICO), as well as the reported findings concerning these. We also evaluate the correctness of the extra information (e.g., explanations) added by LLMs. Using FactPICO, we benchmark a range of existing factuality metrics, including the newly devised ones based on LLMs. We find that plain language summarization of medical evidence is still challenging, especially when balancing between simplicity and factuality, and that existing metrics correlate poorly with expert judgments on the instance level.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2024.acl-long.459.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper introduces FactPICO, a factuality benchmark for evaluating plain language summaries of medical RCT abstracts. It assesses how accurately large language models convey key clinical elements (PICO: Population, Intervention, Comparator, Outcome). Since this benchmark directly supports improving factuality in clinical evidence summarization, it is clearly situated in healthcare AI for evidence-based medicine and trustworthy clinical NLP applications.",
    "prompt_tokens": 22284,
    "completion_tokens": 189,
    "total_tokens": 22473,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Factuality evaluation; Benchmark construction; Large language model assessment; PICO-based factuality metrics",
    "application": "Factuality evaluation – Medical evidence summarization",
    "code_link": "https://github.com/SebaJoe/thresh",
    "dataset_name": [
      "FactPICO",
      "Evidence Inference V2.0"
    ],
    "is_public": true
  },
  {
    "id": "2023.acl-long.133",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Injecting knowledge into language generation: a case study in auto-charting after-visit care instructions from medical dialogue",
    "authors": [
      "Maksim Eremeev",
      "Ilya Valmianski",
      "Xavier Amatriain",
      "Anitha Kannan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Factual correctness is often the limiting factor in practical applications of natural language generation in high-stakes domains such as healthcare. An essential requirement for maintaining factuality is the ability to deal with rare tokens. This paper focuses on rare tokens that appear in both the source and the reference sequences, and which, when missed during generation, decrease the factual correctness of the output text. For high-stake domains that are also knowledge-rich, we show how to use knowledge to (a) identify which rare tokens that appear in both source and reference are important and (b) uplift their conditional probability. We introduce the “utilization rate” that encodes knowledge and serves as a regularizer by maximizing the marginal probability of selected tokens. We present a study in a knowledge-rich domain of healthcare, where we tackle the problem of generating after-visit care instructions based on patient-doctor dialogues. We verify that, in our dataset, specific medical concepts with high utilization rates are underestimated by conventionally trained sequence-to-sequence models. We observe that correcting this with our approach to knowledge injection reduces the uncertainty of the model as well as improves factuality and coherence without negatively impacting fluency.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.133.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly discusses generating after-visit care instructions from patient-doctor dialogues, which is a healthcare-specific task. The abstract mentions high-stakes domains like healthcare and focuses on improving factual correctness in medical contexts, making it highly relevant to Healthcare AI. The use of medical concepts with \"high utilization rates\" further underscores the health-specific application of the proposed techniques. Therefore, the paper fits within the Healthcare AI domain.",
    "prompt_tokens": 22122,
    "completion_tokens": 217,
    "total_tokens": 22339,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-Accuracy improvement of rare token generation in sequence-to-sequence models"
    },
    "method": "Utilization-rate-aware sequence-to-sequence model training; utilization rate regularization; weighted utilization loss",
    "application": "After-visit care instruction generation – medical dialogue",
    "code_link": "https://github.com/curai/curai-research/tree/main/careplan-charting",
    "dataset_name": [
      "Custom internal dataset"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_1463",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Adverse Event Extraction from Discharge Summaries: A New Dataset, Annotation Scheme, and Initial Findings",
    "authors": [
      "Imane Guellil",
      "Salome Andres",
      "Atul Anand",
      "Bruce Guthrie",
      "Huayu Zhang",
      "Abul Hasan",
      "Honghan Wu",
      "Beatrice Alex"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In this work, we present a manually annotated corpus for Adverse Event (AE) extraction from discharge summaries of elderly patients, a population often underrepresented in clinical NLP resources. The dataset includes 14 clinically significant AEs—such as falls, delirium, and intracranial haemorrhage, along with contextual attributes like negation, diagnosis type, and in-hospital occurrence. Uniquely, the annotation schema supports both discontinuous and overlapping entities, addressing challenges rarely tackled in prior work. We evaluate multiple models using FlairNLP across three annotation granularities: fine-grained, coarse-grained, and coarse-grained with negation. While transformer-based models (e.g., BERT-cased) achieve strong performance on document-level coarse-grained extraction (F1 = 0.943), performance drops notably for fine-grained entity-level tasks (e.g., F1 = 0.675), particularly for rare events and complex attributes. These results demonstrate that despite high-level scores, significant challenges remain in detecting underrepresented AEs and capturing nuanced clinical language. Developed within a Trusted Research Environment (TRE), the dataset is available upon request via DataLoch and serves as a robust benchmark for evaluating AE extraction methods and supporting future cross-dataset generalisation.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.1386.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title \"Adverse Event Extraction from Discharge Summaries: A New Dataset, Annotation Scheme, and Initial Findings\" suggests a focus on analyzing discharge summaries, which are clinical documents summarizing patient care during hospitalization. This is directly relevant to Healthcare AI as extracting adverse events from such summaries is critical for understanding patient safety, monitoring outcomes, and improving clinical decision-making. The use of terms like \"Adverse Event\" and \"Discharge Summaries\" indicates an application in the healthcare domain involving clinical data (EHR), aligning with Healthcare AI tasks such as information extraction for clinical insights.",
    "prompt_tokens": 22135,
    "completion_tokens": 216,
    "total_tokens": 22351,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (e.g., BERT)"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Transformer-based models (BERT, BioBERT); Named Entity Recognition (NER)",
    "application": "Adverse Event extraction - clinical discharge summaries",
    "code_link": "N/A",
    "dataset_name": [
      "Dataloch",
      "MIMIC-IV"
    ],
    "is_public": false
  },
  {
    "id": "2023.acl-long.495",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Towards Identifying Fine-Grained Depression Symptoms from Memes",
    "authors": [
      "Shweta Yadav",
      "Cornelia Caragea",
      "Chenye Zhao",
      "Naincy Kumari",
      "Marvin Solberg",
      "Tanmay Sharma"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The past decade has observed significant attention toward developing computational methods for classifying social media data based on the presence or absence of mental health conditions. In the context of mental health, for clinicians to make an accurate diagnosis or provide personalized intervention, it is crucial to identify fine-grained mental health symptoms. To this end, we conduct a focused study on depression disorder and introduce a new task of identifying fine-grained depressive symptoms from memes. Toward this, we create a high-quality dataset (RESTORE) annotated with 8 fine-grained depression symptoms based on the clinically adopted PHQ-9 questionnaire. We benchmark RESTORE on 20 strong monomodal and multimodal methods. Additionally, we show how imposing orthogonal constraints on textual and visual feature representations in a multimodal setting can enforce the model to learn non-redundant and de-correlated features leading to a better prediction of fine-grained depression symptoms. Further, we conduct an extensive human analysis and elaborate on the limitations of existing multimodal models that often overlook the implicit connection between visual and textual elements of a meme.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.495.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on identifying fine-grained depressive symptoms based on the PHQ-9 questionnaire, which is a clinically adopted tool for assessing depression symptoms. This task is directly related to mental health, a healthcare domain, as it aims to assist clinicians in accurate diagnosis and personalized intervention. The development of a dataset (RESTORE) for identifying depressive symptoms and the benchmarking of models to predict these symptoms aligns with applications in Healthcare AI. The discussion of limitations in multimodal models for understanding depressive symptoms further confirms the paper's relevance to Healthcare or Biomedicine AI.",
    "prompt_tokens": 41489,
    "completion_tokens": 272,
    "total_tokens": 41761,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Other Generative Models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Transformer-based models (BERT, VisualBERT, MMBT, CLIP)",
    "application": "Depression symptom identification – Social media memes",
    "code_link": "https://github.com/huggingface/transformers/tree/main/examples/research_projects/visual_bert",
    "dataset_name": [
      "RESTORE"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0998",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "A Modular Approach for Clinical SLMs Driven by Synthetic Data with Pre-Instruction Tuning, Model Merging, and Clinical-Tasks Alignment",
    "authors": [
      "Jean-Philippe Corbeil",
      "Amin Dada",
      "Jean-Michel Attendu",
      "Asma Ben Abacha",
      "Alessandro Sordoni",
      "Lucas Caccia",
      "Francois Beaulieu",
      "Thomas Lin",
      "Jens Kleesiek",
      "Paul Vozila"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "High computation costs and latency of large language models such as GPT-4 have limited their deployment in clinical settings. Small language models (SLMs) offer a cost-effective alternative, but their limited capacity requires biomedical domain adaptation, which remains challenging. An additional bottleneck is the unavailability and high sensitivity of clinical data. To address these challenges, we propose a novel framework for adapting SLMs into high-performing clinical models. We introduce the MediPhi collection of 3.8B-parameter SLMs developed with our novel framework: pre-instruction tuning of experts on relevant medical and clinical corpora (PMC, Medical Guideline, MedWiki, etc.), model merging, and clinical-tasks alignment. To cover most clinical tasks, we extended the CLUE benchmark to CLUE+, doubling its size. Our expert models deliver relative improvements on this benchmark over the base model without any task-specific fine-tuning: 64.3% on medical entities, 49.5% on radiology reports, and 44% on ICD-10 coding (outperforming GPT-4-0125 by 14%). We unify the expert models into MediPhi via model merging, preserving gains across benchmarks. Furthermore, we built the MediFlow collection, a synthetic dataset of 2.5 million high-quality instructions on 14 medical NLP tasks, 98 fine-grained document types, and JSON format support. Alignment of MediPhi using supervised fine-tuning and direct preference optimization achieves further gains of 18.9% on average.",
    "keywords": "N/A",
    "pdf_url": "https://arxiv.org/pdf/2505.10717",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title indicates a focus on \"Clinical SLMs\" (Specialized Language Models), which are likely tailored for clinical tasks, and references \"synthetic data\" and \"clinical-tasks alignment,\" suggesting applicability to healthcare or biomedicine. The mention of pre-instruction tuning and model merging for clinical applications further emphasizes relevance to designing AI systems that support clinical or medical work. Although the abstract and keywords are missing, the emphasis on \"clinical\" throughout the title clearly situates the paper in the Healthcare AI or Biomedicine AI domain.",
    "prompt_tokens": 40410,
    "completion_tokens": 221,
    "total_tokens": 40631,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "AI for Clinical Decision Support (CDS)"
    },
    "method": "Pre-instruction tuning; model merging; fine-tuning",
    "application": "Clinical natural language processing – medical coding",
    "code_link": "N/A",
    "dataset_name": [
      "MTSamples",
      "PMC-Patients",
      "MedFlow",
      "ClinicalBench"
    ],
    "is_public": false
  },
  {
    "id": "2023.acl-long.654",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Logic-driven Indirect Supervision: An Application to Crisis Counseling",
    "authors": [
      "Mattia Medina Grespan",
      "Meghan Broadbent",
      "Xinyao Zhang",
      "Katherine Axford",
      "Brent Kious",
      "Zac Imel",
      "Vivek Srikumar"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Ensuring the effectiveness of text-based crisis counseling requires observing ongoing conversations and providing feedback, both labor-intensive tasks. Automatic analysis of conversations—at the full chat and utterance levels—may help support counselors and provide better care. While some session-level training data (e.g., rating of patient risk) is often available from counselors, labeling utterances requires expensive post hoc annotation. But the latter can not only provide insights about conversation dynamics, but can also serve to support quality assurance efforts for counselors. In this paper, we examine if inexpensive—and potentially noisy—session-level annotation can help improve label utterances. To this end, we propose a logic-based indirect supervision approach that exploits declaratively stated structural dependencies between both levels of annotation to improve utterance modeling. We show that adding these rules gives an improvement of 3.5% f-score over a strong multi-task baseline for utterance-level predictions. We demonstrate via ablation studies how indirect supervision via logic rules also improves the consistency and robustness of the system.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.654.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract discusses text-based crisis counseling, which is a healthcare-related application, specifically in the domain of mental health support. It mentions patient risk assessment as part of the conversation analysis and aims to improve the quality of care provided by counselors. The use of AI techniques to enhance mental health counseling clearly situates this work within the Healthcare AI domain, as it supports mental and emotional well-being, which are integral to healthcare.",
    "prompt_tokens": 22477,
    "completion_tokens": 221,
    "total_tokens": 22698,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Declarative logic-based framework; transformer-based models",
    "application": "Suicidal ideation prediction – Crisis Counseling",
    "code_link": "N/A",
    "dataset_name": [
      "SafeUT Sessions Dataset",
      "SafeUT Utterance Dataset"
    ],
    "is_public": false
  },
  {
    "id": "2023.acl-long.668",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Towards Domain-Agnostic and Domain-Adaptive Dementia Detection from Spoken Language",
    "authors": [
      "Shahla Farzana",
      "Natalie Parde"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Health-related speech datasets are often small and varied in focus. This makes it difficult to leverage them to effectively support healthcare goals. Robust transfer of linguistic features across different datasets orbiting the same goal carries potential to address this concern. To test this hypothesis, we experiment with domain adaptation (DA) techniques on heterogeneous spoken language data to evaluate generalizability across diverse datasets for a common task: dementia detection. We find that adapted models exhibit better performance across conversational and task-oriented datasets. The feature-augmented DA method achieves a 22% increase in accuracy adapting from a conversational to task-specific dataset compared to a jointly trained baseline. This suggests promising capacity of these techniques to allow for productive use of disparate data for a complex spoken language healthcare task.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.668.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on \"dementia detection,\" which is a clear healthcare-related task as it pertains to the diagnosis of a neurodegenerative disease. The use of linguistic features and domain adaptation is directly applied to spoken language data for detecting this medical condition, emphasizing its relevance to Healthcare AI. Additionally, references to \"healthcare goals\" and \"health-related speech datasets\" further solidify its application in the medical domain. The work aligns with the definition of Healthcare AI by aiming to support healthcare tasks through AI techniques.",
    "prompt_tokens": 22350,
    "completion_tokens": 247,
    "total_tokens": 22597,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-Feature-based explanation"
    },
    "method": "Domain Adaptation; Feature-based models; Instance-based models",
    "application": "Dementia detection – Conversations",
    "code_link": "https://github.com/treena908/Domain_Adaptive_Dementia_Detection",
    "dataset_name": [
      "Carolinas Conversation Collection (CCC)",
      "DementiaBank (DB)",
      "ADReSS",
      "Alzheimer’s Disease Research Center (ADRC)"
    ],
    "is_public": true
  },
  {
    "id": "2024.acl-long.26",
    "year": 2024,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "TTM-RE: Memory-Augmented Document-Level Relation Extraction",
    "authors": [
      "Chufan Gao",
      "Xuan Wang",
      "Jimeng Sun"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Document-level relation extraction aims to categorize the association between any two entities within a document.We find that previous methods for document-level relation extraction are ineffective in exploiting the full potential of large amounts of training data with varied noise levels. For example, in the ReDocRED benchmark dataset, state-of-the-art methods trained on the large-scale, lower-quality, distantly supervised training data generally do not perform better than those trained solely on the smaller, high-quality, human-annotated training data. To unlock the full potential of large-scale noisy training data for document-level relation extraction, we propose TTM-RE, a novel approach that integrates a trainable memory module, known as the Token Turing Machine, with a noisy-robust loss function that accounts for the positive-unlabeled setting. The trainable memory module enhances knowledge extraction from the large-scale noisy training dataset through an explicit learning of the memory tokens and a soft integration of the learned memory tokens into the input representation, thereby improving the model’s effectiveness for the final relation classification. Extensive experiments on ReDocRED, a benchmark dataset for document-level relation extraction, reveal that TTM-RE achieves state-of-the-art performance (with an absolute F1 score improvement of over 3%). Ablation studies further illustrate the superiority of TTM-RE in other domains (the ChemDisGene dataset in the biomedical domain) and under highly unlabeled settings.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2024.acl-long.26.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract mentions the use of the TTM-RE approach for document-level relation extraction on datasets, including ChemDisGene, which belongs to the biomedical domain. ChemDisGene is likely focused on associations between chemicals, diseases, and genes, which are central to biomedical research. Furthermore, the paper highlights the relevance of its method in handling biomedical datasets under highly unlabeled settings, implying its applicability to problems in biomedicine. Although no explicit healthcare applications are mentioned, the inclusion of biomedical domain-specific datasets supports classification as Biomedicine AI.",
    "prompt_tokens": 22418,
    "completion_tokens": 227,
    "total_tokens": 22645,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Token Turing Machines with a memory module; Positive-Unlabeled learning; Transformer-based models (RoBERTa-large)",
    "application": "Document-level relation extraction",
    "code_link": "https://github.com/chufangao/TTM-RE",
    "dataset_name": [
      "ReDocRED",
      "ChemDisGene"
    ],
    "is_public": true
  },
  {
    "id": "2022.acl-long.544",
    "year": 2022,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "CBLUE: A Chinese Biomedical Language Understanding Evaluation Benchmark",
    "authors": [
      "Ningyu Zhang",
      "Mosha Chen",
      "Zhen Bi",
      "Xiaozhuan Liang",
      "Lei Li",
      "Xin Shang",
      "Kangping Yin",
      "Chuanqi Tan",
      "Jian Xu",
      "Fei Huang",
      "Luo Si",
      "Yuan Ni",
      "Guotong Xie",
      "Zhifang Sui",
      "Baobao Chang",
      "Hui Zong",
      "Zheng Yuan",
      "Linfeng Li",
      "Jun Yan",
      "Hongying Zan",
      "Kunli Zhang",
      "Buzhou Tang",
      "Qingcai Chen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Artificial Intelligence (AI), along with the recent progress in biomedical language understanding, is gradually offering great promise for medical practice. With the development of biomedical language understanding benchmarks, AI applications are widely used in the medical field. However, most benchmarks are limited to English, which makes it challenging to replicate many of the successes in English for other languages. To facilitate research in this direction, we collect real-world biomedical data and present the first Chinese Biomedical Language Understanding Evaluation (CBLUE) benchmark: a collection of natural language understanding tasks including named entity recognition, information extraction, clinical diagnosis normalization, single-sentence/sentence-pair classification, and an associated online platform for model evaluation, comparison, and analysis. To establish evaluation on these tasks, we report empirical results with the current 11 pre-trained Chinese models, and experimental results show that state-of-the-art neural models perform by far worse than the human ceiling.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2022.acl-long.544.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on the development of CBLUE, a benchmark specifically catering to Chinese Biomedical Language Understanding Evaluation. The explicit mention of \"biomedical language understanding,\" \"clinical diagnosis normalization,\" and \"medical field\" makes it clear that the work is highly relevant to both Healthcare AI and Biomedicine AI. Additionally, the aim of facilitating medical applications is strongly tied to these domains, as the tasks discussed (e.g., named entity recognition and information extraction) are often critical for clinical and biomedical research tasks. The involvement of real-world biomedical data further underscores its relevance.",
    "prompt_tokens": 21626,
    "completion_tokens": 235,
    "total_tokens": 21861,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "EHR/EMR Predictive Modeling"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (GPT, LLaMA)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Transformer-based models (BERT, RoBERTa, ALBERT), Pre-trained Language Models",
    "application": "clinical trial eligibility classification",
    "code_link": "https://github.com/CBLUEbenchmark/CBLUE",
    "dataset_name": [
      "CHIP-CTC",
      "CHIP-STC",
      "CBLUE"
    ],
    "is_public": true
  },
  {
    "id": "2022.acl-long.578",
    "year": 2022,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Improving the Generalizability of Depression Detection by Leveraging Clinical Questionnaires",
    "authors": [
      "Thong Nguyen",
      "Andrew Yates",
      "Ayah Zirikly",
      "Bart Desmet",
      "Arman Cohan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Automated methods have been widely used to identify and analyze mental health conditions (e.g., depression) from various sources of information, including social media. Yet, deployment of such models in real-world healthcare applications faces challenges including poor out-of-domain generalization and lack of trust in black box models. In this work, we propose approaches for depression detection that are constrained to different degrees by the presence of symptoms described in PHQ9, a questionnaire used by clinicians in the depression screening process. In dataset-transfer experiments on three social media datasets, we find that grounding the model in PHQ9’s symptoms substantially improves its ability to generalize to out-of-distribution data compared to a standard BERT-based approach. Furthermore, this approach can still perform competitively on in-domain data. These results and our qualitative analyses suggest that grounding model predictions in clinically-relevant symptoms can improve generalizability while producing a model that is easier to inspect.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2022.acl-long.578.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper develops depression detection models grounded in the PHQ-9 clinical questionnaire, directly aligning with clinical diagnostic processes. It demonstrates that symptom-based constraints improve model generalization and interpretability across social media datasets, situating this research in AI for mental health within healthcare AI.",
    "prompt_tokens": -1,
    "completion_tokens": -1,
    "total_tokens": -1,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "BERT-based Symptom Constrained Modeling"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Symptom-based Model Constraints"
    },
    "method": "PHQ-9 symptom-constrained model; Weakly-supervised symptom classifiers; CNN-based depression classifier; BERT contextual embeddings",
    "application": "Depression detection – Social media text",
    "code_link": "https://github.com/thongnt99/acl22-depression-phq9",
    "dataset_name": [
      "RSDD",
      "eRisk2018",
      "TRT"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_1076",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Consistent Client Simulation for Motivational Interviewing-based Counseling",
    "authors": [
      "Yizhe Yang",
      "Palakorn Achananuparp",
      "Heyan Huang",
      "Jing Jiang",
      "Nicholas Gabriel Lim",
      "Cameron Tan Shi Ern",
      "Phey Ling KIT",
      "Jenny Giam Xiuhui",
      "John Pinto",
      "Ee-Peng Lim"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Simulating human clients in mental health counseling is crucial for training and evaluating counselors (both human or simulated) in a scalable manner. Nevertheless, past research on client simulation did not focus on complex conversation tasks such as mental health counseling. In these tasks, the challenge is to ensure that the client’s actions (i.e., interactions with the counselor) are consistent with with its stipulated profiles and negative behavior settings. In this paper, we propose a novel framework that supports consistent client simulation for mental health counseling. Our framework tracks the mental state of a simulated client, controls its state transitions, and generates for each state behaviors consistent with the client’s motivation, beliefs, preferred plan to change, and receptivity. By varying the client profile and receptivity, we demonstrate that consistent simulated clients for different counseling scenarios can be effectively created. Both our automatic and expert evaluations on the generated counseling sessions also show that our client simulation method achieves higher consistency than previous methods.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.1021.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title includes \"Motivational Interviewing-based Counseling,\" which is a therapeutic approach commonly used in healthcare for behavior change interventions (e.g., substance use, mental health, chronic disease management). While the abstract and keywords are not provided, the context implies the use of AI to simulate clients in a healthcare counseling scenario, which aligns with applications in Healthcare AI. The focus on counseling linked to motivational interviewing strongly suggests relevance to health-related applications.",
    "prompt_tokens": 22204,
    "completion_tokens": 183,
    "total_tokens": 22387,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "LLM-based simulation; state transition control; action selection; information selection module",
    "application": "Simulated counseling",
    "code_link": "N/A",
    "dataset_name": [
      "AnnoMI"
    ],
    "is_public": false
  },
  {
    "id": "acl2025_temp_0546",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Mitigating Gender Confounding Bias from Spoken Language in Dementia Detection via Weight Masking",
    "authors": [
      "Zhecheng Sheng",
      "Xiruo Ding",
      "Brian Hur",
      "Changye Li",
      "Trevor Cohen",
      "Serguei V. S. Pakhomov"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Deep transformer models have been used to detect linguistic anomalies in patient transcripts for early Alzheimer’s disease (AD) screening. While pre-trained neural language models (LMs) fine-tuned on AD transcripts perform well, little research has explored the effects of the gender of the speakers represented by these transcripts. This work addresses gender confounding in dementia detection and proposes two methods: the Extended Confounding Filter and the Dual Filter, which isolate and ablate weights associated with gender. We evaluate these methods on dementia datasets with first-person narratives from patients with cognitive impairment and healthy controls. Our results show transformer models tend to overfit to training data distributions. Disrupting gender-related weights results in a deconfounded dementia classifier, with the trade-off of slightly reduced dementia detection performance.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.514.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title, \"Mitigating Gender Confounding Bias from Spoken Language in Dementia Detection via Weight Masking,\" explicitly involves \"dementia detection,\" which is a clinical task directly related to healthcare. Dementia is a medical condition, and methods to improve its detection fall under the domain of Healthcare AI. Moreover, the focus on spoken language analysis indicates the use of AI to process health-related data for patient diagnosis, further justifying its relevance to Healthcare AI or Biomedicine AI domains. Although no abstract or keywords are available, the clear reference to a clinical application supports this classification.",
    "prompt_tokens": 22429,
    "completion_tokens": 247,
    "total_tokens": 22676,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "new-Bias Mitigation for Dementia Detection in Text Models"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Algorithmic Fairness & Bias Mitigation"
    },
    "method": "Transformer-based models; Extended Confounding Filter; Dual Filter",
    "application": "Dementia detection – Spoken language transcripts",
    "code_link": "https://github.com/LinguisticAnomalies/DualFilter.git",
    "dataset_name": [
      "DementiaBank Pittsburgh Corpus",
      "Carolina Conversations Collection"
    ],
    "is_public": true
  },
  {
    "id": "2023.acl-long.877",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Two-Stage Fine-Tuning for Improved Bias and Variance for Large Pretrained Language Models",
    "authors": [
      "Lijing Wang",
      "Yingya Li",
      "Timothy Miller",
      "Steven Bethard",
      "Guergana Savova"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The bias-variance tradeoff is the idea that learning methods need to balance model complexity with data size to minimize both under-fitting and over-fitting. Recent empirical work and theoretical analysis with over-parameterized neural networks challenges the classic bias-variance trade-off notion suggesting that no such trade-off holds: as the width of the network grows, bias monotonically decreases while variance initially increases followed by a decrease. In this work, we first provide a variance decomposition-based justification criteria to examine whether large pretrained neural models in a fine-tuning setting are generalizable enough to have low bias and variance. We then perform theoretical and empirical analysis using ensemble methods explicitly designed to decrease variance due to optimization. This results in essentially a two-stage fine-tuning algorithm that first ratchets down bias and variance iteratively, and then uses a selected fixed-bias model to further reduce variance due to optimization by ensembling. We also analyze the nature of variance change with the ensemble size in low- and high-resource classes. Empirical results show that this two-stage method obtains strong results on SuperGLUE tasks and clinical information extraction tasks. Code and settings are available: https://github.com/christa60/bias-var-fine-tuning-plms.git",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.877.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract mentions the application of the two-stage fine-tuning method to \"clinical information extraction tasks,\" which directly indicates a focus on healthcare-related applications. This suggests that the proposed methods were explicitly evaluated or used for tasks in the healthcare or biomedicine domain, even though the paper also includes broader discussions on fine-tuning large pretrained language models. The reference to \"clinical\" tasks makes it relevant to healthcare AI.",
    "prompt_tokens": 22426,
    "completion_tokens": 238,
    "total_tokens": 22664,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-Bias and variance reduction strategies"
    },
    "method": "Two-stage fine-tuning; ensemble methods; snapshot learning; cyclic annealing schedule",
    "application": "information extraction – clinical text",
    "code_link": "https://github.com/christa60/bias-var-fine-tuning-plms.git",
    "dataset_name": [
      "SuperGLUE",
      "THYME",
      "i2b2"
    ],
    "is_public": true
  },
  {
    "id": "2023.acl-long.644",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "DARE: Towards Robust Text Explanations in Biomedical and Healthcare Applications",
    "authors": [
      "Adam Ivankay",
      "Mattia Rigotti",
      "Pascal Frossard"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Along with the successful deployment of deep neural networks in several application domains, the need to unravel the black-box nature of these networks has seen a significant increase recently. Several methods have been introduced to provide insight into the inference process of deep neural networks. However, most of these explainability methods have been shown to be brittle in the face of adversarial perturbations of their inputs in the image and generic textual domain. In this work we show that this phenomenon extends to specific and important high stakes domains like biomedical datasets. In particular, we observe that the robustness of explanations should be characterized in terms of the accuracy of the explanation in linking a model’s inputs and its decisions - faithfulness - and its relevance from the perspective of domain experts - plausibility. This is crucial to prevent explanations that are inaccurate but still look convincing in the context of the domain at hand. To this end, we show how to adapt current attribution robustness estimation methods to a given domain, so as to take into account domain-specific plausibility. This results in our DomainAdaptiveAREstimator (DARE) attribution robustness estimator, allowing us to properly characterize the domain-specific robustness of faithful explanations. Next, we provide two methods, adversarial training and FAR training, to mitigate the brittleness characterized by DARE, allowing us to train networks that display robust attributions. Finally, we empirically validate our methods with extensive experiments on three established biomedical benchmarks.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.644.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper proposes DARE, a domain-adaptive estimator for evaluating the robustness of text explanations in biomedical and healthcare tasks. It defines faithfulness and plausibility metrics, introduces adversarial and FAR training methods, and validates them on multiple biomedical datasets. The work directly addresses explainability robustness in high-stakes medical AI applications, aligning with trustworthy and interpretable healthcare AI research.",
    "prompt_tokens": -1,
    "completion_tokens": -1,
    "total_tokens": -1,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Biomedical Text Analysis"
    },
    "Topic Axis II": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "DomainAdaptiveAREstimator (DARE); Adversarial training; FAR training; Attribution robustness estimation",
    "application": "Explainability robustness evaluation – Biomedical text classification",
    "code_link": "https://github.com/adamivankay/DARE",
    "dataset_name": [
      "MedNLI",
      "HoC (Hallmarks of Cancer)",
      "PubMedQA"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0591",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "TC–RAG: Turing–Complete RAG’s Case study on Medical LLM Systems",
    "authors": [
      "Xinke Jiang",
      "Yue Fang",
      "Rihong Qiu",
      "Haoyu Zhang",
      "Yongxin Xu",
      "Hao Chen",
      "WentaoZhang",
      "Ruizhe Zhang",
      "Yuchen Fang",
      "Xinyu Ma",
      "Xu Chu",
      "Junfeng Zhao",
      "Yasha Wang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In the pursuit of enhancing domain-specific Large Language Models (LLMs), Retrieval-Augmented Generation (RAG) emerges as a promising solution to mitigate issues such as hallucinations, outdated knowledge, and limited expertise in highly specialized queries. However, existing approaches to RAG fall short by neglecting system state variables, which are crucial for ensuring adaptive control, retrieval halting, and system convergence. In this paper, we introduce the TC-RAG through rigorous proof, a novel framework that addresses these challenges by incorporating a Turing Complete System to manage state variables, thereby enabling more efficient and accurate knowledge retrieval. By leveraging a memory stack system with adaptive retrieval, reasoning, and planning capabilities, TC-RAG not only ensures the controlled halting of retrieval processes but also mitigates the accumulation of erroneous knowledge via Push and Pop actions. In the case study of the medical domain, our extensive experiments on real-world healthcare datasets demonstrate the superiority of TC-RAG over existing methods in accuracy by over 7.20. Our dataset and code have been available at https://https://github.com/Artessay/SAMA.git.",
    "keywords": "N/A",
    "pdf_url": "https://arxiv.org/pdf/2408.09199",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title, \"TC–RAG: Turing–Complete RAG’s Case study on Medical LLM Systems,\" explicitly references \"Medical LLM Systems,\" which suggests that the paper involves research related to language models applied in medical contexts. These systems are typically designed to analyze, predict, or support healthcare decisions and biomedical applications. While no abstract or keywords were provided, the mention of \"medical\" strongly indicates relevance to Healthcare AI or Biomedicine AI.",
    "prompt_tokens": 22481,
    "completion_tokens": 215,
    "total_tokens": 22696,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Retrieval-Augmented Generation; Prompt Engineering; Memory Stack System",
    "application": "Multi-task medical Q&A and multi-round consultations",
    "code_link": "N/A",
    "dataset_name": [
      "MMCU-Medical",
      "CMB-Exam",
      "CMB-Clin"
    ],
    "is_public": false
  },
  {
    "id": "2024.acl-long.514",
    "year": 2024,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Fine-Grained Image-Text Alignment in Medical Imaging Enables Explainable Cyclic Image-Report Generation",
    "authors": [
      "Wenting Chen",
      "Linlin Shen",
      "Jingyang Lin",
      "Jiebo Luo",
      "Xiang Li",
      "Yixuan Yuan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Fine-grained vision-language models (VLM) have been widely used for inter-modality local alignment between the predefined fixed patches and textual words. However, in medical analysis, lesions exhibit varying sizes and positions, and using fixed patches may cause incomplete representations of lesions. Moreover, these methods provide explainability by using heatmaps to show the general image areas potentially associated with texts rather than specific regions, making their explanations not explicit and specific enough. To address these issues, we propose a novel Adaptive patch-word Matching (AdaMatch) model to correlate chest X-ray (CXR) image regions with words in medical reports and apply it to CXR-report generation to provide explainability for the generation process. AdaMatch exploits the fine-grained relation between adaptive patches and words to provide explanations of specific image regions with corresponding words. To capture the abnormal regions of varying sizes and positions, we introduce an Adaptive Patch extraction (AdaPatch) module to acquire adaptive patches for these regions adaptively. Aiming to provide explicit explainability for the CXR-report generation task, we propose an AdaMatch-based bidirectional LLM for Cyclic CXR-report generation (AdaMatch-Cyclic). It employs AdaMatch to obtain the keywords for CXR images and ‘keypatches’ for medical reports as hints to guide CXR-report generation. Extensive experiments on two publicly available CXR datasets validate the effectiveness of our method and its superior performance over existing methods. Source code will be released.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2024.acl-long.514.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly addresses medical imaging, specifically chest X-ray (CXR) analysis, which is a healthcare application. It introduces a novel Adaptive patch-word Matching (AdaMatch) model and applies it to CXR-report generation, aiming to improve explainability in medical diagnostics. It references critical tasks such as correlating \"image regions with words in medical reports\" and generating \"CXR-report\" for clinical use. These terms and the focus on medical datasets (CXR images and reports) strongly indicate relevance to Healthcare AI.",
    "prompt_tokens": 22244,
    "completion_tokens": 193,
    "total_tokens": 22437,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Radiology"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Vision Foundation Models (VFMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "AdaMatch model; VQ-GAN; instruction-tuned LLM",
    "application": "CXR-to-report and report-to-CXR generation",
    "code_link": "N/A",
    "dataset_name": [
      "MIMIC-CXR",
      "OpenI"
    ],
    "is_public": false
  },
  {
    "id": "2023.acl-long.453",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "MidMed: Towards Mixed-Type Dialogues for Medical Consultation",
    "authors": [
      "Xiaoming Shi",
      "Zeming Liu",
      "Chuan Wang",
      "Haitao Leng",
      "Kui Xue",
      "Xiaofan Zhang",
      "Shaoting Zhang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Most medical dialogue systems assume that patients have clear goals (seeking a diagnosis, medicine querying, etc.) before medical consultation. However, in many real situations, due to the lack of medical knowledge, it is usually difficult for patients to determine clear goals with all necessary slots. In this paper, we identify this challenge as how to construct medical consultation dialogue systems to help patients clarify their goals. For further study, we create a novel human-to-human mixed-type medical consultation dialogue corpus, termed MidMed, covering four dialogue types: task-oriented dialogue for diagnosis, recommendation, QA, and chitchat. MidMed covers four departments (otorhinolaryngology, ophthalmology, skin, and digestive system), with 8,309 dialogues. Furthermore, we build benchmarking baselines on MidMed and propose an instruction-guiding medical dialogue generation framework, termed InsMed, to handle mixed-type dialogues. Experimental results show the effectiveness of InsMed.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.453.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on developing a medical consultation dialogue system, emphasizing the exploration of mixed-type dialogues to assist patients with unclear goals in medical consultations. Specific references to \"medical dialogue systems,\" \"medical consultation,\" and tasks like \"diagnosis\" and \"recommendation\" directly link the research to Healthcare AI. Additionally, the context of handling dialogues in domains such as otorhinolaryngology, ophthalmology, skin, and digestive system further underscores its application in medical and healthcare-related scenarios, qualifying it as relevant to Healthcare AI.",
    "prompt_tokens": 40535,
    "completion_tokens": 208,
    "total_tokens": 40743,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models (e.g., BART)"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "AI for Clinical Decision Support (CDS)"
    },
    "method": "Transformer-based models (BART)",
    "application": "Medical dialogue generation",
    "code_link": "https://github.com/xmshi-trio/MidMed",
    "dataset_name": [
      "MidMed",
      "MedDialog"
    ],
    "is_public": true
  },
  {
    "id": "2022.acl-long.394",
    "year": 2022,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Human Evaluation and Correlation with Automatic Metrics in Consultation Note Generation",
    "authors": [
      "Francesco Moramarco",
      "Alex Papadopoulos Korfiatis",
      "Mark Perera",
      "Damir Juric",
      "Jack Flann",
      "Ehud Reiter",
      "Anya Belz",
      "Aleksandar Savkov"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In recent years, machine learning models have rapidly become better at generating clinical consultation notes; yet, there is little work on how to properly evaluate the generated consultation notes to understand the impact they may have on both the clinician using them and the patient’s clinical safety. To address this we present an extensive human evaluation study of consultation notes where 5 clinicians (i) listen to 57 mock consultations, (ii) write their own notes, (iii) post-edit a number of automatically generated notes, and (iv) extract all the errors, both quantitative and qualitative. We then carry out a correlation study with 18 automatic quality metrics and the human judgements. We find that a simple, character-based Levenshtein distance metric performs on par if not better than common model-based metrics like BertScore. All our findings and annotations are open-sourced.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2022.acl-long.394.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper is strongly relevant to Healthcare AI, as it focuses on evaluating machine learning-generated clinical consultation notes—a task directly tied to healthcare and clinical practice. It discusses the impact of these notes on clinicians and patient safety, indicating applicability within medical workflows. Additionally, the study involves clinicians writing and post-editing notes, which reinforces its context in healthcare settings. Concepts like \"clinical consultation notes\" and \"patient's clinical safety\" are clear indicators of relevance to Healthcare AI.",
    "prompt_tokens": 22344,
    "completion_tokens": 202,
    "total_tokens": 22546,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Fine-tuned BART; neural summarisation models",
    "application": "consultation note generation",
    "code_link": "https://github.com/babylonhealth/primock57",
    "dataset_name": [
      "Primock57"
    ],
    "is_public": true
  },
  {
    "id": "2022.acl-long.343",
    "year": 2022,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Deep Inductive Logic Reasoning for Multi-Hop Reading Comprehension",
    "authors": [
      "Wenya Wang",
      "Sinno Pan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Multi-hop reading comprehension requires an ability to reason across multiple documents. On the one hand, deep learning approaches only implicitly encode query-related information into distributed embeddings which fail to uncover the discrete relational reasoning process to infer the correct answer. On the other hand, logic-based approaches provide interpretable rules to infer the target answer, but mostly work on structured data where entities and relations are well-defined. In this paper, we propose a deep-learning based inductive logic reasoning method that firstly extracts query-related (candidate-related) information, and then conducts logic reasoning among the filtered information by inducing feasible rules that entail the target relation. The reasoning process is accomplished via attentive memories with novel differentiable logic operators. To demonstrate the effectiveness of our model, we evaluate it on two reading comprehension datasets, namely WikiHop and MedHop.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2022.acl-long.343.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract mentions MedHop, which is a dataset explicitly designed for biomedical research. The dataset focuses on multi-hop reading comprehension tasks related to drug development and medical reasoning. This suggests that part of the paper's evaluation is in the context of biomedicine. Therefore, the paper is relevant to Biomedicine AI because it applies logic reasoning methods to biomedical datasets and potentially addresses medical-related inference tasks.",
    "prompt_tokens": 22551,
    "completion_tokens": 198,
    "total_tokens": 22749,
    "Topic Axis I": {
      "MainTopic": "N/A",
      "SubTopic": "N/A"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Hierarchical Attentive Reader; Neural Logic Operators; Multi-hop Reasoner",
    "application": "multi-hop relation prediction",
    "code_link": "N/A",
    "dataset_name": [
      "WikiHop",
      "MedHop"
    ],
    "is_public": false
  },
  {
    "id": "2020.acl-main.458",
    "year": 2020,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Optimizing the Factual Correctness of a Summary: A Study of Summarizing Radiology Reports",
    "authors": [
      "Yuhao Zhang",
      "Derek Merck",
      "Emily Tsai",
      "Christopher D. Manning",
      "Curtis Langlotz"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Neural abstractive summarization models are able to generate summaries which have high overlap with human references. However, existing models are not optimized for factual correctness, a critical metric in real-world applications. In this work, we develop a general framework where we evaluate the factual correctness of a generated summary by fact-checking it automatically against its reference using an information extraction module. We further propose a training strategy which optimizes a neural summarization model with a factual correctness reward via reinforcement learning. We apply the proposed method to the summarization of radiology reports, where factual correctness is a key requirement. On two separate datasets collected from hospitals, we show via both automatic and human evaluation that the proposed approach substantially improves the factual correctness and overall quality of outputs over a competitive neural summarization system, producing radiology summaries that approach the quality of human-authored ones.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2020.acl-main.458.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on optimizing neural summarization models specifically for summarizing radiology reports, a task directly relevant to clinical healthcare applications. The abstract highlights the importance of factual correctness in summaries for radiology reports, which are medical documents pivotal to diagnosis and treatment planning. Additionally, the study uses datasets collected from hospitals, suggesting strong relevance to healthcare settings. The domain-specific focus on radiology—a medical imaging subfield—clearly situates the work within Healthcare AI.",
    "prompt_tokens": 22234,
    "completion_tokens": 203,
    "total_tokens": 22437,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Radiology"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Reinforcement learning with factual correctness rewards; Pointer-generator network",
    "application": "Abstractive summarization – Radiology reports",
    "code_link": "https://github.com/yuhaozhang/summarize-radiology-findings",
    "dataset_name": [
      "Stanford",
      "RH"
    ],
    "is_public": true
  },
  {
    "id": "2023.acl-long.8",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "ACLM: A Selective-Denoising based Generative Data Augmentation Approach for Low-Resource Complex NER",
    "authors": [
      "Sreyan Ghosh",
      "Utkarsh Tyagi",
      "Manan Suri",
      "Sonal Kumar",
      "Ramaneswaran S",
      "Dinesh Manocha"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Complex Named Entity Recognition (NER) is the task of detecting linguistically complex named entities in low-context text. In this paper, we present ACLM Attention-map aware keyword selection for Conditional Language Model fine-tuning), a novel data augmentation approach based on conditional generation, to address the data scarcity problem in low-resource complex NER. ACLM alleviates the context-entity mismatch issue, a problem existing NER data augmentation techniques suffer from and often generates incoherent augmentations by placing complex named entities in the wrong context. ACLM builds on BART and is optimized on a novel text reconstruction or denoising task - we use selective masking (aided by attention maps) to retain the named entities and certain keywords in the input sentence that provide contextually relevant additional knowledge or hints about the named entities. Compared with other data augmentation strategies, ACLM can generate more diverse and coherent augmentations preserving the true word sense of complex entities in the sentence. We demonstrate the effectiveness of ACLM both qualitatively and quantitatively on monolingual, cross-lingual, and multilingual complex NER across various low-resource settings. ACLM outperforms all our neural baselines by a significant margin (1%-36%). In addition, we demonstrate the application of ACLM to other domains that suffer from data scarcity (e.g., biomedical). In practice, ACLM generates more effective and factual augmentations for these domains than prior methods.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.8.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract mentions the application of the proposed ACLM approach to domains with data scarcity, citing \"biomedical\" specifically. While the paper primarily focuses on complex NER and data augmentation methods, the explicit reference to biomedical applications suggests relevance to Biomedicine AI. The method is noted to generate \"effective and factual augmentations for these domains,\" implying that it could be useful in tasks such as entity extraction or information retrieval in biomedical research. This aligns with typical applications of AI in Biomedicine, where named entity recognition is often employed for analyzing medical or biological text data.",
    "prompt_tokens": 22478,
    "completion_tokens": 270,
    "total_tokens": 22748,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-Creating templates with attention-map keywords for contextual enhancement"
    },
    "method": "Conditional generation; Selective masking; BART fine-tuning; mixner augmentation",
    "application": "Named Entity Recognition – low-resource complex biomedical domains",
    "code_link": "https://github.com/Sreyan88/ACLM",
    "dataset_name": [
      "MultiCoNER",
      "BC2GM",
      "NCBI Disease",
      "TDMSci",
      "CoNLL 2003"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0143",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "uMedSum: A Unified Framework for Advancing Medical Abstractive Summarization",
    "authors": [
      "Aishik Nagar",
      "Yutong Liu",
      "Andy T. Liu",
      "Viktor Schlegel",
      "Vijay Prakash Dwivedi",
      "Arun-Kumar Kaliya-Perumal",
      "GUNA PRATHEEP KALANCHIAM",
      "Yili Tang",
      "Robby T. Tan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Clinical abstractive summarization struggles to balance faithfulness and informativeness, sacrificing key information or introducing confabulations. Techniques like in-context learning and fine-tuning have improved overall summary quality orthogonally, without considering the above issue. Conversely, methods aimed at improving faithfulness and informativeness, such as model reasoning and self improvement, have not been systematically evaluated in the clinical domain. We address this gap by first performing a comprehensive benchmark and study of six advanced abstractive summarization methods across three datasets using five reference-based and reference-free metrics, with the latter specifically assessing faithfulness and informativeness. Based on its findings we then develop uMedSum, a modular hybrid framework introducing novel approaches for sequential confabulation removal and key information addition. Our work outperforms previous GPT-4-based state-of-the-art (SOTA) methods in both quantitative metrics and expert evaluations, achieving an 11.8% average improvement in dedicated faithfulness metrics over the previous SOTA. Doctors prefer uMedSum’s summaries 6 times more than previous SOTA in difficult cases containing confabulations or missing information. These results highlight uMedSum’s effectiveness and generalizability across various datasets and metrics, marking a significant advancement in clinical summarization. uMedSum toolkit is made available on GitHub.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.134.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title, \"uMedSum: A Unified Framework for Advancing Medical Abstractive Summarization,\" explicitly references \"medical\" summarization, which suggests a strong relevance to Healthcare AI. Medical summarization typically involves analyzing clinical data such as patient records, electronic health records (EHRs), or other documentation within the healthcare domain. While the abstract and keywords are unavailable, the emphasis on medical applications in the title strongly indicates a focus on advancing AI methods for healthcare-specific tasks, which qualifies the paper under the Healthcare AI domain.",
    "prompt_tokens": 22128,
    "completion_tokens": 221,
    "total_tokens": 22349,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Radiology"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Natural Language Processing (NLP); Abstractive summarization; Confabulation removal using NLI models",
    "application": "clinical document summarization",
    "code_link": "https://github.com/MMSA/uMedSum",
    "dataset_name": [
      "MIMIC-III",
      "MeQSum",
      "ACI-Bench"
    ],
    "is_public": true
  },
  {
    "id": "2022.acl-long.551",
    "year": 2022,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "LinkBERT: Pretraining Language Models with Document Links",
    "authors": [
      "Michihiro Yasunaga",
      "Jure Leskovec",
      "Percy Liang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Language model (LM) pretraining captures various knowledge from text corpora, helping downstream tasks. However, existing methods such as BERT model a single document, and do not capture dependencies or knowledge that span across documents. In this work, we propose LinkBERT, an LM pretraining method that leverages links between documents, e.g., hyperlinks. Given a text corpus, we view it as a graph of documents and create LM inputs by placing linked documents in the same context. We then pretrain the LM with two joint self-supervised objectives: masked language modeling and our new proposal, document relation prediction. We show that LinkBERT outperforms BERT on various downstream tasks across two domains: the general domain (pretrained on Wikipedia with hyperlinks) and biomedical domain (pretrained on PubMed with citation links). LinkBERT is especially effective for multi-hop reasoning and few-shot QA (+5% absolute improvement on HotpotQA and TriviaQA), and our biomedical LinkBERT sets new states of the art on various BioNLP tasks (+7% on BioASQ and USMLE). We release our pretrained models, LinkBERT and BioLinkBERT, as well as code and data.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2022.acl-long.551.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper introduces LinkBERT, a pretraining method leveraging document links for improved language model performance. While the general domain applications might not directly imply healthcare relevance, the abstract explicitly mentions that the biomedical version of the model—BioLinkBERT—is pretrained on PubMed citation links and achieves state-of-the-art performance on biomedical tasks such as BioASQ and USMLE. These tasks are strongly tied to biomedicine and healthcare, involving clinical question answering and medical knowledge evaluation. The references to PubMed, BioNLP tasks, and improvements in question answering systems for medical use solidify its relevance to the Biomedicine AI domain.",
    "prompt_tokens": 22144,
    "completion_tokens": 235,
    "total_tokens": 22379,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Masked language modeling (MLM); Document relation prediction (DRP)",
    "application": "Biomedical question answering",
    "code_link": "https://github.com/michiyasunaga/LinkBERT",
    "dataset_name": [
      "PubMed",
      "MMLU-professional medicine",
      "MedQA-USMLE",
      "BLURB"
    ],
    "is_public": true
  },
  {
    "id": "2023.acl-long.280",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Mixture-of-Domain-Adapters: Decoupling and Injecting Domain Knowledge to Pre-trained Language Models’ Memories",
    "authors": [
      "Shizhe Diao",
      "Tianyang Xu",
      "Ruijia Xu",
      "Jiawei Wang",
      "Tong Zhang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Pre-trained language models (PLMs) demonstrate excellent abilities to understand texts in the generic domain while struggling in a specific domain. Although continued pre-training on a large domain-specific corpus is effective, it is costly to tune all the parameters on the domain. In this paper, we investigate whether we can adapt PLMs both effectively and efficiently by only tuning a few parameters. Specifically, we decouple the feed-forward networks (FFNs) of the Transformer architecture into two parts: the original pre-trained FFNs to maintain the old-domain knowledge and our novel domain-specific adapters to inject domain-specific knowledge in parallel. Then we adopt a mixture-of-adapters gate to fuse the knowledge from different domain adapters dynamically. Our proposed Mixture-of-Domain-Adapters (MixDA) employs a two-stage adapter-tuning strategy that leverages both unlabeled data and labeled data to help the domain adaptation: i) domain-specific adapter on unlabeled data; followed by ii) the task-specific adapter on labeled data. MixDA can be seamlessly plugged into the pretraining-finetuning paradigm and our experiments demonstrate that MixDA achieves superior performance on in-domain tasks (GLUE), out-of-domain tasks (ChemProt, RCT, IMDB, Amazon), and knowledge-intensive tasks (KILT).Further analyses demonstrate the reliability, scalability, and efficiency of our method.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.280.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract mentions domain adaptation tasks that include \"ChemProt\" and \"RCT,\" which are benchmarks for tasks in biomedicine and healthcare NLP. ChemProt focuses on chemical-protein interactions—a common topic in biomedical research—while RCTs likely refer to analyzing randomized controlled trials, an important aspect of healthcare research. These indicators strongly suggest the paper's methods are applied to tasks relevant to biomedicine and healthcare AI, despite the general focus on domain adaptation techniques for pre-trained language models.",
    "prompt_tokens": 22024,
    "completion_tokens": 255,
    "total_tokens": 22279,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "new-Parameter-efficient fine-tuning strategies"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "new-Efficiency and scalability in domain adaptation"
    },
    "method": "Mixture-of-adapters; Adapter Fine-tuning",
    "application": "Domain adaptation – Pretrained language models for in-domain and out-of-domain tasks",
    "code_link": "https://github.com/Amano-Aki/Mixture-of-Domain-Adapters",
    "dataset_name": [
      "GLUE Benchmark",
      "ChemProt",
      "RCT",
      "IMDB",
      "Amazon",
      "FEVER",
      "CommonsenseQA"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_1288",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "$\\mathtt{GeLLM^3O}$: Generalizing Large Language Models for Multi-property Molecule Optimization",
    "authors": [
      "Vishal Dey",
      "Xiao Hu",
      "Xia Ning"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Despite recent advancements, most computational methods for molecule optimization are constrained to single- or double-property optimization tasks and suffer from poor scalability and generalizability to novel optimization tasks. Meanwhile, Large Language Models (LLMs) demonstrate remarkable out-of-domain generalizability to novel tasks. To demonstrate LLMs' potential for molecule optimization, we introduce MuMOInstruct, the first high-quality instruction-tuning dataset specifically focused on complex multi-property molecule optimization tasks. Leveraging MuMOInstruct, we develop GeLLMOs, a series of instruction-tuned LLMs for molecule optimization. Extensive evaluations across 5 in-domain and 5 out-of-domain tasks demonstrate that GeLLMOs consistently outperform state-of-the-art baselines. GeLLMOs also exhibit outstanding zero-shot generalization to unseen tasks, significantly outperforming powerful closed-source LLMs. Such strong generalizability demonstrates the tremendous potential of GeLLMOs as foundational models for molecule optimization, thereby tackling novel optimization tasks without resource-intensive retraining. ",
    "keywords": "N/A",
    "pdf_url": "https://arxiv.org/pdf/2502.13398",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title explicitly mentions \"multi-property molecule optimization,\" which strongly indicates relevance to drug discovery or molecular design, a key area of Biomedical AI. The optimization of molecules is a critical task in biomedicine, often applied in developing new drugs or therapies. While the abstract and keywords are unavailable, the focus on molecules and the context inferred from the title suggest a direct connection to biomedical applications. Multi-property optimization is a common challenge in designing compounds for therapeutic efficacy, safety, and other drug-like properties, further supporting its relevance to the Biomedicine AI domain.",
    "prompt_tokens": 21401,
    "completion_tokens": 193,
    "total_tokens": 21594,
    "Topic Axis I": {
      "MainTopic": "Drug Discovery & Development",
      "SubTopic": "De Novo Molecule Design"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-Generalization to unseen tasks"
    },
    "method": "Instruction-tuned large language models",
    "application": "Multi-property molecule optimization",
    "code_link": "https://github.com/ninglab/GeLLMO",
    "dataset_name": [
      "MuMOInstruct",
      "ZINC"
    ],
    "is_public": true
  },
  {
    "id": "2023.acl-long.531",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Unsupervised Extractive Summarization of Emotion Triggers",
    "authors": [
      "Tiberiu Sosea",
      "Hongli Zhan",
      "Junyi Jessy Li",
      "Cornelia Caragea"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Understanding what leads to emotions during large-scale crises is important as it can provide groundings for expressed emotions and subsequently improve the understanding of ongoing disasters. Recent approaches trained supervised models to both detect emotions and explain emotion triggers (events and appraisals) via abstractive summarization. However, obtaining timely and qualitative abstractive summaries is expensive and extremely time-consuming, requiring highly-trained expert annotators. In time-sensitive, high-stake contexts, this can block necessary responses. We instead pursue unsupervised systems that extract triggers from text. First, we introduce CovidET-EXT, augmenting (Zhan et al., 2022)’s abstractive dataset (in the context of the COVID-19 crisis) with extractive triggers. Second, we develop new unsupervised learning models that can jointly detect emotions and summarize their triggers. Our best approach, entitled Emotion-Aware Pagerank, incorporates emotion information from external sources combined with a language understanding module, and outperforms strong baselines. We release our data and code at https://github.com/tsosea2/CovidET-EXT.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.531.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses the extraction and summarization of emotion triggers in the context of large-scale crises, specifically mentioning the COVID-19 crisis. While the primary focus is on unsupervised learning methods for analyzing emotions, the application deals directly with understanding emotional responses during a public health crisis. This situates the research within a healthcare-relevant domain as it informs responses to crises like COVID-19, which is a biomedical and public health issue. The integration of computational emotion detection and summarization in this context implies a role in improving healthcare communication or mental health interventions during emergencies. Therefore, the paper relates to the Healthcare AI domain.",
    "prompt_tokens": 22290,
    "completion_tokens": 234,
    "total_tokens": 22524,
    "Topic Axis I": {
      "MainTopic": "Population Health & Computational Epidemiology",
      "SubTopic": "Public Health Surveillance"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-Emotion trigger explanation and summarization"
    },
    "method": "Emotion-Aware PageRank; Extractive summarization",
    "application": "Emotion detection and trigger explanation – Social media posts in crisis contexts",
    "code_link": "https://github.com/tsosea2/CovidET-EXT",
    "dataset_name": [
      "COVIDET",
      "COVIDET-EXT"
    ],
    "is_public": true
  },
  {
    "id": "2024.acl-long.107",
    "year": 2024,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Self-Alignment for Factuality: Mitigating Hallucinations in LLMs via Self-Evaluation",
    "authors": [
      "Xiaoying Zhang",
      "Baolin Peng",
      "Ye Tian",
      "Jingyan Zhou",
      "Lifeng Jin",
      "Linfeng Song",
      "Haitao Mi",
      "Helen Meng"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Despite showing impressive abilities, large language models (LLMs) often struggle with factual inaccuracies, i.e., ”hallucinations”, even when they hold relevant knowledge. To mitigate these hallucinations, current approaches typically necessitate high-quality human factuality annotations. In this work, we explore Self-Alignment for Factuality, where we leverage the self-evaluation capability of an LLM to provide training signals that steer the model towards factuality. Specifically, we incorporate Self-Eval, a self-evaluation component, to prompt an LLM to validate the factuality of its own generated responses solely based on its internal knowledge. Additionally, we design Self-Knowledge Tuning (SK-Tuning) to augment the LLM’s self-evaluation ability by improving the model’s confidence estimation and calibration. We then utilize these self-annotated responses to fine-tune the model via Direct Preference Optimization algorithm. We show that the proposed self-alignment approach substantially enhances factual accuracy over Llama family models across three key knowledge-intensive tasks on TruthfulQA and BioGEN.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2024.acl-long.107.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses improving the factuality of large language models (LLMs) and evaluates their performance on tasks including \"TruthfulQA\" and \"BioGEN.\" The mention of \"BioGEN\" strongly suggests relevance to biomedical applications, as \"BioGEN\" is a benchmark dataset specifically geared toward biomedical data generation tasks. Furthermore, the focus on knowledge-intensive tasks involving factual accuracy enhancement is potentially valuable in healthcare and biomedical contexts, as accurate language model responses are critical when applied to domains like clinical decision support or biomedical research.",
    "prompt_tokens": 79108,
    "completion_tokens": 339,
    "total_tokens": 79447,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Inherently Interpretable Models"
    },
    "method": "Self-alignment; Direct Preference Optimization (DPO); SK-TUNING; SELF-EVAL algorithm",
    "application": "Factual information alignment",
    "code_link": "N/A",
    "dataset_name": [
      "TruthfulQA",
      "BioGEN"
    ],
    "is_public": false
  },
  {
    "id": "acl2025_temp_0586",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Large Language and Protein Assistant for Protein-Protein Interactions Prediction",
    "authors": [
      "Peng Zhou",
      "Pengsen Ma",
      "Jianmin Wang",
      "Xibao Cai",
      "Haitao Huang",
      "Wei Liu",
      "Longyue Wang",
      "Lai Hou Tim",
      "xiangxiang Zeng"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Predicting the types and affinities of protein-protein interactions (PPIs) is crucial for understanding biological processes and developing novel therapeutic approaches. While encoding proteins themselves is essential, PPI networks can also provide rich prior knowledge for these predictive tasks. However, existing methods oversimplify the problem of PPI prediction in a semi-supervised manner when utilizing PPI networks, limiting their practical application. Furthermore, how to effectively use the rich prior knowledge of PPI networks for novel proteins not present in the network remains an unexplored issue. Additionally, due to inflexible architectures, most of existing methods cannot handle complexes containing an flexible number of proteins. To overcome these limitations, we introduce LLaPA (Large Language and Protein Assistant), a multimodal large language model that integrates proteins and PPI networks. LLaPA offers a more rational approach to utilizing PPI networks for PPI prediction and can fully exploit the information of PPI networks for unseen proteins. Through natural language instructions, LLaPA can accept flexible number of protein sequences and has the potential to perform various protein tasks. Experiments show that LLaPA achieves state-of-the-art performance in multi-label PPI (mPPI) type prediction and is capable of predicting the binding affinity between multiple interacting proteins based on sequence data.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.554.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title mentions \"Protein-Protein Interactions Prediction,\" which directly relates to the field of biomedicine. Protein-protein interactions are a critical area of focus in biomedical research, as they play a fundamental role in understanding cellular processes, disease mechanisms, and drug discovery. While the abstract and keywords are not provided, the mention of \"Protein-Protein Interactions\" strongly suggests relevance to biomedicine AI, particularly in areas like molecular modeling or therapeutic protein design, which are directly tied to improving healthcare and biomedical applications.",
    "prompt_tokens": 22036,
    "completion_tokens": 216,
    "total_tokens": 22252,
    "Topic Axis I": {
      "MainTopic": "Computational Genomics & Multi-Omics",
      "SubTopic": "Proteomics & Protein Structure"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Retrieval-augmented generation (RAG); multimodal fusion framework",
    "application": "Protein-protein interaction prediction (multi-label) – biological domain",
    "code_link": "https://github.com/HHW-zhou/LLAPA",
    "dataset_name": [
      "PDB2020 (PP)",
      "SHS27k"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_1317",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Temporal Relation Extraction in Clinical Texts: A Span-based Graph Transformer Approach",
    "authors": [
      "Rochana Chaturvedi",
      "Peyman Baghershahi",
      "Sourav Medya",
      "Barbara Di Eugenio"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Temporal information extraction from unstructured text is essential for contextualizing events and deriving actionable insights, particularly in the medical domain. We address the task of extracting clinical events and their temporal relations using the well-studied I2B2 2012 Temporal Relations Challenge corpus. This task is inherently challenging due to complex clinical language, long documents, and sparse annotations. We introduce GRAPHTREX, a novel method integrating span-based entity-relation extraction, clinical large pre-trained language models (LPLMs), and Heterogeneous Graph Transformers (HGT) to capture local and global dependencies. Our HGT component facilitates information propagation across the document through innovative global landmarks that bridge distant entities. Our method improves the state-of-the-art with 5.5% improvement in the tempeval F1 score over the previous best and up to 8.9% improvement on long-range relations, which presents a formidable challenge. We further demonstrate generalizability by establishing a strong baseline on the E3C corpus. This work not only advances temporal information extraction but also lays the groundwork for improved diagnostic and prognostic models through enhanced temporal reasoning.",
    "keywords": "N/A",
    "pdf_url": "https://arxiv.org/pdf/2503.18085",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title of the paper, \"Temporal Relation Extraction in Clinical Texts: A Span-based Graph Transformer Approach,\" explicitly mentions \"clinical texts,\" which are highly indicative of a healthcare or biomedical context. Temporal relation extraction is a task relevant to structuring and analyzing clinical data, such as electronic health records (EHRs), to understand sequences of medical events (e.g., symptoms, treatments, diagnoses). The focus on clinical texts strongly ties the paper to Healthcare AI applications. Additionally, the use of advanced AI techniques (e.g., span-based graph transformer) to handle clinical information further supports this classification.",
    "prompt_tokens": 22434,
    "completion_tokens": 213,
    "total_tokens": 22647,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Graph Representation Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "Human-AI Collaborative Performance"
    },
    "method": "Heterogeneous Graph Transformers (HGT); Span-based entity-relation extraction",
    "application": "Temporal Relation Extraction – Clinical Notes",
    "code_link": "N/A",
    "dataset_name": [
      "I2B2 2012",
      "E3C"
    ],
    "is_public": false
  },
  {
    "id": "acl2025_temp_0009",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "The Impact of Auxiliary Patient Data on Automated Chest X-Ray Report Generation and How to Incorporate It",
    "authors": [
      "Aaron Nicolson",
      "Shengyao Zhuang",
      "Jason Dowling",
      "Bevan Koopman"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "This study investigates the integration of diverse patient data sources into multimodal language models for automated chest X-ray (CXR) report generation. Traditionally, CXR report generation relies solely on data from a patient’s CXR exam, overlooking valuable information from patient electronic health records. Utilising the MIMIC-CXR and MIMIC-IV-ED datasets, we investigate the use of patient data from emergency department (ED) records — such as vital signs measured and medicines reconciled during an ED stay — for CXR report generation, with the aim of enhancing diagnostic accuracy. We also investigate conditioning CXR report generation on the clinical history section of radiology reports, which has been overlooked in the literature. We introduce a novel approach to transform these heterogeneous data sources into patient data embeddings that prompt a multimodal language model (CXRMate-ED). Our comprehensive evaluation indicates that using a broader set of patient data significantly enhances diagnostic accuracy. The model, training code, and dataset are publicly available.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.9.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title, \"The Impact of Auxiliary Patient Data on Automated Chest X-Ray Report Generation and How to Incorporate It,\" indicates a focus on leveraging patient data to generate reports from chest X-rays—a clear application in the medical imaging domain, which is a subset of Healthcare AI. The use of \"patient data\" and \"chest X-ray\" strongly suggests tasks related to clinical decision support or diagnosis, which aligns with healthcare applications. While the abstract and keywords are not provided, the title alone sufficiently demonstrates relevance to Healthcare AI.",
    "prompt_tokens": 22249,
    "completion_tokens": 209,
    "total_tokens": 22458,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Radiology"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Vision Foundation Models (VFMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Multimodal Language Models; Transformer-based models (LLaMA, UniFormer)",
    "application": "Radiology report generation – Chest X-rays",
    "code_link": "https://github.com/aehrc/cxrmate-ed",
    "dataset_name": [
      "MIMIC-CXR",
      "MIMIC-IV-ED"
    ],
    "is_public": true
  },
  {
    "id": "2023.acl-long.451",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "ORGAN: Observation-Guided Radiology Report Generation via Tree Reasoning",
    "authors": [
      "Wenjun Hou",
      "Kaishuai Xu",
      "Yi Cheng",
      "Wenjie Li",
      "Jiang Liu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "This paper explores the task of radiology report generation, which aims at generating free-text descriptions for a set of radiographs. One significant challenge of this task is how to correctly maintain the consistency between the images and the lengthy report. Previous research explored solving this issue through planning-based methods, which generate reports only based on high-level plans. However, these plans usually only contain the major observations from the radiographs (e.g., lung opacity), lacking much necessary information, such as the observation characteristics and preliminary clinical diagnoses. To address this problem, the system should also take the image information into account together with the textual plan and perform stronger reasoning during the generation process. In this paper, we propose an Observation-guided radiology Report Generation framework (ORGan). It first produces an observation plan and then feeds both the plan and radiographs for report generation, where an observation graph and a tree reasoning mechanism are adopted to precisely enrich the plan information by capturing the multi-formats of each observation. Experimental results demonstrate that our framework outperforms previous state-of-the-art methods regarding text quality and clinical efficacy.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.451.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper directly addresses a task within the medical domain, specifically the generation of radiology reports—a critical healthcare application. The abstract mentions generating \"free-text descriptions for a set of radiographs,\" which are medical imaging data used in clinical diagnosis. Additionally, the paper emphasizes maintaining consistency between radiographic images and textual reports, a task explicitly tied to healthcare practice. Terms like \"lung opacity,\" \"clinical diagnoses,\" and \"radiology report generation\" strongly tie the work to Healthcare AI, as it focuses on improving clinical efficacy and assisting radiologists with automated tools tailored for patient care and diagnosis.",
    "prompt_tokens": 22052,
    "completion_tokens": 196,
    "total_tokens": 22248,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Radiology"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Transformer-based models; Observation-guided generation framework",
    "application": "Radiology report generation – chest X-rays",
    "code_link": "https://github.com/wjhou/ORGan",
    "dataset_name": [
      "MIMIC-CXR",
      "IU X-RAY"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0784",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Towards Omni-RAG: Comprehensive Retrieval-Augmented Generation for Large Language Models in Medical Applications",
    "authors": [
      "Zhe Chen",
      "Yusheng Liao",
      "Shuyang Jiang",
      "Pingjie Wang",
      "YiQiu Guo",
      "Yanfeng Wang",
      "Yu Wang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Large language models hold promise for addressing medical challenges, such as medical diagnosis reasoning, research knowledge acquisition, clinical decision-making, and consumer health inquiry support. However, they often generate hallucinations due to limited medical knowledge. Incorporating external knowledge is therefore critical, which necessitates multi-source knowledge acquisition. We address this challenge by framing it as a source planning problem, which is to formulate context-appropriate queries tailored to the attributes of diverse sources. Existing approaches either overlook source planning or fail to achieve it effectively due to misalignment between the model's expectation of the sources and their actual content. To bridge this gap, we present MedOmniKB, a repository comprising multigenre and multi-structured medical knowledge sources. Leveraging these sources, we propose the Source Planning Optimisation method, which enhances multi-source utilisation. Our approach involves enabling an expert model to explore and evaluate potential plans while training a smaller model to learn source alignment. Experimental results demonstrate that our method substantially improves multi-source planning performance, enabling the optimised small model to achieve state-of-the-art results in leveraging diverse medical knowledge sources.",
    "keywords": "N/A",
    "pdf_url": "https://arxiv.org/pdf/2501.02460",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper's title, \"Towards Omni-RAG: Comprehensive Retrieval-Augmented Generation for Large Language Models in Medical Applications,\" explicitly mentions \"medical applications,\" which suggests relevance to Healthcare AI or Biomedicine AI. This likely involves using retrieval-augmented generation (RAG) techniques to enhance language models for tasks related to healthcare or medicine, such as clinical decision support, diagnostic assistance, or medical research. Although the abstract and keywords are not provided, the direct reference to \"medical applications\" in the title strongly indicates domain specificity in healthcare or biomedicine.",
    "prompt_tokens": 22198,
    "completion_tokens": 289,
    "total_tokens": 22487,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "AI for Clinical Decision Support (CDS)"
    },
    "method": "Retrieval-Augmented Generation (RAG); Direct Preference Optimisation (DPO); Supervised Fine-tuning (SFT)",
    "application": "Medical reasoning for diagnosis and treatments",
    "code_link": "https://github.com/Jack-ZC8/Omni-RAG-Medical",
    "dataset_name": [
      "MedQA",
      "MedMCQA",
      "MMLU-Med",
      "PubMedQA",
      "BioASQ",
      "SEER",
      "DDXPlus",
      "MIMIC-IV-ED",
      "LiveQA",
      "MedicationQA",
      "ExpertQA-Biomed"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_1302",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Improving Automatic Evaluation of Large Language Models (LLMs) in Biomedical Relation Extraction via LLMs-as-the-Judge",
    "authors": [
      "Md Tahmid Rahman Laskar",
      "Israt Jahan",
      "Elham Dolatabadi",
      "Chun Peng",
      "Enamul Hoque",
      "Jimmy Huang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Large Language Models (LLMs) have demonstrated impressive performance in biomedical relation extraction, even in zero-shot scenarios. However, evaluating LLMs in this task remains challenging due to their ability to generate human-like text, often producing synonyms or abbreviations of gold-standard answers, making traditional automatic evaluation metrics unreliable. On the other hand, while human evaluation is more reliable, it is costly and time-consuming, making it impractical for real-world applications. This paper investigates the use of LLMs-as-the-Judge as an alternative evaluation method for biomedical relation extraction. We benchmark 8 LLMs as judges to evaluate the responses generated by 5 other LLMs across 3 biomedical relation extraction datasets. Unlike other text-generation tasks, we observe that LLM-based judges perform quite poorly (usually below 50% accuracy) in the biomedical relation extraction task. Our findings reveal that it happens mainly because relations extracted by LLMs do not adhere to any standard format. To address this, we propose structured output formatting for LLM-generated responses that helps LLM-Judges to improve their performance by about 15% (on average). We also introduce a domain adaptation technique to further enhance LLM-Judge performance by effectively transferring knowledge between datasets. We release both our human-annotated and LLM-annotated judgment data (36k samples in total) for public use here: https://github.com/tahmedge/llm_judge_biomedical_re.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.1238.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper's title, \"Improving Automatic Evaluation of Large Language Models (LLMs) in Biomedical Relation Extraction via LLMs-as-the-Judge,\" explicitly references \"Biomedical Relation Extraction,\" which is a key task in biomedicine AI. Biomedical relation extraction often involves identifying relationships between entities (e.g., diseases, drugs, genes) in biomedical texts, which is critical in tasks like drug discovery, clinical knowledge management, or understanding biological pathways. The term \"Biomedical\" in the title and the use of LLMs for evaluating tasks in this domain strongly indicate relevance to Biomedicine AI.",
    "prompt_tokens": 22276,
    "completion_tokens": 217,
    "total_tokens": 22493,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Contextual Directed Semantic Parsing"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Structured Output Formatting; Domain Adaptation",
    "application": "Biomedical relation extraction",
    "code_link": "https://github.com/tahmedge/llm_judge_biomedical_re",
    "dataset_name": [
      "BC5CDR",
      "KD-DTI",
      "DDI"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_1458",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Medical Graph RAG: Evidence-based Medical Large Language Model via Graph Retrieval-Augmented Generation",
    "authors": [
      "Junde Wu",
      "Jiayuan Zhu",
      "Yunli Qi",
      "Jingkun Chen",
      "Min Xu",
      "Filippo Menolascina",
      "Yueming Jin",
      "Vicente Grau"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We introduce MedGraphRAG, a novel graph-based Retrieval-Augmented Generation (RAG) framework designed to enhance LLMs in generating evidence-based medical responses, improving safety and reliability with private medical data. We introduce Triple Graph Construction and U-Retrieval to enhance GraphRAG, enabling holistic insights and evidence-based response generation for medical applications. Specifically, we connect user documents to credible medical sources and integrate Top-down Precise Retrieval with Bottom-up Response Refinement for balanced context awareness and precise indexing. Validated on 9 medical Q&A benchmarks, 2 health fact-checking datasets, and a long-form generation test set, MedGraphRAG outperforms state-of-the-art models while ensuring credible sourcing. Our code is publicly available.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.1381.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title \"Medical Graph RAG: Evidence-based Medical Large Language Model via Graph Retrieval-Augmented Generation\" explicitly references \"medical\" applications, indicating relevance to healthcare and biomedicine. The mention of \"evidence-based\" suggests that this paper focuses on leveraging AI techniques in clinical or biomedical decision-making contexts. Additionally, \"Graph Retrieval-Augmented Generation\" implies an advanced methodology aimed at improving medical AI systems, likely through structured retrieval mechanisms tailored for medical knowledge. Thus, the paper strongly aligns with the Healthcare AI and Biomedicine AI domain.",
    "prompt_tokens": 22237,
    "completion_tokens": 235,
    "total_tokens": 22472,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Retrieval-Augmented Generation (RAG); Graph-based enhancement; U-Retrieval; Triple Graph Construction",
    "application": "medical query answer generation; evidence-based response generation",
    "code_link": "https://github.com/medgraphrag/code-repository",
    "dataset_name": [
      "MedQA",
      "PubMedQA",
      "MedMCQA",
      "DiverseHealth"
    ],
    "is_public": true
  },
  {
    "id": "acl2025_temp_0752",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "EAGLE: Expert-Guided Self-Enhancement for Preference Alignment in Pathology Large Vision-Language Model",
    "authors": [
      "Meidan Ding",
      "Jipeng Zhang",
      "Wenxuan Wang",
      "Haiqin Zhong",
      "Xiaoqin Wang",
      "XINHENG LYU",
      "Wenting Chen",
      "Linlin Shen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Recent advancements in Large Vision Language Models (LVLMs) show promise for pathological diagnosis, yet their application in clinical settings faces critical challenges of multimodal hallucination and biased responses. While preference alignment methods have proven effective in general domains, acquiring high-quality preference data for pathology remains challenging due to limited expert resources and domain complexity. In this paper, we propose EAGLE (Expert-guided self-enhancement for preference Alignment in patholoGy Large vision-languagE model), a novel framework that systematically integrates medical expertise into preference alignment. EAGLE consists of three key stages: initialization through supervised fine-tuning, self-preference creation leveraging expert prompting and medical entity recognition, and iterative preference following-tuning. The self-preference creation stage uniquely combines expert-verified chosen sampling with expert-guided rejected sampling to generate high-quality preference data, while the iterative tuning process continuously refines both data quality and model performance. Extensive experiments demonstrate that EAGLE significantly outperforms existing pathological LVLMs, effectively reducing hallucination and bias while maintaining pathological accuracy. The source code is available at https://github.com/meidandz/EAGLE.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2025.acl-long.711.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title \"EAGLE: Expert-Guided Self-Enhancement for Preference Alignment in Pathology Large Vision-Language Model\" strongly suggests that the work focuses on pathology, which is a key discipline in healthcare and medical diagnostics. The mention of \"Pathology\" indicates specific relevance to the analysis and interpretation of medical images or tissue samples—a core task in Healthcare AI or Biomedicine AI. Additionally, the use of a \"Large Vision-Language Model\" implies an AI system designed for tasks involving image data and language understanding, both of which are commonly applied in medical and pathology-related contexts. While the abstract and keywords are missing, the strong domain-specific term \"Pathology\" justifies classification under Healthcare AI/Biomedicine AI.",
    "prompt_tokens": 22101,
    "completion_tokens": 241,
    "total_tokens": 22342,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Digital Pathology"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Direct Preference Optimization (DPO); Supervised Fine-Tuning (SFT)",
    "application": "Visual question answering for histopathological image interpretation",
    "code_link": "https://github.com/meidandz/EAGLE",
    "dataset_name": [
      "PathVQA",
      "Quilt-VQA",
      "Quilt-Red",
      "Quilt-NoRed"
    ],
    "is_public": true
  },
  {
    "id": "2023.acl-long.685",
    "year": 2023,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "PAL to Lend a Helping Hand: Towards Building an Emotion Adaptive Polite and Empathetic Counseling Conversational Agent",
    "authors": [
      "Kshitij Mishra",
      "Priyanshu Priya",
      "Asif Ekbal"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The World Health Organization (WHO) has significantly emphasized the need for mental health care. The social stigma associated with mental illness prevents individuals from addressing their issues and getting assistance. In such a scenario, the relevance of online counseling has increased dramatically. The feelings and attitudes that a client and a counselor express towards each other result in a higher or lower counseling experience. A counselor should be friendly and gain clients’ trust to make them share their problems comfortably. Thus, it is essential for the counselor to adequately comprehend the client’s emotions and ensure client’s welfare, i.e. s/he should adapt and deal with the clients politely and empathetically to provide a pleasant, cordial and personalized experience. Motivated by this, in this work, we attempt to build a novel Polite and empAthetic counseLing conversational agent PAL to lay down the counseling support to substance addict and crime victims. To have client’s emotion-based polite and empathetic responses, two counseling datasets laying down the counseling support to substance addicts and crime victims are annotated. These annotated datasets are used to build PAL in a reinforcement learning framework. A novel reward function is formulated to ensure correct politeness and empathy preferences as per client’s emotions with naturalness and non-repetitiveness in responses. Thorough automatic and human evaluation showcase the usefulness and strength of the designed novel reward function. Our proposed system is scalable and can be easily modified with different modules of preference models as per need.",
    "keywords": "N/A",
    "pdf_url": "https://aclanthology.org/2023.acl-long.685.pdf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The research paper focuses on building a polite and empathetic conversational agent (PAL) designed to assist in counseling individuals who are substance addicts or crime victims. These target populations are directly associated with healthcare needs, particularly mental health care, as emphasized by the World Health Organization (WHO) in the abstract. The counseling support provided by the system aligns closely with applications in Healthcare AI, as it addresses mental health-related assistance and emotional well-being. While the paper does not explicitly reference clinical data or diagnostic tasks, its focus on improving mental health care through AI qualifies it as relevant to Healthcare AI due to its therapeutic aims.",
    "prompt_tokens": 22318,
    "completion_tokens": 215,
    "total_tokens": 22533,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Digital Health & Wearable Sensor Data"
    },
    "Topic Axis II": {
      "MainTopic": "Sequential Decision Making & Reinforcement Learning",
      "SubTopic": "Offline Reinforcement Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "AI for Clinical Decision Support (CDS)"
    },
    "method": "Principle-guided reinforcement learning; Pre-trained language models",
    "application": "Emotion-adaptive conversational agent for mental health counseling",
    "code_link": "N/A",
    "dataset_name": [
      "en-EmoInHindi",
      "EPE-enEIH",
      "EPE-HLCC",
      "EMPATHETIC-DIALOGUES"
    ],
    "is_public": false
  },
  {
    "id": "acl2025_temp_0154",
    "year": 2025,
    "conference": "ACL (Association for Computational Linguistic)",
    "title": "Less for More: Enhanced Feedback-aligned Mixed LLMs for Molecule Caption Generation and Fine-Grained NLI Evaluation",
    "authors": [
      "Dimitris Gkoumas",
      "Maria Liakata"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Scientific language models drive research innovation but require extensive fine-tuning on large datasets. This work enhances such models by improving their inference and evaluation capabilities with minimal or no additional training. Focusing on molecule caption generation, we explore post-training synergies between alignment fine-tuning and model merging in a cross-modal setup. We reveal intriguing insights into the behaviour and suitability of such methods while significantly surpassing state-of-the-art models. Moreover, we propose a novel atomic-level evaluation method leveraging off-the-shelf Natural Language Inference (NLI) models for use in the unseen chemical domain. Our experiments demonstrate that our evaluation operates at the right level of granularity, effectively handling multiple content units and subsentence reasoning, while widely adopted NLI methods consistently misalign with assessment criteria.",
    "keywords": "N/A",
    "pdf_url": "https://arxiv.org/pdf/2405.13984",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The title references \"molecule caption generation,\" which suggests the use of language models to generate descriptive information about molecular structures. This aligns with drug discovery, molecular modeling, or biomedical research tasks, key areas in Biomedicine AI. Furthermore, \"fine-grained NLI evaluation\" could imply applications to biomedical literature or molecular dataset interpretation, as natural language inference is often relevant to analyzing biomedical contexts or research. The focus on molecules strongly indicates relevance to biomedicine.",
    "prompt_tokens": 22300,
    "completion_tokens": 224,
    "total_tokens": 22524,
    "Topic Axis I": {
      "MainTopic": "Drug Discovery & Development",
      "SubTopic": "new-Molecule caption generation in the chemical domain"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "new-Language-molecule translation and alignment fine-tuning"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Safety & Failure Detection"
    },
    "method": "Contrastive Preference Optimization (CPO); Model merging; Atomic-level Cross-NLI evaluation",
    "application": "Molecule caption generation and validation",
    "code_link": "https://github.com/language-plus-molecules/LPM-24-Dataset",
    "dataset_name": [
      "L+M-24"
    ],
    "is_public": true
  }
]