[
  {
    "id": "HklxbgBKvr",
    "year": 2020,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Model-based reinforcement learning for biological sequence design",
    "authors": [
      "Christof Angermueller",
      "David Dohan",
      "David Belanger",
      "Ramya Deshpande",
      "Kevin Murphy",
      "Lucy Colwell"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The ability to design biological structures such as DNA or proteins would have considerable medical and industrial impact. Doing so presents a challenging black-box optimization problem characterized by the large-batch, low round setting due to the need for labor-intensive wet lab evaluations. In response, we propose using reinforcement learning (RL) based on proximal-policy optimization (PPO) for biological sequence design. RL provides a flexible framework for optimization generative sequence models to achieve specific criteria, such as diversity among the high-quality sequences discovered. We propose a model-based variant of PPO, DyNA-PPO, to improve sample efficiency, where the policy for a new round is trained offline using a simulator fit on functional measurements from prior rounds. To accommodate the growing number of observations across rounds, the simulator model is automatically selected at each round from a pool of diverse models of varying capacity.  On the tasks of designing DNA transcription factor binding sites, designing antimicrobial proteins, and optimizing the energy of Ising models based on protein structure, we find that DyNA-PPO performs significantly better than existing methods in settings in which modeling is feasible, while still not performing worse in situations in which a reliable model cannot be learned.",
    "keywords": "reinforcement learning, blackbox optimization, molecule design",
    "pdf_url": "https://openreview.net/pdf?id=HklxbgBKvr",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This paper focuses on designing biological sequences—including DNA transcription factor binding sites and antimicrobial proteins—which directly falls under molecular modeling and protein design for biomedical applications. The tasks of “designing antimicrobial proteins” and “DNA transcription factor binding sites” are classical biomedicine AI problems in drug discovery and synthetic biology.",
    "prompt_tokens": 20826,
    "completion_tokens": 115,
    "total_tokens": 20941,
    "topic": "Bioinformatics - Biological Sequence Design",
    "method": "Model-based reinforcement learning; Proximal policy optimization (PPO)",
    "application": "Optimization of biological sequences",
    "code_link": "https://github.com/tensorflow/agents",
    "dataset_name": [
      "Protein Contact Ising Models",
      "Transcription Factor Binding Site Dataset",
      "Antimicrobial Peptide Dataset"
    ]
  },
  {
    "id": "BJg866NFvB",
    "year": 2020,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Estimating counterfactual treatment outcomes over time through adversarially balanced representations",
    "authors": [
      "Ioana Bica",
      "Ahmed M Alaa",
      "James Jordon",
      "Mihaela van der Schaar"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Identifying when to give treatments to patients and how to select among multiple treatments over time are important medical problems with a few existing solutions. In this paper, we introduce the Counterfactual Recurrent Network (CRN), a novel sequence-to-sequence model that leverages the increasingly available patient observational data to estimate treatment effects over time and answer such medical questions. To handle the bias from time-varying confounders, covariates affecting the treatment assignment policy in the observational data, CRN uses domain adversarial training to build balancing representations of the patient history. At each timestep, CRN constructs a treatment invariant representation which removes the association between patient history and treatment assignments and thus can be reliably used for making counterfactual predictions. On a simulated model of tumour growth, with varying degree of time-dependent confounding, we show how our model achieves lower error in estimating counterfactuals and in choosing the correct treatment and timing of treatment than current state-of-the-art methods.",
    "keywords": "treatment effects over time, causal inference, counterfactual estimation",
    "pdf_url": "https://openreview.net/pdf?id=BJg866NFvB",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper directly addresses estimating counterfactual treatment effects over time using “patient observational data,” deals with “time‐varying confounders” in treatment assignment, and evaluates on a simulated model of “tumour growth.” These elements—sequential treatment assignment, personalized treatment timing, and tumour response modeling—are quintessential medical/clinical applications, placing the work squarely in Healthcare/ Biomedicine AI.",
    "prompt_tokens": 21018,
    "completion_tokens": 110,
    "total_tokens": 21128,
    "topic": "Clinical Risk Modeling - Treatment Timing",
    "method": "Recurrent neural networks (RNN); domain-adversarial training",
    "application": "Counterfactual outcome prediction for treatment planning",
    "code_link": "https://github.com/sjblim/rmsn_nips_2018",
    "dataset_name": [
      "MIMIC-III"
    ]
  },
  {
    "id": "rklr9kHFDB",
    "year": 2020,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Rotation-invariant clustering of neuronal responses in primary visual cortex",
    "authors": [
      "Ivan Ustyuzhaninov",
      "Santiago A. Cadena",
      "Emmanouil Froudarakis",
      "Paul G. Fahey",
      "Edgar Y. Walker",
      "Erick Cobos",
      "Jacob Reimer",
      "Fabian H. Sinz",
      "Andreas S. Tolias",
      "Matthias Bethge",
      "Alexander S. Ecker"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Similar to a convolutional neural network (CNN), the mammalian retina encodes visual information into several dozen nonlinear feature maps, each formed by one ganglion cell type that tiles the visual space in an approximately shift-equivariant manner. Whether such organization into distinct cell types is maintained at the level of cortical image processing is an open question. Predictive models building upon convolutional features have been shown to provide state-of-the-art performance, and have recently been extended to include rotation equivariance in order to account for the orientation selectivity of V1 neurons. However, generally no direct correspondence between CNN feature maps and groups of individual neurons emerges in these models, thus rendering it an open question whether V1 neurons form distinct functional clusters. Here we build upon the rotation-equivariant representation of a CNN-based V1 model and propose a methodology for clustering the representations of neurons in this model to find functional cell types independent of preferred orientations of the neurons. We apply this method to a dataset of 6000 neurons and visualize the preferred stimuli of the resulting clusters. Our results highlight the range of non-linear computations in mouse V1.",
    "keywords": "computational neuroscience, neural system identification, functional cell types, deep learning, rotational equivariance",
    "pdf_url": "https://openreview.net/pdf?id=rklr9kHFDB",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on modeling and clustering neuronal responses in the primary visual cortex (V1), which falls under “neuroscience or neurobiological modeling” (e.g., neuron type classification, neural system dynamics). Such computational analysis of brain circuitry and cell types is considered part of Biomedicine AI.",
    "prompt_tokens": 20817,
    "completion_tokens": 94,
    "total_tokens": 20911,
    "topic": "Neuroscience - Primary Visual Cortex",
    "method": "Rotation-equivariant CNN; Gaussian mixture model clustering",
    "application": "Functional clustering of V1 neurons",
    "code_link": "N/A",
    "dataset_name": [
      "Published model and data from Ecker et al., 2019"
    ]
  },
  {
    "id": "S1eALyrYDH",
    "year": 2020,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "RNA Secondary Structure Prediction By Learning Unrolled Algorithms",
    "authors": [
      "Xinshi Chen",
      "Yu Li",
      "Ramzan Umarov",
      "Xin Gao",
      "Le Song"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In this paper, we propose an end-to-end deep learning model, called E2Efold, for RNA secondary structure prediction which can effectively take into account the inherent constraints in the problem. The key idea of E2Efold is to directly predict the RNA base-pairing matrix, and use an unrolled algorithm for constrained programming as the template for deep architectures to enforce constraints. With comprehensive experiments on benchmark datasets, we demonstrate the superior performance of E2Efold: it predicts significantly better structures compared to previous SOTA (especially for pseudoknotted structures), while being as efficient as the fastest algorithms in terms of inference time.",
    "keywords": "RNA secondary structure prediction, learning algorithm, deep architecture design, computational biology",
    "pdf_url": "https://openreview.net/pdf?id=S1eALyrYDH",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work focuses on RNA secondary structure prediction, a key task in molecular modeling and genomics. The title and abstract discuss “RNA base-pairing matrix,” “pseudoknotted structures,” and “computational biology,” all of which align with biomedicine applications such as understanding RNA function, drug design, and molecular-level biological research.",
    "prompt_tokens": 20696,
    "completion_tokens": 90,
    "total_tokens": 20786,
    "topic": "Bioinformatics - RNA Structure Prediction",
    "method": "Unrolled Algorithms; Differentiable Optimization",
    "application": "RNA secondary structure prediction",
    "code_link": "N/A",
    "dataset_name": [
      "RNAStralign",
      "ArchiveII"
    ]
  },
  {
    "id": "S1esMkHYPr",
    "year": 2020,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "GraphAF: a Flow-based Autoregressive Model for Molecular Graph Generation",
    "authors": [
      "Chence Shi*",
      "Minkai Xu*",
      "Zhaocheng Zhu",
      "Weinan Zhang",
      "Ming Zhang",
      "Jian Tang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Molecular graph generation is a fundamental problem for drug discovery and has been attracting growing attention. The problem is challenging since it requires not only generating chemically valid molecular structures but also optimizing their chemical properties in the meantime. Inspired by the recent progress in deep generative models, in this paper we propose a flow-based autoregressive model for graph generation called GraphAF. GraphAF combines the advantages of both autoregressive and flow-based approaches and enjoys: (1) high model flexibility for data density estimation; (2) efficient parallel computation for training; (3) an iterative sampling process, which allows leveraging chemical domain knowledge for valency checking. Experimental results show that GraphAF is able to generate 68\\% chemically valid molecules even without chemical knowledge rules and 100\\% valid molecules with chemical rules. The training process of GraphAF is two times faster than the existing state-of-the-art approach GCPN. After fine-tuning the model for goal-directed property optimization with reinforcement learning, GraphAF achieves state-of-the-art performance on both chemical property optimization and constrained property optimization. ",
    "keywords": "Molecular graph generation, deep generative models, normalizing flows, autoregressive models",
    "pdf_url": "https://openreview.net/pdf?id=S1esMkHYPr",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on molecular graph generation “for drug discovery” and “optimizing their chemical properties,” which are core tasks in biomedicine AI. The methods are applied to design valid molecular structures and fine-tuned for goal-directed property optimization in a drug-discovery context, clearly situating it within the Biomedicine AI domain.",
    "prompt_tokens": 20829,
    "completion_tokens": 104,
    "total_tokens": 20933,
    "topic": "Drug Discovery - Molecule Generation",
    "method": "Flow-based generative model; autoregressive modeling",
    "application": "Molecular graph generation",
    "code_link": "https://github.com/DeepGraphLearning/GraphAF",
    "dataset_name": [
      "ZINC250k",
      "QM9",
      "MOSES"
    ]
  },
  {
    "id": "HJlWWJSFDH",
    "year": 2020,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Strategies for Pre-training Graph Neural Networks",
    "authors": [
      "Weihua Hu*",
      "Bowen Liu*",
      "Joseph Gomes",
      "Marinka Zitnik",
      "Percy Liang",
      "Vijay Pande",
      "Jure Leskovec"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Many applications of machine learning require a model to make accurate pre-dictions on test examples that are distributionally different from training ones, while task-specific labels are scarce during training. An effective approach to this challenge is to pre-train a model on related tasks where data is abundant, and then fine-tune it on a downstream task of interest. While pre-training has been effective in many language and vision domains, it remains an open question how to effectively use pre-training on graph datasets. In this paper, we develop a new strategy and self-supervised methods for pre-training Graph Neural Networks (GNNs). The key to the success of our strategy is to pre-train an expressive GNN at the level of individual nodes as well as entire graphs so that the GNN can learn useful local and global representations simultaneously. We systematically study pre-training on multiple graph classification datasets. We find that naïve strategies, which pre-train GNNs at the level of either entire graphs or individual nodes, give limited improvement and can even lead to negative transfer on many downstream tasks. In contrast, our strategy avoids negative transfer and improves generalization significantly across downstream tasks, leading up to 9.4% absolute improvements in ROC-AUC over non-pre-trained models and achieving state-of-the-art performance for molecular property prediction and protein function prediction.",
    "keywords": "Pre-training, Transfer learning, Graph Neural Networks",
    "pdf_url": "https://openreview.net/pdf?id=HJlWWJSFDH",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the paper focuses on general Graph Neural Network pre-training strategies, it evaluates them on molecular property prediction and protein function prediction—classic biomedical tasks (e.g., drug discovery, molecular modeling, protein analysis). These applications fall squarely within the Biomedicine AI domain.",
    "prompt_tokens": 20721,
    "completion_tokens": 148,
    "total_tokens": 20869,
    "topic": "Drug Discovery - Graph Representation",
    "method": "Graph Neural Networks (GNNs); Supervised graph-level pretraining; Node-level self-supervised pretraining; Context Prediction; Attribute Masking",
    "application": "Molecular property prediction; Protein function prediction",
    "code_link": "http://snap.stanford.edu/gnn-pretrain",
    "dataset_name": [
      "ZINC15",
      "ChEMBL",
      "MoleculeNet",
      "PPI Networks"
    ]
  },
  {
    "id": "H1gBhkBFDH",
    "year": 2020,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "B-Spline CNNs on Lie groups",
    "authors": [
      "Erik J Bekkers"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Group convolutional neural networks (G-CNNs) can be used to improve classical CNNs by equipping them with the geometric structure of groups. Central in the success of G-CNNs is the lifting of feature maps to higher dimensional disentangled representations, in which data characteristics are effectively learned, geometric data-augmentations are made obsolete, and predictable behavior under geometric transformations (equivariance) is guaranteed via group theory. Currently, however, the practical implementations of G-CNNs are limited to either discrete groups (that leave the grid intact) or continuous compact groups such as rotations (that enable the use of Fourier theory). In this paper we lift these limitations and propose a modular framework for the design and implementation of G-CNNs for arbitrary Lie groups. In our approach the differential structure of Lie groups is used to expand convolution kernels in a generic basis of B-splines that is defined on the Lie algebra. This leads to a flexible framework that enables localized, atrous, and deformable convolutions in G-CNNs by means of respectively localized, sparse and non-uniform B-spline expansions. The impact and potential of our approach is studied on two benchmark datasets: cancer detection in histopathology slides (PCam dataset) in which rotation equivariance plays a key role and facial landmark localization (CelebA dataset) in which scale equivariance is important. In both cases, G-CNN architectures outperform their classical 2D counterparts and the added value of atrous and localized group convolutions is studied in detail.",
    "keywords": "equivariance, Lie groups, B-Splines, G-CNNs, deep learning, group convolution, computer vision, medical image analysis",
    "pdf_url": "https://openreview.net/pdf?id=H1gBhkBFDH",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper evaluates its method on the PCam dataset, which involves “cancer detection in histopathology slides,” a clear medical imaging and diagnostic task. The abstract also cites “medical image analysis” in the keywords. These are direct applications in Healthcare AI.",
    "prompt_tokens": 20809,
    "completion_tokens": 96,
    "total_tokens": 20905,
    "topic": "Medical Imaging - Landmark Detection",
    "method": "Group Convolutional Neural Networks (G-CNNs)",
    "application": "Facial landmark localization",
    "code_link": "N/A",
    "dataset_name": [
      "PatchCamelyon (PCam)",
      "CelebA"
    ]
  },
  {
    "id": "S1e_9xrFvS",
    "year": 2020,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Energy-based models for atomic-resolution protein conformations",
    "authors": [
      "Yilun Du",
      "Joshua Meier",
      "Jerry Ma",
      "Rob Fergus",
      "Alexander Rives"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We propose an energy-based model (EBM) of protein conformations that operates at atomic scale. The model is trained solely on crystallized protein data. By contrast, existing approaches for scoring conformations use energy functions that incorporate knowledge of physical principles and features that are the complex product of several decades of research and tuning. To evaluate the model, we benchmark on the rotamer recovery task, the problem of predicting the conformation of a side chain from its context within a protein structure, which has been used to evaluate energy functions for protein design. The model achieves performance close to that of the Rosetta energy function, a state-of-the-art method widely used in protein structure prediction and design. An investigation of the model’s outputs and hidden representations finds that it captures physicochemical properties relevant to protein energy.",
    "keywords": "energy-based model, transformer, energy function, protein conformation",
    "pdf_url": "https://openreview.net/pdf?id=S1e_9xrFvS",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on modeling atomic‐resolution protein conformations and benchmarks on rotamer recovery—a core task in protein design. Protein conformations and rotamer modeling are fundamental to molecular modelling and drug discovery, which fall squarely under Biomedicine AI rather than purely general ML.",
    "prompt_tokens": 20691,
    "completion_tokens": 107,
    "total_tokens": 20798,
    "topic": "Bioinformatics - Protein Conformations",
    "method": "Energy-based model (EBM); Transformer-based models",
    "application": "Rotamer recovery – protein side chains",
    "code_link": "https://github.com/facebookresearch/protein-ebm",
    "dataset_name": [
      "CullPDB database",
      "Leaver-Fay test set"
    ]
  },
  {
    "id": "Byg-wJSYDS",
    "year": 2020,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Discrepancy Ratio: Evaluating Model Performance When Even Experts Disagree on the Truth",
    "authors": [
      "Igor Lovchinsky",
      "Alon Daks",
      "Israel Malkin",
      "Pouya Samangouei",
      "Ardavan Saeedi",
      "Yang Liu",
      "Swami Sankaranarayanan",
      "Tomer Gafner",
      "Ben Sternlieb",
      "Patrick Maher",
      "Nathan Silberman"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In most machine learning tasks unambiguous ground truth labels can easily be acquired. However, this luxury is often not afforded to many high-stakes, real-world scenarios such as medical image interpretation, where even expert human annotators typically exhibit very high levels of disagreement with one another. While prior works have focused on overcoming noisy labels during training, the question of how to evaluate models when annotators disagree about ground truth has remained largely unexplored. To address this, we propose the discrepancy ratio: a novel, task-independent and principled framework for validating machine learning models in the presence of high label noise. Conceptually, our approach evaluates a model by comparing its predictions to those of human annotators, taking into account the degree to which annotators disagree with one another. While our approach is entirely general, we show that in the special case of binary classification, our proposed metric can be evaluated in terms of simple, closed-form expressions that depend only on aggregate statistics of the labels and not on any individual label. Finally, we demonstrate how this framework can be used effectively to validate machine learning models using two real-world tasks from medical imaging. The discrepancy ratio metric reveals what conventional metrics do not: that our models not only vastly exceed the average human performance, but even exceed the performance of the best human experts in our datasets.",
    "keywords": "Evaluation Metrics, Medical Imaging",
    "pdf_url": "https://openreview.net/pdf?id=Byg-wJSYDS",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper is motivated by “high-stakes, real-world scenarios such as medical image interpretation,” and the authors validate their proposed discrepancy ratio framework on “two real-world tasks from medical imaging.” This direct application to medical imaging places it squarely in the Healthcare AI domain.",
    "prompt_tokens": 20518,
    "completion_tokens": 95,
    "total_tokens": 20613,
    "topic": "Medical Imaging - Echocardiography",
    "method": "Deep Neural Networks",
    "application": "PLAX measurability classification; LVEF regression",
    "code_link": "N/A",
    "dataset_name": [
      "PLAX measurability classification dataset",
      "LVEF regression dataset"
    ]
  },
  {
    "id": "B1xIj3VYvr",
    "year": 2020,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Weakly Supervised Clustering by Exploiting Unique Class Count",
    "authors": [
      "Mustafa Umit Oner",
      "Hwee Kuan Lee",
      "Wing-Kin Sung"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "A weakly supervised learning based clustering framework is proposed in this paper. As the core of this framework, we introduce a novel multiple instance learning task based on a bag level label called unique class count (ucc), which is the number of unique classes among all instances inside the bag. In this task, no annotations on individual instances inside the bag are needed during training of the models. We mathematically prove that with a perfect ucc classifier, perfect clustering of individual instances inside the bags is possible even when no annotations on individual instances are given during training. We have constructed a neural network based ucc classifier and experimentally shown that the clustering performance of our framework with our weakly supervised ucc classifier is comparable to that of fully supervised learning models where labels for all instances are known. Furthermore, we have tested the applicability of our framework to a real world task of semantic segmentation of breast cancer metastases in histological lymph node sections and shown that the performance of our weakly supervised framework is comparable to the performance of a fully supervised Unet model.",
    "keywords": "weakly supervised clustering, weakly supervised learning, multiple instance learning",
    "pdf_url": "https://openreview.net/pdf?id=B1xIj3VYvr",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning:** Although the paper primarily proposes a general weakly supervised clustering framework, it includes a real-world application in medical imaging: “semantic segmentation of breast cancer metastases in histological lymph node sections.” This pathology task (breast cancer metastasis detection) is a clear healthcare/biomedicine AI application, justifying a Yes classification.",
    "prompt_tokens": 20829,
    "completion_tokens": 107,
    "total_tokens": 20936,
    "topic": "Medical Imaging - Weakly Supervised Learning",
    "method": "Kernel Density Estimation (KDE); Multiple Instance Learning (MIL); Autoencoder-based weak supervision",
    "application": "Semantic segmentation of breast cancer metastases",
    "code_link": "http://bit.ly/uniqueclasscount",
    "dataset_name": [
      "CAMELYON"
    ]
  },
  {
    "id": "rkxawlHKDr",
    "year": 2020,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "End to End Trainable Active Contours via Differentiable Rendering",
    "authors": [
      "Shir Gur",
      "Tal Shaharabany",
      "Lior Wolf"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We present an image segmentation method that iteratively evolves a polygon. At each iteration, the vertices of the polygon are displaced based on the local value of a 2D shift map that is inferred from the input image via an encoder-decoder architecture. The main training loss that is used is the difference between the polygon shape and the ground truth segmentation mask. The network employs a neural renderer to create the polygon from its vertices, making the process fully differentiable. We demonstrate that our method outperforms the state of the art segmentation networks and deep active contour solutions in a variety of benchmarks, including medical imaging and aerial images.",
    "keywords": "",
    "pdf_url": "https://openreview.net/pdf?id=rkxawlHKDr",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the paper proposes a general polygon‐based segmentation method, the abstract explicitly states that it is benchmarked on “medical imaging” data. Image segmentation in medical imaging (e.g., CT, MRI, ultrasound) is a core Healthcare AI task. Therefore, this work falls within the Healthcare AI domain.",
    "prompt_tokens": 20703,
    "completion_tokens": 112,
    "total_tokens": 20815,
    "topic": "Medical Imaging - Segmentation",
    "method": "Active contour models; neural renderer",
    "application": "Cardiac and mammographic image segmentation",
    "code_link": "https://github.com/shirgur/ACDRNet",
    "dataset_name": [
      "INBreast",
      "DDSM-BCRP",
      "Sunnybrook Cardiac Data (SCD)"
    ]
  },
  {
    "id": "SJxUjlBtwB",
    "year": 2020,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Reconstructing continuous distributions of 3D protein structure from cryo-EM images",
    "authors": [
      "Ellen D. Zhong",
      "Tristan Bepler",
      "Joseph H. Davis",
      "Bonnie Berger"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Cryo-electron microscopy (cryo-EM) is a powerful technique for determining the structure of proteins and other macromolecular complexes at near-atomic resolution. In single particle cryo-EM, the central problem is to reconstruct the 3D structure of a macromolecule from $10^{4-7}$ noisy and randomly oriented 2D projection images. However, the imaged protein complexes may exhibit structural variability, which complicates reconstruction and is typically addressed using discrete clustering approaches that fail to capture the full range of protein dynamics. Here, we introduce a novel method for cryo-EM reconstruction that extends naturally to modeling continuous generative factors of structural heterogeneity. This method encodes structures in Fourier space using coordinate-based deep neural networks, and trains these networks from unlabeled 2D cryo-EM images by combining exact inference over image orientation with variational inference for structural heterogeneity. We demonstrate that the proposed method, termed cryoDRGN, can perform ab-initio reconstruction of 3D protein complexes from simulated and real 2D cryo-EM image data. To our knowledge, cryoDRGN is the first neural network-based approach for cryo-EM reconstruction and the first end-to-end method for directly reconstructing continuous ensembles of protein structures from cryo-EM images.",
    "keywords": "generative models, proteins, 3D reconstruction, cryo-EM",
    "pdf_url": "https://openreview.net/pdf?id=SJxUjlBtwB",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work focuses on reconstructing 3D protein structures from cryo-electron microscopy (cryo-EM) data, which is squarely in the realm of molecular modeling and structural biology. The abstract references “macromolecular complexes,” “structural heterogeneity,” and “3D protein complexes,” all of which are key topics in biomedicine and drug discovery. Consequently, this paper contributes to Biomedicine AI.",
    "prompt_tokens": 39327,
    "completion_tokens": 116,
    "total_tokens": 39443,
    "topic": "Bioinformatics - Protein Structure Modeling",
    "method": "Coordinate-based deep neural networks; Variational Inference",
    "application": "3D protein structure reconstruction",
    "code_link": "N/A",
    "dataset_name": [
      "EMPIAR-10028",
      "EMPIAR-10076"
    ]
  },
  {
    "id": "SJlRUkrFPS",
    "year": 2020,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Learning transport cost from subset correspondence",
    "authors": [
      "Ruishan Liu",
      "Akshay Balsubramani",
      "James Zou"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Learning to align multiple datasets is an important problem with many applications, and it is especially useful when we need to integrate multiple experiments or correct for confounding. Optimal transport (OT) is a principled approach to align  datasets, but a key challenge in applying OT is that we need to specify a cost function that accurately captures how the two datasets are related. Reliable cost functions are typically not available and practitioners often resort to using hand-crafted or Euclidean cost even if it may not be appropriate. In this work, we investigate how to learn the cost function using a small amount of side information which is often available. The side information we consider captures subset correspondence---i.e. certain subsets of points in the two data sets are known to be related. For example, we may have some images labeled as cars in both datasets; or we may have a common annotated cell type in single-cell data from two batches. We develop an end-to-end optimizer (OT-SI) that differentiates through the Sinkhorn algorithm and effectively learns the suitable cost function from side information. On systematic experiments in images, marriage-matching and single-cell RNA-seq, our method substantially outperform state-of-the-art benchmarks. ",
    "keywords": "",
    "pdf_url": "https://openreview.net/pdf?id=SJlRUkrFPS",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the core contribution is a general optimal‐transport method for aligning datasets, the paper explicitly evaluates on “single-cell RNA-seq” data and refers to “a common annotated cell type in single-cell data from two batches.” Single-cell transcriptomics is a biomedical domain (genomics, batch‐effect correction), so this work clearly touches on Biomedicine AI.",
    "prompt_tokens": 20888,
    "completion_tokens": 96,
    "total_tokens": 20984,
    "topic": "Optimal Transport - Cost Function Learning",
    "method": "Sinkhorn-Knopp iterations; Mimic learning",
    "application": "Dataset alignment – single-cell RNA and protein data",
    "code_link": "N/A",
    "dataset_name": [
      "CITE-seq CBMCs"
    ]
  },
  {
    "id": "h0de3QWtGG",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Learning \"What-if\" Explanations for Sequential Decision-Making",
    "authors": [
      "Ioana Bica",
      "Daniel Jarrett",
      "Alihan Hüyük",
      "Mihaela van der Schaar"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Building interpretable parameterizations of real-world decision-making on the basis of demonstrated behavior--i.e. trajectories of observations and actions made by an expert maximizing some unknown reward function--is essential for introspecting and auditing policies in different institutions. In this paper, we propose learning explanations of expert decisions by modeling their reward function in terms of preferences with respect to ``\"what if'' outcomes: Given the current history of observations, what would happen if we took a particular action? To learn these cost-benefit tradeoffs associated with the expert's actions, we integrate counterfactual reasoning into batch inverse reinforcement learning. This offers a principled way of defining reward functions and explaining expert behavior, and also satisfies the constraints of real-world decision-making---where active experimentation is often impossible (e.g. in healthcare). Additionally, by estimating the effects of different actions, counterfactuals readily tackle the off-policy nature of policy evaluation in the batch setting, and can naturally accommodate settings where the expert policies depend on histories of observations rather than just current states. Through illustrative experiments in both real and simulated medical environments, we highlight the effectiveness of our batch, counterfactual inverse reinforcement learning approach in recovering accurate and interpretable descriptions of behavior.",
    "keywords": "counterfactuals, explaining decision-making, preference learning",
    "pdf_url": "https://openreview.net/pdf?id=h0de3QWtGG",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly targets real-world decision-making “where active experimentation is often impossible (e.g. in healthcare)” and evaluates its methods in “real and simulated medical environments.” Its focus on interpreting expert decisions in settings like treatment planning or policy evaluation in healthcare domains clearly situates it within Healthcare AI.",
    "prompt_tokens": 20760,
    "completion_tokens": 92,
    "total_tokens": 20852,
    "topic": "EHR - Sequential Decision Modeling",
    "method": "Counterfactual reasoning; batch inverse reinforcement learning; temporal difference learning",
    "application": "Patient treatment optimization – ICU",
    "code_link": "N/A",
    "dataset_name": [
      "MIMIC III"
    ]
  },
  {
    "id": "eJIJF3-LoZO",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Concept Learners for Few-Shot Learning",
    "authors": [
      "Kaidi Cao",
      "Maria Brbic",
      "Jure Leskovec"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Developing algorithms that are able to generalize to a novel task given only a few labeled examples represents a fundamental challenge in closing the gap between machine- and human-level performance. The core of human cognition lies in the structured, reusable concepts that help us to rapidly adapt to new tasks and provide reasoning behind our decisions. However, existing meta-learning methods learn complex representations across prior labeled tasks without imposing any structure on the learned representations. Here we propose COMET, a meta-learning method that improves generalization ability by learning to learn along human-interpretable concept dimensions. Instead of learning a joint unstructured metric space, COMET learns mappings of high-level concepts into semi-structured metric spaces, and effectively combines the outputs of independent concept learners. We evaluate our model on few-shot tasks from diverse domains, including fine-grained image classification, document categorization  and cell type annotation on a novel dataset from a biological domain developed in our work. COMET significantly outperforms strong meta-learning baselines, achieving 6-15% relative improvement on the most challenging 1-shot learning tasks, while unlike existing methods providing interpretations behind the model's predictions.",
    "keywords": "few-shot learning, meta learning",
    "pdf_url": "https://openreview.net/pdf?id=eJIJF3-LoZO",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: While COMET is a general meta‐learning framework, the authors explicitly evaluate it on “cell type annotation on a novel dataset from a biological domain,” which is a core task in biomedical research (single‐cell analysis). This direct application to a biological/biomedical dataset qualifies it as Biomedicine AI.",
    "prompt_tokens": 21132,
    "completion_tokens": 129,
    "total_tokens": 21261,
    "topic": "Meta-Learning - Interpretability",
    "method": "Metric-based learning; concept-specific embeddings; semi-structured representation learning",
    "application": "Few-shot classification – diverse domains (image, NLP, biology)",
    "code_link": "https://github.com/snap-stanford/comet",
    "dataset_name": [
      "CUB",
      "Flowers-102",
      "Reuters",
      "Tabula Muris"
    ]
  },
  {
    "id": "bjkX6Kzb5H",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Cut out the annotator, keep the cutout: better segmentation with weak supervision",
    "authors": [
      "Sarah Hooper",
      "Michael Wornow",
      "Ying Hang Seah",
      "Peter Kellman",
      "Hui Xue",
      "Frederic Sala",
      "Curtis Langlotz",
      "Christopher Re"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Constructing large, labeled training datasets for segmentation models is an expensive and labor-intensive process. This is a common challenge in machine learning, addressed by methods that require few or no labeled data points such as few-shot learning (FSL) and weakly-supervised learning (WS). Such techniques, however, have limitations when applied to image segmentation---FSL methods often produce noisy results and are strongly dependent on which few datapoints are labeled, while WS models struggle to fully exploit rich image information. We propose a framework that fuses FSL and WS for segmentation tasks, enabling users to train high-performing segmentation networks with very few hand-labeled training points. We use FSL models as weak sources in a WS framework, requiring a very small set of reference labeled images, and introduce a new WS model that focuses on key areas---areas with contention among noisy labels---of the image to fuse these weak sources. Empirically, we evaluate our proposed approach over seven well-motivated segmentation tasks. We show that our methods can achieve within 1.4 Dice points compared to fully supervised networks while only requiring five hand-labeled training points. Compared to existing FSL methods, our approach improves performance by a mean 3.6 Dice points over the next-best method. ",
    "keywords": "Weak supervision, segmentation, CNN, latent variable, medical imaging",
    "pdf_url": "https://openreview.net/pdf?id=bjkX6Kzb5H",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper’s keywords include “medical imaging,” and it focuses on improving segmentation models—an essential task in clinical imaging analysis (e.g., CT, MRI, pathology). The weak-supervision framework for segmentation is directly applicable to healthcare workflows that rely on annotated medical images, making this work relevant to Healthcare AI/Biomedicine AI.",
    "prompt_tokens": 20477,
    "completion_tokens": 102,
    "total_tokens": 20579,
    "topic": "Medical Imaging - Weak Supervision Segmentation",
    "method": "Few-shot learning (FSL); Probabilistic Graphical Model (PGM)",
    "application": "Medical image segmentation",
    "code_link": "N/A",
    "dataset_name": [
      "ACDC",
      "Abdominal CT",
      "BRATS"
    ]
  },
  {
    "id": "q-cnWaaoUTH",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Conformation-Guided Molecular Representation with Hamiltonian Neural Networks",
    "authors": [
      "Ziyao Li",
      "Shuwen Yang",
      "Guojie Song",
      "Lingsheng Cai"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Well-designed molecular representations (fingerprints) are vital to combine medical chemistry and deep learning. Whereas incorporating 3D geometry of molecules (i.e. conformations) in their representations seems beneficial, current 3D algorithms are still in infancy. In this paper, we propose a novel molecular representation algorithm which preserves 3D conformations of molecules with a Molecular Hamiltonian Network (HamNet). In HamNet, implicit positions and momentums of atoms in a molecule interact in the Hamiltonian Engine following the discretized Hamiltonian equations. These implicit coordinations are supervised with real conformations with translation- & rotation-invariant losses, and further used as inputs to the Fingerprint Generator, a message-passing neural network. Experiments show that the Hamiltonian Engine can well preserve molecular conformations, and that the fingerprints generated by HamNet achieve state-of-the-art performances on MoleculeNet, a standard molecular machine learning benchmark.",
    "keywords": "Molecular Representation, Neural Physics Engines, Molecular Dynamics, Graph Neural Networks",
    "pdf_url": "https://openreview.net/pdf?id=q-cnWaaoUTH",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the paper focuses on novel graph-based and physics-inspired representation learning for molecules, it explicitly mentions “medical chemistry” and generates molecular fingerprints evaluated on MoleculeNet—a standard benchmark largely used for drug property and discovery tasks. Designing accurate 3D molecular representations is a core challenge in drug discovery and medicinal chemistry, placing this work squarely in the Biomedicine AI domain.",
    "prompt_tokens": 20781,
    "completion_tokens": 101,
    "total_tokens": 20882,
    "topic": "Drug Discovery - Representation Learning",
    "method": "Hamiltonian Engine; Message-Passing Neural Network (MPNN)",
    "application": "Molecular property prediction",
    "code_link": "N/A",
    "dataset_name": [
      "QM9",
      "Tox21",
      "Lipop",
      "FreeSolv",
      "ESOL"
    ]
  },
  {
    "id": "7I12hXRi8F",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "ANOCE: Analysis of Causal Effects with Multiple Mediators via Constrained Structural Learning",
    "authors": [
      "Hengrui Cai",
      "Rui Song",
      "Wenbin Lu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In the era of causal revolution, identifying the causal effect of an exposure on the outcome of interest is an important problem in many areas, such as epidemics, medicine, genetics, and economics. Under a general causal graph, the exposure may have a direct effect on the outcome and also an indirect effect regulated by a set of mediators. An analysis of causal effects that interprets the causal mechanism contributed through mediators is hence challenging but on demand. To the best of our knowledge, there are no feasible algorithms that give an exact decomposition of the indirect effect on the level of individual mediators, due to common interaction among mediators in the complex graph. In this paper, we establish a new statistical framework to comprehensively characterize causal effects with multiple mediators, namely, ANalysis Of Causal Effects (ANOCE), with a newly introduced definition of the mediator effect, under the linear structure equation model. We further propose a constrained causal structure learning method by incorporating a novel identification constraint that specifies the temporal causal relationship of variables. The proposed algorithm is applied to investigate the causal effects of 2020 Hubei lockdowns on reducing the spread of the coronavirus in Chinese major cities out of Hubei. ",
    "keywords": "Causal network, Constrained optimization, COVID-19, Individual mediation effects, Structure learning",
    "pdf_url": "https://openreview.net/pdf?id=7I12hXRi8F",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the core contribution is a general causal‐inference framework (ANOCE) and a constrained structure‐learning algorithm, the paper demonstrates its utility on a clearly health‐related problem—evaluating the causal effect of the 2020 Hubei lockdown on reducing the spread of coronavirus. This application to COVID-19 epidemiology and public‐health intervention analysis places it within the scope of Healthcare AI.",
    "prompt_tokens": 20479,
    "completion_tokens": 106,
    "total_tokens": 20585,
    "topic": "Causal Inference - Mediation Analysis",
    "method": "Constrained Variational Autoencoders (CVAE); causal discovery",
    "application": "Learning causal effects with mediators",
    "code_link": "https://github.com/anoce-cvae/ANOCE-CVAE",
    "dataset_name": [
      "N/A"
    ]
  },
  {
    "id": "1YLJDvSx6J4",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Learning from Protein Structure with Geometric Vector Perceptrons",
    "authors": [
      "Bowen Jing",
      "Stephan Eismann",
      "Patricia Suriana",
      "Raphael John Lamarre Townshend",
      "Ron Dror"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Learning on 3D structures of large biomolecules is emerging as a distinct area in machine learning, but there has yet to emerge a unifying network architecture that simultaneously leverages the geometric and relational aspects of the problem domain. To address this gap, we introduce geometric vector perceptrons, which extend standard dense layers to operate on collections of Euclidean vectors. Graph neural networks equipped with such layers are able to perform both geometric and relational reasoning on efficient representations of macromolecules. We demonstrate our approach on two important problems in learning from protein structure: model quality assessment and computational protein design. Our approach improves over existing classes of architectures on both problems, including state-of-the-art convolutional neural networks and graph neural networks. We release our code at https://github.com/drorlab/gvp.",
    "keywords": "structural biology, graph neural networks, proteins, geometric deep learning",
    "pdf_url": "https://openreview.net/pdf?id=1YLJDvSx6J4",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This paper focuses on learning from 3D protein structures and applies its methods to “model quality assessment” and “computational protein design,” which are core tasks in molecular modeling and drug discovery. Protein design and structural biology are key aspects of biomedical research aimed at developing therapeutics.",
    "prompt_tokens": 20717,
    "completion_tokens": 129,
    "total_tokens": 20846,
    "topic": "Bioinformatics - Protein Structure Analysis",
    "method": "Graph Neural Networks (GNN); Geometric Vector Perceptrons (GVP)",
    "application": "Protein sequence design and model quality assessment",
    "code_link": "https://github.com/drorlab/gvp",
    "dataset_name": [
      "CASP 11",
      "CASP 12",
      "CASP 13",
      "CATH 4.2",
      "TS50"
    ]
  },
  {
    "id": "aGfU_xziEX8",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Efficient Inference of Flexible Interaction in Spiking-neuron Networks",
    "authors": [
      "Feng Zhou",
      "Yixuan Zhang",
      "Jun Zhu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Hawkes process provides an effective statistical framework for analyzing the time-dependent interaction of neuronal spiking activities. Although utilized in many real applications, the classic Hawkes process is incapable of modelling inhibitory interactions among neurons. Instead, the nonlinear Hawkes process allows for a more flexible influence pattern with excitatory or inhibitory interactions. In this paper, three sets of auxiliary latent variables (Polya-Gamma variables, latent marked Poisson processes and sparsity variables) are augmented to make functional connection weights in a Gaussian form, which allows for a simple iterative algorithm with analytical updates. As a result, an efficient expectation-maximization (EM) algorithm is derived to obtain the maximum a posteriori (MAP) estimate. We demonstrate the accuracy and efficiency performance of our algorithm on synthetic and real data. For real neural recordings, we show our algorithm can estimate the temporal dynamics of interaction and reveal the interpretable functional connectivity underlying neural spike trains. ",
    "keywords": "neural spike train, nonlinear Hawkes process, auxiliary latent variable, conjugacy",
    "pdf_url": "https://openreview.net/pdf?id=aGfU_xziEX8",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on modeling and inferring interactions in spiking-neuron networks and on “neural spike trains,” which falls squarely under neurobiological modeling. Analysis of real neural recordings and functional connectivity in the brain is a form of biomedical AI (computational neuroscience), matching the guideline’s “neuroscience or neurobiological modeling” criterion.",
    "prompt_tokens": 20921,
    "completion_tokens": 122,
    "total_tokens": 21043,
    "topic": "Neuroscience - Spike Train Analysis",
    "method": "Sigmoid Nonlinear Multivariate Hawkes Processes (SNMHP); Expectation-Maximization Algorithm",
    "application": "Functional connectivity estimation among neurons",
    "code_link": "https://github.com/zhoufeng6288/SNMHawkesBeta",
    "dataset_name": [
      "Synthetic Dataset",
      "Spike Train Data (cat primary visual cortex)"
    ]
  },
  {
    "id": "tL89RnzIiCd",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Hopfield Networks is All You Need",
    "authors": [
      "Hubert Ramsauer",
      "Bernhard Schäfl",
      "Johannes Lehner",
      "Philipp Seidl",
      "Michael Widrich",
      "Lukas Gruber",
      "Markus Holzleitner",
      "Thomas Adler",
      "David Kreil",
      "Michael K Kopp",
      "Günter Klambauer",
      "Johannes Brandstetter",
      "Sepp Hochreiter"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We introduce a modern Hopfield network with continuous states and a corresponding update rule. The new Hopfield network can store exponentially (with the dimension of the associative space) many patterns, retrieves the pattern with one update, and has exponentially small retrieval errors. It has three types of energy minima (fixed points of the update): (1) global fixed point averaging over all patterns, (2) metastable states averaging over a subset of patterns, and (3) fixed points which store a single pattern. The new update rule is equivalent to the attention mechanism used in transformers. This equivalence enables a characterization of the heads of transformer models. These heads perform in the first layers preferably global averaging and in higher layers partial averaging via metastable states. The new modern Hopfield network can be integrated  into deep learning architectures as layers to allow the storage of and access to raw input data, intermediate results, or learned prototypes.\nThese Hopfield layers enable new ways of deep learning, beyond fully-connected, convolutional, or recurrent networks, and provide pooling, memory, association, and attention mechanisms. We demonstrate the broad applicability of the Hopfield layers\nacross various domains. Hopfield layers improved state-of-the-art on three out of four considered multiple instance learning problems as well as on immune repertoire classification with several hundreds of thousands of instances. On the UCI benchmark collections of small classification tasks, where deep learning methods typically struggle, Hopfield layers yielded a new state-of-the-art when compared to different machine learning methods. Finally, Hopfield layers achieved state-of-the-art on two drug design datasets. The implementation is available at: \\url{https://github.com/ml-jku/hopfield-layers}",
    "keywords": "Modern Hopfield Network, Energy, Attention, Convergence, Storage Capacity, Hopfield layer, Associative Memory",
    "pdf_url": "https://openreview.net/pdf?id=tL89RnzIiCd",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: While the core contribution is a general modern Hopfield network and attention mechanism, the paper explicitly demonstrates state-of-the-art results on “immune repertoire classification” and on “two drug design datasets.” These tasks—immune profiling and computational drug design—are firmly within the biomedicine domain.",
    "prompt_tokens": 20955,
    "completion_tokens": 109,
    "total_tokens": 21064,
    "topic": "Multiple Instance Learning - Immune Repertoire",
    "method": "Hopfield network",
    "application": "Immune repertoire classification",
    "code_link": "https://github.com/ml-jku/hopfield-layers",
    "dataset_name": [
      "CMV dataset",
      "Tiger",
      "Fox",
      "Elephant",
      "UCSB Breast Cancer"
    ]
  },
  {
    "id": "T1XmO8ScKim",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Probabilistic Numeric Convolutional Neural Networks",
    "authors": [
      "Marc Anton Finzi",
      "Roberto Bondesan",
      "Max Welling"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Continuous input signals like images and time series that are irregularly sampled or have missing values are challenging for existing deep learning methods. Coherently defined feature representations must depend on the values in unobserved regions of the input. Drawing from the work in probabilistic numerics, we propose Probabilistic Numeric Convolutional Neural Networks which represent features as Gaussian processes, providing a probabilistic description of discretization error. We then define a convolutional layer as the evolution of a PDE defined on this GP, followed by a nonlinearity. This approach also naturally admits steerable equivariant convolutions under e.g. the rotation group. In experiments we show that our approach yields a $3\\times$ reduction of error from the previous state of the art on the SuperPixel-MNIST dataset and competitive performance on the medical time series dataset PhysioNet2012.",
    "keywords": "probabilistic numerics, gaussian processes, discretization error, pde, superpixel, irregularly spaced time series, misssing data, spatial uncertainty",
    "pdf_url": "https://openreview.net/pdf?id=T1XmO8ScKim",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the paper proposes a general-purpose probabilistic convolutional architecture, one of its main experimental validations is on the PhysioNet2012 dataset—a widely used medical time-series (ICU/EHR) benchmark. The focus on handling irregularly sampled, missing physiological signals is directly relevant to patient monitoring and clinical time-series analysis.",
    "prompt_tokens": 20981,
    "completion_tokens": 112,
    "total_tokens": 21093,
    "topic": "Probabilistic Neural Networks - Irregular Data",
    "method": "Probabilistic Numeric CNN; Gaussian Processes",
    "application": "Image classification – SuperPixel MNIST; Mortality prediction – ICU (PhysioNet2012)",
    "code_link": "N/A",
    "dataset_name": [
      "SuperPixel-MNIST",
      "PhysioNet2012"
    ]
  },
  {
    "id": "fylclEqgvgd",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Transformer protein language models are unsupervised structure learners",
    "authors": [
      "Roshan Rao",
      "Joshua Meier",
      "Tom Sercu",
      "Sergey Ovchinnikov",
      "Alexander Rives"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Unsupervised contact prediction is central to uncovering physical, structural, and functional constraints for protein structure determination and design. For decades, the predominant approach has been to infer evolutionary constraints from a set of related sequences. In the past year, protein language models have emerged as a potential alternative, but performance has fallen short of state-of-the-art approaches in bioinformatics. In this paper we demonstrate that Transformer attention maps learn contacts from the unsupervised language modeling objective. We find the highest capacity models that have been trained to date already outperform a state-of-the-art unsupervised contact prediction pipeline, suggesting these pipelines can be replaced with a single forward pass of an end-to-end model.",
    "keywords": "proteins, language modeling, structure prediction, unsupervised learning, explainable",
    "pdf_url": "https://openreview.net/pdf?id=fylclEqgvgd",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work focuses on unsupervised contact prediction and structure learning of proteins—a core task in molecular modeling and protein design. Protein structure determination is fundamental to biomedical research (e.g., drug discovery, protein engineering), and “protein language models,” “structure prediction,” and “protein design” are all strong indicators of Biomedicine AI relevance.",
    "prompt_tokens": 20912,
    "completion_tokens": 101,
    "total_tokens": 21013,
    "topic": "Bioinformatics - Protein Language Modeling",
    "method": "Transformer-based models; logistic regression",
    "application": "Residue-residue contact prediction",
    "code_link": "https://github.com/facebookresearch/esm",
    "dataset_name": [
      "Uniref50",
      "Pfam",
      "BFD100"
    ]
  },
  {
    "id": "xnC8YwKUE3k",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Clairvoyance: A Pipeline Toolkit for Medical Time Series",
    "authors": [
      "Daniel Jarrett",
      "Jinsung Yoon",
      "Ioana Bica",
      "Zhaozhi Qian",
      "Ari Ercole",
      "Mihaela van der Schaar"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Time-series learning is the bread and butter of data-driven *clinical decision support*, and the recent explosion in ML research has demonstrated great potential in various healthcare settings. At the same time, medical time-series problems in the wild are challenging due to their highly *composite* nature: They entail design choices and interactions among components that preprocess data, impute missing values, select features, issue predictions, estimate uncertainty, and interpret models. Despite exponential growth in electronic patient data, there is a remarkable gap between the potential and realized utilization of ML for clinical research and decision support. In particular, orchestrating a real-world project lifecycle poses challenges in engineering (i.e. hard to build), evaluation (i.e. hard to assess), and efficiency (i.e. hard to optimize). Designed to address these issues simultaneously, Clairvoyance proposes a unified, end-to-end, autoML-friendly pipeline that serves as a (i) software toolkit, (ii) empirical standard, and (iii) interface for optimization. Our ultimate goal lies in facilitating transparent and reproducible experimentation with complex inference workflows, providing integrated pathways for (1) personalized prediction, (2) treatment-effect estimation, and (3) information acquisition. Through illustrative examples on real-world data in outpatient, general wards, and intensive-care settings, we illustrate the applicability of the pipeline paradigm on core tasks in the healthcare journey. To the best of our knowledge, Clairvoyance is the first to demonstrate viability of a comprehensive and automatable pipeline for clinical time-series ML.",
    "keywords": "reproducibility, healthcare, medical time series, pipeline toolkit, software",
    "pdf_url": "https://openreview.net/pdf?id=xnC8YwKUE3k",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on end-to-end pipelines for medical time-series learning in clinical decision support, explicitly mentioning outpatient, general wards, and intensive-care settings. It addresses tasks such as personalized prediction, treatment-effect estimation, and uncertainty in healthcare workflows using EHR data, which clearly places it in the Healthcare AI domain.",
    "prompt_tokens": 20920,
    "completion_tokens": 115,
    "total_tokens": 21035,
    "topic": "Medical Time Series - End-to-end Pipelines",
    "method": "AutoML pipelines; temporal imputation; feature selection; stepwise model selection",
    "application": "Time-series prediction – ICU",
    "code_link": "https://github.com/vanderschaarlab/clairvoyance",
    "dataset_name": [
      "MIMIC",
      "UKCF",
      "WARDS"
    ]
  },
  {
    "id": "YWtLZvLmud7",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "BERTology Meets Biology: Interpreting Attention in Protein Language Models",
    "authors": [
      "Jesse Vig",
      "Ali Madani",
      "Lav R. Varshney",
      "Caiming Xiong",
      "richard socher",
      "Nazneen Rajani"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Transformer architectures have proven to learn useful representations for protein classification and generation tasks. However, these representations present challenges in interpretability. In this work, we demonstrate a set of methods for analyzing protein Transformer models through the lens of attention. We show that attention: (1) captures the folding structure of proteins, connecting amino acids that are far apart in the underlying sequence, but spatially close in the three-dimensional structure, (2) targets binding sites, a key functional component of proteins, and (3) focuses on progressively more complex biophysical properties with increasing layer depth. We find this behavior to be consistent across three Transformer architectures (BERT, ALBERT, XLNet) and two distinct protein datasets. We also present a three-dimensional visualization of the interaction between attention and protein structure. Code for visualization and analysis is available at https://github.com/salesforce/provis.",
    "keywords": "interpretability, black box, computational biology, representation learning, attention, transformers, visualization, natural language processing",
    "pdf_url": "https://openreview.net/pdf?id=YWtLZvLmud7",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work applies transformer-based language models to proteins—capturing folding structure, identifying binding sites, and modeling biophysical properties—which are central tasks in molecular modeling and protein design (key areas of Biomedicine AI). The abstract’s focus on “protein classification and generation tasks,” “folding structure of proteins,” and “targets binding sites” aligns directly with biomedical research in drug discovery and molecular biology.",
    "prompt_tokens": 21011,
    "completion_tokens": 98,
    "total_tokens": 21109,
    "topic": "Bioinformatics - Protein Analysis",
    "method": "Attention analysis; probing tasks",
    "application": "Structural and functional protein analysis",
    "code_link": "https://github.com/salesforce/provis",
    "dataset_name": [
      "ProteinNet",
      "Secondary Structure",
      "Binding Sites/PTM"
    ]
  },
  {
    "id": "unI5ucw_Jk",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Explaining by Imitating: Understanding Decisions by Interpretable Policy Learning",
    "authors": [
      "Alihan Hüyük",
      "Daniel Jarrett",
      "Cem Tekin",
      "Mihaela van der Schaar"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Understanding human behavior from observed data is critical for transparency and accountability in decision-making. Consider real-world settings such as healthcare, in which modeling a decision-maker’s policy is challenging—with no access to underlying states, no knowledge of environment dynamics, and no allowance for live experimentation. We desire learning a data-driven representation of decision- making behavior that (1) inheres transparency by design, (2) accommodates partial observability, and (3) operates completely offline. To satisfy these key criteria, we propose a novel model-based Bayesian method for interpretable policy learning (“Interpole”) that jointly estimates an agent’s (possibly biased) belief-update process together with their (possibly suboptimal) belief-action mapping. Through experiments on both simulated and real-world data for the problem of Alzheimer’s disease diagnosis, we illustrate the potential of our approach as an investigative device for auditing, quantifying, and understanding human decision-making behavior.",
    "keywords": "interpretable policy learning, understanding decision-making",
    "pdf_url": "https://openreview.net/pdf?id=unI5ucw_Jk",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly targets a healthcare application—modeling and interpreting decision‐making in settings such as “healthcare” and demonstrates experiments on “real‐world data for the problem of Alzheimer’s disease diagnosis.” This clearly situates the work within the Healthcare AI domain.",
    "prompt_tokens": 21170,
    "completion_tokens": 97,
    "total_tokens": 21267,
    "topic": "Healthcare Decision Modeling - Alzheimer’s Diagnosis",
    "method": "Bayesian Interpretable Policy Learning; Input-Output Hidden Markov Models (IOHMM)",
    "application": "Diagnosing Alzheimer’s disease",
    "code_link": "N/A",
    "dataset_name": [
      "ADNI"
    ]
  },
  {
    "id": "9YlaeLfuhJF",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Model Patching: Closing the Subgroup Performance Gap with Data Augmentation",
    "authors": [
      "Karan Goel",
      "Albert Gu",
      "Yixuan Li",
      "Christopher Re"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Classifiers in machine learning are often brittle when deployed. Particularly concerning are models with inconsistent performance on specific subgroups of a class, e.g., exhibiting disparities in skin cancer classification in the presence or absence of a spurious bandage. To mitigate these performance differences, we introduce model patching, a two-stage framework for improving robustness that encourages the model to be invariant to subgroup differences, and focus on class information shared by subgroups. Model patching first models subgroup features within a class and learns semantic transformations between them, and then trains a classifier with data augmentations that deliberately manipulate subgroup features. We instantiate model patching with CAMEL, which (1) uses a CycleGAN to learn the intra-class, inter-subgroup augmentations, and (2) balances subgroup performance using a theoretically-motivated subgroup consistency regularizer, accompanied by a new robust objective. We demonstrate CAMEL’s effectiveness on 3 benchmark datasets, with reductions in robust error of up to 33% relative to the best baseline. Lastly, CAMEL successfully patches a model that fails due to spurious features on a real-world skin cancer dataset.",
    "keywords": "Robust Machine Learning, Data Augmentation, Consistency Training, Invariant Representations",
    "pdf_url": "https://openreview.net/pdf?id=9YlaeLfuhJF",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the paper proposes a general ML robustness framework, it explicitly evaluates and “patches” models on a real-world skin cancer dataset—i.e. a medical imaging classification task where spurious features (a bandage) affect cancer diagnosis. This direct application to a clinical imaging problem qualifies it as Healthcare AI.",
    "prompt_tokens": 20820,
    "completion_tokens": 116,
    "total_tokens": 20936,
    "topic": "Robust Machine Learning - Subgroup Robustness",
    "method": "CycleGAN; subgroup consistency regularizer",
    "application": "Subgroup robustness improvement across classification tasks",
    "code_link": "https://github.com/HazyResearch/model-patching",
    "dataset_name": [
      "MNIST-Correlation",
      "CelebA-Undersampled",
      "Waterbirds",
      "ISIC"
    ]
  },
  {
    "id": "kHSu4ebxFXY",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "MARS: Markov Molecular Sampling for Multi-objective Drug Discovery",
    "authors": [
      "Yutong Xie",
      "Chence Shi",
      "Hao Zhou",
      "Yuwei Yang",
      "Weinan Zhang",
      "Yong Yu",
      "Lei Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Searching for novel molecules with desired chemical properties is crucial in drug discovery. Existing work focuses on developing neural models to generate either molecular sequences or chemical graphs. However, it remains a big challenge to find novel and diverse compounds satisfying several properties. In this paper, we propose MARS, a method for multi-objective drug molecule discovery. MARS is based on the idea of generating the chemical candidates by iteratively editing fragments of molecular graphs. To search for high-quality candidates, it employs Markov chain Monte Carlo sampling (MCMC) on molecules with an annealing scheme and an adaptive proposal. To further improve sample efficiency, MARS uses a graph neural network (GNN) to represent and select candidate edits, where the GNN is trained on-the-fly with samples from MCMC. Experiments show that MARS achieves state-of-the-art performance in various multi-objective settings where molecular bio-activity, drug-likeness, and synthesizability are considered. Remarkably, in the most challenging setting where all four objectives are simultaneously optimized, our approach outperforms previous methods significantly in comprehensive evaluations. The code is available at https://github.com/yutxie/mars.",
    "keywords": "drug discovery, molecular graph generation, MCMC sampling",
    "pdf_url": "https://openreview.net/pdf?id=kHSu4ebxFXY",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “drug discovery,” specifically generating novel molecules optimized for bio-activity, drug-likeness, and synthesizability. These objectives are central to biomedicine and therapeutic development, placing the work squarely in the Biomedical AI domain.",
    "prompt_tokens": 20933,
    "completion_tokens": 107,
    "total_tokens": 21040,
    "topic": "Drug Discovery - Multi-objective Optimization",
    "method": "Markov chain Monte Carlo sampling (MCMC); Graph Neural Networks (GNN); Adaptive proposal learning",
    "application": "Multi-objective molecular design",
    "code_link": "https://github.com/yutxie/mars",
    "dataset_name": [
      "ChEMBL"
    ]
  },
  {
    "id": "lVgB2FUbzuQ",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Predicting Infectiousness for Proactive Contact Tracing",
    "authors": [
      "Yoshua Bengio",
      "Prateek Gupta",
      "Tegan Maharaj",
      "Nasim Rahaman",
      "Martin Weiss",
      "Tristan Deleu",
      "Eilif Benjamin Muller",
      "Meng Qu",
      "victor schmidt",
      "Pierre-Luc St-Charles",
      "hannah alsdurf",
      "Olexa Bilaniuk",
      "david buckeridge",
      "gaetan caron",
      "pierre luc carrier",
      "Joumana Ghosn",
      "satya ortiz gagne",
      "Christopher Pal",
      "Irina Rish",
      "Bernhard Schölkopf",
      "abhinav sharma",
      "Jian Tang",
      "andrew williams"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The COVID-19 pandemic has spread rapidly worldwide, overwhelming manual contact tracing in many countries and resulting in widespread lockdowns for emergency containment. Large-scale digital contact tracing (DCT) has emerged as a potential solution to resume economic and social activity while minimizing spread of the virus. Various DCT methods have been proposed, each making trade-offs be-tween privacy, mobility restrictions, and public health. The most common approach, binary contact tracing (BCT), models infection as a binary event, informed only by an individual’s test results, with corresponding binary recommendations that either all or none of the individual’s contacts quarantine. BCT ignores the inherent uncertainty in contacts and the infection process, which could be used to tailor messaging to high-risk individuals, and prompt proactive testing or earlier warnings. It also does not make use of observations such as symptoms or pre-existing medical conditions, which could be used to make more accurate infectiousness predictions. In this paper, we use a recently-proposed COVID-19 epidemiological simulator to develop and test methods that can be deployed to a smartphone to locally and proactively predict an individual’s infectiousness (risk of infecting others) based on their contact history and other information, while respecting strong privacy constraints. Predictions are used to provide personalized recommendations to the individual via an app, as well as to send anonymized messages to the individual’s contacts, who use this information to better predict their own infectiousness, an approach we call proactive contact tracing (PCT). Similarly to other works, we find that compared to no tracing, all DCT methods tested are able to reduce spread of the disease and thus save lives, even at low adoption rates, strongly supporting a role for DCT methods in managing the pandemic. Further, we find a deep-learning based PCT method which improves over BCT for equivalent average mobility, suggesting PCT could help in safe re-opening and second-wave prevention.",
    "keywords": "covid-19, contact tracing, distributed inference, set transformer, deepset, epidemiology, applications, domain randomization, retraining, simulation",
    "pdf_url": "https://openreview.net/pdf?id=lVgB2FUbzuQ",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on predicting individual COVID-19 infectiousness and improving digital contact tracing to reduce disease spread—a clear public health and patient‐facing application. It involves epidemiological simulation, symptom and contact history to inform personalized quarantine and testing recommendations, fitting squarely within Healthcare AI.",
    "prompt_tokens": 21024,
    "completion_tokens": 113,
    "total_tokens": 21137,
    "topic": "Epidemiology - Infectious Disease Modeling",
    "method": "Deep learning; Proactive Contact Tracing (PCT); Set Transformer; Domain randomization",
    "application": "Infectiousness prediction",
    "code_link": "https://github.com/mila-iqia/COVI-AgentSim",
    "dataset_name": [
      "COVI-AgentSim"
    ]
  },
  {
    "id": "agHLCOBM5jP",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Fully Unsupervised Diversity Denoising with Convolutional Variational Autoencoders",
    "authors": [
      "Mangal Prakash",
      "Alexander Krull",
      "Florian Jug"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Deep Learning based methods have emerged as the indisputable leaders for virtually all image restoration tasks. Especially in the domain of microscopy images, various content-aware image restoration (CARE) approaches are now used to improve the interpretability of acquired data. Naturally, there are limitations to what can be restored in corrupted images, and like for all inverse problems, many potential solutions exist, and one of them must be chosen. Here, we propose DivNoising, a denoising approach based on fully convolutional variational autoencoders (VAEs), overcoming the problem of having to choose a single solution by predicting a whole distribution of denoised images. First we introduce a principled way of formulating the unsupervised denoising problem within the VAE framework by explicitly incorporating imaging noise models into the decoder. Our approach is fully unsupervised, only requiring noisy images and a suitable description of the imaging noise distribution. We show that such a noise model can either be measured, bootstrapped from noisy data, or co-learned during training. If desired, consensus predictions can be inferred from a set of DivNoising predictions, leading to competitive results with other unsupervised methods and, on occasion, even with the supervised state-of-the-art. DivNoising samples from the posterior enable a plethora of useful applications. We are (i) showing denoising results for 13 datasets, (ii) discussing how optical character recognition (OCR) applications can benefit from diverse predictions, and are (iii) demonstrating how instance cell segmentation improves when using diverse DivNoising predictions.",
    "keywords": "Diversity denoising, Unsupervised denoising, Variational Autoencoders, Noise model",
    "pdf_url": "https://openreview.net/pdf?id=agHLCOBM5jP",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although this paper primarily proposes a generic unsupervised denoising framework, its motivating application domain is microscopy—“content-aware image restoration (CARE) approaches … in the domain of microscopy images.” Moreover, they demonstrate benefits for “instance cell segmentation” and other bio-imaging tasks. Microscopy and cell segmentation are core steps in biomedical research, making this work relevant to the Biomedicine AI domain.",
    "prompt_tokens": 20595,
    "completion_tokens": 151,
    "total_tokens": 20746,
    "topic": "Image Denoising - Variational Autoencoder",
    "method": "Variational Autoencoder (VAE); convolutional neural networks",
    "application": "Image denoising with diverse outputs",
    "code_link": "N/A",
    "dataset_name": [
      "FU-PN2V Convallaria",
      "FU-PN2V Mouse nuclei",
      "FU-PN2V Mouse actin",
      "W2S",
      "DenoiSeg Mouse",
      "DenoiSeg Flywing",
      "BioID Face",
      "MNIST",
      "KMNIST"
    ]
  },
  {
    "id": "snOgiCYZgJ7",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Neural representation and generation for RNA secondary structures",
    "authors": [
      "Zichao Yan",
      "William L. Hamilton",
      "Mathieu Blanchette"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Our work is concerned with the generation and targeted design of RNA, a type of genetic macromolecule that can adopt complex structures which influence their cellular activities and functions. The design of large scale and complex biological structures spurs dedicated graph-based deep generative modeling techniques, which represents a key but underappreciated aspect of computational drug discovery. In this work, we investigate the principles behind representing and generating different RNA structural modalities, and propose a flexible framework to jointly embed and generate these molecular structures along with their sequence in a meaningful latent space. Equipped with a deep understanding of RNA molecular structures, our most sophisticated encoding and decoding methods operate on the molecular graph as well as the junction tree hierarchy, integrating strong inductive bias about RNA structural regularity and folding mechanism such that high structural validity, stability and diversity of generated RNAs are achieved. Also, we seek to adequately organize the latent space of RNA molecular embeddings with regard to the interaction with proteins, and targeted optimization is used to navigate in this latent space to search for desired novel RNA molecules.",
    "keywords": "Graph neural network, Deep generative modeling, Machine learning, Drug discovery, RNA structure, RNA structure embedding, RNA-protein interaction prediction",
    "pdf_url": "https://openreview.net/pdf?id=snOgiCYZgJ7",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on graph-based deep generative modeling of RNA secondary structures and targeted RNA design—central tasks in molecular modeling and drug discovery. It explicitly mentions “drug discovery,” “RNA structure,” and “RNA-protein interaction prediction,” all of which are core to Biomedicine AI.",
    "prompt_tokens": 20741,
    "completion_tokens": 105,
    "total_tokens": 20846,
    "topic": "Bioinformatics - RNA Design and Prediction",
    "method": "Variational Autoencoders (VAEs); Normalizing Flows; Hierarchical Representation Learning",
    "application": "RNA molecule generation and targeted design",
    "code_link": "N/A",
    "dataset_name": [
      "RNAcompete-S",
      "Human Transcriptome GRCh38"
    ]
  },
  {
    "id": "ZK6vTvb84s",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "A Trainable Optimal Transport Embedding for Feature Aggregation and its Relationship to Attention",
    "authors": [
      "Grégoire Mialon",
      "Dexiong Chen",
      "Alexandre d'Aspremont",
      "Julien Mairal"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We address the problem of learning on sets of features, motivated by the need of performing pooling operations in long biological sequences of varying sizes, with long-range dependencies, and possibly few labeled data. To address this challenging task, we introduce a parametrized representation of fixed size, which  embeds and then aggregates elements from a given input set according to the optimal transport plan between the set and a trainable reference. Our approach scales to large datasets and allows end-to-end training of the reference, while also providing a simple unsupervised learning mechanism with small computational cost. Our aggregation technique admits two useful interpretations: it may be seen as a mechanism related to attention layers in neural networks, or it may be seen as a scalable surrogate of a classical optimal transport-based kernel. We experimentally demonstrate the effectiveness of our approach on biological sequences, achieving state-of-the-art results for protein fold recognition and detection of chromatin profiles tasks, and, as a proof of concept, we show promising results for processing natural language sequences. We provide an open-source implementation of our embedding that can be used alone or as a module in larger learning models at https://github.com/claying/OTK.",
    "keywords": "bioinformatics, optimal transport, kernel methods, attention, transformers",
    "pdf_url": "https://openreview.net/pdf?id=ZK6vTvb84s",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly targets biological sequence tasks—“protein fold recognition” and “detection of chromatin profiles”—which are core bioinformatics and genomics problems. The keywords also include “bioinformatics,” indicating a focus on biomedical data. These applications place the work squarely in the Biomedicine AI domain.",
    "prompt_tokens": 20630,
    "completion_tokens": 99,
    "total_tokens": 20729,
    "topic": "Bioinformatics - Genome Regulation",
    "method": "Optimal transport embedding; supervised learning",
    "application": "Chromatin profile prediction",
    "code_link": "http://deepsea.princeton.edu/media/code/deepsea_train_bundle.v0.9.tar.gz",
    "dataset_name": [
      "DeepSEA"
    ]
  },
  {
    "id": "dx4b7lm8jMM",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Seq2Tens: An Efficient Representation of Sequences by Low-Rank Tensor Projections",
    "authors": [
      "Csaba Toth",
      "Patric Bonnier",
      "Harald Oberhauser"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Sequential data such as time series, video, or text can be challenging to analyse as the ordered structure gives rise to complex dependencies. At the heart of this is non-commutativity, in the sense that reordering the elements of a sequence can completely change its meaning. We use a classical mathematical object -- the free algebra -- to capture this non-commutativity. To address the innate computational complexity of this algebra, we use compositions of low-rank tensor projections. This yields modular and scalable building blocks that give state-of-the-art performance on standard benchmarks such as multivariate time series classification, mortality prediction and generative models for video.",
    "keywords": "time series, sequential data, representation learning, low-rank tensors, classification, generative modelling",
    "pdf_url": "https://openreview.net/pdf?id=dx4b7lm8jMM",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the paper develops a general sequence‐representation method, it explicitly demonstrates “state-of-the-art performance on … mortality prediction,” which is a clinical prediction task. Mortality prediction typically involves patient data (e.g., EHR or physiologic time series) and falls squarely under Healthcare AI.",
    "prompt_tokens": 20525,
    "completion_tokens": 99,
    "total_tokens": 20624,
    "topic": "Time Series - Representation Learning",
    "method": "Low-rank tensor projection; neural network layers for sequence data",
    "application": "Mortality prediction – ICU",
    "code_link": "https://github.com/tgcsaba/seq2tens",
    "dataset_name": [
      "PHYSIONET2012"
    ]
  },
  {
    "id": "D_KeYoqCYC",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Sparse encoding for more-interpretable feature-selecting representations in probabilistic matrix factorization",
    "authors": [
      "Joshua C Chang",
      "Patrick Fletcher",
      "Jungmin Han",
      "Ted L Chang",
      "Shashaank Vattikuti",
      "Bart Desmet",
      "Ayah Zirikly",
      "Carson C Chow"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Dimensionality reduction methods for count data are critical to a wide range of applications in medical informatics and other fields where model interpretability is paramount. For such data, hierarchical Poisson matrix factorization (HPF) and other sparse probabilistic non-negative matrix factorization (NMF) methods are considered to be interpretable generative models. They consist of sparse transformations for decoding their learned representations into predictions. However, sparsity in representation decoding does not necessarily imply sparsity in the encoding of representations from the original data features.  HPF is often incorrectly interpreted in the literature as if it possesses encoder sparsity. The distinction between decoder sparsity and encoder sparsity is subtle but important. Due to the lack of encoder sparsity, HPF does not possess the column-clustering property of classical NMF -- the factor loading matrix does not sufficiently define how each factor is formed from the original features. We address this deficiency by self-consistently enforcing encoder sparsity, using a generalized additive model  (GAM), thereby allowing one to relate each representation coordinate to a subset of the original data features. In doing so, the method also gains the ability to perform feature selection. We demonstrate our method on simulated data and give an example of how encoder sparsity is of practical use in a concrete application of representing inpatient comorbidities in Medicare patients.",
    "keywords": "poisson matrix factorization, generalized additive model, probabilistic matrix factorization, bayesian, sparse coding, interpretability, factor analysis",
    "pdf_url": "https://openreview.net/pdf?id=D_KeYoqCYC",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract explicitly cites “applications in medical informatics” and gives a concrete example of “representing inpatient comorbidities in Medicare patients,” indicating use on healthcare data. The method is applied to patient comorbidity profiles, which is a clinical/healthcare task.",
    "prompt_tokens": 21108,
    "completion_tokens": 119,
    "total_tokens": 21227,
    "topic": "Medical Informatics - Probabilistic Matrix Factorization",
    "method": "Hierarchical Poisson matrix factorization (HPF); Bayesian inference; Horseshoe prior; Fully-factorized mean-field ADVI",
    "application": "Feature selection – Comorbidity representation",
    "code_link": "https://github.com/mederrata/spmf",
    "dataset_name": [
      "Medicare Limited Data Set (LDS)"
    ]
  },
  {
    "id": "4c0J6lwQ4_",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Multi-Time Attention Networks for Irregularly Sampled Time Series",
    "authors": [
      "Satya Narayan Shukla",
      "Benjamin Marlin"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Irregular sampling occurs in many time series modeling applications where it presents a significant challenge to standard deep learning models. This work is motivated by the analysis of physiological time series data in electronic health records, which are sparse, irregularly sampled, and multivariate. In this paper, we propose a new deep learning framework for this setting that we call Multi-Time Attention Networks. Multi-Time Attention Networks learn an embedding of continuous time values and use an attention mechanism to produce a fixed-length representation of a time series containing a variable number of observations. We investigate the performance of this framework on interpolation and classification tasks using multiple datasets. Our results show that the proposed approach performs as well or better than a range of baseline and recently proposed models while offering significantly faster training times than current state-of-the-art methods.",
    "keywords": "irregular sampling, multivariate time series, attention, missing data",
    "pdf_url": "https://openreview.net/pdf?id=4c0J6lwQ4_",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper is explicitly motivated by “physiological time series data in electronic health records,” and focuses on modeling sparse, irregularly sampled multivariate signals from patient EHRs. These are core Healthcare AI tasks involving clinical data representation and prediction.",
    "prompt_tokens": 20661,
    "completion_tokens": 116,
    "total_tokens": 20777,
    "topic": "Time Series - Irregular Sampling",
    "method": "Multi-Time Attention Module (mTAN)",
    "application": "Mortality prediction – ICU; Activity classification – Human Activities",
    "code_link": "https://github.com/reml-lab/mTAN",
    "dataset_name": [
      "MIMIC-III",
      "PhysioNet Challenge 2012",
      "Human Activity Dataset"
    ]
  },
  {
    "id": "QfTXQiGYudJ",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Stabilized Medical Image Attacks",
    "authors": [
      "Gege Qi",
      "Lijun GONG",
      "Yibing Song",
      "Kai Ma",
      "Yefeng Zheng"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Convolutional Neural Networks (CNNs) have advanced existing medical systems for automatic disease diagnosis. However, a threat to these systems arises that adversarial attacks make CNNs vulnerable. Inaccurate diagnosis results make a negative influence on human healthcare. There is a need to investigate potential adversarial attacks to robustify deep medical diagnosis systems. On the other side, there are several modalities of medical images (e.g., CT, fundus, and endoscopic image) of which each type is significantly different from others. It is more challenging to generate adversarial perturbations for different types of medical images. In this paper, we propose an image-based medical adversarial attack method to consistently produce adversarial perturbations on medical images. The objective function of our method consists of a loss deviation term and a loss stabilization term. The loss deviation term increases the divergence between the CNN prediction of an adversarial example and its ground truth label. Meanwhile, the loss stabilization term ensures similar CNN predictions of this example and its smoothed input. From the perspective of the whole iterations for perturbation generation, the proposed loss stabilization term exhaustively searches the perturbation space to smooth the single spot for local optimum escape. We further analyze the KL-divergence of the proposed loss function and find that the loss stabilization term makes the perturbations updated towards a fixed objective spot while deviating from the ground truth. This stabilization ensures the proposed medical attack effective for different types of medical images while producing perturbations in small variance. Experiments on several medical image analysis benchmarks including the recent COVID-19 dataset show the stability of the proposed method.",
    "keywords": "Healthcare, Biometrics",
    "pdf_url": "https://openreview.net/pdf?id=QfTXQiGYudJ",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper specifically targets “medical image attacks” on Convolutional Neural Networks used for “automatic disease diagnosis” in multiple medical imaging modalities (CT, fundus, endoscopic images). It addresses robustness in deep “medical diagnosis systems” and evaluates on healthcare datasets including COVID-19 scans. These are all clear indicators of an AI application in the medical imaging and clinical diagnosis domain.",
    "prompt_tokens": 20829,
    "completion_tokens": 125,
    "total_tokens": 20954,
    "topic": "Medical Imaging - Adversarial Attacks",
    "method": "Adversarial perturbation generation; Loss stabilization term",
    "application": "Robustness evaluation of medical diagnosis systems",
    "code_link": "https://github.com/imogenqi/SMA",
    "dataset_name": [
      "COVID-19",
      "APTOS-2019",
      "Kaggle-DR",
      "EAD-2019"
    ]
  },
  {
    "id": "KtH8W3S_RE",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Multi-resolution modeling of a discrete stochastic process identifies causes of cancer",
    "authors": [
      "Adam Uri Yaari",
      "Maxwell Sherman",
      "Oliver Clarke Priebe",
      "Po-Ru Loh",
      "Boris Katz",
      "Andrei Barbu",
      "Bonnie Berger"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Detection of cancer-causing mutations within the vast and mostly unexplored human genome is a major challenge. Doing so requires modeling the background mutation rate, a highly non-stationary stochastic process, across regions of interest varying in size from one to millions of positions. Here, we present the split-Poisson-Gamma (SPG) distribution, an extension of the classical Poisson-Gamma formulation, to model a discrete stochastic process at multiple resolutions. We demonstrate that the probability model has a closed-form posterior, enabling efficient and accurate linear-time prediction over any length scale after the parameters of the model have been inferred a single time. We apply our framework to model mutation rates in tumors and show that model parameters can be accurately inferred from high-dimensional epigenetic data using a convolutional neural network, Gaussian process, and maximum-likelihood estimation. Our method is both more accurate and more efficient than existing models over a large range of length scales. We demonstrate the usefulness of multi-resolution modeling by detecting genomic elements that drive tumor emergence and are of vastly differing sizes.",
    "keywords": "Computational Biology, non-stationary stochastic processes, cancer research, deep learning, probabelistic models, graphical models",
    "pdf_url": "https://openreview.net/pdf?id=KtH8W3S_RE",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on modeling somatic mutation rates and identifying cancer‐causing mutations (“Detection of cancer‐causing mutations,” “model mutation rates in tumors,” “genomic elements that drive tumor emergence”). It applies probabilistic modeling and deep learning to tumor genomics and epigenetic data, which clearly places it within the Biomedicine AI domain.",
    "prompt_tokens": 20986,
    "completion_tokens": 111,
    "total_tokens": 21097,
    "topic": "Cancer Genomics - Mutation Modeling",
    "method": "Convolutional Neural Network (CNN); Gaussian Process (GP); Dimensionality Reduction",
    "application": "Cancer-specific mutation pattern prediction",
    "code_link": "https://github.com/nvictus/pybbi",
    "dataset_name": [
      "Roadmap Epigenomics",
      "PCAWG"
    ]
  },
  {
    "id": "l0mSUROpwY",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Intrinsic-Extrinsic Convolution and Pooling for Learning on 3D Protein Structures",
    "authors": [
      "Pedro Hermosilla",
      "Marco Schäfer",
      "Matej Lang",
      "Gloria Fackelmann",
      "Pere-Pau Vázquez",
      "Barbora Kozlikova",
      "Michael Krone",
      "Tobias Ritschel",
      "Timo Ropinski"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Proteins perform a large variety of functions in living organisms and thus play a key role in biology. However, commonly used algorithms in protein representation learning were not specifically designed for protein data, and are therefore not able to capture all relevant structural levels of a protein during learning. To fill this gap, we propose two new learning operators, specifically designed to process protein structures. First, we introduce a novel convolution operator that considers the primary, secondary, and tertiary structure of a protein by using $n$-D convolutions defined on both the Euclidean distance, as well as multiple geodesic distances between the atoms in a multi-graph. Second, we introduce a set of hierarchical pooling operators that enable multi-scale protein analysis. We further evaluate the accuracy of our algorithms on common downstream tasks, where we outperform state-of-the-art protein learning algorithms.",
    "keywords": "classification, bioinformatics",
    "pdf_url": "https://openreview.net/pdf?id=l0mSUROpwY",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This paper develops novel convolution and pooling operators specifically for learning on 3D protein structures. Protein structure modeling and representation learning are core tasks in molecular modeling and bioinformatics, which directly support biomedicine applications such as drug discovery, protein design, and understanding molecular function. The abstract’s focus on “primary, secondary, and tertiary structure of a protein” and its use of bioinformatics concepts places it squarely within Biomedicine AI.",
    "prompt_tokens": 20998,
    "completion_tokens": 116,
    "total_tokens": 21114,
    "topic": "Bioinformatics - Protein Structure Analysis",
    "method": "Graph Convolutional Networks (GCNN); Hierarchical pooling; Intrinsic-Extrinsic convolution",
    "application": "Protein fold classification; enzyme-catalyzed reaction classification",
    "code_link": "N/A",
    "dataset_name": [
      "SCOPe 1.75",
      "Protein Data Bank (PDB)"
    ]
  },
  {
    "id": "jHefDGsorp5",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Molecule Optimization by Explainable Evolution",
    "authors": [
      "Binghong Chen",
      "Tianzhe Wang",
      "Chengtao Li",
      "Hanjun Dai",
      "Le Song"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Optimizing molecules for desired properties is a fundamental yet challenging task in chemistry, material science, and drug discovery. This paper develops a novel algorithm for optimizing molecular properties via an Expectation-Maximization (EM) like explainable evolutionary process. The algorithm is designed to mimic human experts in the process of searching for desirable molecules and alternate between two stages: the first stage on explainable local search which identifies rationales, i.e., critical subgraph patterns accounting for desired molecular properties, and the second stage on molecule completion which explores the larger space of molecules containing good rationales. We test our approach against various baselines on a real-world multi-property optimization task where each method is given the same number of queries to the property oracle. We show that our evolution-by-explanation algorithm is 79% better than the best baseline in terms of a generic metric combining aspects such as success rate, novelty, and diversity. Human expert evaluation on optimized molecules shows that 60% of top molecules obtained from our methods are deemed successful. ",
    "keywords": "Molecule Design, Explainable Model, Evolutionary Algorithm, Reinforcement Learning, Graph Generative Model",
    "pdf_url": "https://openreview.net/pdf?id=jHefDGsorp5",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on optimizing molecular structures with applications in “drug discovery,” which is a core task in Biomedicine AI. It develops graph-based generative and evolutionary methods to design molecules with desired properties, directly aligning with AI-driven drug discovery and molecular modeling in the biomedical domain.",
    "prompt_tokens": 20929,
    "completion_tokens": 108,
    "total_tokens": 21037,
    "topic": "Drug Discovery - Molecule Optimization",
    "method": "Expectation-Maximization (EM)-like algorithm; explainable evolutionary process; conditional generative model",
    "application": "Multi-property molecule optimization",
    "code_link": "https://github.com/binghong-ml/MolEvol",
    "dataset_name": [
      "ChEMBL",
      "eMolecules"
    ]
  },
  {
    "id": "TVjLza1t4hI",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Representation learning for improved interpretability and classification accuracy of clinical factors from EEG",
    "authors": [
      "Garrett Honke",
      "Irina Higgins",
      "Nina Thigpen",
      "Vladimir Miskovic",
      "Katie Link",
      "Sunny Duan",
      "Pramod Gupta",
      "Julia Klawohn",
      "Greg Hajcak"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Despite extensive standardization, diagnostic interviews for mental health disorders encompass substantial subjective judgment. Previous studies have demonstrated that EEG-based neural measures can function as reliable objective correlates of depression, or even predictors of depression and its course. However, their clinical utility has not been fully realized because of 1) the lack of automated ways to deal with the inherent noise associated with EEG data at scale, and 2) the lack of knowledge of which aspects of the EEG signal may be markers of a clinical disorder. Here we adapt an unsupervised pipeline from the recent deep representation learning literature to address these problems by 1) learning a disentangled representation using $\\beta$-VAE to denoise the signal, and 2) extracting interpretable features associated with a sparse set of clinical labels using a Symbol-Concept Association Network (SCAN). We demonstrate that our method is able to outperform the canonical hand-engineered baseline classification method on a number of factors, including participant age and depression diagnosis. Furthermore, our method recovers a representation that can be used to automatically extract denoised Event Related Potentials (ERPs) from novel, single EEG trajectories, and supports fast supervised re-mapping to various clinical labels, allowing clinicians to re-use a single EEG representation regardless of updates to the standardized diagnostic system. Finally, single factors of the learned disentangled representations often correspond to meaningful markers of clinical factors, as automatically detected by SCAN, allowing for human interpretability and post-hoc expert analysis of the recommendations made by the model.",
    "keywords": "EEG, ERP, electroencephalography, depression, representation learning, disentanglement, beta-VAE",
    "pdf_url": "https://openreview.net/pdf?id=TVjLza1t4hI",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper applies representation learning to EEG (a biomedical, clinical signal) for the automated detection of depression diagnosis and other clinical factors. It explicitly targets “clinical labels,” “depression diagnosis,” and “denoised Event Related Potentials (ERPs)” for mental‐health assessment, fitting squarely within Healthcare AI’s use of biosignals (EEG) for disease diagnosis and patient monitoring.",
    "prompt_tokens": 20783,
    "completion_tokens": 97,
    "total_tokens": 20880,
    "topic": "Mental Health Diagnostics - EEG Analysis",
    "method": "β-VAE; Symbol-Concept Association Network (SCAN)",
    "application": "Depression diagnosis and biomarker discovery",
    "code_link": "N/A",
    "dataset_name": [
      "International Affective Picture System (IAPS)"
    ]
  },
  {
    "id": "tnSo6VRLmT",
    "year": 2021,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Efficient Conformal Prediction via Cascaded Inference with Expanded Admission",
    "authors": [
      "Adam Fisch",
      "Tal Schuster",
      "Tommi S. Jaakkola",
      "Regina Barzilay"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In this paper, we present a novel approach for conformal prediction (CP), in which we aim to identify a set of promising prediction candidates---in place of a single prediction. This set is guaranteed to contain a correct answer with high probability, and is well-suited for many open-ended classification tasks. In the standard CP paradigm, the predicted set can often be unusably large and also costly to obtain. This is particularly pervasive in settings where the correct answer is not unique, and the number of total possible answers is high. We first expand the CP correctness criterion to allow for additional, inferred \"admissible\" answers, which can substantially reduce the size of the predicted set while still providing valid performance guarantees. Second, we amortize costs by conformalizing prediction cascades, in which we aggressively prune implausible labels early on by using progressively stronger classifiers---again, while still providing valid performance guarantees. We demonstrate the empirical effectiveness of our approach for multiple applications in natural language processing and computational chemistry for drug discovery.",
    "keywords": "conformal prediction, uncertainty estimation, efficient inference methods, natural language processing, chemistry",
    "pdf_url": "https://openreview.net/pdf?id=tnSo6VRLmT",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract explicitly mentions applications in “computational chemistry for drug discovery,” which is a core task in Biomedicine AI. Although the main focus is on conformal prediction methods, the inclusion of drug discovery indicates relevance to the biomedical domain.",
    "prompt_tokens": 20801,
    "completion_tokens": 104,
    "total_tokens": 20905,
    "topic": "Information Retrieval - Fact Verification",
    "method": "Conformal prediction; Cascaded ensemble models",
    "application": "Snippet retrieval for claim verification",
    "code_link": "https://github.com/ajfisch/conformal-cascades",
    "dataset_name": [
      "FEVER",
      "Natural Questions",
      "ChEMBL"
    ]
  },
  {
    "id": "DYypjaRdph2",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Inverse Online Learning: Understanding Non-Stationary and Reactionary Policies",
    "authors": [
      "Alex Chan",
      "Alicia Curth",
      "Mihaela van der Schaar"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Human decision making is well known to be imperfect and the ability to analyse such processes individually is crucial when attempting to aid or improve a decision-maker's ability to perform a task, e.g. to alert them to potential biases or oversights on their part. To do so, it is necessary to develop interpretable representations of how agents make decisions and how this process changes over time as the agent learns online in reaction to the accrued experience. To then understand the decision-making processes underlying a set of observed trajectories, we cast the policy inference problem as the inverse to this online learning problem. By interpreting actions within a potential outcomes framework, we introduce a meaningful mapping based on agents choosing an action they believe to have the greatest treatment effect. We introduce a practical algorithm for retrospectively estimating such perceived effects, alongside the process through which agents update them, using a novel architecture built upon an expressive family of deep state-space models. Through application to the analysis of UNOS organ donation acceptance decisions, we demonstrate that our approach can bring valuable insights into the factors that govern decision processes and how they change over time. ",
    "keywords": "Decision Modelling, Imitation Learning, Inverse Online Learning",
    "pdf_url": "https://openreview.net/pdf?id=DYypjaRdph2",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper applies its inverse online learning framework to “UNOS organ donation acceptance decisions,” which is clearly a healthcare domain application involving clinical decision-making around organ transplantation. The focus on modelling and interpreting real-world medical decision processes (acceptance of organ donations) places it squarely in Healthcare AI.",
    "prompt_tokens": 20782,
    "completion_tokens": 103,
    "total_tokens": 20885,
    "topic": "Medical Decision-making - Transplant Policies",
    "method": "Deep state-space models; Inverse online learning",
    "application": "Transplant offer acceptance decision modeling",
    "code_link": "https://github.com/XanderJC/inverse-online",
    "dataset_name": [
      "United Network for Organ Sharing (UNOS)"
    ]
  },
  {
    "id": "-w2oomO6qgc",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "GeneDisco: A Benchmark for Experimental Design in Drug Discovery",
    "authors": [
      "Arash Mehrjou",
      "Ashkan Soleymani",
      "Andrew Jesson",
      "Pascal Notin",
      "Yarin Gal",
      "Stefan Bauer",
      "Patrick Schwab"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In vitro cellular experimentation with genetic interventions, using for example CRISPR technologies, is an essential step in early-stage drug discovery and target validation that serves to assess initial hypotheses about causal associations between biological mechanisms and disease pathologies. With billions of potential hypotheses to test, the experimental design space for in vitro genetic experiments is extremely vast, and the available experimental capacity - even at the largest research institutions in the world - pales in relation to the size of this biological hypothesis space. Machine learning methods, such as active and reinforcement learning, could aid in optimally exploring the vast biological space by integrating prior knowledge from various information sources as well as extrapolating to yet unexplored areas of the experimental design space based on available data. However, there exist no standardised benchmarks and data sets for this challenging task and little research has been conducted in this area to date. Here, we introduce GeneDisco, a benchmark suite for evaluating active learning algorithms for experimental design in drug discovery. GeneDisco contains a curated set of multiple publicly available experimental data sets as well as open-source implementations of state-of-the-art active learning policies for experimental design and exploration.",
    "keywords": "batch active learning, drug discovery, benchmark",
    "pdf_url": "https://openreview.net/pdf?id=-w2oomO6qgc",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper addresses early-stage drug discovery and target validation using in vitro genetic interventions (e.g., CRISPR), and proposes a benchmark (GeneDisco) for active learning in experimental design for drug discovery. Drug discovery and experimental design with biological data are core topics in Biomedicine AI.",
    "prompt_tokens": 20902,
    "completion_tokens": 98,
    "total_tokens": 21000,
    "topic": "Drug Discovery - Target-based",
    "method": "Batch active learning; Bayesian Neural Networks (BNNs); Random Forest",
    "application": "Target identification using CRISPR screens",
    "code_link": "N/A",
    "dataset_name": [
      "Achilles",
      "STRING",
      "CCLE"
    ]
  },
  {
    "id": "vaRCHVj0uGI",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Solving Inverse Problems in Medical Imaging with Score-Based Generative Models",
    "authors": [
      "Yang Song",
      "Liyue Shen",
      "Lei Xing",
      "Stefano Ermon"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Reconstructing medical images from partial measurements is an important inverse problem in Computed Tomography (CT) and Magnetic Resonance Imaging (MRI). Existing solutions based on machine learning typically train a model to directly map measurements to medical images, leveraging a training dataset of paired images and measurements. These measurements are typically synthesized from images using a fixed physical model of the measurement process, which hinders the generalization capability of models to unknown measurement processes. To address this issue, we propose a fully unsupervised technique for inverse problem solving, leveraging the recently introduced score-based generative models. Specifically, we first train a score-based generative model on medical images to capture their prior distribution. Given measurements and a physical model of the measurement process at test time, we introduce a sampling method to reconstruct an image consistent with both the prior and the observed measurements. Our method does not assume a fixed measurement process during training, and can thus be flexibly adapted to different measurement processes at test time. Empirically, we observe comparable or better performance to supervised learning techniques in several medical imaging tasks in CT and MRI, while demonstrating significantly better generalization to unknown measurement processes.",
    "keywords": "score-based generative modeling, inverse problems, sparse-view CT, undersampled MRI, metal artifact removal, diffusion",
    "pdf_url": "https://openreview.net/pdf?id=vaRCHVj0uGI",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “Reconstructing medical images from partial measurements” specifically in CT and MRI, which are core medical imaging modalities. Medical imaging reconstruction is a classic Healthcare AI task, as highlighted by phrases like “sparse-view CT,” “undersampled MRI,” and “metal artifact removal.” The work directly aims to improve clinical imaging workflows, placing it squarely in the Healthcare AI domain.",
    "prompt_tokens": 20724,
    "completion_tokens": 98,
    "total_tokens": 20822,
    "topic": "Medical Imaging - Inverse Problems",
    "method": "Score-based generative model",
    "application": "Sparse-view CT reconstruction; Undersampled MRI reconstruction",
    "code_link": "N/A",
    "dataset_name": [
      "LIDC",
      "LDCT",
      "BraTS 2021"
    ]
  },
  {
    "id": "6IYp-35L-xJ",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "CADDA: Class-wise Automatic Differentiable Data Augmentation for EEG Signals",
    "authors": [
      "Cédric Rommel",
      "Thomas Moreau",
      "Joseph Paillard",
      "Alexandre Gramfort"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Data augmentation is a key element of deep learning pipelines, as it informs the network during training about transformations of the input data that keep the label unchanged. Manually finding adequate augmentation methods and parameters for a given pipeline is however rapidly cumbersome. In particular, while intuition can guide this decision for images, the design and choice of augmentation policies remains unclear for more complex types of data, such as neuroscience signals. Besides, class-dependent augmentation strategies have been surprisingly unexplored in the literature, although it is quite intuitive: changing the color of a car image does not change the object class to be predicted, but doing the same to the picture of an orange does. This paper investigates gradient-based automatic data augmentation algorithms  amenable to class-wise policies with exponentially larger search spaces. Motivated by supervised learning applications using EEG signals for which good augmentation policies are mostly unknown, we propose a new differentiable relaxation of the problem. In the class-agnostic setting, results show that our new relaxation leads to optimal performance with faster training than competing gradient-based methods, while also outperforming gradient-free methods in the class-wise setting. This work proposes also novel differentiable augmentation operations relevant for sleep stage classification.",
    "keywords": "Neuroscience, EEG, Sleep staging, Automatic data augmentation",
    "pdf_url": "https://openreview.net/pdf?id=6IYp-35L-xJ",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on EEG signal processing and specifically proposes augmentation operations for sleep stage classification—an established biomedical and clinical task in neuroscience and sleep medicine. Keywords such as “EEG,” “Sleep staging,” and the context of neuroscience signals indicate direct relevance to healthcare AI.",
    "prompt_tokens": 20770,
    "completion_tokens": 96,
    "total_tokens": 20866,
    "topic": "EEG Analysis - Data Augmentation",
    "method": "Gradient-based automatic data augmentation; differentiable relaxation",
    "application": "Sleep stage classification",
    "code_link": "N/A",
    "dataset_name": [
      "MASS - Session 3",
      "Physionet Sleep Dataset"
    ]
  },
  {
    "id": "RQ428ZptQfU",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "A Deep Variational Approach to Clustering Survival Data",
    "authors": [
      "Laura Manduchi",
      "Ričards Marcinkevičs",
      "Michela C. Massi",
      "Thomas Weikert",
      "Alexander Sauter",
      "Verena Gotta",
      "Timothy Müller",
      "Flavio Vasella",
      "Marian C. Neidert",
      "Marc Pfister",
      "Bram Stieltjes",
      "Julia E Vogt"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In this work, we study the problem of clustering survival data — a challenging and so far under-explored task. We introduce a novel semi-supervised probabilistic approach to cluster survival data by leveraging recent advances in stochastic gradient variational inference. In contrast to previous work, our proposed method employs a deep generative model to uncover the underlying distribution of both the explanatory variables and censored survival times. We compare our model to the related work on clustering and mixture models for survival data in comprehensive experiments on a wide range of synthetic, semi-synthetic, and real-world datasets, including medical imaging data. Our method performs better at identifying clusters and is competitive at predicting survival times. Relying on novel generative assumptions, the proposed model offers a holistic perspective on clustering survival data and holds a promise of discovering subpopulations whose survival is regulated by different generative mechanisms.",
    "keywords": "survival analysis, clustering, healthcare, variational autoencoders, deep generative models",
    "pdf_url": "https://openreview.net/pdf?id=RQ428ZptQfU",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper addresses clustering of censored survival times and compares performance on real-world datasets including medical imaging data, directly pertaining to patient survival prediction and subgroup discovery in a healthcare context. The use of “survival analysis” and “healthcare” in the keywords further underscores its relevance to clinical outcome modeling.",
    "prompt_tokens": 20738,
    "completion_tokens": 122,
    "total_tokens": 20860,
    "topic": "Time Series - Survival Analysis",
    "method": "Variational Deep Survival Clustering; Semi-supervised learning",
    "application": "Survival time clustering",
    "code_link": "https://github.com/i6092467/vadesc",
    "dataset_name": [
      "Synthetic",
      "survMNIST",
      "SUPPORT",
      "FLChain",
      "HGG",
      "Hemodialysis",
      "NSCLC"
    ]
  },
  {
    "id": "Lwr8We4MIxn",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "A Biologically Interpretable Graph Convolutional Network to Link Genetic Risk Pathways and Imaging Phenotypes of Disease ",
    "authors": [
      "Sayan Ghosal",
      "Qiang Chen",
      "Giulio Pergola",
      "Aaron L Goldman",
      "William Ulrich",
      "Daniel R Weinberger",
      "Archana Venkataraman"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We propose a novel end-to-end framework for whole-brain and whole-genome imaging-genetics. Our genetics network uses hierarchical graph convolution and pooling operations to embed subject-level data onto a low-dimensional latent space. The hierarchical network implicitly tracks the convergence of genetic risk across well-established biological pathways, while an attention mechanism automatically identifies the salient edges of this network at the subject level. In parallel, our imaging network projects multimodal data onto a set of latent embeddings. For interpretability, we implement a Bayesian feature selection strategy to extract the discriminative imaging biomarkers; these feature weights are optimized alongside the other model parameters. We couple the imaging and genetic embeddings with a predictor network, to ensure that the learned representations are linked to phenotype. We evaluate our framework on a schizophrenia dataset that includes two functional MRI paradigms and gene scores derived from Single Nucleotide Polymorphism data. Using repeated 10-fold cross-validation, we show that our imaging-genetics fusion achieves the better classification performance than state-of-the-art baselines. In an exploratory analysis, we further show that the biomarkers identified by our model are reproducible and closely associated with deficits in schizophrenia. ",
    "keywords": "Imaging-genetics, Hierarchical Graph Convolution, Gene Ontology, Bayesian Feature Selection, Schizophrenia",
    "pdf_url": "https://openreview.net/pdf?id=Lwr8We4MIxn",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on linking genetic risk pathways (gene scores from SNP data, gene ontology) with brain imaging phenotypes (two fMRI paradigms) to classify and interpret schizophrenia—a clear biomedical and clinical neuroscience application. It develops biomarkers for a specific disease and uses patient‐level genetic and imaging data, fitting squarely within Biomedicine AI.",
    "prompt_tokens": 21214,
    "completion_tokens": 95,
    "total_tokens": 21309,
    "topic": "Imaging Genetics - Disease Prediction",
    "method": "Graph Convolutional Networks (GCN); Bayesian Feature Selection",
    "application": "Patient classification – Schizophrenia",
    "code_link": "N/A",
    "dataset_name": [
      "Anonymous Schizophrenia Dataset"
    ]
  },
  {
    "id": "w_drCosT76",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Differentiable Scaffolding Tree for Molecule Optimization",
    "authors": [
      "Tianfan Fu",
      "Wenhao Gao",
      "Cao Xiao",
      "Jacob Yasonik",
      "Connor W. Coley",
      "Jimeng Sun"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The structural design of functional molecules, also called molecular optimization, is an essential chemical science and engineering task with important applications, such as drug discovery. Deep generative models and combinatorial optimization methods achieve initial success but still struggle with directly modeling discrete chemical structures and often heavily rely on brute-force enumeration. The challenge comes from the discrete and non-differentiable nature of molecule structures. To address this, we propose differentiable scaffolding tree (DST) that utilizes a learned knowledge network to convert discrete chemical structures to locally differentiable ones. DST enables a gradient-based optimization on a chemical graph structure by back-propagating the derivatives from the target properties through a graph neural network (GNN). Our empirical studies show the gradient-based molecular optimizations are both effective and sample efficient (in terms of oracle calling number). Furthermore, the learned graph parameters can also provide an explanation that helps domain experts understand the model output. The code repository (including processed data, trained model, demonstration, molecules with the highest property) is available at https://github.com/futianfan/DST.",
    "keywords": "",
    "pdf_url": "https://openreview.net/pdf?id=w_drCosT76",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “molecular optimization” and cites “drug discovery” as a key application, which places it squarely in the biomedicine AI domain. The proposed method (Differentiable Scaffolding Tree) is used to design functional molecules—a core task in therapeutic design and pharmaceutical research.",
    "prompt_tokens": 20438,
    "completion_tokens": 116,
    "total_tokens": 20554,
    "topic": "Drug Discovery - Phenotype-based",
    "method": "Differentiable Scaffolding Tree (DST); Graph Neural Network (GNN)",
    "application": "De novo molecular generation",
    "code_link": "https://github.com/futianfan/DST",
    "dataset_name": [
      "ZINC 250K"
    ]
  },
  {
    "id": "GQjaI9mLet",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Independent SE(3)-Equivariant Models for End-to-End Rigid Protein Docking",
    "authors": [
      "Octavian-Eugen Ganea",
      "Xinyuan Huang",
      "Charlotte Bunne",
      "Yatao Bian",
      "Regina Barzilay",
      "Tommi S. Jaakkola",
      "Andreas Krause"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Protein complex formation is a central problem in biology, being involved in most of the cell's processes, and essential for applications, e.g. drug design or protein engineering. We tackle rigid body protein-protein docking, i.e., computationally predicting the 3D structure of a protein-protein complex from the individual unbound structures, assuming no conformational change within the proteins happens during binding. We design a novel pairwise-independent SE(3)-equivariant graph matching network to predict the rotation and translation to place one of the proteins at the right docked position relative to the second protein. We mathematically guarantee a basic principle: the predicted complex is always identical regardless of the initial locations and orientations of the two structures. Our model, named EquiDock, approximates the binding pockets and predicts the docking poses using keypoint matching and alignment, achieved through optimal transport and a differentiable Kabsch algorithm. Empirically, we achieve significant running time improvements and often outperform existing  docking software despite not relying on heavy candidate sampling, structure refinement, or templates.",
    "keywords": "protein complexes, protein structure, rigid body docking, SE(3) equivariance, graph neural networks",
    "pdf_url": "https://openreview.net/pdf?id=GQjaI9mLet",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper addresses rigid protein–protein docking—a core problem in molecular modeling with direct applications in “drug design” and “protein engineering.” It develops SE(3)-equivariant graph neural networks to predict how proteins bind, which is central to **biomedicine AI** tasks like **drug discovery** and **protein complex structure prediction**.",
    "prompt_tokens": 20663,
    "completion_tokens": 117,
    "total_tokens": 20780,
    "topic": "Drug Discovery - Protein Docking",
    "method": "SE(3)-equivariant graph matching networks; attention-based keypoint selection; optimal transport; differentiable superimposition",
    "application": "Rigid body docking prediction",
    "code_link": "https://github.com/octavian-ganea/equidock_public",
    "dataset_name": [
      "DIPS",
      "DB5.5"
    ]
  },
  {
    "id": "1HxTO6CTkz",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Unifying Likelihood-free Inference with Black-box Optimization and Beyond",
    "authors": [
      "Dinghuai Zhang",
      "Jie Fu",
      "Yoshua Bengio",
      "Aaron Courville"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Black-box optimization formulations for biological sequence design have drawn recent attention due to their promising potential impact on the pharmaceutical industry. In this work, we propose to unify two seemingly distinct worlds: likelihood-free inference and black-box optimization, under one probabilistic framework. In tandem, we provide a recipe for constructing various sequence design methods based on this framework. We show how previous optimization approaches can be \"reinvented\" in our framework, and further propose new probabilistic black-box optimization algorithms. Extensive experiments on sequence design application illustrate the benefits of the proposed methodology.",
    "keywords": "biological sequence design, black-box optimization, likelihood-free inference, Bayesian inference",
    "pdf_url": "https://openreview.net/pdf?id=1HxTO6CTkz",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “biological sequence design” and mentions its “promising potential impact on the pharmaceutical industry,” which directly aligns with drug discovery and molecular design—core tasks in Biomedicine AI. The keywords “biological sequence design” and “black-box optimization” in a pharmaceutical context clearly indicate a biomedical application rather than a purely general ML methodology.",
    "prompt_tokens": 20962,
    "completion_tokens": 111,
    "total_tokens": 21073,
    "topic": "Bioinformatics - Biological Sequence Design",
    "method": "Composite probabilistic methods; Bayesian inference framework; BiLSTM models",
    "application": "Biological sequence design – optimizing DNA/protein sequences",
    "code_link": "N/A",
    "dataset_name": [
      "5’ UTR Benchmark",
      "AMP Dataset",
      "Fluo Benchmark",
      "TfBind"
    ]
  },
  {
    "id": "FRxhHdnxt1",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Amortized Tree Generation for Bottom-up Synthesis Planning and Synthesizable Molecular Design",
    "authors": [
      "Wenhao Gao",
      "Rocío Mercado",
      "Connor W. Coley"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Molecular design and synthesis planning are two critical steps in the process of molecular discovery that we propose to formulate as a single shared task of conditional synthetic pathway generation. We report an amortized approach to generate synthetic pathways as a Markov decision process conditioned on a target molecular embedding. This approach allows us to conduct synthesis planning in a bottom-up manner and design synthesizable molecules by decoding from optimized conditional codes, demonstrating the potential to solve both problems of design and synthesis simultaneously. The approach leverages neural networks to probabilistically model the synthetic trees, one reaction step at a time, according to reactivity rules encoded in a discrete action space of reaction templates. We train these networks on hundreds of thousands of artificial pathways generated from a pool of purchasable compounds and a list of expert-curated templates. We validate our method with (a) the recovery of molecules using conditional generation, (b) the identification of synthesizable structural analogs, and (c) the optimization of molecular structures given oracle functions relevant to bioactivity and drug discovery.",
    "keywords": "molecular design, synthesis planning, tree generation, graph generation",
    "pdf_url": "https://openreview.net/pdf?id=FRxhHdnxt1",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “molecular design and synthesis planning” with direct applications in “bioactivity and drug discovery.” It describes generating “synthesizable structural analogs” and optimizing “molecular structures given oracle functions relevant to bioactivity and drug discovery,” which places it squarely in the Biomedicine AI domain.",
    "prompt_tokens": 21040,
    "completion_tokens": 105,
    "total_tokens": 21145,
    "topic": "Drug Discovery - Synthesis Planning",
    "method": "Markov Decision Process; Genetic Algorithm",
    "application": "Synthesis planning and molecular optimization",
    "code_link": "https://github.com/wenhao-gao/SynNet",
    "dataset_name": [
      "ChEMBL",
      "Enamine Building Blocks",
      "TDC"
    ]
  },
  {
    "id": "fXHl76nO2AZ",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Gradient Importance Learning for Incomplete Observations",
    "authors": [
      "Qitong Gao",
      "Dong Wang",
      "Joshua David Amason",
      "Siyang Yuan",
      "Chenyang Tao",
      "Ricardo Henao",
      "Majda Hadziahmetovic",
      "Lawrence Carin",
      "Miroslav Pajic"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Though recent works have developed methods that can generate estimates (or imputations) of the missing entries in a dataset to facilitate downstream analysis, most depend on assumptions that may not align with real-world applications and could suffer from poor performance in subsequent tasks such as classification. This is particularly true if the data have large missingness rates or a small sample size. More importantly, the imputation error could be propagated into the prediction step that follows, which may constrain the capabilities of the prediction model. In this work, we introduce the gradient importance learning (GIL) method to train multilayer perceptrons (MLPs) and long short-term memories (LSTMs) to directly perform inference from inputs containing missing values without imputation. Specifically, we employ reinforcement learning (RL) to adjust the gradients used to train these models via back-propagation. This allows the model to exploit the underlying information behind missingness patterns. We test the approach on real-world time-series (i.e., MIMIC-III), tabular data obtained from an eye clinic, and a standard dataset (i.e., MNIST), where our imputation-free predictions outperform the traditional two-step imputation-based predictions using state-of-the-art imputation methods.",
    "keywords": "Missing Data, Reinforcement Learning, Representation Learning",
    "pdf_url": "https://openreview.net/pdf?id=fXHl76nO2AZ",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper evaluates its missing‐data learning method on MIMIC-III (a widely used ICU/EHR dataset) and on tabular data from an eye clinic. These are clearly clinical/healthcare datasets, and the work targets inference directly on medical time‐series and patient records without imputation. Therefore, it falls within Healthcare AI.",
    "prompt_tokens": 21020,
    "completion_tokens": 120,
    "total_tokens": 21140,
    "topic": "EHR - Predictive Models",
    "method": "Gradient Importance Learning (GIL); Reinforcement Learning (RL); LSTM; MLP",
    "application": "Septic shock early prediction – ICU",
    "code_link": "N/A",
    "dataset_name": [
      "MIMIC-III",
      "Physionet Challenge 2012",
      "MNIST",
      "Ophthalmic Dataset"
    ]
  },
  {
    "id": "hm2tNDdgaFK",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Learning 3D Representations of Molecular Chirality with Invariance to Bond Rotations",
    "authors": [
      "Keir Adams",
      "Lagnajit Pattanaik",
      "Connor W. Coley"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Molecular chirality, a form of stereochemistry most often describing relative spatial arrangements of bonded neighbors around tetrahedral carbon centers, influences the set of 3D conformers accessible to the molecule without changing its 2D graph connectivity. Chirality can strongly alter (bio)chemical interactions, particularly protein-drug binding. Most 2D graph neural networks (GNNs) designed for molecular property prediction at best use atomic labels to naïvely treat chirality, while E(3)-invariant 3D GNNs are invariant to chirality altogether. To enable representation learning on molecules with defined stereochemistry, we design an SE(3)-invariant model that processes torsion angles of a 3D molecular conformer. We explicitly model conformational flexibility by integrating a novel type of invariance to rotations about internal molecular bonds into the architecture, mitigating the need for multi-conformer data augmentation. We test our model on four benchmarks: contrastive learning to distinguish conformers of different stereoisomers in a learned latent space, classification of chiral centers as R/S, prediction of how enantiomers rotate circularly polarized light, and ranking enantiomers by their docking scores in an enantiosensitive protein pocket. We compare our model, Chiral InterRoto-Invariant Neural Network (ChIRo), with 2D and 3D GNNs to demonstrate that our model achieves state of the art performance when learning chiral-sensitive functions from molecular structures.",
    "keywords": "geometric deep learning, equivariance, molecules",
    "pdf_url": "https://openreview.net/pdf?id=hm2tNDdgaFK",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The work focuses on learning 3D molecular representations to distinguish stereoisomers, predict chiral center configurations, model how enantiomers rotate polarized light, and rank enantiomers by docking scores in protein pockets. These tasks—“protein-drug binding,” “enantiomers,” and “docking in an enantiosensitive protein pocket”—are core to drug discovery and molecular modeling in biomedicine.",
    "prompt_tokens": 20739,
    "completion_tokens": 112,
    "total_tokens": 20851,
    "topic": "Drug Discovery - Molecular Chirality",
    "method": "Graph neural networks; SE(3)-invariant representation; Torsion encoder",
    "application": "Chirality-based molecular property prediction",
    "code_link": "https://github.com/keiradams/ChIRo",
    "dataset_name": [
      "Reaxys",
      "PubChem3D"
    ]
  },
  {
    "id": "xQUe1pOKPam",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Pre-training Molecular Graph Representation with 3D Geometry",
    "authors": [
      "Shengchao Liu",
      "Hanchen Wang",
      "Weiyang Liu",
      "Joan Lasenby",
      "Hongyu Guo",
      "Jian Tang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Molecular graph representation learning is a fundamental problem in modern drug and material discovery. Molecular graphs are typically modeled by their 2D topological structures, but it has been recently discovered that 3D geometric information plays a more vital role in predicting molecular functionalities. However, the lack of 3D information in real-world scenarios has significantly impeded the learning of geometric graph representation. To cope with this challenge, we propose the Graph Multi-View Pre-training (GraphMVP) framework where self-supervised learning (SSL) is performed by leveraging the correspondence and consistency between 2D topological structures and 3D geometric views. GraphMVP effectively learns a 2D molecular graph encoder that is enhanced by richer and more discriminative 3D geometry. We further provide theoretical insights to justify the effectiveness of GraphMVP. Finally, comprehensive experiments show that GraphMVP can consistently outperform existing graph SSL methods. Code is available on GitHub: https://github.com/chao1224/GraphMVP.",
    "keywords": "Pre-training, SSL, Molecule, 3D Geometry, 2D representation",
    "pdf_url": "https://openreview.net/pdf?id=xQUe1pOKPam",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper targets molecular graph representation learning specifically for “drug discovery” (abstract: “a fundamental problem in modern drug and material discovery”) and leverages 3D molecular geometry—tasks squarely within Biomedicine AI for molecular modeling and therapeutic design.",
    "prompt_tokens": 21218,
    "completion_tokens": 164,
    "total_tokens": 21382,
    "topic": "Drug Discovery - Geometry-based Representations",
    "method": "Contrastive SSL; Generative SSL; Variational Representation Reconstruction (VRR); EBM-NCE",
    "application": "Molecular property prediction and drug-target affinity prediction",
    "code_link": "N/A",
    "dataset_name": [
      "GEOM",
      "BBBP",
      "Tox21",
      "ToxCast",
      "SIDER",
      "ClinTox",
      "MUV",
      "HIV",
      "BACE",
      "ESOL",
      "Lipo",
      "Malaria",
      "CEP",
      "Davis",
      "KIBA"
    ]
  },
  {
    "id": "0kPL3xO4R5",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Fast topological clustering with Wasserstein distance",
    "authors": [
      "Tananun Songdechakraiwut",
      "Bryan M Krause",
      "Matthew I Banks",
      "Kirill V Nourski",
      "Barry D Van Veen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The topological patterns exhibited by many real-world networks motivate the development of topology-based methods for assessing the similarity of networks. However, extracting topological structure is difficult, especially for large and dense networks whose node degrees range over multiple orders of magnitude. In this paper, we propose a novel and computationally practical topological clustering method that clusters complex networks with intricate topology using principled theory from persistent homology and optimal transport. Such networks are aggregated into clusters through a centroid-based clustering strategy based on both their topological and geometric structure, preserving correspondence between nodes in different networks. The notions of topological proximity and centroid are characterized using a novel and efficient approach to computation of the Wasserstein distance and barycenter for persistence barcodes associated with connected components and cycles. The proposed method is demonstrated to be effective using both simulated networks and measured functional brain networks.",
    "keywords": "Topological data analysis, cluster analysis, persistent homology, Wasserstein distance, Wasserstein barycenter, brain networks, intracranial electrophysiology, consciousness",
    "pdf_url": "https://openreview.net/pdf?id=0kPL3xO4R5",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the core contribution is a general topology‐based clustering method, the paper demonstrates its effectiveness on “measured functional brain networks” derived from “intracranial electrophysiology” and studies “consciousness.” These are clearly biomedical/neuroscience applications, indicating relevance to Biomedicine AI.",
    "prompt_tokens": 20580,
    "completion_tokens": 99,
    "total_tokens": 20679,
    "topic": "Neuroinformatics - Brain Network Analysis",
    "method": "Topological clustering; Wasserstein distance; graph filtration",
    "application": "Behavioral state classification during anesthesia",
    "code_link": "https://github.com/topolearn",
    "dataset_name": [
      "Alpha band weighted phase lag index dataset"
    ]
  },
  {
    "id": "yfe1VMYAXa4",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "OntoProtein: Protein Pretraining With Gene Ontology Embedding",
    "authors": [
      "Ningyu Zhang",
      "Zhen Bi",
      "Xiaozhuan Liang",
      "Siyuan Cheng",
      "Haosen Hong",
      "Shumin Deng",
      "Qiang Zhang",
      "Jiazhang Lian",
      "Huajun Chen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Self-supervised protein language models have proved their effectiveness in learning the proteins representations. With the increasing computational power, current protein language models pre-trained with millions of diverse sequences can advance the parameter scale from million-level to billion-level and achieve remarkable improvement. However, those prevailing approaches rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better protein representations. We argue that informative biology knowledge in KGs can enhance protein representation with external knowledge. In this work, we propose OntoProtein, the first general framework that makes use of structure in GO (Gene Ontology) into protein pre-training models. We construct a novel large-scale knowledge graph that consists of GO and its related proteins, and gene annotation texts or protein sequences describe all nodes in the graph. We propose novel contrastive learning with knowledge-aware negative sampling to jointly optimize the knowledge graph and protein embedding during pre-training.  Experimental results show that OntoProtein can surpass state-of-the-art methods with pre-trained protein language models in TAPE benchmark and yield better performance compared with baselines in protein-protein interaction and protein function prediction.",
    "keywords": "pre-trained language model, knowledge graph, protein representation",
    "pdf_url": "https://openreview.net/pdf?id=yfe1VMYAXa4",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The work focuses on protein representation learning by incorporating Gene Ontology (GO) knowledge graphs, and evaluates on tasks such as protein–protein interaction and protein function prediction. These are core problems in molecular biology and bioinformatics, directly aligning with Biomedicine AI.",
    "prompt_tokens": 20743,
    "completion_tokens": 130,
    "total_tokens": 20873,
    "topic": "Bioinformatics - Knowledge-Enhanced Protein Pretraining",
    "method": "Knowledge Embedding (KE); Contrastive Learning; Masked Protein Modeling (MLM)",
    "application": "Protein function prediction; Protein-protein interaction prediction",
    "code_link": "https://github.com/zjunlp/OntoProtein",
    "dataset_name": [
      "ProteinKG25",
      "TAPE",
      "STRING",
      "SHS27k",
      "SHS148k"
    ]
  },
  {
    "id": "PzcvxEMzvQC",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "GeoDiff: A Geometric Diffusion Model for Molecular Conformation Generation",
    "authors": [
      "Minkai Xu",
      "Lantao Yu",
      "Yang Song",
      "Chence Shi",
      "Stefano Ermon",
      "Jian Tang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Predicting molecular conformations from molecular graphs is a fundamental problem in cheminformatics and drug discovery. Recently, significant progress has been achieved with machine learning approaches, especially with deep generative models. Inspired by the diffusion process in classical non-equilibrium thermodynamics where heated particles will diffuse from original states to a noise distribution, in this paper, we propose a novel generative model named GeoDiff for molecular conformation prediction. GeoDiff treats each atom as a particle and learns to directly reverse the diffusion process (i.e., transforming from a noise distribution to stable conformations) as a Markov chain. Modeling such a generation process is however very challenging as the likelihood of conformations should be roto-translational invariant. We theoretically show that Markov chains evolving with equivariant Markov kernels can induce an invariant distribution by design, and further propose building blocks for the Markov kernels to preserve the desirable equivariance property. The whole framework can be efficiently trained in an end-to-end fashion by optimizing a weighted variational lower bound to the (conditional) likelihood. Experiments on multiple benchmarks show that GeoDiff is superior or comparable to existing state-of-the-art approaches, especially on large molecules. ",
    "keywords": "molecular conformation generation, deep generative models, diffusion probabilistic models",
    "pdf_url": "https://openreview.net/pdf?id=PzcvxEMzvQC",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “molecular conformation generation,” a key task in cheminformatics and explicitly cites “drug discovery” as an application area. Generative modeling of molecular structures directly supports the design and optimization of therapeutic compounds, which falls squarely under Biomedicine AI.",
    "prompt_tokens": 20660,
    "completion_tokens": 117,
    "total_tokens": 20777,
    "topic": "Drug Discovery - Conformation Prediction",
    "method": "Denoising Diffusion Model",
    "application": "Equilibrium conformation generation",
    "code_link": "https://github.com/MinkaiXu/GeoDiff",
    "dataset_name": [
      "GEOM-QM9",
      "GEOM-Drugs"
    ]
  },
  {
    "id": "AJsI-ymaKn_",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "POETREE: Interpretable Policy Learning with Adaptive Decision Trees",
    "authors": [
      "Alizée Pace",
      "Alex Chan",
      "Mihaela van der Schaar"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Building models of human decision-making from observed behaviour is critical to better understand, diagnose and support real-world policies such as clinical care. As established policy learning approaches remain focused on imitation performance, they fall short of explaining the demonstrated decision-making process. Policy Extraction through decision Trees (POETREE) is a novel framework for interpretable policy learning, compatible with fully-offline and partially-observable clinical decision environments -- and builds probabilistic tree policies determining physician actions based on patients' observations and medical history. Fully-differentiable tree architectures are grown incrementally during optimization to adapt their complexity to the modelling task, and learn a representation of patient history through recurrence, resulting in decision tree policies that adapt over time with patient information. This policy learning method outperforms the state-of-the-art on real and synthetic medical datasets, both in terms of understanding, quantifying and evaluating observed behaviour as well as in accurately replicating it -- with potential to improve future decision support systems.",
    "keywords": "Imitation Learning, Interpretable ML, Clinical Decision Support, Sequential Decision-Making",
    "pdf_url": "https://openreview.net/pdf?id=AJsI-ymaKn_",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly targets “clinical decision environments,” learning “probabilistic tree policies determining physician actions based on patients’ observations and medical history.” It emphasizes “clinical decision support” and evaluates on “real and synthetic medical datasets,” making it directly relevant to Healthcare AI.",
    "prompt_tokens": 20800,
    "completion_tokens": 108,
    "total_tokens": 20908,
    "topic": "Medical Prognosis - Policy Interpretability",
    "method": "Recurrent Decision Trees; Incremental Tree Growth",
    "application": "MRI scan ordering prediction – Cognitive disorders; Antibiotic prescription prediction – ICU",
    "code_link": "N/A",
    "dataset_name": [
      "ADNI",
      "MIMIC-III",
      "SYNTH"
    ]
  },
  {
    "id": "CS4463zx6Hi",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Geometric Transformers for Protein Interface Contact Prediction",
    "authors": [
      "Alex Morehead",
      "Chen Chen",
      "Jianlin Cheng"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Computational methods for predicting the interface contacts between proteins come highly sought after for drug discovery as they can significantly advance the accuracy of alternative approaches, such as protein-protein docking, protein function analysis tools, and other computational methods for protein bioinformatics. In this work, we present the Geometric Transformer, a novel geometry-evolving graph transformer for rotation and translation-invariant protein interface contact prediction, packaged within DeepInteract, an end-to-end prediction pipeline. DeepInteract predicts partner-specific protein interface contacts (i.e., inter-protein residue-residue contacts) given the 3D tertiary structures of two proteins as input. In rigorous benchmarks, DeepInteract, on challenging protein complex targets from the 13th and 14th CASP-CAPRI experiments as well as Docking Benchmark 5, achieves 14% and 1.1% top L/5 precision (L: length of a protein unit in a complex), respectively. In doing so, DeepInteract, with the Geometric Transformer as its graph-based backbone, outperforms existing methods for interface contact prediction in addition to other graph-based neural network backbones compatible with DeepInteract, thereby validating the effectiveness of the Geometric Transformer for learning rich relational-geometric features for downstream tasks on 3D protein structures.",
    "keywords": "Geometric Deep Learning, Graph Transformers, Protein Bioinformatics, Invariance",
    "pdf_url": "https://openreview.net/pdf?id=CS4463zx6Hi",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work focuses on predicting protein–protein interface contacts to aid drug discovery (“computational methods for predicting the interface contacts between proteins come highly sought after for drug discovery”), uses 3D protein structures, and lies squarely in protein bioinformatics and molecular modeling—clear indicators of a Biomedicine AI application.",
    "prompt_tokens": 20753,
    "completion_tokens": 105,
    "total_tokens": 20858,
    "topic": "Bioinformatics - Protein Interaction Prediction",
    "method": "Geometric deep learning; Graph Transformers",
    "application": "Protein interface contact prediction",
    "code_link": "https://github.com/BioinfoMachineLearning/DeepInteract",
    "dataset_name": [
      "DIPS-Plus",
      "DB5",
      "CASP-CAPRI"
    ]
  },
  {
    "id": "P1QUVhOtEFP",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Topologically Regularized Data Embeddings",
    "authors": [
      "Robin Vandaele",
      "Bo Kang",
      "Jefrey Lijffijt",
      "Tijl De Bie",
      "Yvan Saeys"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Unsupervised feature learning often finds low-dimensional embeddings that capture the structure of complex data.  For tasks for which prior expert topological knowledge is available, incorporating this into the learned representation may lead to higher quality embeddings. For example, this may help one to embed the data into a given number of clusters, or to accommodate for noise that prevents one from deriving the distribution of the data over the model directly, which can then be learned more effectively. However, a general tool for integrating different prior topological knowledge into embeddings is lacking. Although differentiable topology layers have been recently developed that can (re)shape embeddings into prespecified topological models, they have two important limitations for representation learning, which we address in this paper. First, the currently suggested topological losses fail to represent simple models such as clusters and flares in a natural manner. Second, these losses neglect all original structural (such as neighborhood) information in the data that is useful for learning. We overcome these limitations by introducing a new set of topological losses, and proposing their usage as a way for topologically regularizing data embeddings to naturally represent a prespecified model. We include thorough experiments on synthetic and real data that highlight the usefulness and versatility of this approach, with applications ranging from modeling high-dimensional single-cell data, to graph embedding.",
    "keywords": "Embedding, Dimensionality Reduction, Topological Data Analysis, Persistent Homology, Optimization, Regularization",
    "pdf_url": "https://openreview.net/pdf?id=P1QUVhOtEFP",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the core contribution is a general topologically regularized embedding method, the abstract explicitly cites “modeling high-dimensional single-cell data,” which is a biomedical application (single-cell genomics/omics). This use of single-cell analysis places the work squarely in the Biomedicine AI domain.",
    "prompt_tokens": 20922,
    "completion_tokens": 106,
    "total_tokens": 21028,
    "topic": "Representation Learning - Topological Regularization",
    "method": "Topological regularization",
    "application": "Embedding optimization",
    "code_link": "https://github.com/robinvndaele/topembedding",
    "dataset_name": [
      "Synthetic Cycle",
      "Cell Cycle",
      "Cell Bifurcating",
      "Karate Network"
    ]
  },
  {
    "id": "OtEDS2NWhqa",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Using Graph Representation Learning with Schema Encoders to Measure the Severity of Depressive Symptoms",
    "authors": [
      "Simin Hong",
      "Anthony Cohn",
      "David Crossland Hogg"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Graph neural networks (GNNs) are widely used in regression and classification problems applied to text, in areas such as sentiment analysis and medical decision-making processes. We propose a novel form for node attributes within a GNN based model that captures node-specific embeddings for every word in the vocabulary. This provides a global representation at each node, coupled with node-level updates according to associations among words in a transcript. We demonstrate the efficacy of the approach by augmenting the accuracy of measuring major depressive disorder (MDD). Prior research has sought to make a diagnostic prediction of depression levels from patient data using several modalities, including audio, video, and text. On the DAIC-WOZ benchmark, our method outperforms state-of-art methods by a substantial margin, including those using multiple modalities. Moreover, we also evaluate the performance of our novel model on a Twitter sentiment dataset. We show that our model outperforms a general GNN model by leveraging our novel 2-D node attributes. These results demonstrate the generality of the proposed method.",
    "keywords": "Graph neural networks sentiment analysis node-embedding algorithm  diagnostic prediction task",
    "pdf_url": "https://openreview.net/pdf?id=OtEDS2NWhqa",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “measuring the severity of depressive symptoms” and making a “diagnostic prediction of depression levels” (i.e., major depressive disorder, MDD) from patient data (DAIC-WOZ benchmark). This is a direct application of AI for mental‐health diagnosis and thus falls squarely under Healthcare AI.",
    "prompt_tokens": 20717,
    "completion_tokens": 114,
    "total_tokens": 20831,
    "topic": "Mental Health - Depression Severity Prediction",
    "method": "Graph Neural Networks (GNN); Schema-based graph representations",
    "application": "Depression severity estimation",
    "code_link": "https://github.com/sword-ace/Using-SGNN-for-Depression-Estimate",
    "dataset_name": [
      "DAIC-WOZ",
      "Borderlands Sentiment Twitter"
    ]
  },
  {
    "id": "12RoR2o32T",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Out-of-distribution Generalization in the Presence of Nuisance-Induced Spurious Correlations",
    "authors": [
      "Aahlad Manas Puli",
      "Lily H Zhang",
      "Eric Karl Oermann",
      "Rajesh Ranganath"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In many prediction problems, spurious correlations are induced by a changing relationship between the label and a nuisance variable that is also correlated with the covariates. For example, in classifying animals in natural images, the background, which is a nuisance, can predict the type of animal. This nuisance-label relationship does not always hold, and the performance of a model trained under one such relationship may be poor on data with a different nuisance-label relationship. To build predictive models that perform well regardless of the nuisance-label relationship, we develop Nuisance-Randomized Distillation (NURD). We introduce the nuisance-randomized distribution, a distribution where the nuisance and the label are independent. Under this distribution, we define the set of representations such that conditioning on any member, the nuisance and the label remain independent. We prove that the representations in this set always perform better than chance, while representations outside of this set may not. NURD finds a representation from this set that is most informative of the label under the nuisance-randomized distribution, and we prove that this representation achieves the highest performance regardless of the nuisance-label relationship. We evaluate NURD on several tasks including chest X-ray classification where, using non-lung patches as the nuisance, NURD produces models that predict pneumonia under strong spurious correlations.",
    "keywords": "spurious correlations, out of distribution generalization, ml for health, representation learning",
    "pdf_url": "https://openreview.net/pdf?id=12RoR2o32T",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: While the paper develops a general ML method for out-of-distribution robustness (NURD), it specifically demonstrates its use on chest X-ray classification—“using non-lung patches as the nuisance, NURD produces models that predict pneumonia under strong spurious correlations”—and lists “ml for health” as a keyword. This direct application to a medical imaging task (pneumonia diagnosis) places it within the Healthcare AI domain.",
    "prompt_tokens": 20814,
    "completion_tokens": 106,
    "total_tokens": 20920,
    "topic": "Medical Imaging - Pneumonia Detection",
    "method": "Generative-NURD; Reweighting-NURD",
    "application": "Pneumonia detection",
    "code_link": "https://github.com/rajesh-lab/nurd-code-public",
    "dataset_name": [
      "CheXpert",
      "MIMIC-CXR"
    ]
  },
  {
    "id": "d_2lcDh0Y9c",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "DriPP: Driven Point Processes to Model Stimuli Induced Patterns in M/EEG Signals",
    "authors": [
      "Cédric Allain",
      "Alexandre Gramfort",
      "Thomas Moreau"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The quantitative analysis of non-invasive electrophysiology signals from electroencephalography (EEG) and magnetoencephalography (MEG) boils down to the identification of temporal patterns such as evoked responses, transient bursts of neural oscillations but also blinks or heartbeats for data cleaning. Several works have shown that these patterns can be extracted efficiently in an unsupervised way, e.g., using Convolutional Dictionary Learning. This leads to an event-based description of the data. Given these events, a natural question is to estimate how their occurrences are modulated by certain cognitive tasks and experimental manipulations. To address it, we propose a point process approach. While point processes have been used in neuroscience in the past, in particular for single cell recordings (spike trains), techniques such as Convolutional Dictionary Learning make them amenable to human studies based on EEG/MEG signals. We develop a novel statistical point process model – called driven temporal point processes (DriPP) – where the intensity function of the point process model is linked to a set of point processes corresponding to stimulation events. We derive a fast and principled expectation-maximization algorithm to estimate the parameters of this model. Simulations reveal that model parameters can be identified from long enough signals. Results on standard MEG datasets demonstrate that our methodology reveals event-related neural responses – both evoked and induced – and isolates non-task specific temporal patterns.",
    "keywords": "Electrophysiology, Neuroscience, Temporal point processes, Convolutional Dictionary Learning",
    "pdf_url": "https://openreview.net/pdf?id=d_2lcDh0Y9c",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper proposes methods for modeling and extracting patterns from M/EEG signals—non-invasive electrophysiology data typically used in neuroscience and clinical neuroimaging. It deals with time-series biomedical signals (EEG/MEG) and event-related neural responses, fitting squarely into the “time-series biomedical data” and “neuroscience” criteria outlined for Biomedicine AI.",
    "prompt_tokens": 21081,
    "completion_tokens": 115,
    "total_tokens": 21196,
    "topic": "Neuroscience - Temporal Point Processes",
    "method": "Convolutional dictionary learning; Driven Temporal Point Process (DriPP)",
    "application": "Characterization of neural responses in M/EEG datasets",
    "code_link": "N/A",
    "dataset_name": [
      "MNE Sample",
      "MNE Somatosensory (Somato)",
      "Cam-CAN"
    ]
  },
  {
    "id": "LI2bhrE_2A",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Iterative Refinement Graph Neural Network for Antibody Sequence-Structure Co-design",
    "authors": [
      "Wengong Jin",
      "Jeremy Wohlwend",
      "Regina Barzilay",
      "Tommi S. Jaakkola"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Antibodies are versatile proteins that bind to pathogens like viruses and stimulate the adaptive immune system. The specificity of antibody binding is determined by complementarity-determining regions (CDRs) at the tips of these Y-shaped proteins. In this paper, we propose a generative model to automatically design the CDRs of antibodies with enhanced binding specificity or neutralization capabilities. Previous generative approaches formulate protein design as a structure-conditioned sequence generation task, assuming the desired 3D structure is given a priori. In contrast, we propose to co-design the sequence and 3D structure of CDRs as graphs. Our model unravels a sequence autoregressively while iteratively refining its predicted global structure. The inferred structure in turn guides subsequent residue choices. For efficiency, we model the conditional dependence between residues inside and outside of a CDR in a coarse-grained manner. Our method achieves superior log-likelihood on the test set and outperforms previous baselines in designing antibodies capable of neutralizing the SARS-CoV-2 virus.\n",
    "keywords": "Drug Discovery, Antibody Design, Generative Models, Graph Generation",
    "pdf_url": "https://openreview.net/pdf?id=LI2bhrE_2A",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on generative modeling for antibody CDR sequence-structure co-design aimed at enhancing binding specificity or virus neutralization. It explicitly addresses “antibody design,” “drug discovery,” and “neutralizing the SARS-CoV-2 virus,” all of which are central to biomedicine and therapeutic development.",
    "prompt_tokens": 20740,
    "completion_tokens": 120,
    "total_tokens": 20860,
    "topic": "Protein Design - Antibody Sequence and Structure",
    "method": "Graph Neural Networks; iterative refinement; multi-resolution modeling",
    "application": "Antibody sequence and structure co-design for SARS-CoV-2 neutralization",
    "code_link": "https://github.com/wengong-jin/RefineGNN",
    "dataset_name": [
      "SAbDab",
      "CoVAbDab"
    ]
  },
  {
    "id": "ZTsoE8G3GG",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Learning to Extend Molecular Scaffolds with Structural Motifs",
    "authors": [
      "Krzysztof Maziarz",
      "Henry Richard Jackson-Flux",
      "Pashmina Cameron",
      "Finton Sirockin",
      "Nadine Schneider",
      "Nikolaus Stiefl",
      "Marwin Segler",
      "Marc Brockschmidt"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Recent advancements in deep learning-based modeling of molecules promise to accelerate in silico drug discovery. A plethora of generative models is available, building molecules either atom-by-atom and bond-by-bond or fragment-by-fragment. However, many drug discovery projects require a fixed scaffold to be present in the generated molecule, and incorporating that constraint has only recently been explored. Here, we propose MoLeR, a graph-based model that naturally supports scaffolds as initial seed of the generative procedure, which is possible because it is not conditioned on the generation history. Our experiments show that MoLeR performs comparably to state-of-the-art methods on unconstrained molecular optimization tasks, and outperforms them on scaffold-based tasks, while being an order of magnitude faster to train and sample from than existing approaches. Furthermore, we show the influence of a number of seemingly minor design choices on the overall performance.",
    "keywords": "molecules, graph neural networks, scaffold, generative model",
    "pdf_url": "https://openreview.net/pdf?id=ZTsoE8G3GG",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper proposes a graph‐based generative model for extending molecular scaffolds “to accelerate in silico drug discovery,” directly addressing a drug discovery task—a key area within Biomedicine AI. It leverages molecular modeling and graph neural networks for chemistry-based generative design, a strong indicator of relevance to biomedical research.",
    "prompt_tokens": 21031,
    "completion_tokens": 106,
    "total_tokens": 21137,
    "topic": "Drug Discovery - Scaffold-based Molecule Generation",
    "method": "Graph Neural Networks (GNN); variational autoencoder (VAE); motif-based generation",
    "application": "Scaffold-constrained molecule generation",
    "code_link": "https://github.com/microsoft/molecule-generation",
    "dataset_name": [
      "GuacaMol"
    ]
  },
  {
    "id": "nf3A0WZsXS5",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Surreal-GAN:Semi-Supervised Representation Learning via GAN for uncovering heterogeneous disease-related imaging patterns",
    "authors": [
      "Zhijian Yang",
      "Junhao Wen",
      "Christos Davatzikos"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "A plethora of machine learning methods have been applied to imaging data, enabling the construction of clinically relevant imaging signatures of neurological and neuropsychiatric diseases. Oftentimes, such methods don't explicitly model the heterogeneity of disease effects, or approach it via nonlinear models that are not interpretable. Moreover, unsupervised methods may parse heterogeneity that is driven by nuisance confounding factors that affect brain structure or function, rather than heterogeneity relevant to a pathology of interest. On the other hand, semi-supervised clustering methods seek to derive a dichotomous subtype membership, ignoring the truth that disease heterogeneity spatially and temporally extends along a continuum.  To address the aforementioned limitations, herein, we propose a novel method, termed Surreal-GAN (Semi-SUpeRvised ReprEsentAtion Learning via GAN). Using cross-sectional imaging data, Surreal-GAN dissects underlying disease-related heterogeneity under the principle of semi-supervised clustering (cluster mappings from normal control to patient), proposes a continuously dimensional representation, and infers the disease severity of patients at individual level along each dimension. The model first learns a transformation function from normal control (CN) domain to the patient (PT) domain with latent variables controlling transformation directions. An inverse mapping function together with regularization on function continuity, pattern orthogonality and monotonicity was also imposed to make sure that the transformation function captures necessarily meaningful imaging patterns with clinical significance. We first validated the model through extensive semi-synthetic experiments, and then demonstrate its potential in capturing biologically plausible imaging patterns in Alzheimer's disease (AD).",
    "keywords": "Representation Learning, Disease-related imaging patterns, Alzheimer's disease, MRI, GAN",
    "pdf_url": "https://openreview.net/pdf?id=nf3A0WZsXS5",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper develops a semi-supervised GAN to uncover “disease-related imaging patterns” from “cross-sectional imaging data” specifically applied to Alzheimer’s disease (AD) using MRI. It explicitly targets “disease heterogeneity,” “patient severity,” and “clinically significant” imaging signatures, all of which fall squarely within medical imaging and neurological disease analysis—core topics in Healthcare/​Biomedicine AI.",
    "prompt_tokens": 21155,
    "completion_tokens": 100,
    "total_tokens": 21255,
    "topic": "Medical Imaging - Neurodegenerative Diseases",
    "method": "Semi-supervised learning; GAN; Representation Learning",
    "application": "Disease-related imaging pattern extraction",
    "code_link": "N/A",
    "dataset_name": [
      "iSAGING Consortium"
    ]
  },
  {
    "id": "Kwm8I7dU-l5",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Graph-Guided Network for Irregularly Sampled Multivariate Time Series",
    "authors": [
      "Xiang Zhang",
      "Marko Zeman",
      "Theodoros Tsiligkaridis",
      "Marinka Zitnik"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In many domains, including healthcare, biology, and climate science, time series are irregularly sampled with varying time intervals between successive readouts and different subsets of variables (sensors) observed at different time points. Here, we introduce RAINDROP, a graph neural network that embeds irregularly sampled and multivariate time series while also learning the dynamics of sensors purely from observational data. RAINDROP represents every sample as a separate sensor graph and models time-varying dependencies between sensors with a novel message passing operator. It estimates the latent sensor graph structure and leverages the structure together with nearby observations to predict misaligned readouts. This model can be interpreted as a graph neural network that sends messages over graphs that are optimized for capturing time-varying dependencies among sensors. We use RAINDROP to classify time series and interpret temporal dynamics on three healthcare and human activity datasets. RAINDROP outperforms state-of-the-art methods by up to 11.4% (absolute F1-score points), including techniques that deal with irregular sampling using fixed discretization and set functions. RAINDROP shows superiority in diverse setups, including challenging leave-sensor-out settings. ",
    "keywords": "time seres, irregular time series, graph neural networks, attention mechanism, time series classification, multivariate time series, representation learning, embeddings",
    "pdf_url": "https://openreview.net/pdf?id=Kwm8I7dU-l5",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly evaluates its model “on three healthcare and human activity datasets,” focusing on irregularly sampled multivariate time series from sensors—a common scenario in patient monitoring and wearable health devices. The use of healthcare datasets for time series classification and the emphasis on handling missing and irregular clinical/sensor readouts indicate a clear application in Healthcare AI.",
    "prompt_tokens": 20875,
    "completion_tokens": 114,
    "total_tokens": 20989,
    "topic": "Time Series - Representation Learning",
    "method": "Graph Neural Networks; Message passing; Temporal attention",
    "application": "Time series classification – Healthcare and human activity",
    "code_link": "https://github.com/mims-harvard/Raindrop",
    "dataset_name": [
      "P19",
      "P12",
      "PAM"
    ]
  },
  {
    "id": "k9bx1EfHI_-",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Self-Supervised Graph Neural Networks for Improved Electroencephalographic Seizure Analysis",
    "authors": [
      "Siyi Tang",
      "Jared Dunnmon",
      "Khaled Kamal Saab",
      "Xuan Zhang",
      "Qianying Huang",
      "Florian Dubost",
      "Daniel Rubin",
      "Christopher Lee-Messer"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Automated seizure detection and classification from electroencephalography (EEG) can greatly improve seizure diagnosis and treatment. However, several modeling challenges remain unaddressed in prior automated seizure detection and classification studies: (1) representing non-Euclidean data structure in EEGs, (2) accurately classifying rare seizure types, and (3) lacking a quantitative interpretability approach to measure model ability to localize seizures. In this study, we address these challenges by (1) representing the spatiotemporal dependencies in EEGs using a graph neural network (GNN) and proposing two EEG graph structures that capture the electrode geometry or dynamic brain connectivity, (2) proposing a self-supervised pre-training method that predicts preprocessed signals for the next time period to further improve model performance, particularly on rare seizure types, and (3) proposing a quantitative model interpretability approach to assess a model’s ability to localize seizures within EEGs. When evaluating our approach on seizure detection and classification on a large public dataset (5,499 EEGs), we find that our GNN with self-supervised pre-training achieves 0.875 Area Under the Receiver Operating Characteristic Curve on seizure detection and 0.749 weighted F1-score on seizure classification, outperforming previous methods for both seizure detection and classification. Moreover, our self-supervised pre-training strategy significantly improves classification of rare seizure types (e.g. 47 points increase in combined tonic seizure accuracy over baselines). Furthermore, quantitative interpretability analysis shows that our GNN with self-supervised pre-training precisely localizes 25.4% focal seizures, a 21.9 point improvement over existing CNNs. Finally, by superimposing the identified seizure locations on both raw EEG signals and EEG graphs, our approach could provide clinicians with an intuitive visualization of localized seizure regions.",
    "keywords": "Graph neural network, Self-supervision, Interpretability, Visualization, Neuroscience, Electroencephalography, Seizure, Epilepsy, Time Series",
    "pdf_url": "https://openreview.net/pdf?id=k9bx1EfHI_-",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on automated seizure detection and classification from electroencephalography (EEG), a clinical brain-monitoring technique used in healthcare and epilepsy diagnosis/treatment. It proposes graph neural network models and self-supervised learning to improve seizure analysis, explicitly addressing “seizure detection,” “seizure classification,” and “localize seizures,” all of which are medical tasks in neurology.",
    "prompt_tokens": 20536,
    "completion_tokens": 157,
    "total_tokens": 20693,
    "topic": "Epilepsy - Seizure Detection and Classification",
    "method": "Graph Neural Networks (GNN); self-supervised pretraining",
    "application": "Seizure detection and classification",
    "code_link": "https://github.com/tsy935/eeg-gnn-ssl",
    "dataset_name": [
      "Temple University Hospital EEG Seizure Corpus (TUSZ)"
    ]
  },
  {
    "id": "nZOUYEN6Wvy",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Granger causal inference on DAGs identifies genomic loci regulating transcription",
    "authors": [
      "Alexander P Wu",
      "Rohit Singh",
      "Bonnie Berger"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "When a dynamical system can be modeled as a sequence of observations, Granger causality is a powerful approach for detecting predictive interactions between its variables. However, traditional Granger causal inference has limited utility in domains where the dynamics need to be represented as directed acyclic graphs (DAGs) rather than as a linear sequence, such as with cell differentiation trajectories. Here, we present GrID-Net, a framework based on graph neural networks with lagged message passing for Granger causal inference on DAG-structured systems. Our motivating application is the analysis of single-cell multimodal data to identify genomic loci that mediate the regulation of specific genes. To our knowledge, GrID-Net is the first single-cell analysis tool that accounts for the temporal lag between a genomic locus becoming accessible and its downstream effect on a target gene's expression. We applied GrID-Net on multimodal single-cell assays that profile chromatin accessibility (ATAC-seq) and gene expression (RNA-seq) in the same cell and show that it dramatically outperforms existing methods for inferring regulatory locus-gene links, achieving up to 71% greater agreement with independent population genetics-based estimates. By extending Granger causality to DAG-structured dynamical systems, our work unlocks new domains for causal analyses and, more specifically, opens a path towards elucidating gene regulatory interactions relevant to cellular differentiation and complex human diseases at unprecedented scale and resolution.",
    "keywords": "Granger causality, causal inference, graph neural networks, gene regulation, single-cell genomics, chromatin accessibility, directed acyclic graphs, single-cell multimodal",
    "pdf_url": "https://openreview.net/pdf?id=nZOUYEN6Wvy",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper develops a Granger‐causal framework for analyzing single‐cell multimodal genomics data (ATAC-seq and RNA-seq) to identify regulatory genomic loci affecting gene expression. Terms like “single‐cell genomics,” “chromatin accessibility,” “gene regulation,” and “genomic loci” place it squarely in the Biomedicine AI domain, as it advances computational methods for understanding molecular‐level biological mechanisms.",
    "prompt_tokens": 20534,
    "completion_tokens": 121,
    "total_tokens": 20655,
    "topic": "Bioinformatics - Gene Regulatory Dynamics",
    "method": "Graph Neural Networks (GNN); Granger Causality on DAGs",
    "application": "Peak-gene link prediction",
    "code_link": "https://github.com/alexw16/gridnet",
    "dataset_name": [
      "sci-CAR",
      "SHARE-seq",
      "SNARE-seq"
    ]
  },
  {
    "id": "085y6YPaYjP",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Zero-Shot Self-Supervised Learning for MRI Reconstruction",
    "authors": [
      "Burhaneddin Yaman",
      "Seyed Amir Hossein Hosseini",
      "Mehmet Akcakaya"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Deep learning (DL) has emerged as a powerful tool for accelerated MRI reconstruction, but often necessitates a database of fully-sampled measurements for training. Recent self-supervised and unsupervised learning approaches enable training without fully-sampled data. However, a database of undersampled measurements may not be available in many scenarios, especially for scans involving contrast or translational acquisitions in development. Moreover, recent studies show that database-trained models may not generalize well when the unseen measurements differ in terms of sampling pattern, acceleration rate, SNR, image contrast, and anatomy. Such challenges necessitate a new methodology to enable subject-specific DL MRI reconstruction without external training datasets, since it is clinically imperative to provide high-quality reconstructions that can be used to identify lesions/disease for $\\textit{every individual}$. In this work, we propose a zero-shot self-supervised learning approach to perform subject-specific accelerated DL MRI reconstruction to tackle these issues. The proposed approach partitions the available measurements from a single scan into three disjoint sets. Two of these sets are used to enforce data consistency and define loss during training for self-supervision, while the last set serves to self-validate, establishing an early stopping criterion. In the presence of models pre-trained on a database with different image characteristics, we show that the proposed approach can be combined with transfer learning for faster convergence time and reduced computational complexity.",
    "keywords": "Zero-shot learning, Self-supervised learning, MRI Reconstruction, Transfer learning, Physics-guided deep learning",
    "pdf_url": "https://openreview.net/pdf?id=085y6YPaYjP",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on accelerated MRI reconstruction, a core medical imaging task. It proposes a zero-shot self-supervised deep-learning method to improve subject-specific MRI image quality without external fully-sampled datasets—clearly situated in the clinical/healthcare imaging domain. MRI reconstruction is directly applicable to patient scans and diagnosis, indicating a healthcare AI application.",
    "prompt_tokens": 20864,
    "completion_tokens": 96,
    "total_tokens": 20960,
    "topic": "Medical Imaging - MRI Reconstruction",
    "method": "Zero-shot self-supervised learning; transfer learning; algorithm unrolling",
    "application": "MRI reconstruction",
    "code_link": "N/A",
    "dataset_name": [
      "fastMRI - Knee",
      "fastMRI - Brain"
    ]
  },
  {
    "id": "P07dq7iSAGr",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Explaining Point Processes by Learning Interpretable Temporal Logic Rules",
    "authors": [
      "Shuang Li",
      "Mingquan Feng",
      "Lu Wang",
      "Abdelmajid Essofi",
      "Yufeng Cao",
      "Junchi Yan",
      "Le Song"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We propose a principled method to learn a set of human-readable logic rules to explain temporal point processes. \nWe assume that the generative mechanisms underlying the temporal point processes are governed by a set of first-order temporal logic rules, as a compact representation of domain knowledge. Our method formulates the rule discovery process from noisy event data as a maximum likelihood problem, and designs an efficient and tractable branch-and-price algorithm to progressively search for new rules and expand existing rules. The proposed algorithm alternates between the rule generation stage and the rule evaluation stage, and uncovers the most important collection of logic rules within a fixed time limit for both synthetic and real event data. In a real healthcare application, we also had human experts (i.e., doctors) verify the learned temporal logic rules and provide further improvements. These expert-revised interpretable rules lead to a point process model which outperforms previous state-of-the-arts for symptom prediction, both in their occurrence times and types. ",
    "keywords": "Temporal Point Process, Temporal Logic Rules, Explainable Models",
    "pdf_url": "https://openreview.net/pdf?id=P07dq7iSAGr",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: While the core contribution is a general method for learning temporal logic rules for point processes, the paper explicitly evaluates in “a real healthcare application” where “doctors verify the learned temporal logic rules.” Moreover, the learned rules improve a point process model for “symptom prediction,” directly targeting clinical outcomes (occurrence times and types of symptoms). This clear application to symptom forecasting in a health setting justifies classification as Healthcare AI.",
    "prompt_tokens": 21011,
    "completion_tokens": 99,
    "total_tokens": 21110,
    "topic": "Causal Inference - Temporal Logic",
    "method": "Temporal logic point process (TLPP); rule discovery; rule weight learning",
    "application": "Sepsis condition modeling",
    "code_link": "N/A",
    "dataset_name": [
      "MIMIC-III",
      "Crime Incident Reports"
    ]
  },
  {
    "id": "DnG75_KyHjX",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "MoReL: Multi-omics Relational Learning",
    "authors": [
      "Arman Hasanzadeh",
      "Ehsan Hajiramezanali",
      "Nick Duffield",
      "Xiaoning Qian"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Multi-omics data analysis has the potential to discover hidden molecular interactions, revealing potential regulatory and/or signal transduction pathways for cellular processes of interest when studying life and disease systems. One of critical challenges when dealing with real-world multi-omics data is that they may manifest heterogeneous structures and data quality as often existing data may be collected from different subjects under different conditions for each type of omics data. We propose a novel deep Bayesian generative model to efficiently infer a multi-partite graph encoding molecular interactions across such heterogeneous views, using a fused Gromov-Wasserstein (FGW) regularization between latent representations of corresponding views for integrative analysis. With such an optimal transport regularization in the deep Bayesian generative model, it not only allows incorporating view-specific side information, either with graph-structured or unstructured data in different views, but also increases the model flexibility with the distribution-based regularization. This allows efficient alignment of heterogeneous latent variable distributions to derive reliable interaction predictions compared to the existing point-based graph embedding methods. Our experiments on several real-world datasets demonstrate enhanced performance of MoReL in inferring meaningful interactions compared to existing baselines.",
    "keywords": "relational learning, data integration, multi-view learning, Bayesian generative model",
    "pdf_url": "https://openreview.net/pdf?id=DnG75_KyHjX",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “multi-omics data analysis” and discovering “hidden molecular interactions, revealing potential regulatory and/or signal transduction pathways,” which are core tasks in biomedical research (e.g., genomics, proteomics). Its methods are applied to biological molecular data, fitting squarely within the Biomedicine AI domain.",
    "prompt_tokens": 20620,
    "completion_tokens": 117,
    "total_tokens": 20737,
    "topic": "Bioinformatics - Multi-Omics Integration",
    "method": "Fused Gromov-Wasserstein (FGW); Bayesian generative model",
    "application": "Multi-partite graph construction for molecular interaction prediction",
    "code_link": "N/A",
    "dataset_name": [
      "Cystic Fibrosis (CF)",
      "The Drug–Gene Interaction Database (DGIdb)"
    ]
  },
  {
    "id": "kavTY__jxp",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Spatial Graph Attention and Curiosity-driven Policy for Antiviral Drug Discovery",
    "authors": [
      "Yulun Wu",
      "Nicholas Choma",
      "Andrew Deru Chen",
      "Mikaela Cashman",
      "Erica Teixeira Prates",
      "Veronica G Melesse Vergara",
      "Manesh B Shah",
      "Austin Clyde",
      "Thomas Brettin",
      "Wibe Albert de Jong",
      "Neeraj Kumar",
      "Martha S Head",
      "Rick L. Stevens",
      "Peter Nugent",
      "Daniel A Jacobson",
      "James B Brown"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We developed Distilled Graph Attention Policy Network (DGAPN), a reinforcement learning model to generate novel graph-structured chemical representations that optimize user-defined objectives by efficiently navigating a physically constrained domain. The framework is examined on the task of generating molecules that are designed to bind, noncovalently, to functional sites of SARS-CoV-2 proteins. We present a spatial Graph Attention (sGAT) mechanism that leverages self-attention over both node and edge attributes as well as encoding the spatial structure --- this capability is of considerable interest in synthetic biology and drug discovery. An attentional policy network is introduced to learn the decision rules for a dynamic, fragment-based chemical environment, and state-of-the-art policy gradient techniques are employed to train the network with stability. Exploration is driven by the stochasticity of the action space design and the innovation reward bonuses learned and proposed by random network distillation. In experiments, our framework achieved outstanding results compared to state-of-the-art algorithms, while reducing the complexity of paths to chemical synthesis.",
    "keywords": "reinforcement learning, graph neural network, molecule generation, drug discovery, curiosity-driven policy",
    "pdf_url": "https://openreview.net/pdf?id=kavTY__jxp",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper develops a reinforcement‐learning framework for “generating molecules that are designed to bind, noncovalently, to functional sites of SARS-CoV-2 proteins,” explicitly targeting antiviral drug discovery. It leverages “spatial Graph Attention” and fragment‐based chemical synthesis in the context of “synthetic biology and drug discovery,” which clearly places it in the Biomedicine AI domain.",
    "prompt_tokens": 20624,
    "completion_tokens": 99,
    "total_tokens": 20723,
    "topic": "Drug Discovery - Target-based",
    "method": "Spatial graph attention; reinforcement learning",
    "application": "Molecule generation and optimization – antiviral drug discovery",
    "code_link": "https://github.com/yulun-rayn/DGAPN",
    "dataset_name": [
      "MCULE molecular library"
    ]
  },
  {
    "id": "kQ2SOflIOVC",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Towards Better Understanding and Better Generalization of Low-shot Classification in Histology Images with Contrastive Learning",
    "authors": [
      "Jiawei Yang",
      "Hanbo Chen",
      "Jiangpeng Yan",
      "Xiaoyu Chen",
      "Jianhua Yao"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Few-shot learning is an established topic in natural images for years, but few work is attended to histology images, which is of high clinical value since well-labeled datasets and rare abnormal samples are expensive to collect. Here, we facilitate the study of few-shot learning in histology images by setting up three cross-domain tasks that simulate real clinics problems. To enable label-efficient learning and better generalizability, we propose to incorporate contrastive learning (CL) with latent augmentation (LA) to build a few-shot system. CL learns useful representations without manual labels, while LA transfers semantic variations of the base dataset in an unsupervised way. These two components fully exploit unlabeled training data and can scale gracefully to other label-hungry problems. In experiments, we find i) models learned by CL generalize better than supervised learning for histology images in unseen classes, and ii) LA brings consistent gains over baselines. Prior studies of self-supervised learning mainly focus on ImageNet-like images, which only present a dominant object in their centers. Recent attention has been paid to images with multi-objects and multi-textures. Histology images are a natural choice for such a study. We show the superiority of CL over supervised learning in terms of generalization for such data and provide our empirical understanding for this observation. The findings in this work could contribute to understanding how the model generalizes in the context of both representation learning and histological image analysis. Code is available.",
    "keywords": "Few shot learning, Histology Image, Knowledge Transferring",
    "pdf_url": "https://openreview.net/pdf?id=kQ2SOflIOVC",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on few-shot classification of histology images, which are pathology slides used in clinical diagnosis. It explicitly mentions “real clinics problems,” “rare abnormal samples,” and “histological image analysis,” all of which indicate a healthcare/biomedicine application.",
    "prompt_tokens": 20452,
    "completion_tokens": 112,
    "total_tokens": 20564,
    "topic": "Medical Imaging - Histology Analysis",
    "method": "Contrastive learning; latent augmentation",
    "application": "Few-shot classification in histology",
    "code_link": "https://github.com/TencentAILabHealthcare/Few-shot-WSI",
    "dataset_name": [
      "NCT-CRC-HE-100K",
      "LC25000",
      "PAIP 2019"
    ]
  },
  {
    "id": "rI0LYgGeYaw",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Understanding approximate and unrolled dictionary learning for pattern recovery",
    "authors": [
      "Benoît Malézieux",
      "Thomas Moreau",
      "Matthieu Kowalski"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Dictionary learning consists of finding a sparse representation from noisy data and is a common way to encode data-driven prior knowledge on signals. Alternating minimization (AM) is standard for the underlying optimization, where gradient descent steps alternate with sparse coding procedures. The major drawback of this method is its prohibitive computational cost, making it unpractical on large real-world data sets. This work studies an approximate formulation of dictionary learning based on unrolling and compares it to alternating minimization to find the best trade-off between speed and precision. We analyze the asymptotic behavior and convergence rate of gradients estimates in both methods. We show that unrolling performs better on the support of the inner problem solution and during the first iterations. Finally, we apply unrolling on pattern learning in magnetoencephalography (MEG) with the help of a stochastic algorithm and compare the performance to a state-of-the-art method.",
    "keywords": "Dictionary learning, bi-level optimization, unrolling, pattern learning",
    "pdf_url": "https://openreview.net/pdf?id=rI0LYgGeYaw",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the paper primarily proposes a general optimization method (“approximate and unrolled dictionary learning”), it explicitly applies this approach to “pattern learning in magnetoencephalography (MEG).” MEG is a biomedical neuroimaging modality for capturing brain activity, placing this work squarely in the realm of biosignal analysis and neuroscience applications, which qualifies as Biomedicine AI.",
    "prompt_tokens": 20844,
    "completion_tokens": 108,
    "total_tokens": 20952,
    "topic": "Brain Imaging - Pattern Learning",
    "method": "Unrolled dictionary learning; Convolutional sparse coding",
    "application": "Pattern recovery – Magnetoencephalography (MEG)",
    "code_link": "https://github.com/bmalezieux/unrolled_dl",
    "dataset_name": [
      "alphacsc",
      "MNE sample dataset"
    ]
  },
  {
    "id": "C03Ajc-NS5W",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "An Autoregressive Flow Model for 3D Molecular Geometry Generation from Scratch",
    "authors": [
      "Youzhi Luo",
      "Shuiwang Ji"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We consider the problem of generating 3D molecular geometries from scratch. While multiple methods have been developed for generating molecular graphs, generating 3D molecular geometries from scratch is largely under-explored. In this work, we propose G-SphereNet, a novel autoregressive flow model for generating 3D molecular geometries. G-SphereNet employs a flexible sequential generation scheme by placing atoms in 3D space step-by-step. Instead of generating 3D coordinates directly, we propose to determine 3D positions of atoms by generating distances, angles and torsion angles, thereby ensuring both invariance and equivariance properties. In addition, we propose to use spherical message passing and attention mechanism for conditional information extraction. Experimental results show that G-SphereNet outperforms previous methods on random molecular geometry generation and targeted molecule discovery tasks. Our code is publicly available as part of the DIG package (https://github.com/divelab/DIG).",
    "keywords": "3D molecular geometry generation, flow models, SphereNet",
    "pdf_url": "https://openreview.net/pdf?id=C03Ajc-NS5W",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This paper proposes a model for generating 3D molecular geometries “from scratch” and evaluates it on “targeted molecule discovery tasks,” which directly aligns with chemistry-based drug discovery—a core application area in Biomedicine AI. The focus on creating novel molecular structures (distances, angles, torsions) and the mention of “targeted molecule discovery” indicate its relevance to biomedical research efforts in therapeutic design.",
    "prompt_tokens": 20725,
    "completion_tokens": 98,
    "total_tokens": 20823,
    "topic": "Drug Discovery - Molecular Geometry",
    "method": "Autoregressive flow model; Spherical message passing; Attention mechanism",
    "application": "3D molecular geometry generation",
    "code_link": "https://github.com/divelab/DIG",
    "dataset_name": [
      "QM9"
    ]
  },
  {
    "id": "w60btE_8T2m",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Spanning Tree-based Graph Generation for Molecules",
    "authors": [
      "Sungsoo Ahn",
      "Binghong Chen",
      "Tianzhe Wang",
      "Le Song"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In this paper, we explore the problem of generating molecules using deep neural networks, which has recently gained much interest in chemistry. To this end, we propose a spanning tree-based graph generation (STGG) framework based on formulating molecular graph generation as a construction of a spanning tree and the residual edges. Such a formulation exploits the sparsity of molecular graphs and allows using compact tree-constructive operations to define the molecular graph connectivity. Based on the intermediate graph structure of the construction process, our framework can constrain its generation to molecular graphs that satisfy the chemical valence rules. We also newly design a Transformer architecture with tree-based relative positional encodings for realizing the tree construction procedure. Experiments on QM9, ZINC250k, and MOSES benchmarks verify the effectiveness of the proposed framework in metrics such as validity, Frechet ChemNet distance, and fragment similarity. We also demonstrate the usefulness of STGG in maximizing penalized LogP value of molecules.",
    "keywords": "molecule generation, tree generation, graph generation, deep generative model, de novo drug design",
    "pdf_url": "https://openreview.net/pdf?id=w60btE_8T2m",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on deep generative models for molecular graph construction and explicitly mentions “de novo drug design,” optimizing molecular properties (e.g., penalized LogP), and benchmarks like QM9 and ZINC, which are standard in drug discovery. This places it squarely in the Biomedicine AI domain.",
    "prompt_tokens": 20216,
    "completion_tokens": 95,
    "total_tokens": 20311,
    "topic": "Drug Discovery - Molecular Graph Generation",
    "method": "Transformer-based models; graph generation with spanning trees",
    "application": "Molecular graph generation",
    "code_link": "N/A",
    "dataset_name": [
      "QM9",
      "ZINC250K",
      "MOSES"
    ]
  },
  {
    "id": "ULfq0qR25dY",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Maximum n-times Coverage for Vaccine Design",
    "authors": [
      "Ge Liu",
      "Alexander Dimitrakakis",
      "Brandon Carter",
      "David Gifford"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We introduce the maximum $n$-times coverage problem that selects $k$ overlays to maximize the summed coverage of weighted elements, where each element must be covered at least $n$ times. We also define the min-cost $n$-times coverage problem where the objective is to select the minimum set of overlays such that the sum of the weights of elements that are covered at least $n$ times is at least $\\tau$. Maximum $n$-times coverage is a generalization of the multi-set multi-cover problem, is NP-complete, and is not submodular. We introduce two new practical solutions for $n$-times coverage based on integer linear programming and sequential greedy optimization. We show that maximum $n$-times coverage is a natural way to frame peptide vaccine design, and find that it produces a pan-strain COVID-19 vaccine design that is superior to 29 other published designs in predicted population coverage and the expected number of peptides displayed by each individual's HLA molecules.",
    "keywords": "computational biology, vaccine design, COVID-19, maximum n-times coverage, combinatorial optimization, integer linear programming",
    "pdf_url": "https://openreview.net/pdf?id=ULfq0qR25dY",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly applies combinatorial optimization to \"peptide vaccine design\" and demonstrates a \"pan-strain COVID-19 vaccine design,” which falls squarely within computational biology and biomedicine. It focuses on generating vaccine candidates, a core biomedical application involving molecular- and population-level immunology.",
    "prompt_tokens": 20645,
    "completion_tokens": 112,
    "total_tokens": 20757,
    "topic": "Vaccine Design - Machine Learning Optimization",
    "method": "Integer linear programming (ILP); beam search (MarginalGreedy)",
    "application": "Peptide vaccine design – COVID-19",
    "code_link": "https://github.com/gifford-lab/optivax",
    "dataset_name": [
      "EvalVax-Robust coverage dataset"
    ]
  },
  {
    "id": "oDFvtxzPOx",
    "year": 2022,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Self-Supervision Enhanced Feature Selection with Correlated Gates",
    "authors": [
      "Changhee Lee",
      "Fergus Imrie",
      "Mihaela van der Schaar"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Discovering relevant input features for predicting a target variable is a key scientific question. However, in many domains, such as medicine and biology, feature selection is confounded by a scarcity of labeled samples coupled with significant correlations among features. In this paper, we propose a novel deep learning approach to feature selection that addresses both challenges simultaneously. First, we pre-train the network using unlabeled samples within a self-supervised learning framework by solving pretext tasks that require the network to learn informative representations from partial feature sets. Then, we fine-tune the pre-trained network to discover relevant features using labeled samples. During both training phases, we explicitly account for the correlation structure of the input features by generating correlated gate vectors from a multivariate Bernoulli distribution. Experiments on multiple real-world datasets including clinical and omics demonstrate that our model discovers relevant features that provide superior prediction performance compared to the state-of-the-art benchmarks in practical scenarios where there is often limited labeled data and high correlations among features.",
    "keywords": "Feature Selection, Feature Importance, Self-Supervised Learning",
    "pdf_url": "https://openreview.net/pdf?id=oDFvtxzPOx",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract specifically reports experiments on “clinical and omics” datasets, indicating applications in medicine and biology. References to scarce labeled samples in “medicine and biology” and the use of omics data (genomic/proteomic features) strongly place this work within biomedicine AI.",
    "prompt_tokens": 20927,
    "completion_tokens": 109,
    "total_tokens": 21036,
    "topic": "Feature Selection - Semi-supervised Learning",
    "method": "Self-supervised feature selection framework",
    "application": "Feature selection for prediction tasks under low labeled data conditions",
    "code_link": "https://github.com/chl8856/SEFS",
    "dataset_name": [
      "UKCF",
      "CCLE",
      "PBMC"
    ]
  },
  {
    "id": "aKcS3xojnwY",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "GEASS: Neural causal feature selection for high-dimensional biological data",
    "authors": [
      "Mingze Dong",
      "Yuval Kluger"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Identifying nonlinear causal relationships in high-dimensional biological data is an important task. However, current neural network based causality detection approaches for such data suffer from poor interpretability and cannot scale well to the high dimensional regime. Here we present GEASS (Granger fEAture Selection of Spatiotemporal data), which identifies sparse Granger causality mechanisms of high dimensional spatiotemporal data by a single neural network. GEASS maximizes sparsity-regularized modified transfer entropy with a theoretical guarantee of recovering features with spatial/temporal Granger causal relationships. The sparsity regularization is achieved by a novel combinatorial stochastic gate layer to select sparse non-overlapping feature subsets. We demonstrate the efficacy of GEASS in several synthetic datasets and real biological data from single-cell RNA sequencing and spatial transcriptomics.",
    "keywords": "Granger causality, feature selection, neural networks, single-cell genomics, spatial transcriptomics",
    "pdf_url": "https://openreview.net/pdf?id=aKcS3xojnwY",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on identifying causal relationships in high-dimensional biological data and explicitly demonstrates applications on single-cell RNA sequencing and spatial transcriptomics—key tasks in genomics and biomedical research. These techniques are central to Biomedicine AI for understanding molecular mechanisms and disease biology.",
    "prompt_tokens": 20817,
    "completion_tokens": 108,
    "total_tokens": 20925,
    "topic": "Bioinformatics - Causal Feature Selection",
    "method": "Modified Transfer Entropy; neural networks; stochastic gate layer",
    "application": "Causal feature selection in high-dimensional biological data",
    "code_link": "N/A",
    "dataset_name": [
      "MERFISH human cortex dataset",
      "scRNA-seq pancreatic endocrinogenesis dataset"
    ]
  },
  {
    "id": "H0gdPxSwkPb",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Diffusion Adversarial Representation Learning for Self-supervised Vessel Segmentation",
    "authors": [
      "Boah Kim",
      "Yujin Oh",
      "Jong Chul Ye"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Vessel segmentation in medical images is one of the important tasks in the diagnosis of vascular diseases and therapy planning. Although learning-based segmentation approaches have been extensively studied, a large amount of ground-truth labels are required in supervised methods and confusing background structures make neural networks hard to segment vessels in an unsupervised manner. To address this, here we introduce a novel diffusion adversarial representation learning (DARL) model that leverages a denoising diffusion probabilistic model with adversarial learning, and apply it to vessel segmentation. In particular, for self-supervised vessel segmentation, DARL learns the background signal using a diffusion module, which lets a generation module effectively provide vessel representations. Also, by adversarial learning based on the proposed switchable spatially-adaptive denormalization, our model estimates synthetic fake vessel images as well as vessel segmentation masks, which further makes the model capture vessel-relevant semantic information. Once the proposed model is trained, the model generates segmentation masks in a single step and can be applied to general vascular structure segmentation of coronary angiography and retinal images. Experimental results on various datasets show that our method significantly outperforms existing unsupervised and self-supervised vessel segmentation methods.",
    "keywords": "Diffusion model, Adversarial learning, Self-supervised learning, Vessel segmentation",
    "pdf_url": "https://openreview.net/pdf?id=H0gdPxSwkPb",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on vessel segmentation in medical images (“diagnosis of vascular diseases,” “therapy planning,” “coronary angiography and retinal images”), which is a classic medical imaging task used in Healthcare AI.",
    "prompt_tokens": 20992,
    "completion_tokens": 114,
    "total_tokens": 21106,
    "topic": "Medical Imaging - Vessel Segmentation",
    "method": "Diffusion model; adversarial learning; switchable SPADE layers",
    "application": "Self-supervised vessel segmentation",
    "code_link": "https://github.com/bispl-kaist/DARL",
    "dataset_name": [
      "XCAD",
      "134 XCA",
      "30 XCA",
      "DRIVE",
      "STARE"
    ]
  },
  {
    "id": "9X-hgLDLYkQ",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Learning Hierarchical Protein Representations via Complete 3D Graph Networks",
    "authors": [
      "Limei Wang",
      "Haoran Liu",
      "Yi Liu",
      "Jerry Kurtin",
      "Shuiwang Ji"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We consider representation learning for proteins with 3D structures. We build 3D graphs based on protein structures and develop graph networks to learn their representations. Depending on the levels of details that we wish to capture, protein representations can be computed at different levels, \\emph{e.g.}, the amino acid, backbone, or all-atom levels. Importantly, there exist hierarchical relations among different levels. In this work, we propose to develop a novel hierarchical graph network, known as ProNet, to capture the relations. Our ProNet is very flexible and can be used to compute protein representations at different levels of granularity. By treating each amino acid as a node in graph modeling as well as harnessing the inherent hierarchies, our ProNet is more effective and efficient than existing methods. We also show that, given a base 3D graph network that is complete, our ProNet representations are also complete at all levels. Experimental results show that ProNet outperforms recent methods on most datasets. In addition, results indicate that different downstream tasks may require representations at different levels. Our code is publicly available as part of the DIG library (\\url{https://github.com/divelab/DIG}).",
    "keywords": "",
    "pdf_url": "https://openreview.net/pdf?id=9X-hgLDLYkQ",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on learning hierarchical representations of proteins from their 3D structures using graph networks. Protein structure modeling is a core task in molecular modeling and biomedicine, as noted under “Biomedical research: … molecular modeling” in the guidelines. Although no specific drug-discovery application is described, the work is directly relevant to biomedicine AI through its development of methods for protein representation.",
    "prompt_tokens": 20903,
    "completion_tokens": 103,
    "total_tokens": 21006,
    "topic": "Bioinformatics - 3D Protein Representation",
    "method": "3D Graph Network; hierarchical protein representation",
    "application": "Protein structure representation and prediction",
    "code_link": "https://github.com/divelab/DIG",
    "dataset_name": [
      "DIPS",
      "DB5",
      "PDBbind"
    ]
  },
  {
    "id": "2EpjkjzdCAa",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Effectively Modeling Time Series with Simple Discrete State Spaces",
    "authors": [
      "Michael Zhang",
      "Khaled Kamal Saab",
      "Michael Poli",
      "Tri Dao",
      "Karan Goel",
      "Christopher Re"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Time series modeling is a well-established problem, which often requires that methods (1) expressively represent complicated dependencies, (2) forecast long horizons, and (3) efficiently train over long sequences. State-space models (SSMs) are classical models for time series, and prior works combine SSMs with deep learning layers for efficient sequence modeling. However, we find fundamental limitations with these prior approaches, proving their SSM representations cannot express  autoregressive time series processes. We thus introduce SpaceTime, a new state-space time series architecture that improves all three criteria. For expressivity, we propose a new SSM parameterization based on the companion matrix---a canonical representation for discrete-time processes---which enables SpaceTime's SSM layers to learn desirable autoregressive processes. For long horizon forecasting, we introduce a \"closed-loop\" variation of the companion SSM, which enables SpaceTime to predict many future time-steps by generating its own layer-wise inputs. For efficient training and inference, we introduce an algorithm that reduces the memory and compute of a forward pass with the companion matrix. With sequence length $\\ell$ and state-space size $d$, we go from $\\tilde{O}(d \\ell)$ naïvely to $\\tilde{O}(d + \\ell)$. In experiments, our contributions lead to state-of-the-art results on extensive and diverse benchmarks, with best or second-best AUROC on 6 / 7 ECG and speech time series classification, and best MSE on 14 / 16 Informer forecasting tasks. Furthermore, we find SpaceTime (1) fits AR($p$) processes that prior deep SSMs fail on, (2) forecasts notably more accurately on longer horizons than prior state-of-the-art, and (3) speeds up training on real-world ETTh1 data by 73% and 80% relative wall-clock time over Transformers and LSTMs.",
    "keywords": "time series, forecasting, state-space models, time series classification",
    "pdf_url": "https://openreview.net/pdf?id=2EpjkjzdCAa",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although SpaceTime is presented as a general-purpose time-series modeling architecture, one of its primary benchmarks is ECG time-series classification—a classic biomedical signal analysis task. The abstract explicitly cites “best or second-best AUROC on 6 / 7 ECG … classification” and positions the method’s applicability to biosignals. This direct use of ECG data for classification places the work within the Healthcare AI / Biomedicine AI domain.",
    "prompt_tokens": 20815,
    "completion_tokens": 113,
    "total_tokens": 20928,
    "topic": "Time Series - Forecasting & Classification",
    "method": "State-space models (SSMs); closed-loop SSM variants; deep learning architectures",
    "application": "Multivariate time series forecasting; ECG classification",
    "code_link": "N/A",
    "dataset_name": [
      "Informer",
      "Monash Forecasting Repository",
      "PTB-XL",
      "Speech Commands"
    ]
  },
  {
    "id": "b0RuGUYo8pA",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Transfer Learning with Deep Tabular Models",
    "authors": [
      "Roman Levin",
      "Valeriia Cherepanova",
      "Avi Schwarzschild",
      "Arpit Bansal",
      "C. Bayan Bruss",
      "Tom Goldstein",
      "Andrew Gordon Wilson",
      "Micah Goldblum"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Recent work on deep learning for tabular data demonstrates the strong performance of deep tabular models, often bridging the gap between gradient boosted decision trees and neural networks. Accuracy aside, a major advantage of neural models is that they are easily fine-tuned in new domains and learn reusable features. This property is often exploited in computer vision and natural language applications, where transfer learning is indispensable when task-specific training data is scarce. In this work, we explore the benefits that representation learning provides for knowledge transfer in the tabular domain. We conduct experiments in a realistic medical diagnosis test bed with limited amounts of downstream data and find that transfer learning with deep tabular models provides a definitive advantage over gradient boosted decision tree methods. We further compare the supervised and self-supervised pretraining strategies and provide practical advice on transfer learning with tabular models. Finally, we propose a pseudo-feature method for cases where the upstream and downstream feature sets differ, a tabular-specific problem widespread in real-world applications.",
    "keywords": "tabular data, transfer learning, tabular models, representation learning",
    "pdf_url": "https://openreview.net/pdf?id=b0RuGUYo8pA",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract specifically states that experiments are conducted “in a realistic medical diagnosis test bed with limited amounts of downstream data,” indicating that the transfer‐learning methods for tabular data are evaluated on a healthcare/clinical task. This direct reference to medical diagnosis situates the work firmly in the Healthcare AI domain.",
    "prompt_tokens": 21021,
    "completion_tokens": 108,
    "total_tokens": 21129,
    "topic": "Transfer Learning - Tabular Data",
    "method": "FT-Transformer; MLP",
    "application": "Disease prediction – limited data",
    "code_link": "https://github.com/ModelOriented/metaMIMIC/",
    "dataset_name": [
      "MetaMIMIC",
      "Yeast",
      "Emotions"
    ]
  },
  {
    "id": "YDJRFWBMNby",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "HotProtein: A Novel Framework for Protein Thermostability Prediction and Editing",
    "authors": [
      "Tianlong Chen",
      "Chengyue Gong",
      "Daniel Jesus Diaz",
      "Xuxi Chen",
      "Jordan Tyler Wells",
      "qiang liu",
      "Zhangyang Wang",
      "Andrew Ellington",
      "Alex Dimakis",
      "Adam Klivans"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The molecular basis of protein thermal stability is only partially understood and has major significance for drug and vaccine discovery.  The lack of datasets and standardized benchmarks considerably limits learning-based discovery methods. We present \\texttt{HotProtein}, a large-scale protein dataset with \\textit{growth temperature} annotations of thermostability, containing $182$K amino acid sequences and $3$K folded structures from $230$ different species with a wide temperature range $-20^{\\circ}\\texttt{C}\\sim 120^{\\circ}\\texttt{C}$. Due to functional domain differences and data scarcity within each species, existing methods fail to generalize well on our dataset. We address this problem through a novel learning framework, consisting of ($1$) Protein structure-aware pre-training (SAP) which leverages 3D information to enhance sequence-based pre-training; ($2$) Factorized sparse tuning (FST) that utilizes low-rank and sparse priors as an implicit regularization, together with feature augmentations. Extensive empirical studies demonstrate that our framework improves thermostability prediction compared to other deep learning models. Finally, we introduce a novel editing algorithm to efficiently generate positive amino acid mutations that improve thermostability. Codes are available in https://github.com/VITA-Group/HotProtein.",
    "keywords": "Protein Thermostability, Protein Editing, Dataset, Structure-aware Pre-training, Factorized Sparse Tuning",
    "pdf_url": "https://openreview.net/pdf?id=YDJRFWBMNby",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “protein thermal stability” and “protein editing” with direct implications for “drug and vaccine discovery.” It develops methods for predicting and improving protein thermostability—key tasks in molecular-level design for therapeutics—placing it squarely in the Biomedicine AI domain.",
    "prompt_tokens": 20687,
    "completion_tokens": 102,
    "total_tokens": 20789,
    "topic": "Protein Engineering - Thermostability",
    "method": "Structure-aware pretraining; factorized sparse tuning; feature augmentation",
    "application": "Protein thermostability prediction",
    "code_link": "https://github.com/VITA-Group/HotProtein",
    "dataset_name": [
      "HotProtein",
      "FireProtDB"
    ]
  },
  {
    "id": "O8Vc52xFSUR",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Quasi-optimal Reinforcement Learning with Continuous Actions",
    "authors": [
      "Yuhan Li",
      "Wenzhuo Zhou",
      "Ruoqing Zhu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Many real-world applications of reinforcement learning (RL) require making decisions in continuous action environments. In particular, determining the optimal dose level plays a vital role in developing medical treatment regimes. One challenge in adapting existing RL algorithms to medical applications, however, is that the popular infinite support stochastic policies, e.g., Gaussian policy, may assign riskily high dosages and harm patients seriously. Hence, it is important to induce a policy class whose support only contains near-optimal actions, and shrink the action-searching area for effectiveness and reliability. To achieve this, we develop a novel quasi-optimal learning algorithm, which can be easily optimized in off-policy settings with guaranteed convergence under general function approximations. Theoretically, we analyze the consistency, sample complexity, adaptability, and convergence of the proposed algorithm. We evaluate our algorithm with comprehensive simulated experiments and a dose suggestion real application to Ohio Type 1 diabetes dataset.",
    "keywords": "Continuous Treatments, Markov Decision Process, Safe Action Allocation",
    "pdf_url": "https://openreview.net/pdf?id=O8Vc52xFSUR",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper develops an RL algorithm specifically for “determining the optimal dose level” in “medical treatment regimes” and evaluates it on an Ohio Type 1 diabetes dataset for dose suggestion. These details clearly situate the work in a healthcare context, as it addresses safe, personalized dosing in a real medical application.",
    "prompt_tokens": 20710,
    "completion_tokens": 104,
    "total_tokens": 20814,
    "topic": "Reinforcement Learning - Healthcare Applications",
    "method": "Quasi-optimal reinforcement learning; kernel embedding",
    "application": "Optimal dose suggestion – Diabetes management",
    "code_link": "https://github.com/liyuhan529/Quasi-optimal-Learning",
    "dataset_name": [
      "Ohio Type 1 Diabetes"
    ]
  },
  {
    "id": "xmcYx_reUn6",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "BrainBERT: Self-supervised representation learning for intracranial recordings",
    "authors": [
      "Christopher Wang",
      "Vighnesh Subramaniam",
      "Adam Uri Yaari",
      "Gabriel Kreiman",
      "Boris Katz",
      "Ignacio Cases",
      "Andrei Barbu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We create a reusable Transformer, BrainBERT, for intracranial recordings bringing modern representation learning approaches to neuroscience. Much like in NLP and speech recognition, this Transformer enables classifying complex concepts, i.e., decoding neural data, with higher accuracy and with much less data by being pretrained in an unsupervised manner on a large corpus of unannotated neural recordings. Our approach generalizes to new subjects with electrodes in new positions and to unrelated tasks showing that the representations robustly disentangle the neural signal. Just like in NLP where one can study language by investigating what a language model learns, this approach opens the door to investigating the brain by what a model of the brain learns. As a first step along this path, we demonstrate a new analysis of the intrinsic dimensionality of the computations in different areas of the brain. To construct these representations, we combine a technique for producing super-resolution spectrograms of neural data with an approach designed for generating contextual representations of audio by masking. In the future, far more concepts will be decodable from neural recordings by using representation learning, potentially unlocking the brain like language models unlocked language.  ",
    "keywords": "neuroscience, language models, self-supervision, transformer, decoding",
    "pdf_url": "https://openreview.net/pdf?id=xmcYx_reUn6",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on self-supervised representation learning for intracranial recordings, i.e. brain decoding from neural data. The abstract explicitly mentions “intracranial recordings,” “decoding neural data,” and “investigating the brain by what a model of the brain learns,” placing it squarely in the neuroscience / neurobiological modeling domain, which is a recognized subfield of Healthcare AI / Biomedicine AI.",
    "prompt_tokens": 20858,
    "completion_tokens": 97,
    "total_tokens": 20955,
    "topic": "Neuroscience - Brain Signal Processing",
    "method": "Transformer-based embeddings; Masked spectrogram modeling",
    "application": "Brain activity decoding",
    "code_link": "https://github.com/czlwang/BrainBERT",
    "dataset_name": [
      "Annotated intracranial recordings"
    ]
  },
  {
    "id": "to3qCB3tOh9",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Protein Representation Learning by Geometric Structure Pretraining",
    "authors": [
      "Zuobai Zhang",
      "Minghao Xu",
      "Arian Rokkum Jamasb",
      "Vijil Chenthamarakshan",
      "Aurelie Lozano",
      "Payel Das",
      "Jian Tang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Learning effective protein representations is critical in a variety of tasks in biology such as predicting protein function or structure. Existing approaches usually pretrain protein language models on a large number of unlabeled amino acid sequences and then finetune the models with some labeled data in downstream tasks. Despite the effectiveness of sequence-based approaches, the power of pretraining on known protein structures, which are available in smaller numbers only, has not been explored for protein property prediction, though protein structures are known to be determinants of protein function. In this paper, we propose to pretrain protein representations according to their 3D structures. We first present a simple yet effective encoder to learn the geometric features of a protein. We pretrain the protein graph encoder by leveraging multiview contrastive learning and different self-prediction tasks. Experimental results on both function prediction and fold classification tasks show that our proposed pretraining methods outperform or are on par with the state-of-the-art sequence-based methods, while using much less pretraining data. Our implementation is available at https://github.com/DeepGraphLearning/GearNet.",
    "keywords": "Protein representation learning, self-supervised learning",
    "pdf_url": "https://openreview.net/pdf?id=to3qCB3tOh9",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on learning protein representations from 3D structures (“pretrain the protein graph encoder,” “protein function prediction and fold classification”). Protein structure and function modeling is a core task in molecular biology and biomedicine (e.g., protein design, molecular modeling), which falls squarely under Biomedicine AI.",
    "prompt_tokens": 20988,
    "completion_tokens": 109,
    "total_tokens": 21097,
    "topic": "Bioinformatics - Protein Structure Prediction",
    "method": "Multiview contrastive learning; self-prediction tasks",
    "application": "Protein function prediction and fold classification",
    "code_link": "https://github.com/DeepGraphLearning/GearNet",
    "dataset_name": [
      "AlphaFold Database",
      "Protein Data Bank (PDB)"
    ]
  },
  {
    "id": "8efJYMBrNb",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Multiple sequence alignment as a sequence-to-sequence learning problem",
    "authors": [
      "Edo Dotan",
      "Yonatan Belinkov",
      "Oren Avram",
      "Elya Wygoda",
      "Noa Ecker",
      "Michael Alburquerque",
      "Omri Keren",
      "Gil Loewenthal",
      "Tal Pupko"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The sequence alignment problem is one of the most fundamental problems in bioinformatics and a plethora of methods were devised to tackle it. Here we introduce BetaAlign, a methodology for aligning sequences using an NLP approach. BetaAlign accounts for the possible variability of the evolutionary process among different datasets by using an ensemble of transformers, each trained on millions of samples generated from a different evolutionary model. Our approach leads to alignment accuracy that is similar and often better than commonly used methods, such as MAFFT, DIALIGN, ClustalW, T-Coffee, PRANK, and MUSCLE.",
    "keywords": "sequence alignment, molecular evolution, natural language processing, bioinformatics",
    "pdf_url": "https://openreview.net/pdf?id=8efJYMBrNb",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper introduces an AI method for multiple sequence alignment—a core bioinformatics task used in genomics and molecular evolution studies. It explicitly deals with “sequence alignment,” “molecular evolution,” and “bioinformatics,” which places it squarely in the Biomedicine AI domain for analyzing molecular‐level (e.g., DNA/protein) data.",
    "prompt_tokens": 20335,
    "completion_tokens": 101,
    "total_tokens": 20436,
    "topic": "Bioinformatics - Sequence Alignment",
    "method": "Transformer-based models; transfer learning",
    "application": "Multiple sequence alignment",
    "code_link": "N/A",
    "dataset_name": [
      "PD1",
      "PD2",
      "ND1",
      "ND2",
      "SND1",
      "SPD1"
    ]
  },
  {
    "id": "r0xte-t40I",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Learning Human-Compatible Representations for Case-Based Decision Support",
    "authors": [
      "Han Liu",
      "Yizhou Tian",
      "Chacha Chen",
      "Shi Feng",
      "Yuxin Chen",
      "Chenhao Tan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Algorithmic case-based decision support provides examples to help human make sense of predicted labels and aid human in decision-making tasks. Despite the promising performance of supervised learning, representations learned by supervised models may not align well with human intuitions: what models consider as similar examples can be perceived as distinct by humans. As a result, they have limited effectiveness in case-based decision support. In this work, we incorporate ideas from metric learning with supervised learning to examine the importance of alignment for effective decision support. In addition to instance-level labels, we use human-provided triplet judgments to learn human-compatible decision-focused representations. Using both synthetic data and human subject experiments in multiple classification tasks, we demonstrate that such representation is better aligned with human perception than representation solely optimized for classification. Human-compatible representations identify nearest neighbors that are perceived as more similar by humans and allow humans to make more accurate predictions, leading to substantial improvements in human decision accuracies (17.8% in butterfly vs. moth classification and 13.2% in pneumonia classification).",
    "keywords": "human-compatible representation learning, human triplet judgments",
    "pdf_url": "https://openreview.net/pdf?id=r0xte-t40I",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the paper’s core contribution is a general metric-learning approach for human-compatible representations, one of its key evaluation tasks is “pneumonia classification,” a medical diagnosis problem. The work focuses on case-based decision support—specifically improving human decision accuracy in a clinical task—and thus directly touches on Healthcare AI.",
    "prompt_tokens": 57590,
    "completion_tokens": 116,
    "total_tokens": 57706,
    "topic": "Medical Imaging - Decision Support",
    "method": "Human-compatible representation learning; triplet embedding",
    "application": "Pneumonia classification",
    "code_link": "N/A",
    "dataset_name": [
      "CXR Dataset by Kermany et al."
    ]
  },
  {
    "id": "6ve2CkeQe5S",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "MEDFAIR: Benchmarking Fairness for Medical Imaging",
    "authors": [
      "Yongshuo Zong",
      "Yongxin Yang",
      "Timothy Hospedales"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "A multitude of work has shown that machine learning-based medical diagnosis systems can be biased against certain subgroups of people. This has motivated a growing number of bias mitigation algorithms that aim to address fairness issues in machine learning. However, it is difficult to compare their effectiveness in medical imaging for two reasons. First, there is little consensus on the criteria to assess fairness. Second, existing bias mitigation algorithms are developed under different settings, e.g., datasets, model selection strategies, backbones, and fairness metrics, making a direct comparison and evaluation based on existing results impossible. In this work, we introduce MEDFAIR, a framework to benchmark the fairness of machine learning models for medical imaging. MEDFAIR covers eleven algorithms from various categories, ten datasets from different imaging modalities, and three model selection criteria. Through extensive experiments, we find that the under-studied issue of model selection criterion can have a significant impact on fairness outcomes; while in contrast, state-of-the-art bias mitigation algorithms do not significantly improve fairness outcomes over empirical risk minimization (ERM) in both in-distribution and out-of-distribution settings. We evaluate fairness from various perspectives and make recommendations for different medical application scenarios that require different ethical principles. Our framework provides a reproducible and easy-to-use entry point for the development and evaluation of future bias mitigation algorithms in deep learning. Code is available at https://github.com/ys-zong/MEDFAIR.",
    "keywords": "Fairness, Bias Mitigation, Medical Imaging, Benchmark",
    "pdf_url": "https://openreview.net/pdf?id=6ve2CkeQe5S",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses explicitly on “medical imaging” and “machine learning-based medical diagnosis systems,” addressing biases in healthcare settings. It develops a framework (MEDFAIR) to benchmark fairness across medical imaging datasets and models, which is directly relevant to Healthcare AI.",
    "prompt_tokens": 20694,
    "completion_tokens": 158,
    "total_tokens": 20852,
    "topic": "Medical Imaging - Fairness Evaluation",
    "method": "Bias mitigation algorithms; adversarial learning; disentanglement",
    "application": "Binary classification tasks with fairness constraints",
    "code_link": "https://ys-zong.github.io/MEDFAIR/",
    "dataset_name": [
      "CheXpert",
      "MIMIC-CXR",
      "HAM10000",
      "Fitzpatrick17k",
      "OL3I",
      "COVID-CT-MD",
      "PAPILA",
      "OCT",
      "ADNI-1.5T",
      "ADNI-3T"
    ]
  },
  {
    "id": "QCrw0u9LQ7",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Iterative Patch Selection for High-Resolution Image Recognition",
    "authors": [
      "Benjamin Bergner",
      "Christoph Lippert",
      "Aravindh Mahendran"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "High-resolution images are prevalent in various applications, such as autonomous driving and computer-aided diagnosis. However, training neural networks on such images is computationally challenging and easily leads to out-of-memory errors even on modern GPUs. We propose a simple method, Iterative Patch Selection (IPS), which decouples the memory usage from the input size and thus enables the processing of arbitrarily large images under tight hardware constraints. IPS achieves this by selecting only the most salient patches, which are then aggregated into a global representation for image recognition. For both patch selection and aggregation, a cross-attention based transformer is introduced, which exhibits a close connection to Multiple Instance Learning. Our method demonstrates strong performance and has wide applicability across different domains, training regimes and image sizes while using minimal accelerator memory. For example, we are able to finetune our model on whole-slide images consisting of up to 250k patches (>16 gigapixels) with only 5 GB of GPU VRAM at a batch size of 16.",
    "keywords": "high-resolution images, memory-efficient deep learning, multiple instance learning, transformer, image recognition, computer vision",
    "pdf_url": "https://openreview.net/pdf?id=QCrw0u9LQ7",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly mentions “computer-aided diagnosis” in the abstract and demonstrates its method on whole-slide images (up to 16 gigapixels), which are pathology slides used for medical diagnosis. These are medical imaging tasks central to Healthcare AI, so the work falls within the Healthcare AI / Biomedicine AI domain.",
    "prompt_tokens": 20926,
    "completion_tokens": 115,
    "total_tokens": 21041,
    "topic": "Medical Imaging - Gigapixel Analysis",
    "method": "Iterative Patch Selection (IPS); Cross-attention transformer",
    "application": "Binary classification – Lymph node metastases",
    "code_link": "https://github.com/benbergner/ips",
    "dataset_name": [
      "CAMELYON16",
      "Megapixel MNIST",
      "Swedish Traffic Signs"
    ]
  },
  {
    "id": "01KmhBsEPFO",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Exploring Low-Rank Property in Multiple Instance Learning for Whole Slide Image Classification",
    "authors": [
      "Jinxi Xiang",
      "Jun Zhang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The classification of gigapixel-sized whole slide images (WSIs) with slide-level labels can be formulated as a multiple-instance-learning (MIL) problem. State-of-the-art models often consist of two decoupled parts: local feature embedding with a pre-trained model followed by a global feature aggregation network for classification. We leverage the properties of the apparent similarity in high-resolution WSIs, which essentially exhibit \\textit{low-rank} structures in the data manifold, to develop a novel MIL with a boost in both feature embedding and feature aggregation. We extend the contrastive learning with a pathology-specific Low-Rank Constraint  (LRC) for feature embedding to pull together samples (i.e., patches) belonging to the same pathological tissue in the low-rank subspace and simultaneously push apart those from different latent subspaces. At the feature aggregation stage, we introduce an iterative low-rank attention MIL (ILRA-MIL) model to aggregate features with low-rank learnable latent vectors to model global interactions among all instances. We highlight the importance of instance correlation modeling but refrain from directly using the transformer encoder considering the $O(n^2)$ complexity. ILRA-MIL with LRC pre-trained features achieves strong empirical results across various benchmarks, including (i) 96.49\\% AUC on the CAMELYON16 for binary metastasis classification, (ii) 97.63\\% AUC on the TCGA-NSCLC for lung cancer subtyping, and (iii) 0.6562 kappa on the large-scale PANDA dataset for prostate cancer classification. The code is available at https://github.com/jinxixiang/low_rank_wsi.",
    "keywords": "computational pathology, multiple instance learning, low-rank constraint, self-attention",
    "pdf_url": "https://openreview.net/pdf?id=01KmhBsEPFO",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on multiple‐instance learning for gigapixel whole‐slide images in pathology and reports results on cancer tasks (e.g., “96.49% AUC on CAMELYON16 for binary metastasis classification,” “97.63% AUC on TCGA-NSCLC for lung cancer subtyping,” “0.6562 kappa on PANDA for prostate cancer classification”). These are medical imaging tasks directly relevant to disease diagnosis and subtyping in a clinical/biomedical context.",
    "prompt_tokens": 21142,
    "completion_tokens": 112,
    "total_tokens": 21254,
    "topic": "Medical Imaging - Pathology",
    "method": "Iterative low-rank attention MIL; pathology-specific contrastive loss",
    "application": "Whole Slide Image Classification",
    "code_link": "https://github.com/jinxixiang/low_rank_wsi",
    "dataset_name": [
      "CAMELYON16",
      "TCGA-NSCLC",
      "PANDA"
    ]
  },
  {
    "id": "P5Z-Zl9XJ7",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Continuous-Discrete Convolution for Geometry-Sequence Modeling in Proteins",
    "authors": [
      "Hehe Fan",
      "Zhangyang Wang",
      "Yi Yang",
      "Mohan Kankanhalli"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The structure of proteins involves 3D geometry of amino acid coordinates and 1D sequence of peptide chains. The 3D structure exhibits irregularity because amino acids are distributed unevenly in Euclidean space and their coordinates are continuous variables. In contrast, the 1D structure is regular because amino acids are arranged uniformly in the chains and their sequential positions (orders) are discrete variables. Moreover, geometric coordinates and sequential orders are in two types of spaces and their units of length are incompatible. These inconsistencies make it challenging to capture the 3D and 1D structures while avoiding the impact of sequence and geometry modeling on each other. This paper proposes a Continuous-Discrete Convolution (CDConv) that uses irregular and regular approaches to model the geometry and sequence structures, respectively. Specifically, CDConv employs independent learnable weights for different regular sequential displacements but directly encodes geometric displacements due to their irregularity. In this way, CDConv significantly improves protein modeling by reducing the impact of geometric irregularity on sequence modeling. Extensive experiments on a range of tasks, including protein fold classification, enzyme reaction classification, gene ontology term prediction and enzyme commission number prediction, demonstrate the effectiveness of the proposed CDConv. ",
    "keywords": "Protein representation learning, 3D geometry modeling, 1D sequence modeling, continuous convolution, discrete convolution.",
    "pdf_url": "https://openreview.net/pdf?id=P5Z-Zl9XJ7",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on protein representation learning and downstream tasks such as “protein fold classification,” “enzyme reaction classification,” “gene ontology term prediction,” and “enzyme commission number prediction.” These are core molecular‐level tasks in biomedicine (protein and enzyme modeling) and directly pertain to understanding biological macromolecules. Therefore, it falls under the Biomedicine AI domain.",
    "prompt_tokens": 20703,
    "completion_tokens": 140,
    "total_tokens": 20843,
    "topic": "Bioinformatics - Protein Modeling",
    "method": "Continuous and discrete convolution; relative spatial encoding",
    "application": "Protein fold classification; enzyme reaction classification; gene ontology prediction; enzyme commission prediction",
    "code_link": "https://github.com/hehefan/Continuous-Discrete-Convolution",
    "dataset_name": [
      "SCOPe 1.75",
      "Hermosilla Enzyme Dataset",
      "Gligorijevic Gene Ontology Dataset",
      "Gligorijevic Enzyme Commission Dataset"
    ]
  },
  {
    "id": "0WVNuEnqVu",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Deep Reinforcement Learning for Cost-Effective Medical Diagnosis",
    "authors": [
      "Zheng Yu",
      "Yikuan Li",
      "Joseph Chahn Kim",
      "Kaixuan Huang",
      "Yuan Luo",
      "Mengdi Wang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Dynamic diagnosis is desirable when medical tests are costly or time-consuming. In this work, we use reinforcement learning (RL) to find a dynamic policy that selects lab test panels sequentially based on previous observations, ensuring accurate testing at a low cost. Clinical diagnostic data are often highly imbalanced; therefore, we aim to maximize the F1 score instead of the error rate. However, optimizing the non-concave $F_1$ score is not a classic RL problem, thus invalidating standard RL methods. To remedy this issue, we develop a reward shaping approach, leveraging properties of the $F_1$ score and duality of policy optimization, to provably find the set of all Pareto-optimal policies for budget-constrained $F_1$ score maximization. To handle the combinatorially complex state space, we propose a Semi-Model-based Deep Diagnosis Policy Optimization (SM-DDPO) framework that is compatible with end-to-end training and online learning. SM-DDPO is tested on diverse clinical tasks: ferritin abnormality detection, sepsis mortality prediction, and acute kidney injury diagnosis. Experiments with real-world data validate that SM-DDPO trains efficiently and identify all Pareto-front solutions. Across all tasks, SM-DDPO is able to achieve state-of-the-art diagnosis accuracy (in some cases higher than conventional methods) with up to $85\\%$ reduction in testing cost. Core codes are available at https://github.com/Zheng321/Deep-Reinforcement-Learning-for-Cost-Effective-Medical-Diagnosis.",
    "keywords": "medical diagnostics, Pareto front, reinforcement learning, non-Markovian reward, semi-model-based policy optimization",
    "pdf_url": "https://openreview.net/pdf?id=0WVNuEnqVu",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “medical diagnosis,” specifically “ferritin abnormality detection, sepsis mortality prediction, and acute kidney injury diagnosis,” and addresses the cost and sequencing of “lab test panels.” These are core clinical decision‐support problems in Healthcare AI, involving EHR‐style data and patient outcomes.",
    "prompt_tokens": 20811,
    "completion_tokens": 88,
    "total_tokens": 20899,
    "topic": "Clinical Risk Modeling - Acute Kidney Injury Prediction",
    "method": "Reinforcement learning",
    "application": "Risk Prediction within 72 hours ICU admission",
    "code_link": "N/A",
    "dataset_name": [
      "MIMIC III"
    ]
  },
  {
    "id": "65XDF_nwI61",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "A Graph Neural Network Approach to Automated Model Building in Cryo-EM Maps",
    "authors": [
      "Kiarash Jamali",
      "Dari Kimanius",
      "Sjors HW Scheres"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Electron cryo-microscopy (cryo-EM) produces three-dimensional (3D) maps of the electrostatic potential of biological macromolecules, including proteins. At sufficient resolution, the cryo-EM maps, along with some knowledge about the imaged molecules, allow de novo atomic modelling. Typically, this is done through a laborious manual process. Recent advances in machine learning applications to protein structure prediction show potential for automating this process. Taking inspiration from these techniques, we have built ModelAngelo for automated model building of proteins in cryo-EM maps. ModelAngelo first uses a residual convolutional neural network (CNN) to initialize a graph representation with nodes assigned to individual amino acids of the proteins in the map and edges representing the protein chain. The graph is then refined with a graph neural network (GNN) that combines the cryo-EM data, the amino acid sequence data and prior knowledge about protein geometries. The GNN refines the geometry of the protein chain and classifies the amino acids for each of its nodes. The final graph is post-processed with a hidden Markov model (HMM) search to map each protein chain to entries in a user provided sequence file. Application to 28 test cases shows that ModelAngelo outperforms state-of-the-art and approximates manual building for cryo-EM maps with resolutions better than 3.5 A.",
    "keywords": "cryo-em, model building, graph neural networks, attention networks, proteins",
    "pdf_url": "https://openreview.net/pdf?id=65XDF_nwI61",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper presents an AI method for automated atomic modelling of proteins from cryo-EM maps. Cryo-electron microscopy and de novo protein structure building are core techniques in structural biology and molecular modeling, which are key components of biomedical research (e.g., drug discovery, protein design). The abstract’s focus on “molecular modelling,” “proteins,” and “cryo-EM maps” places it squarely in the Biomedicine AI domain.",
    "prompt_tokens": 20287,
    "completion_tokens": 103,
    "total_tokens": 20390,
    "topic": "Bioinformatics - Protein Modeling",
    "method": "Graph Neural Networks (GNN); Cryo-EM attention; Spatial Invariant Point Attention (IPA); Sequence Attention",
    "application": "De novo atomic model building",
    "code_link": "N/A",
    "dataset_name": [
      "EMDB",
      "PDB"
    ]
  },
  {
    "id": "txlWziuCE5W",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "MEDICAL IMAGE UNDERSTANDING WITH PRETRAINED VISION LANGUAGE MODELS: A COMPREHENSIVE STUDY",
    "authors": [
      "Ziyuan Qin",
      "Huahui Yi",
      "Qicheng Lao",
      "Kang Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The large-scale pre-trained vision language models (VLM) have shown remarkable domain transfer capability on natural images. However, it remains unknown whether this capability can also apply to the medical image domain. This paper thoroughly studies the knowledge transferability of pre-trained VLMs to the medical domain, where we show that well-designed medical prompts are the key to elicit knowledge from pre-trained VLMs. We demonstrate that by prompting with expressive attributes that are shared between domains, the VLM can carry the knowledge across domains and improve its generalization. This mechanism empowers VLMs to recognize novel objects with fewer or without image samples. Furthermore, to avoid the laborious manual designing process, we develop three approaches for automatic generation of medical prompts, which can inject expert-level medical knowledge and image-specific information into the prompts for fine-grained grounding. We conduct extensive experiments on thirteen different medical datasets across various modalities, showing that our well-designed prompts greatly improve the zero-shot performance compared to the default prompts, and our fine-tuned models surpass the supervised models by a significant margin.",
    "keywords": "Vision Language models, Multimodality, Medical images, Few-shot learning, zero-shot",
    "pdf_url": "https://openreview.net/pdf?id=txlWziuCE5W",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses explicitly on “medical image domain” and “medical prompts” for vision-language models, evaluating on “thirteen different medical datasets across various modalities.” It addresses tasks like zero-shot and few-shot recognition of medical objects, which places it squarely in the medical imaging and Healthcare AI domain.",
    "prompt_tokens": 20146,
    "completion_tokens": 205,
    "total_tokens": 20351,
    "topic": "Medical Imaging - Multimodal Vision Language Models",
    "method": "Vision-Language Pretraining; Prompt-based domain transfer; Masked language model (MLM); Visual question answering (VQA)",
    "application": "Medical object detection – Various modalities (e.g., X-ray, CT, MRI, ultrasound)",
    "code_link": "https://github.com/MembrLab/MIU-VL",
    "dataset_name": [
      "ISIC 2016",
      "DFUC 2020",
      "CVC-300",
      "CVC-ClinicDB",
      "CVC-ColonDB",
      "Kvasir",
      "ETIS",
      "BCCD",
      "CPM-17",
      "TBX11K",
      "Luna16",
      "ADNI",
      "TN3k"
    ]
  },
  {
    "id": "Rq13idF0F73",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Molecule Generation For Target Protein Binding with Structural Motifs",
    "authors": [
      "ZAIXI ZHANG",
      "Yaosen Min",
      "Shuxin Zheng",
      "Qi Liu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Designing ligand molecules that bind to specific protein binding sites is a fundamental problem in structure-based drug design. Although deep generative models and geometric deep learning have made great progress in drug design, existing works either sample in the 2D graph space or fail to generate valid molecules with realistic substructures. To tackle these problems, we propose a Fragment-based LigAnd Generation framework (FLAG), to generate 3D molecules with valid and realistic substructures fragment-by-fragment. In FLAG, a motif vocabulary is constructed by extracting common molecular fragments (i.e., motif) in the dataset. At each generation step, a 3D graph neural network is first employed to encode the intermediate context information. Then, our model selects the focal motif, predicts the next motif type, and attaches the new motif. The bond lengths/angles can be quickly and accurately determined by cheminformatics tools. Finally, the molecular geometry is further adjusted according to the predicted rotation angle and the structure refinement. Our model not only achieves competitive performances on conventional metrics such as binding affinity, QED, and SA, but also outperforms baselines by a large margin in generating molecules with realistic substructures.",
    "keywords": "Structure-based Drug Design",
    "pdf_url": "https://openreview.net/pdf?id=Rq13idF0F73",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on fragment-based 3D molecular generation for “structure-based drug design,” explicitly targeting ligand–protein binding and evaluating metrics such as binding affinity, QED, and synthetic accessibility. These topics fall squarely within drug discovery and molecular modeling, key areas of Biomedicine AI.",
    "prompt_tokens": 20974,
    "completion_tokens": 104,
    "total_tokens": 21078,
    "topic": "Drug Discovery - Target-based",
    "method": "3D Graph Neural Networks (GNN); motif-based generation; structure refinement",
    "application": "3D molecule generation for target protein binding",
    "code_link": "https://github.com/zaixizhang/FLAG",
    "dataset_name": [
      "CrossDocked"
    ]
  },
  {
    "id": "Yo06F8kfMa1",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "How Much Space Has Been Explored? Measuring the Chemical Space Covered by Databases and Machine-Generated Molecules",
    "authors": [
      "Yutong Xie",
      "Ziqiao Xu",
      "Jiaqi Ma",
      "Qiaozhu Mei"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Forming a molecular candidate set that contains a wide range of potentially effective compounds is crucial to the success of drug discovery. While most databases and machine-learning-based generation models aim to optimize particular chemical properties, there is limited literature on how to properly measure the coverage of the chemical space by those candidates included or generated. This problem is challenging due to the lack of formal criteria to select good measures of the chemical space. In this paper, we propose a novel evaluation framework for measures of the chemical space based on two analyses: an axiomatic analysis with three intuitive axioms that a good measure should obey, and an empirical analysis on the correlation between a measure and a proxy gold standard. Using this framework, we are able to identify #Circles, a new measure of chemical space coverage, which is superior to existing measures both analytically and empirically. We further evaluate how well the existing databases and generation models cover the chemical space in terms of #Circles. The results suggest that many generation models fail to explore a larger space over existing databases, which leads to new opportunities for improving generation models by encouraging exploration. \n",
    "keywords": "molecular generation, drug discovery, coverea measures, chemical space measures",
    "pdf_url": "https://openreview.net/pdf?id=Yo06F8kfMa1",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “molecular generation” and “drug discovery,” explicitly aiming to form candidate sets of compounds for therapeutic purposes. It develops measures to evaluate chemical space coverage in databases and machine-generated molecules, which directly relates to biomedical research and AI-driven drug discovery.",
    "prompt_tokens": 21119,
    "completion_tokens": 119,
    "total_tokens": 21238,
    "topic": "Drug Discovery - Evaluation Frameworks",
    "method": "Coverage measures; chemical space evaluation",
    "application": "Chemical space measure optimization – molecular generation",
    "code_link": "https://github.com/bytedance/markov-molecular-sampling",
    "dataset_name": [
      "ChEMBL",
      "BioActivity",
      "ZINC-250k",
      "MOSES",
      "GDB-17"
    ]
  },
  {
    "id": "iYC5hOMqUg",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Bayesian Oracle for bounding information gain in neural encoding models",
    "authors": [
      "Konstantin-Klemens Lurz",
      "Mohammad Bashiri",
      "Edgar Y. Walker",
      "Fabian H. Sinz"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In recent years, deep learning models have set new standards in predicting neural population responses. Most of these models currently focus on predicting the mean response of each neuron for a given input. However, neural variability around this mean is not just noise and plays a central role in several theories on neural computation. To capture this variability, we need models that predict full response distributions for a given stimulus. However, to measure the quality of such models, commonly used correlation-based metrics are not sufficient as they mainly care about the mean of the response distribution. An interpretable alternative evaluation metric for likelihood-based models is \\textit{Information Gain} (IG) which evaluates the likelihood of a model relative to a lower and upper bound. However, while a lower bound is usually easy to obtain, constructing an upper bound turns out to be challenging for neural recordings with relatively low numbers of repeated trials, high (shared) variability, and sparse responses. In this work, we generalize the jack-knife oracle estimator for the mean---commonly used for correlation metrics---to a flexible Bayesian oracle estimator for IG based on posterior predictive distributions. We describe and address the challenges that arise when estimating the lower and upper bounds from small datasets. We then show that our upper bound estimate is data-efficient and robust even in the case of sparse responses and low signal-to-noise ratio. We further provide the derivation of the upper bound estimator for a variety of common distributions including the state-of-the-art zero-inflated mixture models, and relate IG to common mean-based metrics. Finally, we use our approach to evaluate such a mixture model resulting in $90\\%$ IG performance.",
    "keywords": "information theory, evaluation metrics, Bayesian, Neuroscience, encoding models",
    "pdf_url": "https://openreview.net/pdf?id=iYC5hOMqUg",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on modeling neural population responses and variability in a neuroscience context (“predicting neural population responses,” “neural variability,” “neural encoding models”). Neuroscience or neurobiological modeling falls under the Biomedicine AI domain according to the provided guidelines, even though it is not a clinical application. The work develops evaluation metrics (Information Gain) and Bayesian oracles specifically for neural data, making it a domain‐specific methodological contribution to Biomedicine AI.",
    "prompt_tokens": 20933,
    "completion_tokens": 96,
    "total_tokens": 21029,
    "topic": "Neural Encoding Models - Variability Evaluation",
    "method": "Bayesian posterior predictive distributions; Zero-inflated Log-Normal likelihood",
    "application": "Neural response distribution prediction",
    "code_link": "N/A",
    "dataset_name": [
      "Mouse primary visual cortex dataset"
    ]
  },
  {
    "id": "VbCMhg7MRmj",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Protein Representation Learning via Knowledge Enhanced Primary Structure Reasoning",
    "authors": [
      "Hong-Yu Zhou",
      "Yunxiang Fu",
      "Zhicheng Zhang",
      "Bian Cheng",
      "Yizhou Yu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Protein representation learning has primarily benefited from the remarkable development of language models (LMs). Accordingly, pre-trained protein models also suffer from a problem in LMs: a lack of factual knowledge. The recent solution models the relationships between protein and associated knowledge terms as the knowledge encoding objective. However, it fails to explore the relationships at a more granular level, i.e., the token level. To mitigate this, we propose Knowledge-exploited Auto-encoder for Protein (KeAP), which performs token-level knowledge graph exploration for protein representation learning. In practice, non-masked amino acids iteratively query the associated knowledge tokens to extract and integrate helpful information for restoring masked amino acids via attention. We show that KeAP can consistently outperform the previous counterpart on 9 representative downstream applications, sometimes surpassing it by large margins. These results suggest that KeAP provides an alternative yet effective way to perform knowledge enhanced protein representation learning.",
    "keywords": "Protein Science, Representation Learning, Knowledge Graph",
    "pdf_url": "https://openreview.net/pdf?id=VbCMhg7MRmj",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This paper focuses on protein representation learning (“Protein Representation Learning via Knowledge Enhanced Primary Structure Reasoning”), a core task in molecular modeling and drug discovery within Biomedicine AI. It introduces a knowledge-enhanced auto-encoder for proteins and evaluates on multiple downstream biological tasks, indicating direct relevance to biomedical research on protein function and design.",
    "prompt_tokens": 20718,
    "completion_tokens": 110,
    "total_tokens": 20828,
    "topic": "Bioinformatics - Protein Representation Learning",
    "method": "Cross-attention; Knowledge-enhanced pretraining; Masked Language Modeling (MLM)",
    "application": "Protein representation learning for downstream tasks",
    "code_link": "https://github.com/RL4M/KeAP",
    "dataset_name": [
      "ProteinKG25"
    ]
  },
  {
    "id": "KXRSh0sdVTP",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Meta-learning Adaptive Deep Kernel Gaussian Processes for Molecular Property Prediction",
    "authors": [
      "Wenlin Chen",
      "Austin Tripp",
      "José Miguel Hernández-Lobato"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We propose Adaptive Deep Kernel Fitting with Implicit Function Theorem (ADKF-IFT), a novel framework for learning deep kernel Gaussian processes (GPs) by interpolating between meta-learning and conventional deep kernel learning. Our approach employs a bilevel optimization objective where we meta-learn generally useful feature representations across tasks, in the sense that task-specific GP models estimated on top of such features achieve the lowest possible predictive loss on average. We solve the resulting nested optimization problem using the implicit function theorem (IFT). We show that our ADKF-IFT framework contains previously proposed Deep Kernel Learning (DKL) and Deep Kernel Transfer (DKT) as special cases. Although ADKF-IFT is a completely general method, we argue that it is especially well-suited for drug discovery problems and demonstrate that it significantly outperforms previous state-of-the-art methods on a variety of real-world few-shot molecular property prediction tasks and out-of-domain molecular property prediction and optimization tasks.",
    "keywords": "meta-learning, few-shot learning, Gaussian processes, deep kernel learning, bilevel optimization, chemistry, molecules, drug discovery",
    "pdf_url": "https://openreview.net/pdf?id=KXRSh0sdVTP",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly targets \"drug discovery problems\" and focuses on \"few-shot molecular property prediction\" and \"out-of-domain molecular property prediction and optimization tasks.\" These are core applications in biomedicine AI, as they involve predicting biochemical properties of molecules for therapeutic development.",
    "prompt_tokens": 21335,
    "completion_tokens": 125,
    "total_tokens": 21460,
    "topic": "Drug Discovery - Few-shot Molecular Property",
    "method": "Meta-learning; Deep Kernel Learning; Bilevel Optimization",
    "application": "Molecular property prediction",
    "code_link": "https://github.com/Wenlin-Chen/ADKF-IFT",
    "dataset_name": [
      "MoleculeNet",
      "FS-Mol",
      "DOCKSTRING",
      "Harvard Clean Energy Project",
      "Antibiotic Training Set",
      "COVID Moonshot"
    ]
  },
  {
    "id": "-HHJZlRpGb",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Learning Domain-Agnostic Representation for Disease Diagnosis",
    "authors": [
      "Churan Wang",
      "Jing  Li",
      "Xinwei Sun",
      "Fandong Zhang",
      "Yizhou Yu",
      "Yizhou Wang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In clinical environments, image-based diagnosis is desired to achieve robustness on multi-center samples. Toward this goal, a natural way is to capture only clinically disease-related features. However, such disease-related features are often entangled with center-effect, disabling robust transferring to unseen centers/domains. To disentangle disease-related features, we first leverage structural causal modeling to explicitly model disease-related and center-effects that are provable to be disentangled from each other. Guided by this, we propose a novel Domain Agnostic Representation Model (DarMo) based on variational Auto-Encoder. To facilitate disentanglement, we design domain-agnostic and domain-aware encoders to respectively capture disease-related features and varied center-effects by incorporating a domain-aware batch normalization layer. Besides, we constrain the disease-related features to well predict the disease label as well as clinical attributes, by leveraging Graph Convolutional Network (GCN) into our decoder. The effectiveness and utility of our method are demonstrated by the superior performance over others on both public datasets and inhouse datasets.",
    "keywords": "multi centers disease diagnosis, mammogram classification",
    "pdf_url": "https://openreview.net/pdf?id=-HHJZlRpGb",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly addresses “image-based diagnosis” in “clinical environments,” aims to learn representations for “disease‐related features,” and validates on “mammogram classification,” all of which are core medical imaging and disease diagnosis tasks in Healthcare AI.",
    "prompt_tokens": 20818,
    "completion_tokens": 111,
    "total_tokens": 20929,
    "topic": "Medical Imaging - Domain Generalization",
    "method": "Graph Convolutional Network; Variational Autoencoders; Domain-aware batch normalization",
    "application": "Mammogram benign/malignant classification",
    "code_link": "N/A",
    "dataset_name": [
      "DDSM",
      "InH1",
      "InH2",
      "InH3"
    ]
  },
  {
    "id": "w-x7U26GM7j",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Advancing Radiograph Representation Learning with Masked Record Modeling",
    "authors": [
      "Hong-Yu Zhou",
      "Chenyu Lian",
      "Liansheng Wang",
      "Yizhou Yu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Modern studies in radiograph representation learning (R$^2$L) rely on either self-supervision to encode invariant semantics or associated radiology reports to incorporate medical expertise, while the complementarity between them is barely noticed. To explore this, we formulate the self- and report-completion as two complementary objectives and present a unified framework based on masked record modeling (MRM). In practice, MRM reconstructs masked image patches and masked report tokens following a multi-task scheme to learn knowledge-enhanced semantic representations. With MRM pre-training, we obtain pre-trained models that can be well transferred to various radiography tasks. Specifically, we find that MRM offers superior performance in label-efficient fine-tuning. For instance, MRM achieves 88.5% mean AUC on CheXpert using 1% labeled data, outperforming previous R$^2$L methods with 100% labels. On NIH ChestX-ray, MRM outperforms the best performing counterpart by about 3% under small labeling ratios. Besides, MRM surpasses self- and report-supervised pre-training in identifying the pneumonia type and the pneumothorax area, sometimes by large margins.",
    "keywords": "Representation Learning, Radiograph, Self-supervised Learning, Medical Imaging",
    "pdf_url": "https://openreview.net/pdf?id=w-x7U26GM7j",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on radiograph representation learning and explicitly references medical imaging tasks—e.g., “CheXpert,” “NIH ChestX-ray,” “pneumonia type,” and “pneumothorax area.” It uses radiology reports and radiograph data, both of which are firmly within medical/clinical contexts. This clearly places it in the Healthcare AI domain.",
    "prompt_tokens": 20904,
    "completion_tokens": 137,
    "total_tokens": 21041,
    "topic": "Medical Imaging - X-ray Classification and Segmentation",
    "method": "Masked record modeling (MRM); radiograph representation learning",
    "application": "Disease classification and segmentation",
    "code_link": "https://github.com/RL4M/MRM-pytorch",
    "dataset_name": [
      "NIH ChestX-ray",
      "CheXpert",
      "RSNA Pneumonia",
      "COVID-19 Image Data Collection",
      "SIIM-ACR Pneumothorax Segmentation"
    ]
  },
  {
    "id": "5cFfz6yMVPU",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "$\\mathcal{O}$-GNN: incorporating ring priors into molecular modeling",
    "authors": [
      "Jinhua Zhu",
      "Kehan Wu",
      "Bohan Wang",
      "Yingce Xia",
      "Shufang Xie",
      "Qi Meng",
      "Lijun Wu",
      "Tao Qin",
      "Wengang Zhou",
      "Houqiang Li",
      "Tie-Yan Liu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Cyclic compounds that contain at least one ring play an important role in drug design. Despite the recent success of molecular modeling with graph neural networks (GNNs), few models explicitly take rings in compounds into consideration, consequently limiting the expressiveness of the models. In this work, we design a new variant of GNN, ring-enhanced GNN ($\\mathcal{O}$-GNN), that explicitly models rings in addition to atoms and bonds in compounds. In $\\mathcal{O}$-GNN,  each ring is represented by a latent vector, which contributes to and is iteratively updated by atom and bond representations. Theoretical analysis shows that $\\mathcal{O}$-GNN is able to distinguish two isomorphic subgraphs lying on different rings using only one layer while conventional graph convolutional neural networks require multiple layers to distinguish, demonstrating that $\\mathcal{O}$-GNN is more expressive. Through experiments, $\\mathcal{O}$-GNN shows good performance on $\\bf{11}$ public datasets. In particular, it achieves state-of-the-art validation result on the PCQM4Mv1 benchmark (outperforming the previous KDDCup champion solution) and the drug-drug interaction prediction task on DrugBank. Furthermore, $\\mathcal{O}$-GNN outperforms strong baselines (without modeling rings) on the molecular property prediction and retrosynthesis prediction tasks.",
    "keywords": "Graph Neural Network, Ring, Molecular Modeling",
    "pdf_url": "https://openreview.net/pdf?id=5cFfz6yMVPU",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly targets molecular modeling for drug design (“Cyclic compounds that contain at least one ring play an important role in drug design”), includes a drug–drug interaction prediction task on DrugBank, and focuses on molecular property and retrosynthesis prediction—key activities in drug discovery. These are core applications in Biomedicine AI.",
    "prompt_tokens": 20194,
    "completion_tokens": 128,
    "total_tokens": 20322,
    "topic": "Drug Discovery - Graph Neural Networks",
    "method": "Graph Neural Network (GNN); ring-enhanced modeling",
    "application": "Molecular property prediction; drug-drug interaction prediction; retrosynthesis",
    "code_link": "https://github.com/O-GNN/O-GNN",
    "dataset_name": [
      "PCQM4Mv1",
      "MoleculeNet",
      "FS-Mol",
      "DrugBank",
      "USPTO-50k"
    ]
  },
  {
    "id": "Qc_OopMEBnC",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Learning to Segment from Noisy Annotations: A Spatial Correction Approach",
    "authors": [
      "Jiachen Yao",
      "Yikai Zhang",
      "Songzhu Zheng",
      "Mayank Goswami",
      "Prateek Prasanna",
      "Chao Chen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Noisy labels can significantly affect the performance of deep neural networks (DNNs). In medical image segmentation tasks, annotations are error-prone due to the high demand in annotation time and in the annotators' expertise. Existing methods mostly tackle label noise in classification tasks. Their independent-noise assumptions do not fit label noise in segmentation task. In this paper, we propose a novel noise model for segmentation problems that encodes spatial correlation and bias, which are prominent in segmentation annotations. Further, to mitigate such label noise, we propose a label correction method to recover true label progressively. We provide theoretical guarantees of the correctness of the proposed method. Experiments show that our approach outperforms current state-of-the-art methods on both synthetic and real-world noisy annotations.",
    "keywords": "",
    "pdf_url": "https://openreview.net/pdf?id=Qc_OopMEBnC",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly addresses “medical image segmentation tasks,” noting that “annotations are error-prone” in that domain. Techniques for correcting noisy labels in medical image segmentation are squarely within Healthcare AI, as they directly impact the quality of clinical imaging analyses.",
    "prompt_tokens": 20671,
    "completion_tokens": 114,
    "total_tokens": 20785,
    "topic": "Medical Imaging - Label Noise Correction",
    "method": "Markov process-based label correction; iterative denoising",
    "application": "Segmentation label denoising",
    "code_link": "N/A",
    "dataset_name": [
      "JSRT",
      "ISIC 2017",
      "Brats 2020",
      "LIDC-IDRI",
      "Cityscapes"
    ]
  },
  {
    "id": "kKF8_K-mBbS",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "DiffDock: Diffusion Steps, Twists, and Turns for Molecular Docking",
    "authors": [
      "Gabriele Corso",
      "Hannes Stärk",
      "Bowen Jing",
      "Regina Barzilay",
      "Tommi S. Jaakkola"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Predicting the binding structure of a small molecule ligand to a protein---a task known as molecular docking---is critical to drug design. Recent deep learning methods that treat docking as a regression problem have decreased runtime compared to traditional search-based methods but have yet to offer substantial improvements in accuracy. We instead frame molecular docking as a generative modeling problem and develop DiffDock, a diffusion generative model over the non-Euclidean manifold of ligand poses. To do so, we map this manifold to the product space of the degrees of freedom (translational, rotational, and torsional) involved in docking and develop an efficient diffusion process on this space. Empirically, DiffDock obtains a 38% top-1 success rate (RMSD<2A) on PDBBind, significantly outperforming the previous state-of-the-art of traditional docking (23%) and deep learning (20%) methods. Moreover, while previous methods are not able to dock on computationally folded structures (maximum accuracy 10.4%), DiffDock maintains significantly higher precision (21.7%). Finally, DiffDock has fast inference times and provides confidence estimates with high selective accuracy. ",
    "keywords": "molecular docking, protein-ligand binding, diffusion models, score-based models, molecular structure, equivariance, geometric deep learning",
    "pdf_url": "https://openreview.net/pdf?id=kKF8_K-mBbS",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This paper focuses on molecular docking of small‐molecule ligands to proteins—a core task in drug discovery (“Predicting the binding structure … critical to drug design”). It develops a deep learning method for protein–ligand binding, directly relevant to biomedicine and pharmaceutical research.",
    "prompt_tokens": 20820,
    "completion_tokens": 87,
    "total_tokens": 20907,
    "topic": "Drug Discovery - Molecular Docking",
    "method": "Diffusion model",
    "application": "Binding pose prediction",
    "code_link": "https://github.com/gcorso/DiffDock",
    "dataset_name": [
      "PDBBind"
    ]
  },
  {
    "id": "_geIwiOyUhZ",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Bayes-MIL: A New Probabilistic Perspective on Attention-based Multiple Instance Learning for Whole Slide Images",
    "authors": [
      "Yufei CUI",
      "Ziquan Liu",
      "Xiangyu Liu",
      "Xue Liu",
      "Cong Wang",
      "Tei-Wei Kuo",
      "Chun Jason Xue",
      "Antoni B. Chan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Multiple instance learning (MIL) is a popular weakly-supervised learning model on the whole slide image (WSI) for AI-assisted pathology diagnosis. The recent advance in attention-based MIL allows the model to find its region-of-interest (ROI) for interpretation by learning the attention weights for image patches of WSI slides. However, we empirically find that the interpretability of some related methods is either untrustworthy as the principle of MIL is violated or unsatisfactory as the high-attention regions are not consistent with experts' annotations. In this paper, we propose Bayes-MIL to address the problem from a probabilistic perspective. The induced patch-level uncertainty is proposed as a new measure of MIL interpretability, which outperforms previous methods in matching doctors annotations. We design a slide-dependent patch regularizer (SDPR) for the attention, imposing constraints derived from the MIL assumption, on the attention distribution. SDPR explicitly constrains the model to generate correct attention values. The spatial information is further encoded by an approximate convolutional conditional random field (CRF), for better interpretability. Experimental results show Bayes-MIL outperforms the related methods in patch-level and slide-level metrics and provides much better interpretable ROI on several large-scale WSI datasets. ",
    "keywords": "Multiple instance learning, medical imaging, histopathology, Bayesian neural network",
    "pdf_url": "https://openreview.net/pdf?id=_geIwiOyUhZ",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on multiple instance learning for whole slide images (WSIs) in AI‐assisted pathology diagnosis, explicitly addressing “medical imaging,” “histopathology,” and matching “doctors’ annotations.” These are clear indicators of a healthcare/biomedical application.",
    "prompt_tokens": 20966,
    "completion_tokens": 95,
    "total_tokens": 21061,
    "topic": "Medical Imaging - Whole Slide Images",
    "method": "Attention-based Multiple Instance Learning (MIL); Bayesian modeling",
    "application": "Patch-level tumor region localization; Slide-level classification",
    "code_link": "N/A",
    "dataset_name": [
      "CAMELYON16",
      "CAMELYON17"
    ]
  },
  {
    "id": "77lSWa-Tm3Z",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Variational Information Pursuit for Interpretable Predictions",
    "authors": [
      "Aditya Chattopadhyay",
      "Kwan Ho Ryan Chan",
      "Benjamin David Haeffele",
      "Donald Geman",
      "Rene Vidal"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "There is a growing interest in the machine learning community in developing predictive algorithms that are interpretable by design. To this end, recent work proposes to sequentially ask interpretable queries about data until a high confidence prediction can be made based on the answers obtained (the history). To promote short query-answer chains, a greedy procedure called Information Pursuit (IP) is used, which adaptively chooses queries in order of information gain. Generative models are employed to learn the distribution of query-answers and labels, which is in turn used to estimate the most informative query. However, learning and inference with a full generative model of the data is often intractable for complex tasks. In this work, we propose Variational Information Pursuit (V-IP), a variational characterization of IP which bypasses the need to learn generative models. V-IP is based on finding a query selection strategy and a classifier that minimize the expected cross-entropy between true and predicted labels. We prove that the IP strategy is the optimal solution to this problem. Therefore, instead of learning generative models, we can use our optimal strategy to directly pick the most informative query given any history. We then develop a practical algorithm by defining a finite-dimensional parameterization of our strategy and classifier using deep networks and train them end-to-end using our objective. Empirically, V-IP is 10-100x faster than IP on different Vision and NLP tasks with competitive performance. Moreover, V-IP finds much shorter query chains when compared to reinforcement learning which is typically used in sequential-decision-making problems. Finally, we demonstrate the utility of V-IP on challenging tasks like medical diagnosis where the performance is far superior to the generative modeling approach.",
    "keywords": "Interpretable ML, Explainable AI, Information Pursuit",
    "pdf_url": "https://openreview.net/pdf?id=77lSWa-Tm3Z",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the core contribution is a general interpretable ML framework (Variational Information Pursuit), the abstract explicitly states that the method is demonstrated on “challenging tasks like medical diagnosis,” indicating an application in the healthcare domain.",
    "prompt_tokens": 20729,
    "completion_tokens": 146,
    "total_tokens": 20875,
    "topic": "Learning Algorithms - Interpretable Query Sequences",
    "method": "Variational query optimization; Mutual information",
    "application": "Diagnosis or classification with minimal queries",
    "code_link": "https://github.com/ryanchankh/VariationalInformationPursuit",
    "dataset_name": [
      "MNIST",
      "KMNIST",
      "Fashion-MNIST",
      "CIFAR-10",
      "CIFAR-100",
      "SymCAT",
      "MuZhi",
      "Dxy"
    ]
  },
  {
    "id": "hhvkdRdWt1F",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Dual Algorithmic Reasoning",
    "authors": [
      "Danilo Numeroso",
      "Davide Bacciu",
      "Petar Veličković"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Neural Algorithmic Reasoning is an emerging area of machine learning which seeks to infuse algorithmic computation in neural networks, typically by training neural models to approximate steps of classical algorithms. In this context, much of the current work has focused on learning reachability and shortest path graph algorithms, showing that joint learning on similar algorithms is beneficial for generalisation. However, when targeting more complex problems, such \"similar\" algorithms become more difficult to find. Here, we propose to learn algorithms by exploiting duality of the underlying algorithmic problem. Many algorithms solve optimisation problems. We demonstrate that simultaneously learning the dual definition of these optimisation problems in algorithmic learning allows for better learning and qualitatively better solutions. Specifically, we exploit the max-flow min-cut theorem to simultaneously learn these two algorithms over synthetically generated graphs, demonstrating the effectiveness of the proposed approach. We then validate the real-world utility of our dual algorithmic reasoner by deploying it on a challenging brain vessel classification task, which likely depends on the vessels’ flow properties. We demonstrate a clear performance gain when using our model within such a context, and empirically show that learning the max-flow and min-cut algorithms together is critical for achieving such a result.",
    "keywords": "Algorithmic Reasoning, Deep Learning for Graphs",
    "pdf_url": "https://openreview.net/pdf?id=hhvkdRdWt1F",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the core of the paper focuses on Neural Algorithmic Reasoning and graph algorithms (max-flow/min-cut), the authors validate their approach on a “brain vessel classification task,” which is a medical imaging problem involving cerebral vasculature. This real-world deployment in a clinical context (classifying brain vessels) makes it relevant to Healthcare AI.",
    "prompt_tokens": 20880,
    "completion_tokens": 117,
    "total_tokens": 20997,
    "topic": "Neural Algorithmic Reasoning - Graph Learning",
    "method": "Dual Algorithmic Reasoning (DAR); Graph Neural Networks (GNN)",
    "application": "Edge classification – brain vessel graphs",
    "code_link": "N/A",
    "dataset_name": [
      "Brain Vessel Graphs (CD1-E-1, CD1-E-2, CD1-E-3)",
      "Synthetic brain vessel graph"
    ]
  },
  {
    "id": "TUBpc5rqGA",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Neural Design for Genetic Perturbation Experiments",
    "authors": [
      "Aldo Pacchiano",
      "Drausin Wulsin",
      "Robert A Barton",
      "Luis Voloch"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The problem of how to genetically modify cells in order to maximize a certain cellular phenotype has taken center stage in drug development over the last few years (with, for example, genetically edited CAR-T, CAR-NK, and CAR-NKT cells entering cancer clinical trials). Exhausting the search space for all possible genetic edits (perturbations) or combinations thereof is infeasible due to cost and experimental limitations. This work provides a theoretically sound framework for iteratively exploring the space of perturbations in pooled batches in order to maximize a target phenotype under an experimental budget. Inspired by this application domain, we study the problem of batch query bandit optimization and introduce the Optimistic Arm Elimination ($\\mathrm{OAE}$) principle designed to find an almost optimal arm under different functional relationships between the queries (arms) and the outputs (rewards). We analyze the convergence properties of $\\mathrm{OAE}$ by relating it to the Eluder dimension of the algorithm's function class and validate that $\\mathrm{OAE}$ outperforms other strategies in finding optimal actions in experiments on simulated problems, public datasets well-studied in bandit contexts, and in genetic perturbation datasets when the regression model is a deep neural network. OAE also outperforms the benchmark algorithms in 3 of 4 datasets in the GeneDisco experimental planning challenge. ",
    "keywords": "genetiic perturbation experiments, gene disco, optimism, neural optimism",
    "pdf_url": "https://openreview.net/pdf?id=TUBpc5rqGA",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper’s core application is genetic perturbation experiments for drug development (e.g., “genetically edited CAR-T, CAR-NK, and CAR-NKT cells entering cancer clinical trials”) and optimizing cellular phenotypes via gene edits. This focus on genomics, synthetic biology, and therapeutic cell design clearly places it in the Biomedicine AI domain.",
    "prompt_tokens": 20710,
    "completion_tokens": 112,
    "total_tokens": 20822,
    "topic": "Causal Inference - Bandit Optimization",
    "method": "Optimistic Arm Elimination (OAE); diversity regularization; neural network ensembles",
    "application": "Genetic perturbation optimization",
    "code_link": "N/A",
    "dataset_name": [
      "Adult",
      "Bank",
      "BikeSharingDay",
      "BikeSharingHour",
      "BlogFeedback",
      "GeneDisco"
    ]
  },
  {
    "id": "6TxBxqNME1Y",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Diffusion Probabilistic Modeling of Protein Backbones in 3D for the motif-scaffolding problem",
    "authors": [
      "Brian L. Trippe",
      "Jason Yim",
      "Doug Tischer",
      "David Baker",
      "Tamara Broderick",
      "Regina Barzilay",
      "Tommi S. Jaakkola"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Construction of a scaffold structure that supports a desired motif, conferring protein function, shows promise for the design of vaccines and enzymes. But a general solution to this motif-scaffolding problem remains open. Current machine-learning techniques for scaffold design are either limited to unrealistically small scaffolds (up to length 20) or struggle to produce multiple diverse scaffolds. We propose to learn a distribution over diverse and longer protein backbone structures via an E(3)-equivariant graph neural network. We develop SMCDiff to efficiently sample scaffolds from this distribution conditioned on a given motif; our algorithm is the first to theoretically guarantee conditional samples from a diffusion model in the large-compute limit. We evaluate our designed backbones by how well they align with AlphaFold2-predicted structures. We show that our method can (1) sample scaffolds up to 80 residues and (2) achieve structurally diverse scaffolds for a fixed motif.",
    "keywords": "Diffusion Models, Sequential Monte Carlo, Protein Design, Geometric Deep Learning",
    "pdf_url": "https://openreview.net/pdf?id=6TxBxqNME1Y",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on 3D protein‐backbone design (“motif‐scaffolding”) with clear applications to “vaccines and enzymes,” placing it squarely in protein design and molecular modeling for biomedical purposes. This aligns with drug discovery and synthetic biology efforts within the Biomedicine AI domain.",
    "prompt_tokens": 20581,
    "completion_tokens": 95,
    "total_tokens": 20676,
    "topic": "Bioinformatics - Protein Structure Generation",
    "method": "Diffusion probabilistic models; Sequential Monte Carlo sampling",
    "application": "Protein backbone generation and motif-scaffolding",
    "code_link": "N/A",
    "dataset_name": [
      "Protein Data Bank (PDB)"
    ]
  },
  {
    "id": "LFHFQbjxIiP",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Conditional Antibody Design as 3D Equivariant Graph Translation",
    "authors": [
      "Xiangzhe Kong",
      "Wenbing Huang",
      "Yang Liu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Antibody design is valuable for therapeutic usage and biological research. Existing deep-learning-based methods encounter several key issues: 1) incomplete context for Complementarity-Determining Regions (CDRs) generation; 2) incapability of capturing the entire 3D geometry of the input structure; 3) inefficient prediction of the CDR sequences in an autoregressive manner. In this paper, we propose Multi-channel Equivariant Attention Network (MEAN) to co-design 1D sequences and 3D structures of CDRs. To be specific, MEAN formulates antibody design as a conditional graph translation problem by importing extra components including the target antigen and the light chain of the antibody. Then, MEAN resorts to E(3)-equivariant message passing along with a proposed attention mechanism to better capture the geometrical correlation between different components. Finally, it outputs both the 1D sequences and 3D structure via a multi-round progressive full-shot scheme, which enjoys more efficiency and precision against previous autoregressive approaches. Our method significantly surpasses state-of-the-art models in sequence and structure modeling, antigen-binding CDR design, and binding affinity optimization. Specifically, the relative improvement to baselines is about 23\\% in antigen-binding CDR design and 34\\% for affinity optimization.",
    "keywords": "conditional antibody generation, equivariant, multi-channel attention",
    "pdf_url": "https://openreview.net/pdf?id=LFHFQbjxIiP",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on computational design of antibodies (“Conditional Antibody Design,” “CDRs generation,” “antigen-binding CDR design,” “affinity optimization”), which is directly related to protein engineering for therapeutic use. Antibody and antigen interactions are central to drug discovery and biomedicine applications.",
    "prompt_tokens": 21186,
    "completion_tokens": 139,
    "total_tokens": 21325,
    "topic": "Drug Discovery - Antibody Design",
    "method": "Equivariant Graph Neural Network (E(3)-equivariant GNN); Progressive full-shot decoding",
    "application": "Antigen-binding Complementarity-Determining Region (CDR) design",
    "code_link": "https://github.com/THUNLP-MT/MEAN",
    "dataset_name": [
      "Structural Antibody Database (SAbDab)",
      "RAbD",
      "SKEMPI V2.0"
    ]
  },
  {
    "id": "pRCMXcfdihq",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Protein Sequence and Structure Co-Design with Equivariant Translation",
    "authors": [
      "Chence Shi",
      "Chuanrui Wang",
      "Jiarui Lu",
      "Bozitao Zhong",
      "Jian Tang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Proteins are macromolecules that perform essential functions in all living organisms. Designing novel proteins with specific structures and desired functions has been a long-standing challenge in the field of bioengineering. Existing approaches generate both protein sequence and structure using either autoregressive models or diffusion models, both of which suffer from high inference costs. In this paper, we propose a new approach capable of protein sequence and structure co-design, which iteratively translates both protein sequence and structure into the desired state from random initialization, based on context features given a priori. Our model consists of a trigonometry-aware encoder that reasons geometrical constraints and interactions from context features, and a roto-translation equivariant decoder that translates protein sequence and structure interdependently. Notably, all protein amino acids are updated in one shot in each translation step, which significantly accelerates the inference process. Experimental results across multiple tasks show that our model outperforms previous state-of-the-art baselines by a large margin, and is able to design proteins of high fidelity as regards both sequence and structure, with running time orders of magnitude less than sampling-based methods.",
    "keywords": "protein design, sequence structure co-design, equivariant translation, geometric deep learning",
    "pdf_url": "https://openreview.net/pdf?id=pRCMXcfdihq",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “protein sequence and structure co-design,” a core task in molecular-level bioengineering and biomedicine. It explicitly addresses “designing novel proteins with specific structures and desired functions,” which directly aligns with biomedical research applications such as drug discovery and synthetic biology. The keywords—“protein design,” “molecular modeling”—are strong indicators of relevance to the Biomedicine AI domain.",
    "prompt_tokens": 20351,
    "completion_tokens": 95,
    "total_tokens": 20446,
    "topic": "Bioinformatics - Protein Design",
    "method": "Roto-translation equivariant model; one-shot sequence-structure co-design",
    "application": "Protein sequence and structure co-design",
    "code_link": "N/A",
    "dataset_name": [
      "CATH S40 Dataset"
    ]
  },
  {
    "id": "6K2RM6wVqKu",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Uni-Mol: A Universal 3D Molecular Representation Learning Framework",
    "authors": [
      "Gengmo Zhou",
      "Zhifeng Gao",
      "Qiankun Ding",
      "Hang Zheng",
      "Hongteng Xu",
      "Zhewei Wei",
      "Linfeng Zhang",
      "Guolin Ke"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Molecular representation learning (MRL) has gained tremendous attention due to its critical role in learning from limited supervised data for applications like drug design. In most MRL methods, molecules are treated as 1D sequential tokens or 2D topology graphs, limiting their ability to incorporate 3D information for downstream tasks and, in particular, making it almost impossible for 3D geometry prediction/generation. In this paper, we propose a universal 3D MRL framework, called Uni-Mol, that significantly enlarges the representation ability and application scope of MRL schemes. Uni-Mol contains two pretrained models with the same SE(3) Transformer architecture: a molecular model pretrained by 209M molecular conformations; a pocket model pretrained by 3M candidate protein pocket data. Besides, Uni-Mol contains several finetuning strategies to apply the pretrained models to various downstream tasks. By properly incorporating 3D information, Uni-Mol outperforms SOTA in 14/15 molecular property prediction tasks. Moreover, Uni-Mol achieves superior performance in 3D spatial tasks, including protein-ligand binding pose prediction, molecular conformation generation, etc. The code, model, and data are made publicly available at https://github.com/dptech-corp/Uni-Mol.",
    "keywords": "Representation Learning, Large-Scale 3D Molecular Pretraining, Molecular Property, Protein-Ligand Complex",
    "pdf_url": "https://openreview.net/pdf?id=6K2RM6wVqKu",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on molecular representation learning with explicit applications to drug design (“applications like drug design”), protein–ligand binding pose prediction, and molecular property prediction—all core tasks in biomedical research and drug discovery. These indicate clear relevance to Biomedicine AI.",
    "prompt_tokens": 21189,
    "completion_tokens": 187,
    "total_tokens": 21376,
    "topic": "Drug Discovery - Molecular Representation Learning",
    "method": "Transformer-based models; SE(3)-Equivariant representation learning",
    "application": "Molecular property prediction; Protein-ligand binding pose prediction",
    "code_link": "https://github.com/dptech-corp/Uni-Mol",
    "dataset_name": [
      "BBBP",
      "BACE",
      "ClinTox",
      "Tox21",
      "ToxCast",
      "SIDER",
      "HIV",
      "PCBA",
      "MUV",
      "ESOL",
      "FreeSolv",
      "Lipo",
      "QM7",
      "QM8",
      "QM9",
      "GEOM-QM9",
      "GEOM-Drugs",
      "NRDLD"
    ]
  },
  {
    "id": "KE_wJD2RK4",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Modeling Multimodal Aleatoric Uncertainty in Segmentation with Mixture of Stochastic Experts",
    "authors": [
      "Zhitong Gao",
      "Yucong Chen",
      "Chuyu Zhang",
      "Xuming He"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Equipping predicted segmentation with calibrated uncertainty is essential for safety-critical applications. In this work, we focus on capturing the data-inherent uncertainty (aka aleatoric uncertainty) in segmentation, typically when ambiguities exist in input images. Due to the high-dimensional output space and potential multiple modes in segmenting ambiguous images, it remains challenging to predict well-calibrated uncertainty for segmentation. To tackle this problem, we propose a novel mixture of stochastic experts (MoSE) model, where each expert network estimates a distinct mode of the aleatoric uncertainty and a gating network predicts the probabilities of an input image being segmented in those modes. This yields an efficient two-level uncertainty representation. To learn the model, we develop a Wasserstein-like loss that directly minimizes the distribution distance between the MoSE and ground truth annotations. The loss can easily integrate traditional segmentation quality measures and be efficiently optimized via constraint relaxation. We validate our method on the LIDC-IDRI dataset and a modified multimodal Cityscapes dataset. Results demonstrate that our method achieves the state-of-the-art or competitive performance on all metrics.",
    "keywords": "Semantic Segmentation, Aleatoric Uncertainty, Stochastic Segmentation, Multiple Annotations",
    "pdf_url": "https://openreview.net/pdf?id=KE_wJD2RK4",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper’s method is validated on the LIDC-IDRI dataset, which consists of radiologist-annotated lung CT scans, indicating a clear medical imaging application (segmentation of chest CT). Although the model is also tested on Cityscapes, the use of LIDC-IDRI demonstrates relevance to clinical/healthcare AI in medical image analysis.",
    "prompt_tokens": 21075,
    "completion_tokens": 113,
    "total_tokens": 21188,
    "topic": "Medical Imaging - Semantic Segmentation",
    "method": "Mixture of Stochastic Experts (MoSE); Wasserstein-like loss",
    "application": "Multimodal uncertainty estimation in segmentation",
    "code_link": "https://github.com/gaozhitong/MoSE-AUSeg",
    "dataset_name": [
      "LIDC-IDRI",
      "Cityscapes"
    ]
  },
  {
    "id": "ZxdkjTgK_Dl",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "BSTT: A Bayesian Spatial-Temporal Transformer for Sleep Staging",
    "authors": [
      "Yuchen Liu",
      "Ziyu Jia"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Sleep staging is helpful in assessing sleep quality and diagnosing sleep disorders. However, how to adequately capture the temporal and spatial relations of the brain during sleep remains a challenge. In particular, existing methods cannot adaptively infer spatial-temporal relations of the brain under different sleep stages. In this paper, we propose a novel Bayesian spatial-temporal relation inference neural network, named Bayesian spatial-temporal transformer (BSTT), for sleep staging. Our model is able to adaptively infer brain spatial-temporal relations during sleep for spatial-temporal feature modeling through a well-designed Bayesian relation inference component. Meanwhile, our model also includes a spatial transformer for extracting brain spatial features and a temporal transformer for capturing temporal features. Experiments show that our BSTT outperforms state-of-the-art baselines on ISRUC and MASS datasets. In addition, the visual analysis shows that the spatial-temporal relations obtained by BSTT inference have certain interpretability for sleep staging.\n",
    "keywords": "Spatial-Temporal Transformer, Sleep Staging, Bayesian Deep Learning",
    "pdf_url": "https://openreview.net/pdf?id=ZxdkjTgK_Dl",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on sleep staging—a clinical task used for “assessing sleep quality and diagnosing sleep disorders”—and operates on EEG brain signals (MASS and ISRUC datasets). These elements (sleep disorder diagnosis, EEG-based patient monitoring) clearly place it within Healthcare AI.",
    "prompt_tokens": 20993,
    "completion_tokens": 102,
    "total_tokens": 21095,
    "topic": "Time Series - Sleep Study",
    "method": "Bayesian spatial-temporal transformers; relational inference",
    "application": "Sleep stage classification",
    "code_link": "https://github.com/YuchenLiu1225/BSTT/tree/main/BSTT",
    "dataset_name": [
      "ISRUC",
      "MASS-SS3"
    ]
  },
  {
    "id": "q8vgHfPdoQP",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "When to Make and Break Commitments?",
    "authors": [
      "Alihan Hüyük",
      "Zhaozhi Qian",
      "Mihaela van der Schaar"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In many scenarios, decision-makers must commit to long-term actions until their resolution before receiving the payoff of said actions, and usually, staying committed to such actions incurs continual costs. For instance, in healthcare, a newly-discovered treatment cannot be marketed to patients until a clinical trial is conducted, which both requires time and is also costly. Of course in such scenarios, not all commitments eventually pay off. For instance, a clinical trial might end up failing to show efficacy. Given the time pressure created by the continual cost of keeping a commitment, we aim to answer: When should a decision-maker break a commitment that is likely to fail—either to make an alternative commitment or to make no further commitments at all? First, we formulate this question as a new type of optimal stopping/switching problem called the optimal commitment problem (OCP). Then, we theoretically analyze OCP, and based on the insights we gain, propose a practical algorithm for solving it. Finally, we empirically evaluate the performance of our algorithm in running clinical trials with subpopulation selection.",
    "keywords": "optimal stopping/switching, sequential hypothesis testing, adaptive experimentation",
    "pdf_url": "https://openreview.net/pdf?id=q8vgHfPdoQP",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly formulates and evaluates its algorithm in the context of running “clinical trials with subpopulation selection,” and the abstract opens with a healthcare example of conducting costly clinical trials for new treatments. This focus on sequential decision-making in trial design places it squarely within Healthcare AI.",
    "prompt_tokens": 21103,
    "completion_tokens": 111,
    "total_tokens": 21214,
    "topic": "Clinical Trials - Adaptive Experimentation",
    "method": "Optimal commitment problem (OCP); Bayes-OCP",
    "application": "Subpopulation selection in adaptive trials",
    "code_link": "https://github.com/alihanhyk/optcommit; https://github.com/vanderschaarlab/optcommit",
    "dataset_name": "N/A"
  },
  {
    "id": "ySCL-NG_I3",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Learning Harmonic Molecular Representations on Riemannian Manifold",
    "authors": [
      "Yiqun Wang",
      "Yuning Shen",
      "Shi Chen",
      "Lihao Wang",
      "Fei YE",
      "Hao Zhou"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Molecular representation learning plays a crucial role in AI-assisted drug discovery research. Encoding 3D molecular structures through Euclidean neural networks has become the prevailing method in the geometric deep learning community. However, the equivariance constraints and message passing in Euclidean space may limit the network expressive power. In this work, we propose a Harmonic Molecular Representation learning (HMR) framework, which represents a molecule using the Laplace-Beltrami eigenfunctions of the molecular surface. HMR offers a multi-resolution representation of molecular geometric and chemical properties on 2D Riemannian manifold. We also introduce a harmonic message passing method to realize efficient spectral message passing over the surface manifold for better molecular encoding. Our proposed method shows comparable predictive power to current models in small molecule property prediction, and outperforms the state-of-the-art deep learning models for the rigid protein docking challenge, demonstrating its versatility in molecular representation learning.",
    "keywords": "Riemannian manifold, molecular surface, harmonic analysis, functional map, binding site prediction, rigid protein docking",
    "pdf_url": "https://openreview.net/pdf?id=ySCL-NG_I3",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on molecular representation learning for tasks such as small-molecule property prediction and rigid protein docking, explicitly citing “AI-assisted drug discovery,” “binding site prediction,” and “protein docking.” These are core biomedicine applications in drug design and molecular modeling.",
    "prompt_tokens": 21034,
    "completion_tokens": 128,
    "total_tokens": 21162,
    "topic": "Drug Discovery - Molecular Representation Learning",
    "method": "Harmonic message passing; manifold harmonic analysis",
    "application": "Molecular property prediction; ligand-binding pocket classification; rigid protein docking",
    "code_link": "https://github.com/GeomMolDesign/HMR",
    "dataset_name": [
      "QM9",
      "DIPS",
      "DIPS-Het",
      "Ligand-binding Pocket Classification",
      "Docking Benchmark 5.5"
    ]
  },
  {
    "id": "m9LCdYgN8-6",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "DAG Learning on the Permutahedron",
    "authors": [
      "Valentina Zantedeschi",
      "Luca Franceschi",
      "Jean Kaddour",
      "Matt Kusner",
      "Vlad Niculae"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We propose a continuous optimization framework for discovering a latent directed acyclic graph (DAG) from observational data. Our approach optimizes over the polytope of permutation vectors, the so-called Permutahedron, to learn a topological ordering. Edges can be optimized jointly, or learned conditional on the ordering via a non-differentiable subroutine. Compared to existing continuous optimization approaches our formulation has a number of advantages including: 1. validity: optimizes over exact DAGs as opposed to other relaxations optimizing approximate DAGs; 2. modularity: accommodates any edge-optimization procedure, edge structural parameterization, and optimization loss; 3. end-to-end: either alternately iterates between node-ordering and edge-optimization, or optimizes them jointly; We demonstrate, on real-world data problems in protein-signaling and transcriptional network discovery, that our approach lies on the Pareto frontier of two key metrics, the SID and SHD.",
    "keywords": "directed acyclic graph, causal discovery, differentiable sorting",
    "pdf_url": "https://openreview.net/pdf?id=m9LCdYgN8-6",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the paper proposes a general continuous optimization framework for DAG learning, its primary applications—“protein-signaling” and “transcriptional network discovery”—are core tasks in molecular biology and systems biology. These domains fall under Biomedicine AI, as they involve elucidating biological networks at the protein and gene expression level.",
    "prompt_tokens": 20941,
    "completion_tokens": 110,
    "total_tokens": 21051,
    "topic": "Causal Inference - Graphical Model Learning",
    "method": "Permutation-based causal discovery; SparseMAP relaxation",
    "application": "Directed Acyclic Graph (DAG) structure learning",
    "code_link": "https://github.com/vzantedeschi/DAGuerreotype",
    "dataset_name": [
      "Sachs",
      "SynTReN"
    ]
  },
  {
    "id": "q9VherQJd8_",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Matching receptor to odorant with protein language and graph neural networks",
    "authors": [
      "Matej Hladiš",
      "Maxence Lalis",
      "Sebastien Fiorucci",
      "Jérémie Topin"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Odor perception in mammals is triggered by interactions between volatile organic compounds and a subset of hundreds of proteins called olfactory receptors (ORs). Molecules activate these receptors in a complex combinatorial coding allowing mammals to discriminate a vast number of chemical stimuli. Recently, ORs have gained attention as new therapeutic targets following the discovery of their involvement in other physiological processes and diseases. To date, predicting molecule-induced activation for ORs is highly challenging since $43\\%$ of ORs have no identified active compound. In this work, we combine [CLS] token from protBERT with a molecular graph and propose a tailored GNN architecture incorporating inductive biases from the protein-molecule binding. We abstract the biological process of protein-molecule activation as the injection of a molecule into a protein-specific environment. On a newly gathered dataset of $46$ $700$ OR-molecule pairs, this model outperforms state-of-the-art models on drug-target interaction prediction as well as standard GNN baselines. Moreover, by incorporating non-bonded interactions the model is able to work with mixtures of compounds. Finally, our predictions reveal a similar activation pattern for molecules within a given odor family, which is in agreement with the theory of combinatorial coding in olfaction.",
    "keywords": "Olfaction, protein-ligand binding, olfactory receptors, computational biology, protein language modelling, graph neural networks",
    "pdf_url": "https://openreview.net/pdf?id=q9VherQJd8_",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on predicting molecule-induced activation of olfactory receptors (ORs) using protein language models and graph neural networks. This falls squarely into the domain of molecular modeling and drug-target interaction prediction, which are key tasks in Biomedicine AI. Specifically, the abstract mentions “a newly gathered dataset of 46 700 OR-molecule pairs,” “outperforms state-of-the-art models on drug-target interaction prediction,” and “protein-ligand binding,” all of which are strong indicators of relevance to biomedical research and drug discovery.",
    "prompt_tokens": 20492,
    "completion_tokens": 111,
    "total_tokens": 20603,
    "topic": "Bioinformatics - Olfactory Receptor Activation",
    "method": "Graph Neural Networks (GNN); Multi-head Attention",
    "application": "Molecule-receptor interaction prediction",
    "code_link": "https://github.com/MatejHl/Receptor2Odorant",
    "dataset_name": [
      "M2OR",
      "DAVIS",
      "KIBA"
    ]
  },
  {
    "id": "XGagtiJ8XC",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Multi-level Protein Structure Pre-training via Prompt Learning",
    "authors": [
      "Zeyuan Wang",
      "Qiang Zhang",
      "Shuang-Wei HU",
      "Haoran Yu",
      "Xurui Jin",
      "Zhichen Gong",
      "Huajun Chen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "A protein can focus on different structure levels to implement its functions. Each structure has its own merit and driving forces in describing some specific characteristics, and they cannot replace each other. Most existing function prediction methods take the tertiary structure as input, unintentionally ignoring the other levels of protein structures. Considering protein sequences can determine multi-level structures, in this paper, we aim to realize the comprehensive potential of protein sequences for function prediction. Specifically, we propose a new prompt-guided multi-task pre-training and fine-tuning framework, and the resulting protein model is called PromptProtein. Through the prompt-guided multi-task pre-training, we learn multiple prompt signals to steer the model to focus on different structure levels. We also design a prompt fine-tuning module to provide downstream tasks the on-demand flexibility of utilizing respective levels of structure information. Extensive experiments on function prediction and protein engineering show that PromptProtein outperforms state-of-the-art methods by large margins.",
    "keywords": "protein representation learning, prompt learning, multi-task learning, multi-level structure",
    "pdf_url": "https://openreview.net/pdf?id=XGagtiJ8XC",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This paper focuses on multi‐level protein structure representation learning and applies it to “function prediction” and “protein engineering,” which fall squarely under molecular modeling and protein design—key areas of Biomedicine AI. By targeting protein sequences, structures, and engineering tasks, the work addresses core biomedical challenges in understanding and designing proteins.",
    "prompt_tokens": 20547,
    "completion_tokens": 113,
    "total_tokens": 20660,
    "topic": "Bioinformatics - Protein Function Prediction",
    "method": "Prompt-Guided Multi-Task Learning; Pretrained Protein Models",
    "application": "Protein function annotation and regression tasks",
    "code_link": "N/A",
    "dataset_name": [
      "UniRef50",
      "Protein Data Bank (PDB)",
      "STRING",
      "FLIP",
      "SAbDab"
    ]
  },
  {
    "id": "ICYasJBlZNs",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Predicting Cellular Responses with Variational Causal Inference and Refined Relational Information",
    "authors": [
      "Yulun Wu",
      "Rob Barton",
      "Zichen Wang",
      "Vassilis N. Ioannidis",
      "Carlo De Donno",
      "Layne C Price",
      "Luis F. Voloch",
      "George Karypis"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Predicting the responses of a cell under perturbations may bring important benefits to drug discovery and personalized therapeutics. In this work, we propose a novel graph variational Bayesian causal inference framework to predict a cell's gene expressions under counterfactual perturbations (perturbations that this cell did not factually receive), leveraging information representing biological knowledge in the form of gene regulatory networks (GRNs) to aid individualized cellular response predictions. Aiming at a data-adaptive GRN, we also developed an adjacency matrix updating technique for graph convolutional networks and used it to refine GRNs during pre-training, which generated more insights on gene relations and enhanced model performance. Additionally, we propose a robust estimator within our framework for the asymptotically efficient estimation of marginal perturbation effect, which is yet to be carried out in previous works. With extensive experiments, we exhibited the advantage of our approach over state-of-the-art deep learning models for individual response prediction.",
    "keywords": "graph neural network, causal inference, variational bayes, asymptotic statistics, single-cell perturbation",
    "pdf_url": "https://openreview.net/pdf?id=ICYasJBlZNs",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on predicting cellular gene‐expression responses under perturbations with applications in “drug discovery and personalized therapeutics,” uses “gene regulatory networks (GRNs)” and “single-cell perturbation,” all of which are core topics in biomedical research. This clearly situates the work in the Biomedicine AI domain.",
    "prompt_tokens": 20403,
    "completion_tokens": 111,
    "total_tokens": 20514,
    "topic": "Bioinformatics - Gene Network",
    "method": "Graph Neural Networks (GNN); Variational Bayesian Causal Inference",
    "application": "Gene expression prediction under perturbations",
    "code_link": "https://github.com/yulun-rayn/graphVCI",
    "dataset_name": [
      "SciPlex",
      "Marson",
      "L008"
    ]
  },
  {
    "id": "OXP9Ns0gnIq",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Differentiable Gaussianization Layers for Inverse Problems Regularized by Deep Generative Models",
    "authors": [
      "Dongzhuo Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Deep generative models such as GANs, normalizing flows, and diffusion models are powerful regularizers for inverse problems. They exhibit great potential for helping reduce ill-posedness and attain high-quality results. However, the latent tensors of such deep generative models can fall out of the desired high-dimensional standard Gaussian distribution during inversion, particularly in the presence of data noise and inaccurate forward models, leading to low-fidelity solutions. To address this issue, we propose to reparameterize and Gaussianize the latent tensors using novel differentiable data-dependent layers wherein custom operators are defined by solving optimization problems. These proposed layers constrain inverse problems to obtain high-fidelity in-distribution solutions. We validate our technique on three inversion tasks: compressive-sensing MRI, image deblurring, and eikonal tomography (a nonlinear PDE-constrained inverse problem) using two representative deep generative models: StyleGAN2 and Glow. Our approach achieves state-of-the-art performance in terms of accuracy and consistency.",
    "keywords": "Deep generative models, inverse problems, Gaussianization",
    "pdf_url": "https://openreview.net/pdf?id=OXP9Ns0gnIq",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the core contribution is a general inverse-problem regularization method, one of the primary applications evaluated is compressive-sensing MRI—a medical imaging modality (see “compressive-sensing MRI” in the abstract). Medical imaging tasks such as MRI reconstruction fall squarely under Healthcare AI.",
    "prompt_tokens": 20770,
    "completion_tokens": 125,
    "total_tokens": 20895,
    "topic": "Medical Imaging - Tomography",
    "method": "Generative flow networks; Gaussianization layers; ICA",
    "application": "Compressive sensing MRI; Image deblurring; Eikonal traveltime tomography",
    "code_link": "N/A",
    "dataset_name": [
      "fastMRI",
      "TCIA-GBM",
      "OASIS-3",
      "CelebA-HQ"
    ]
  },
  {
    "id": "UaAD-Nu86WX",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "DiGress: Discrete Denoising diffusion for graph generation",
    "authors": [
      "Clement Vignac",
      "Igor Krawczuk",
      "Antoine Siraudin",
      "Bohan Wang",
      "Volkan Cevher",
      "Pascal Frossard"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "This work introduces DiGress, a discrete denoising diffusion model for generating graphs with categorical node and edge attributes.\nOur model utilizes a discrete diffusion process that progressively edits graphs with noise, through the process of adding or removing edges and changing the categories.\nA graph transformer network is trained to revert this process, simplifying the problem of distribution learning over graphs into a sequence of node and edge classification tasks.\nWe further improve sample quality by introducing a Markovian noise model that preserves the marginal distribution of node and edge types during diffusion, and by incorporating auxiliary graph-theoretic features.\nA procedure for conditioning the generation on graph-level features is also proposed.\nDiGress achieves state-of-the-art performance on molecular and non-molecular datasets, with up to 3x validity improvement on a planar graph dataset. \nIt is also the first model to scale to the large GuacaMol dataset containing 1.3M drug-like molecules without the use of molecule-specific representations.",
    "keywords": "Graph generation, Denoising Diffusion Model, Molecule Generation, Permutation Equivariance, Discrete Diffusion",
    "pdf_url": "https://openreview.net/pdf?id=UaAD-Nu86WX",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on generative models for graphs and explicitly evaluates on “molecular datasets” and the GuacaMol benchmark of “1.3M drug-like molecules,” directly placing it in the domain of molecular design and drug discovery, which are core topics in Biomedicine AI.",
    "prompt_tokens": 20905,
    "completion_tokens": 108,
    "total_tokens": 21013,
    "topic": "Generative Models - Molecular Graphs",
    "method": "Discrete denoising diffusion model; Graph transformer network; Auxiliary structural features",
    "application": "Graph generation",
    "code_link": "https://github.com/cvignac/DiGress",
    "dataset_name": [
      "QM9",
      "MOSES",
      "GuacaMol"
    ]
  },
  {
    "id": "vDFA1tpuLvk",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Retrieval-based Controllable Molecule Generation",
    "authors": [
      "Zichao Wang",
      "Weili Nie",
      "Zhuoran Qiao",
      "Chaowei Xiao",
      "Richard Baraniuk",
      "Anima Anandkumar"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Generating new molecules with specified chemical and biological properties via generative models has emerged as a promising direction for drug discovery. However, existing methods require extensive training/fine-tuning with a large dataset, often unavailable in real-world generation tasks. In this work, we propose a new retrieval-based framework for controllable molecule generation. We use a small set of exemplar molecules,  i.e., those that (partially) satisfy the design criteria, to steer the pre-trained generative model towards synthesizing molecules that satisfy the given design criteria. We design a retrieval mechanism that retrieves and fuses the exemplar molecules with the input molecule, which is trained by a new self-supervised objective that predicts the nearest neighbor of the input molecule. We also propose an iterative refinement process to dynamically update the generated molecules and retrieval database for better generalization. Our approach is agnostic to the choice of generative models and requires no task-specific fine-tuning. On various tasks ranging from simple design criteria to a challenging real-world scenario for designing lead compounds that bind to the SARS-CoV-2 main protease, we demonstrate our approach extrapolates well beyond the retrieval database, and achieves better performance and wider applicability than previous methods.",
    "keywords": "controllable molecule generation, retrieval mechanism, exemplar molecules, drug discovery",
    "pdf_url": "https://openreview.net/pdf?id=vDFA1tpuLvk",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “controllable molecule generation” for “drug discovery,” specifically designing “lead compounds that bind to the SARS-CoV-2 main protease.” These are clear indicators of a biomedical application at the molecular level, fitting squarely within Biomedicine AI (drug discovery and molecular modeling).",
    "prompt_tokens": 20668,
    "completion_tokens": 106,
    "total_tokens": 20774,
    "topic": "Drug Discovery - Target-based",
    "method": "Retrieval-augmented molecule generation; Information fusion; Iterative refinement",
    "application": "Optimized molecular design – SARS-CoV-2 main protease inhibitors",
    "code_link": "N/A",
    "dataset_name": [
      "ZINC250k",
      "ChEMBL"
    ]
  },
  {
    "id": "sO1QiAftQFv",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "E3Bind: An End-to-End Equivariant Network for Protein-Ligand Docking",
    "authors": [
      "Yangtian Zhang",
      "Huiyu Cai",
      "Chence Shi",
      "Jian Tang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In silico prediction of the ligand binding pose to a given protein target is a crucial but challenging task in drug discovery.\nThis work focuses on blind flexible self-docking, where we aim to predict the positions, orientations and conformations of docked molecules. Traditional physics-based methods usually suffer from inaccurate scoring functions and high inference cost. Recently, data-driven methods based on deep learning techniques are attracting growing interest thanks to their efficiency during inference and promising performance. These methods usually either adopt a two-stage approach by first predicting the distances between proteins and ligands and then generating the final coordinates based on the predicted distances, or directly predicting the global roto-translation of ligands. In this paper, we take a different route. Inspired by the resounding success of AlphaFold2 for protein structure prediction, we propose E3Bind, an end-to-end equivariant network that iteratively updates the ligand pose. E3Bind models the protein-ligand interaction through careful consideration of the geometric constraints in docking and the local context of the binding site. Experiments on standard benchmark datasets demonstrate the superior performance of our end-to-end trainable model compared to traditional and recently-proposed deep learning methods.",
    "keywords": "protein-ligand docking, end-to-end training, iterative refinement framework, geometric deep learning",
    "pdf_url": "https://openreview.net/pdf?id=sO1QiAftQFv",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “protein-ligand docking,” a core problem in structure‐based drug discovery. It describes an end‐to‐end equivariant network for predicting ligand binding poses to protein targets, directly referencing “in silico prediction of the ligand binding pose” and “drug discovery.” Such molecular modeling methods are fundamental to Biomedicine AI.",
    "prompt_tokens": 20375,
    "completion_tokens": 95,
    "total_tokens": 20470,
    "topic": "Drug Discovery - Target-based",
    "method": "Protein-ligand docking; E(3)-equivariant network",
    "application": "Prediction of docked ligand poses",
    "code_link": "N/A",
    "dataset_name": [
      "PDBbind v2020"
    ]
  },
  {
    "id": "9OmCr1q54Z",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "AE-FLOW: Autoencoders with Normalizing Flows  for  Medical Images Anomaly Detection ",
    "authors": [
      "Yuzhong Zhao",
      "Qiaoqiao Ding",
      "Xiaoqun Zhang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Anomaly detection from medical images is an important task for clinical screening and diagnosis. In general, a large dataset of normal images are available while only few abnormal images can be collected in clinical practice. By mimicking the diagnosis process of radiologists, we attempt to tackle this problem by learning a tractable distribution of normal images and identify anomalies by differentiating the original image and the reconstructed normal image. More specifically, we propose a normalizing flow-based autoencoder for an efficient and tractable representation of normal medical images. The anomaly score consists of the likelihood originated from the normalizing  flow  and the reconstruction error of the autoencoder, which allows to identify the abnormality and provide an interpretability at both image and pixel levels. Experimental evaluation on two  medical images datasets showed that the proposed model outperformed the other approaches by a large margin, which validated the  effectiveness and robustness of the proposed method.",
    "keywords": "Anomaly Detection, Normalizing Flow, Auto-encoder.",
    "pdf_url": "https://openreview.net/pdf?id=9OmCr1q54Z",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly targets “medical images anomaly detection” for “clinical screening and diagnosis,” mentions mimicking the process of “radiologists,” and evaluates on “medical image datasets.” These keywords and the focus on diagnostic imaging firmly place it in the Healthcare AI domain.",
    "prompt_tokens": 20621,
    "completion_tokens": 111,
    "total_tokens": 20732,
    "topic": "Medical Imaging - Anomaly Detection",
    "method": "Normalizing flows; autoencoder",
    "application": "Medical anomaly detection",
    "code_link": "https://github.com/VLL-HD/FrEIA",
    "dataset_name": [
      "OCT",
      "Chest X-ray",
      "ISIC2018",
      "BraTS2021",
      "MIIC"
    ]
  },
  {
    "id": "Do9MOlwWHu0",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Learning Sparse Group Models Through Boolean Relaxation",
    "authors": [
      "Yijie Wang",
      "Yuan Zhou",
      "Xiaoqing Huang",
      "Kun Huang",
      "Jie Zhang",
      "Jianzhu Ma"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We introduce an efficient algorithmic framework for learning sparse group models formulated as the natural convex relaxation of a cardinality-constrained program with Boolean variables. We provide theoretical techniques to characterize the equivalent condition when the relaxation achieves the exact integral optimal solution, as well as a rounding algorithm to produce a feasible integral solution once the optimal relaxation solution is fractional. We demonstrate the power of our equivalent condition by applying it to two ensembles of random problem instances that are challenging and popularly used in literature and prove that our method achieves exactness with overwhelming probability and nearly optimal sample complexity. Empirically, we use synthetic datasets to demonstrate that our proposed method significantly outperforms the state-of-the-art group sparse learning models in terms of individual and group support recovery when the number of samples is small. Furthermore, we show the out-performance of our method in cancer drug response prediction.",
    "keywords": "Structured sparisity, Convex relaxation, Cardinality-constrained program, Small sample size",
    "pdf_url": "https://openreview.net/pdf?id=Do9MOlwWHu0",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the core contribution is a general sparse‐group learning algorithm, the paper explicitly applies it to “cancer drug response prediction,” a biomedical task. The model’s demonstrated superiority on predicting drug response in oncology indicates clear relevance to Biomedicine AI.",
    "prompt_tokens": 20854,
    "completion_tokens": 137,
    "total_tokens": 20991,
    "topic": "Cancer Research - Drug Response Prediction",
    "method": "Sparse group models; Boolean relaxation",
    "application": "Drug response prediction",
    "code_link": "https://anonymous.4open.science/r/L0GL-F107/Readme",
    "dataset_name": [
      "Cancer Therapeutics Response Portal (CTRP) v2",
      "Genomics of Drug Sensitivity in Cancer (GDSC)",
      "CCLE"
    ]
  },
  {
    "id": "v3y68gz-WEz",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Riemannian Metric Learning via Optimal Transport",
    "authors": [
      "Christopher Scarvelis",
      "Justin Solomon"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We introduce an optimal transport-based model for learning a metric tensor from cross-sectional samples of evolving probability measures on a common Riemannian manifold. We neurally parametrize the metric as a spatially-varying matrix field and efficiently optimize our model's objective using a simple alternating scheme. Using this learned metric, we can non-linearly interpolate between probability measures and compute geodesics on the manifold. We show that metrics learned using our method improve the quality of trajectory inference on scRNA and bird migration data at the cost of little additional cross-sectional data.",
    "keywords": "optimal transport, riemannian geometry, manifold learning, time series",
    "pdf_url": "https://openreview.net/pdf?id=v3y68gz-WEz",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper applies its Riemannian metric learning method to trajectory inference on scRNA data (“scRNA” refers to single-cell RNA sequencing), which is a core task in biomedical research (“single-cell analysis,” “trajectory inference”). Although the methodology is general, the concrete application to scRNA places it within the Biomedicine AI domain.",
    "prompt_tokens": 20767,
    "completion_tokens": 99,
    "total_tokens": 20866,
    "topic": "Ecological Modeling - Migratory Trajectories",
    "method": "Optimal Transport; Riemannian Metric Learning",
    "application": "Trajectory inference - Migratory Birds",
    "code_link": "N/A",
    "dataset_name": [
      "eBird Basic Dataset",
      "Banks Island SNGO"
    ]
  },
  {
    "id": "zaq4LV55xHl",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "On Pre-training Language Model for Antibody",
    "authors": [
      "Danqing Wang",
      "Fei YE",
      "Hao Zhou"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Antibodies are vital proteins offering robust protection for the human body from pathogens. The development of general protein and antibody-specific pre-trained language models both facilitate antibody prediction tasks. However, there have been limited studies that comprehensively explore the representation capability of distinct pre-trained language models on different antibody tasks. To investigate the problem, we aim to answer several key questions in this paper, such as how pre-trained language models perform in antibody tasks with different specificity and how introducing specific biological mechanisms to the pre-training process can benefit the model. Additionally, we evaluate if the learned antibody pre-trained representations can be applied to real-world antibody problems, like drug discovery and immune process understanding. Previously, no benchmark available largely hindered the study to answer these questions. To aid in our investigation, we provide an AnTibody Understanding Evaluation (ATUE) benchmark. We comprehensively evaluate the performance of protein pre-trained language models by empirical study along with conclusions and new insights. Our ATUE and code are released at https://github.com/dqwang122/EATLM.",
    "keywords": "",
    "pdf_url": "https://openreview.net/pdf?id=zaq4LV55xHl",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work focuses on pre-training language models specifically for antibodies—key biological molecules—and evaluates their use in real-world antibody problems such as drug discovery and immune process understanding. It falls squarely under Biomedicine AI because it applies AI techniques to protein/antibody representation and therapeutic design.",
    "prompt_tokens": 20936,
    "completion_tokens": 167,
    "total_tokens": 21103,
    "topic": "Bioinformatics - Antibody Evolution",
    "method": "Pre-trained protein language models (PPLMs); pre-trained antibody language models (PALMs); evolutionary antibody-tailored language model (EATLM)",
    "application": "Antibody representation learning – SARS-CoV-2 antibody discovery",
    "code_link": "https://github.com/dqwang122/EATLM",
    "dataset_name": [
      "Observed Antibody Space (OAS)",
      "CoV-AbDab",
      "Mason et al. (2021)",
      "Liberis et al. (2018)",
      "Mroczek et al. (2014)"
    ]
  },
  {
    "id": "0vqjc50HfcC",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "DDM$^2$: Self-Supervised Diffusion MRI Denoising with Generative Diffusion Models",
    "authors": [
      "Tiange Xiang",
      "Mahmut Yurt",
      "Ali B Syed",
      "Kawin Setsompop",
      "Akshay Chaudhari"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Magnetic resonance imaging (MRI) is a common and life-saving medical imaging technique. However, acquiring high signal-to-noise ratio MRI scans requires long scan times, resulting in increased costs and patient discomfort, and decreased throughput. Thus, there is great interest in denoising MRI scans, especially for the subtype of diffusion MRI scans that are severely SNR-limited. While most prior MRI denoising methods are supervised in nature, acquiring supervised training datasets for the multitude of anatomies, MRI scanners, and scan parameters proves impractical. Here, we propose Denoising Diffusion Models for Denoising Diffusion MRI (DDM^2), a self-supervised denoising method for MRI denoising using diffusion denoising generative models. Our three-stage framework integrates statistic-based denoising theory into diffusion models and performs denoising through conditional generation. During inference, we represent input noisy measurements as a sample from an intermediate posterior distribution within the diffusion Markov chain. We conduct experiments on 4 real-world in-vivo diffusion MRI datasets and show that our DDM^2 demonstrates superior denoising performances ascertained with clinically-relevant visual qualitative and quantitative metrics.",
    "keywords": "Unsupervised MRI Denoising, Diffusion Models",
    "pdf_url": "https://openreview.net/pdf?id=0vqjc50HfcC",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on denoising diffusion MRI scans, which are a critical medical imaging modality used in clinical and research settings. By improving the quality of MRI data (“high signal-to-noise ratio MRI scans,” “diffusion MRI scans”), the work directly addresses a healthcare imaging problem. The abstract’s mention of “clinically-relevant visual qualitative and quantitative metrics” further confirms its relevance to Healthcare AI.",
    "prompt_tokens": 20650,
    "completion_tokens": 129,
    "total_tokens": 20779,
    "topic": "Medical Imaging - MRI Denoising",
    "method": "Diffusion model; self-supervised learning",
    "application": "MRI denoising – diffusion MRI",
    "code_link": "https://github.com/StanfordMIMI/DDM2",
    "dataset_name": [
      "gSlider",
      "Sherbrooke 3-Shell",
      "Stanford HARDI",
      "PPMI",
      "SKM-TEA"
    ]
  },
  {
    "id": "wsZsjOSytRA",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "3D UX-Net: A Large Kernel Volumetric ConvNet Modernizing Hierarchical Transformer for Medical Image Segmentation",
    "authors": [
      "Ho Hin Lee",
      "Shunxing Bao",
      "Yuankai Huo",
      "Bennett A. Landman"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The recent 3D medical ViTs (e.g., SwinUNETR) achieve the state-of-the-art performances on several 3D volumetric data benchmarks, including 3D medical image segmentation. Hierarchical transformers (e.g., Swin Transformers) reintroduced several ConvNet priors and further enhanced the practical viability of adapting volumetric segmentation in 3D medical datasets. The effectiveness of hybrid approaches is largely credited to the large receptive field for non-local self-attention and the large number of model parameters. We hypothesize that volumetric ConvNets can simulate the large receptive field behavior of these learning approaches with fewer model parameters using depth-wise convolution. In this work, we propose a lightweight volumetric ConvNet, termed 3D UX-Net, which adapts the hierarchical transformer using ConvNet modules for robust volumetric segmentation. Specifically, we revisit volumetric depth-wise convolutions with large kernel (LK) size (e.g. starting from $7\\times7\\times7$) to enable the larger global receptive fields, inspired by Swin Transformer. We further substitute the multi-layer perceptron (MLP) in Swin Transformer blocks with pointwise depth convolutions and enhance model performances with fewer normalization and activation layers, thus reducing the number of model parameters. 3D UX-Net competes favorably with current SOTA transformers (e.g. SwinUNETR) using three challenging public datasets on volumetric brain and abdominal imaging: 1) MICCAI Challenge 2021 FLARE, 2) MICCAI Challenge 2021 FeTA, and 3) MICCAI Challenge 2022 AMOS. 3D UX-Net consistently outperforms SwinUNETR with improvement from 0.929 to 0.938 Dice (FLARE2021) and 0.867 to 0.874 Dice (Feta2021). We further evaluate the transfer learning capability of 3D UX-Net with AMOS2022 and demonstrates another improvement of $2.27\\%$ Dice (from 0.880 to 0.900). The source code with our proposed model are available at https://github.com/MASILab/3DUX-Net.",
    "keywords": "Depth-wise Convolution, Large Kernel Convolution, Convolutional Neural Network, Hierarchical Transformer, Volumetric Segmentation, Medical Image Segmentation",
    "pdf_url": "https://openreview.net/pdf?id=wsZsjOSytRA",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on 3D volumetric medical image segmentation, explicitly citing 3D medical ViTs, “volumetric brain and abdominal imaging,” and benchmarks from MICCAI Challenges (FLARE, FeTA, AMOS). These are standard medical imaging tasks (e.g., CT/MRI segmentation), which places it squarely in the Healthcare AI domain.",
    "prompt_tokens": 20783,
    "completion_tokens": 105,
    "total_tokens": 20888,
    "topic": "Medical Imaging - Volume Segmentation",
    "method": "Depthwise convolution; hierarchical transformers",
    "application": "Volumetric segmentation",
    "code_link": "https://github.com/MASILab/3DUX-Net",
    "dataset_name": [
      "FeTA2021",
      "FLARE2021",
      "AMOS2022"
    ]
  },
  {
    "id": "XrMWUuEevr",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Context-enriched molecule representations improve few-shot drug discovery",
    "authors": [
      "Johannes Schimunek",
      "Philipp Seidl",
      "Lukas Friedrich",
      "Daniel Kuhn",
      "Friedrich Rippmann",
      "Sepp Hochreiter",
      "Günter Klambauer"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "A central task in computational drug discovery is to construct models from known active molecules to find further promising molecules for subsequent screening. However, typically only very few active molecules are known. Therefore, few-shot learning methods have the potential to improve the effectiveness of this critical phase of the drug discovery process. We introduce a new method for few-shot drug discovery. Its main idea is to enrich a molecule representation by knowledge about known context or reference molecules. Our novel concept for molecule representation enrichment is to associate molecules from both the support set and the query set with a large set of reference (context) molecules through a modern Hopfield network. Intuitively, this enrichment step is analogous to a human expert who would associate a given molecule with familiar molecules whose properties are known. The enrichment step reinforces and amplifies the covariance structure of the data, while simultaneously removing spurious correlations arising from the decoration of molecules. Our approach is compared with other few-shot methods for drug discovery on the FS-Mol benchmark dataset. On FS-Mol, our approach outperforms all compared methods and therefore sets a new state-of-the art for few-shot learning in drug discovery. An ablation study shows that the enrichment step of our method is the key to improve the predictive quality. In a domain shift experiment, we further demonstrate the robustness of our method.",
    "keywords": "",
    "pdf_url": "https://openreview.net/pdf?id=XrMWUuEevr",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper addresses few-shot learning for drug discovery, focusing on representing and screening molecules—clearly a biomedical application in the domain of *drug discovery*. It evaluates methods on the FS-Mol drug discovery benchmark and discusses active molecules and screening, which are strong indicators of Biomedicine AI.",
    "prompt_tokens": 20710,
    "completion_tokens": 99,
    "total_tokens": 20809,
    "topic": "Drug Discovery - Few-shot Learning",
    "method": "Modern Hopfield Networks for context enrichment; few-shot learning; cross-attention",
    "application": "Molecular property prediction",
    "code_link": "https://github.com/ml-jku/MHNfs",
    "dataset_name": [
      "FS-Mol",
      "Tox21"
    ]
  },
  {
    "id": "4MbGnp4iPQ",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Equivariant Shape-Conditioned Generation of 3D Molecules for Ligand-Based Drug Design",
    "authors": [
      "Keir Adams",
      "Connor W. Coley"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Shape-based virtual screening is widely used in ligand-based drug design to search chemical libraries for molecules with similar 3D shapes yet novel 2D graph structures compared to known ligands. 3D deep generative models can potentially automate this exploration of shape-conditioned 3D chemical space; however, no existing models can reliably generate geometrically realistic drug-like molecules in conformations with a specific shape. We introduce a new multimodal 3D generative model that enables shape-conditioned 3D molecular design by equivariantly encoding molecular shape and variationally encoding chemical identity. We ensure local geometric and chemical validity of generated molecules by using autoregressive fragment-based generation with heuristic bonding geometries, allowing the model to prioritize the scoring of rotatable bonds to best align the growing conformation to the target shape. We evaluate our 3D generative model in tasks relevant to drug design including shape-conditioned generation of chemically diverse molecular structures and shape-constrained molecular property optimization, demonstrating its utility over virtual screening of enumerated libraries.",
    "keywords": "molecules, equivariance, generation",
    "pdf_url": "https://openreview.net/pdf?id=4MbGnp4iPQ",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper addresses shape-based virtual screening in ligand-based drug design and introduces a 3D generative model for creating drug-like molecules. This work directly targets drug discovery, a core area of Biomedicine AI.",
    "prompt_tokens": 20638,
    "completion_tokens": 100,
    "total_tokens": 20738,
    "topic": "Drug Discovery - Shape-conditioned Molecular Design",
    "method": "Equivariant generative model; shape-constrained optimization",
    "application": "3D molecular structure generation conditioned on shape",
    "code_link": "https://github.com/keiradams/SQUID",
    "dataset_name": [
      "MOSES"
    ]
  },
  {
    "id": "lcSfirnflpW",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "ManyDG: Many-domain Generalization for Healthcare Applications",
    "authors": [
      "Chaoqi Yang",
      "M Brandon Westover",
      "Jimeng Sun"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The vast amount of health data has been continuously collected for each patient, providing opportunities to support diverse healthcare predictive tasks such as seizure detection and hospitalization prediction. Existing models are mostly trained on other patients’ data and evaluated on new patients. Many of them might suffer from poor generalizability. One key reason can be overfitting due to the unique information related to patient identities and their data collection environments, referred to as patient covariates in the paper. These patient covariates usually do not contribute to predicting the targets but are often difficult to remove. As a result, they can bias the model training process and impede generalization. In healthcare applications, most existing domain generalization methods assume a small number of domains. In this paper, considering the diversity of patient covariates, we propose a new setting by treating each patient as a separate domain (leading to many domains). We develop a new domain generalization method ManyDG, that can scale to such many-domain problems. Our method identifies the patient do- main covariates by mutual reconstruction, and removes them via an orthogonal projection step. Extensive experiments show that ManyDG can boost the generalization performance on multiple real-world healthcare tasks (e.g., 3.7% Jaccard improvements on MIMIC drug recommendation) and support realistic but challenging settings such as insufficient data and continuous learning. The code is available at https://github.com/ycq091044/ManyDG. ",
    "keywords": "Patient covariate shift, Domain Generalization, Healthcare, EEG, EHR",
    "pdf_url": "https://openreview.net/pdf?id=lcSfirnflpW",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses explicitly on healthcare predictive tasks—“seizure detection,” “hospitalization prediction,” and “drug recommendation” using real-world clinical datasets such as MIMIC (an EHR database) and EEG data. It addresses patient covariate shift in healthcare applications and aims to improve generalization on patient data, which clearly places it in the Healthcare AI domain.",
    "prompt_tokens": 21054,
    "completion_tokens": 120,
    "total_tokens": 21174,
    "topic": "EHR - Generalization",
    "method": "Siamese-type architecture; latent generative model; orthogonal projection",
    "application": "Drug recommendation and readmission prediction",
    "code_link": "https://github.com/ycq091044/ManyDG",
    "dataset_name": [
      "MIMIC-III",
      "eICU",
      "Sleep-EDF",
      "Seizure Dataset"
    ]
  },
  {
    "id": "op-ceGueqc4",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Scaling Laws For Deep Learning Based Image Reconstruction",
    "authors": [
      "Tobit Klug",
      "Reinhard Heckel"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Deep neural networks trained end-to-end to map a measurement of a (noisy) image to a clean image perform excellent for a variety of linear inverse problems. \nCurrent methods are only trained on a few hundreds or thousands of images as opposed to the millions of examples deep networks are trained on in other domains. \nIn this work, we study whether major performance gains are expected from scaling up the training set size.\nWe consider image denoising, accelerated magnetic resonance imaging, and super-resolution and empirically determine the reconstruction quality as a function of training set size, while simultaneously scaling the network size.  \nFor all three tasks we find that an initially steep power-law scaling slows significantly already at moderate training set sizes. \nInterpolating those scaling laws suggests that even training on millions of images would not significantly improve performance. \nTo understand the expected behavior, we analytically characterize the performance of a linear estimator learned with early stopped gradient descent. \nThe result formalizes the intuition that once the error induced by learning the signal model is small relative to the error floor, more training examples do not improve performance.",
    "keywords": "scaling laws, number of training examples, inverse problems, deep learning, denoising, magnetic resonance imaging, super-resolution",
    "pdf_url": "https://openreview.net/pdf?id=op-ceGueqc4",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the paper focuses on general deep‐learning scaling laws for image reconstruction, one of its core applications is “accelerated magnetic resonance imaging,” which is explicitly a medical imaging modality. Medical imaging (e.g., MRI) is a recognized Healthcare AI domain, and techniques that improve reconstruction quality directly impact clinical imaging workflows.",
    "prompt_tokens": 20735,
    "completion_tokens": 131,
    "total_tokens": 20866,
    "topic": "Medical Imaging - Reconstruction",
    "method": "Empirical scaling laws; Image denoising; Compressive sensing",
    "application": "Accelerated MRI reconstruction",
    "code_link": "https://github.com/MLI-lab/Scaling_Laws_For_Deep_Learning_Based_Image_Reconstruction",
    "dataset_name": [
      "fastMRI",
      "ImageNet"
    ]
  },
  {
    "id": "FE99-fDrWd5",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Semi-Parametric Inducing Point Networks and Neural Processes",
    "authors": [
      "Richa Rastogi",
      "Yair Schiff",
      "Alon Hacohen",
      "Zhaozhi Li",
      "Ian Lee",
      "Yuntian Deng",
      "Mert R. Sabuncu",
      "Volodymyr Kuleshov"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We introduce semi-parametric inducing point networks (SPIN), a general-purpose architecture that can query the training set at inference time in a compute-efficient manner. Semi-parametric architectures are typically more compact than parametric models, but their computational complexity is often quadratic. In contrast, SPIN attains linear complexity via a cross-attention mechanism between datapoints inspired by inducing point methods. Querying large training sets can be particularly useful in meta-learning, as it unlocks additional training signal, but often exceeds the scaling limits of existing models. We use SPIN as the basis of the Inducing Point Neural Process, a probabilistic model which supports large contexts in meta-learning and achieves high accuracy where existing models fail. In our experiments, SPIN reduces memory requirements, improves accuracy across a range of meta-learning tasks, and improves state-of-the-art performance on an important practical problem, genotype imputation.",
    "keywords": "",
    "pdf_url": "https://openreview.net/pdf?id=FE99-fDrWd5",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: While the paper primarily develops a general-purpose meta-learning architecture (SPIN), it explicitly demonstrates application to “genotype imputation,” a core problem in genomics and biomedical research. Genotype imputation is a well-established technique in biomedical and clinical genetics, making this work relevant to the Biomedicine AI domain.",
    "prompt_tokens": 39501,
    "completion_tokens": 132,
    "total_tokens": 39633,
    "topic": "Bioinformatics - Genotype Imputation",
    "method": "Semi-parametric inducing point networks (SPIN); cross-attention; meta-learning",
    "application": "Genotype imputation",
    "code_link": "https://github.com/RichRast/SPIN",
    "dataset_name": [
      "UCI datasets",
      "1000 Genomes"
    ]
  },
  {
    "id": "_X9Yl1K2mD",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Rotamer Density Estimator is an Unsupervised Learner of the Effect of Mutations on Protein-Protein Interaction",
    "authors": [
      "Shitong Luo",
      "Yufeng Su",
      "Zuofan Wu",
      "Chenpeng Su",
      "Jian Peng",
      "Jianzhu Ma"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Protein-protein interactions are crucial to many biological processes, and predicting the effect of amino acid mutations on binding is important for protein engineering. While data-driven approaches using deep learning have shown promise, the scarcity of annotated experimental data remains a major challenge. In this work, we propose a new approach that predicts mutational effects on binding using the change in conformational flexibility of the protein-protein interface. Our approach, named Rotamer Density Estimator (RDE), employs a flow-based generative model to estimate the probability distribution of protein side-chain conformations and uses entropy to measure flexibility. RDE is trained solely on protein structures and does not require the supervision of experimental values of changes in binding affinities. Furthermore, the unsupervised representations extracted by RDE can be used for downstream neural network predictions with even greater accuracy. Our method outperforms empirical energy functions and other machine learning-based approaches.",
    "keywords": "effect of mutations, protein-protein interaction, unsupervised learning",
    "pdf_url": "https://openreview.net/pdf?id=_X9Yl1K2mD",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper develops a model (Rotamer Density Estimator) for predicting how amino‐acid mutations affect protein–protein binding by modeling side‐chain conformational flexibility. Protein–protein interaction prediction, mutational impact on binding affinities, and structural modeling are central to molecular modeling, protein design, and drug discovery—core tasks within Biomedicine AI.",
    "prompt_tokens": 21080,
    "completion_tokens": 100,
    "total_tokens": 21180,
    "topic": "Protein Interaction - Mutation Effects",
    "method": "Rotamer Density Estimation; Neural Networks",
    "application": "∆∆G prediction for protein-protein binding",
    "code_link": "https://github.com/luost26/RDE-PPI",
    "dataset_name": [
      "SKEMPI2"
    ]
  },
  {
    "id": "CjTHVo1dvR",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Molecular Geometry Pretraining with SE(3)-Invariant Denoising Distance Matching",
    "authors": [
      "Shengchao Liu",
      "Hongyu Guo",
      "Jian Tang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Molecular representation pretraining is critical in various applications for drug and material discovery due to the limited number of labeled molecules, and most existing work focuses on pretraining on 2D molecular graphs. However, the power of pretraining on 3D geometric structures has been less explored. This is owing to the difficulty of finding a sufficient proxy task that can empower the pretraining to effectively extract essential features from the geometric structures. Motivated by the dynamic nature of 3D molecules, where the continuous motion of a molecule in the 3D Euclidean space forms a smooth potential energy surface, we propose GeoSSL, a 3D coordinate denoising pretraining framework to model such an energy landscape. Further by leveraging an SE(3)-invariant score matching method, we propose GeoSSL-DDM in which the coordinate denoising proxy task is effectively boiled down to denoising the pairwise atomic distances in a molecule. Our comprehensive experiments confirm the effectiveness and robustness of our proposed method.",
    "keywords": "molecule, pretraining, representation, geometry, denoising score matching",
    "pdf_url": "https://openreview.net/pdf?id=CjTHVo1dvR",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on molecular representation learning explicitly motivated by “drug … discovery” (Abstract: “critical in various applications for drug and material discovery”). Methodological advances in 3D molecular modeling and pretraining for molecular graphs directly support computational drug discovery workflows, which falls under Biomedicine AI.",
    "prompt_tokens": 20961,
    "completion_tokens": 116,
    "total_tokens": 21077,
    "topic": "Drug Discovery - Geometric Representation Learning",
    "method": "Self-supervised learning; energy-based modeling; denoising distance matching",
    "application": "Binding affinity prediction",
    "code_link": "https://github.com/MilaGeoSSL-DDM",
    "dataset_name": [
      "Atom3D",
      "Molecule3D"
    ]
  },
  {
    "id": "oMsN9TYwJ0j",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "PiFold: Toward effective and efficient protein inverse folding",
    "authors": [
      "Zhangyang Gao",
      "Cheng Tan",
      "Stan Z. Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "How can we design protein sequences folding into the desired structures effectively and efficiently? AI methods for structure-based protein design have attracted increasing attention in recent years; however, few methods can simultaneously improve the accuracy and efficiency due to the lack of expressive features and autoregressive sequence decoder. To address these issues, we propose PiFold, which contains a novel residue featurizer and PiGNN layers to generate protein sequences in a one-shot way with improved recovery. Experiments show that PiFold could achieve 51.66\\% recovery on CATH 4.2, while the inference speed is 70 times faster than the autoregressive competitors. In addition, PiFold achieves 58.72\\% and 60.42\\% recovery scores on TS50 and TS500, respectively. We conduct comprehensive ablation studies to reveal the role of different types of protein features and model designs, inspiring further simplification and improvement. The PyTorch code is available at \\href{https://github.com/A4Bio/PiFold}{GitHub}.",
    "keywords": "",
    "pdf_url": "https://openreview.net/pdf?id=oMsN9TYwJ0j",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “structure-based protein design” and “protein inverse folding,” which are central tasks in molecular modeling and synthetic biology for drug discovery and therapeutic protein engineering. These are strong indicators of Biomedicine AI relevance.",
    "prompt_tokens": 20941,
    "completion_tokens": 106,
    "total_tokens": 21047,
    "topic": "Bioinformatics - Protein Design",
    "method": "Graph Neural Networks (GNN); one-shot generative schema",
    "application": "Inverse protein folding",
    "code_link": "https://github.com/A4Bio/PiFold",
    "dataset_name": [
      "CATH 4.2",
      "TS50",
      "TS500"
    ]
  },
  {
    "id": "kJqXEPXMsE0",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "3D Equivariant Diffusion for Target-Aware Molecule Generation and Affinity Prediction",
    "authors": [
      "Jiaqi Guan",
      "Wesley Wei Qian",
      "Xingang Peng",
      "Yufeng Su",
      "Jian Peng",
      "Jianzhu Ma"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Rich data and powerful machine learning models allow us to design drugs for a specific protein target <em>in silico</em>. Recently, the inclusion of 3D structures during targeted drug design shows superior performance to other target-free models as the atomic interaction in the 3D space is explicitly modeled. However, current 3D target-aware models either rely on the voxelized atom densities or the autoregressive sampling process, which are not equivariant to rotation or easily violate geometric constraints resulting in unrealistic structures. In this work, we develop a 3D equivariant diffusion model to solve the above challenges. To achieve target-aware molecule design, our method learns a joint generative process of both continuous atom coordinates and categorical atom types with a SE(3)-equivariant network. Moreover, we show that our model can serve as an unsupervised feature extractor to estimate the binding affinity under proper parameterization, which provides an effective way for drug screening. To evaluate our model, we propose a comprehensive framework to evaluate the quality of sampled molecules from different dimensions. Empirical studies show our model could generate molecules with more realistic 3D structures and better affinities towards the protein targets, and improve binding affinity ranking and prediction without retraining.",
    "keywords": "",
    "pdf_url": "https://openreview.net/pdf?id=kJqXEPXMsE0",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “target-aware molecule design,” “drug screening,” and “binding affinity” prediction for protein targets, which are core tasks in drug discovery and molecular modeling. These topics fall squarely under Biomedicine AI, as they involve AI-driven molecular generation and protein–ligand interaction modeling for therapeutic development.",
    "prompt_tokens": 21044,
    "completion_tokens": 109,
    "total_tokens": 21153,
    "topic": "Drug Discovery - Target-based",
    "method": "Diffusion model; SE(3)-equivariant graph neural network",
    "application": "Target-aware molecule generation",
    "code_link": "https://github.com/guanjq/targetdiff",
    "dataset_name": [
      "CrossDocked2020",
      "PDBBind v2020"
    ]
  },
  {
    "id": "6P9Y25Pljl6",
    "year": 2023,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "FedDAR: Federated Domain-Aware Representation Learning",
    "authors": [
      "Aoxiao Zhong",
      "Hao He",
      "Zhaolin Ren",
      "Na Li",
      "Quanzheng Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Cross-silo Federated learning (FL) has become a promising tool in machine learning applications for healthcare. It allows hospitals/institutions to train models with sufficient data while the data is kept private. To make sure the FL model is robust when facing heterogeneous data among FL clients, most efforts focus on personalizing models for clients. However, the latent relationships between clients' data are ignored. In this work, we focus on a special non-iid FL problem, called Domain-mixed FL, where each client's data distribution is assumed to be a mixture of several predefined domains.  Recognizing the diversity of domains and the similarity within domains, we propose a novel method, FedDAR, which learns a domain shared representation and domain-wise personalized prediction heads in a decoupled manner. For simplified linear regression settings, we have theoretically proved that FedDAR enjoys a linear convergence rate.  For general settings, we have performed intensive empirical studies on both synthetic and real-world medical datasets which demonstrate its superiority over prior FL methods. Our code is available at https://github.com/zlz0414/FedDAR.     ",
    "keywords": "federated learning, healthcare, fairness, personalization",
    "pdf_url": "https://openreview.net/pdf?id=6P9Y25Pljl6",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly targets cross-silo federated learning for healthcare institutions (“allows hospitals/institutions to train models with sufficient data while the data is kept private”) and evaluates on real-world medical datasets. It is clearly motivated by and applied to healthcare data heterogeneity and personalization across hospitals.",
    "prompt_tokens": 20463,
    "completion_tokens": 134,
    "total_tokens": 20597,
    "topic": "Federated Learning - Domain Personalization",
    "method": "Federated domain-aware representation learning; multi-head representations",
    "application": "Prediction of severe symptoms (higher than high-flow oxygen therapy) in COVID-19 patients",
    "code_link": "https://github.com/zlz0414/FedDAR",
    "dataset_name": [
      "EXAM dataset",
      "FairFace",
      "Digits datasets (SVHN, USPS, MNIST, SynthDigits, MNIST-M)"
    ]
  },
  {
    "id": "qNrJJZAKI3",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "FairSeg: A Large-Scale Medical Image Segmentation Dataset for Fairness Learning Using Segment Anything Model with Fair Error-Bound Scaling",
    "authors": [
      "Yu Tian",
      "Min Shi",
      "Yan Luo",
      "Ava Kouhana",
      "Tobias Elze",
      "Mengyu Wang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Fairness in artificial intelligence models has gained significantly more attention in recent years, especially in the area of medicine, as fairness in medical models is critical to people's well-being and lives. High-quality medical fairness datasets are needed to promote fairness learning research. Existing medical fairness datasets are all for classification tasks, and no fairness datasets are available for medical segmentation, while medical segmentation is an equally important clinical task as classifications, which can provide detailed spatial information on organ abnormalities ready to be assessed by clinicians. In this paper, we propose the first fairness dataset for medical segmentation named Harvard-FairSeg with 10,000 subject samples. In addition, we propose a fair error-bound scaling approach to reweight the loss function with the upper error-bound in each identity group, using the segment anything model (SAM). We anticipate that the segmentation performance equity can be improved by explicitly tackling the hard cases with high training errors in each identity group. To facilitate fair comparisons, we utilize a novel equity-scaled segmentation performance metric to compare segmentation metrics in the context of fairness, such as the equity-scaled Dice coefficient. Through comprehensive experiments, we demonstrate that our fair error-bound scaling approach either has superior or comparable fairness performance to the state-of-the-art fairness learning models. The dataset and code are publicly accessible via https://ophai.hms.harvard.edu/datasets/harvard-fairseg10k.",
    "keywords": "Medical Segmentation, Medical Imaging, Fairness Learning, Health Equity, Deep Learning, Trustworthy AI",
    "pdf_url": "https://openreview.net/pdf?id=qNrJJZAKI3",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “medical image segmentation,” introduces a large-scale dataset (Harvard-FairSeg) of 10,000 subject samples for fairness in “medical segmentation,” and targets a clinical task by providing spatial information on organ abnormalities. These details clearly place it within Healthcare AI.",
    "prompt_tokens": 19435,
    "completion_tokens": 113,
    "total_tokens": 19548,
    "topic": "Medical Imaging - Fair Segmentation",
    "method": "Fair Error-Bound Scaling (FEBS); SAMed; TransUNet",
    "application": "Optic disc and cup segmentation",
    "code_link": "https://ophai.hms.harvard.edu/datasets/harvard-fairseg10k",
    "dataset_name": [
      "Harvard-FairSeg"
    ]
  },
  {
    "id": "BIveOmD1Nh",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Equivariant Scalar Fields for Molecular Docking with Fast Fourier Transforms",
    "authors": [
      "Bowen Jing",
      "Tommi S. Jaakkola",
      "Bonnie Berger"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Molecular docking is critical to structure-based virtual screening, yet the throughput of such workflows is limited by the expensive optimization of scoring functions involved in most docking algorithms. We explore how machine learning can accelerate this process by learning a scoring function with a functional form that allows for more rapid optimization. Specifically, we define the scoring function to be the cross-correlation of multi-channel ligand and protein scalar fields parameterized by equivariant graph neural networks, enabling rapid optimization over rigid-body degrees of freedom with fast Fourier transforms. The runtime of our approach can be amortized at several levels of abstraction, and is particularly favorable for virtual screening settings with a common binding pocket. We benchmark our scoring functions on two simplified docking-related tasks: decoy pose scoring and rigid conformer docking. Our method attains similar but faster performance on crystal structures compared to the widely-used Vina and Gnina scoring functions, and is more robust on computationally predicted structures. Code is available at https://github.com/bjing2016/scalar-fields.",
    "keywords": "protein structure, structural biology, drug discovery, molecular docking",
    "pdf_url": "https://openreview.net/pdf?id=BIveOmD1Nh",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on molecular docking and structure-based virtual screening—key steps in drug discovery—which falls squarely within biomedicine AI. It discusses “scoring functions,” “ligand and protein scalar fields,” and benchmarks against docking tools like Vina and Gnina, all of which are central to computational drug design and protein–ligand interactions in biomedical research.",
    "prompt_tokens": 20337,
    "completion_tokens": 106,
    "total_tokens": 20443,
    "topic": "Drug Discovery - Molecular Docking",
    "method": "Equivariant scalar field networks; fast Fourier transforms (FFTs)",
    "application": "Pose optimization in molecular docking",
    "code_link": "https://github.com/bjing2016/scalar-fields",
    "dataset_name": [
      "PDBBind",
      "PDE10A"
    ]
  },
  {
    "id": "Je5SHCKpPa",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Multimodal Patient Representation Learning with Missing Modalities and Labels",
    "authors": [
      "Zhenbang Wu",
      "Anant Dadu",
      "Nicholas Tustison",
      "Brian Avants",
      "Mike Nalls",
      "Jimeng Sun",
      "Faraz Faghri"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Multimodal patient representation learning aims to integrate information from multiple modalities and generate comprehensive patient representations for subsequent clinical predictive tasks. However, many existing approaches either presuppose the availability of all modalities and labels for each patient or only deal with missing modalities. In reality, patient data often comes with both missing modalities and labels for various reasons (i.e., the missing modality and label issue). Moreover, multimodal models might over-rely on certain modalities, causing sub-optimal performance when these modalities are absent (i.e., the modality collapse issue). To address these issues, we introduce MUSE: a mutual-consistent graph contrastive learning method. MUSE uses a flexible bipartite graph to represent the patient-modality relationship, which can adapt to various missing modality patterns. To tackle the modality collapse issue, MUSE learns to focus on modality-general and label-decisive features via a mutual-consistent contrastive learning loss. Notably, the unsupervised component of the contrastive objective only requires self-supervision signals, thereby broadening the training scope to incorporate patients with missing labels. We evaluate MUSE on three publicly available datasets: MIMIC-IV, eICU, and ADNI. Results show that MUSE outperforms all baselines, and MUSE+ further elevates the absolute improvement to ~4% by extending the training scope to patients with absent labels.",
    "keywords": "multi-modal learning, missing modalities, missing labels, clinical predictive modeling, patient representation learning",
    "pdf_url": "https://openreview.net/pdf?id=Je5SHCKpPa",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “multimodal patient representation learning” for “subsequent clinical predictive tasks” and explicitly evaluates on healthcare datasets (MIMIC-IV, eICU, ADNI). It addresses challenges in patient data (missing modalities/labels) and aims to improve clinical prediction, which places it squarely in the Healthcare AI domain.",
    "prompt_tokens": 21288,
    "completion_tokens": 136,
    "total_tokens": 21424,
    "topic": "Multimodal Learning - Missing Data",
    "method": "Graph Neural Networks (GNN); contrastive learning (supervised and unsupervised)",
    "application": "Mortality and readmission prediction – ICU; disease progression prediction – Alzheimer's",
    "code_link": "https://github.com/zzachw/MUSE",
    "dataset_name": [
      "MIMIC-IV",
      "eICU",
      "ADNI"
    ]
  },
  {
    "id": "MREQ0k6qvD",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "One-hot Generalized Linear Model for Switching Brain State Discovery",
    "authors": [
      "Chengrui Li",
      "Soon Ho Kim",
      "Chris Rodgers",
      "Hannah Choi",
      "Anqi Wu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Exposing meaningful and interpretable neural interactions is critical to understanding neural circuits. Inferred neural interactions from neural signals primarily reflect functional connectivity. In a long experiment, subject animals may experience different stages defined by the experiment, stimuli, or behavioral states, and hence functional connectivity can change over time. To model dynamically changing functional connectivity, prior work employs state-switching generalized linear models with hidden Markov models (i.e., HMM-GLMs). However, we argue they lack biological plausibility, as functional connectivities are shaped and confined by the underlying anatomical connectome. Here, we propose two novel prior-informed state-switching GLMs, called Gaussian HMM-GLM (Gaussian prior) and one-hot HMM-GLM (Gumbel-Softmax one-hot prior). We show that the learned prior should capture the state-invariant interaction, shedding light on the underlying anatomical connectome and revealing more likely physical neuron interactions. The state-dependent interaction modeled by each GLM offers traceability to capture functional variations across multiple brain states. Our methods effectively recover true interaction structures in simulated data, achieve the highest predictive likelihood, and enhance the interpretability of interaction patterns and hidden states when applied to real neural data. The code is available at \\url{https://github.com/JerrySoybean/onehot-hmmglm}.",
    "keywords": "Hidden markov models, generalized linear models, functional connectivity inference",
    "pdf_url": "https://openreview.net/pdf?id=MREQ0k6qvD",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on modeling neural interactions and functional connectivity in the brain (“functional connectivity,” “anatomical connectome,” “switching brain state discovery,” “real neural data”), which falls under neuroscience and neurobiological modeling. Such work analyzing brain signals and connectivity is a core part of Biomedicine AI.",
    "prompt_tokens": 20861,
    "completion_tokens": 111,
    "total_tokens": 20972,
    "topic": "Neuroscience - Functional Connectivity",
    "method": "HMM-GLM; Gumbel-Softmax prior",
    "application": "Neural interaction modeling – Spike trains",
    "code_link": "https://github.com/JerrySoybean/onehot-hmmglm",
    "dataset_name": [
      "PFC-6",
      "Barrel Cortex"
    ]
  },
  {
    "id": "rzBskAEmoc",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "CAMIL: Context-Aware Multiple Instance Learning for Cancer Detection and Subtyping in Whole Slide Images",
    "authors": [
      "Olga Fourkioti",
      "Matt De Vries",
      "Chris Bakal"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The visual examination of tissue biopsy sections is fundamental for cancer diagnosis, with pathologists analyzing sections at multiple magnifications to discern tumor cells and their subtypes. However, existing attention-based multiple instance learning (MIL) models used for analyzing Whole Slide Images (WSIs) in cancer diagnostics often overlook the contextual information of tumor and neighboring tiles, leading to misclassifications. To address this, we propose the Context-Aware Multiple Instance Learning (CAMIL) architecture. CAMIL incorporates neighbor-constrained attention to consider dependencies among tiles within a WSI and integrates contextual constraints as prior knowledge into the MIL model. We evaluated CAMIL on subtyping non-small cell lung cancer (TCGA-NSCLC) and detecting lymph node (CAMELYON16 and CAMELYON17) metastasis, achieving test AUCs of 97.5\\%, 95.9\\%, and 88.1\\%, respectively, outperforming other state-of-the-art methods. Additionally, CAMIL enhances model interpretability by identifying regions of high diagnostic value. Our code is available at https://github.com/olgarithmics/ICLR_CAMIL.",
    "keywords": "Multiple Instance Learning, Histopathology, Nearest Neighbors, Graph Representation",
    "pdf_url": "https://openreview.net/pdf?id=rzBskAEmoc",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on cancer diagnosis and subtyping using histopathology Whole Slide Images (WSIs), explicitly mentioning tasks such as “subtyping non-small cell lung cancer” and “detecting lymph node metastasis.” It proposes a model for analyzing tissue biopsy sections—a core medical imaging application—making it clearly relevant to Healthcare AI.",
    "prompt_tokens": 20950,
    "completion_tokens": 140,
    "total_tokens": 21090,
    "topic": "Medical Imaging - Cancer Detection",
    "method": "Multiple instance learning (MIL); Nystromformer; Neighbor-constrained attention",
    "application": "Cancer detection and subtyping",
    "code_link": "https://github.com/olgarithmics/ICLR_CAMIL",
    "dataset_name": [
      "CAMELYON16",
      "CAMELYON17",
      "TCGA-NSCLC"
    ]
  },
  {
    "id": "ArpwmicoYW",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "FairTune: Optimizing Parameter Efficient Fine Tuning for Fairness in Medical Image Analysis",
    "authors": [
      "Raman Dutt",
      "Ondrej Bohdal",
      "Sotirios A. Tsaftaris",
      "Timothy Hospedales"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Training models with robust group fairness properties is crucial in ethically sensitive application areas such as medical diagnosis. Despite the growing body of work aiming to minimise demographic bias in AI, this problem remains challenging. A key reason for this challenge is the fairness generalisation gap: High-capacity deep learning models can fit all training data nearly perfectly, and thus also exhibit perfect fairness during training. In this case, bias emerges only during testing when generalisation performance differs across sub-groups. This motivates us to take a bi-level optimisation perspective on fair learning: Optimising the learning strategy based on validation fairness. Specifically, we consider the highly effective workflow of adapting pre-trained models to downstream medical imaging tasks using parameter-efficient fine-tuning (PEFT) techniques. There is a trade-off between updating more parameters, enabling a better fit to the task of interest vs. fewer parameters, potentially reducing the generalisation gap. To manage this tradeoff, we propose FairTune, a framework to optimise the choice of PEFT parameters with respect to fairness. We demonstrate empirically that FairTune leads to improved fairness on a range of medical imaging datasets. The code is available at https://github.com/Raman1121/FairTune.",
    "keywords": "Fairness, PEFT, Hyperparameter Optimization, Medical Imaging",
    "pdf_url": "https://openreview.net/pdf?id=ArpwmicoYW",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly targets “medical image analysis” and “medical diagnosis” tasks, focusing on adapting pre-trained models to downstream **medical imaging** datasets using PEFT. References to “medical imaging tasks” and “ethically sensitive application areas such as medical diagnosis” confirm its application in the Healthcare AI domain.",
    "prompt_tokens": 20647,
    "completion_tokens": 137,
    "total_tokens": 20784,
    "topic": "Medical Imaging - Fairness Optimization",
    "method": "Parameter-Efficient Fine-Tuning (PEFT); Fairness Regularization",
    "application": "Fair classification - Medical imaging datasets",
    "code_link": "https://github.com/Raman1121/FairTune",
    "dataset_name": [
      "Fitzpatrick17k",
      "HAM10000",
      "PAPILA",
      "OL3I",
      "OASIS",
      "Harvard-GF3300",
      "CheXpert"
    ]
  },
  {
    "id": "jZPqf2G9Sw",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Dynamics-Informed Protein Design with Structure Conditioning",
    "authors": [
      "Urszula Julia Komorowska",
      "Simon V Mathis",
      "Kieran Didi",
      "Francisco Vargas",
      "Pietro Lio",
      "Mateja Jamnik"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Current protein generative models are able to design novel backbones with desired shapes or functional motifs. However, despite the importance of a protein’s dynamical properties for its function, conditioning on dynamical properties remains elusive. We present a new approach to protein generative modeling by leveraging Normal Mode Analysis that enables us to capture dynamical properties too. We introduce a method for conditioning the diffusion probabilistic models on protein dynamics, specifically on the lowest non-trivial normal mode of oscillation. Our method, similar to the classifier guidance conditioning, formulates the sampling process as being driven by conditional and unconditional terms. However, unlike previous works, we approximate the conditional term with a simple analytical function rather than an external neural network, thus making the eigenvector calculations approachable. We present the corresponding SDE theory as a formal justification of our approach. We extend our framework to conditioning on structure and dynamics at the same time, enabling scaffolding of the dynamical motifs. We demonstrate the empirical effectiveness of our method by turning the open-source unconditional protein diffusion model Genie into the conditional model with no retraining. Generated proteins exhibit the desired dynamical and structural properties while still being biologically plausible. Our work represents a first step towards incorporating dynamical behaviour in protein design and may open the door to designing more flexible and functional proteins in the future.",
    "keywords": "Diffusion Models, Generative Modeling, Protein Design, Normal Mode Analysis",
    "pdf_url": "https://openreview.net/pdf?id=jZPqf2G9Sw",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “protein generative models” and “protein design” via diffusion models and Normal Mode Analysis—topics squarely within molecular modeling and drug discovery research. Designing novel protein backbones with specified dynamic and structural properties is a core task in biomedicine AI, particularly for therapeutic protein engineering and enzyme design.",
    "prompt_tokens": 20945,
    "completion_tokens": 102,
    "total_tokens": 21047,
    "topic": "Bioinformatics - Protein Dynamics",
    "method": "Diffusion model; Normal Mode Analysis (NMA)",
    "application": "Protein backbone generation",
    "code_link": "https://github.com/ujk21/dyn-informed",
    "dataset_name": [
      "CATHv4.3",
      "SCOPe"
    ]
  },
  {
    "id": "pAoqRlTBtY",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Causal Modelling Agents: Causal Graph Discovery through Synergising Metadata- and Data-driven Reasoning",
    "authors": [
      "Ahmed Abdulaal",
      "adamos hadjivasiliou",
      "Nina Montana-Brown",
      "Tiantian He",
      "Ayodeji Ijishakin",
      "Ivana Drobnjak",
      "Daniel C. Castro",
      "Daniel C. Alexander"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Scientific discovery hinges on the effective integration of metadata, which refers to a set of 'cognitive' operations such as determining what information is relevant for inquiry, and data, which encompasses physical operations such as observation and experimentation. This paper introduces the Causal Modelling Agent (CMA), a novel framework that synergizes the metadata-based reasoning capabilities of Large Language Models (LLMs) with the data-driven modelling of Deep Structural Causal Models (DSCMs) for the task of causal discovery. We evaluate the CMA's performance on a number of benchmarks, as well as on the real-world task of modelling the clinical and radiological phenotype of Alzheimer's Disease (AD). Our experimental results indicate that the CMA can outperform previous data-driven or metadata-driven approaches to causal discovery. In our real-world application, we use the CMA to derive new insights into the causal relationships among biomarkers of AD.",
    "keywords": "Causal Reasoning, Causal Discovery, Structural Causal Models, Large Language Models",
    "pdf_url": "https://openreview.net/pdf?id=pAoqRlTBtY",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper specifically applies its causal discovery framework to model the “clinical and radiological phenotype of Alzheimer’s Disease (AD)” and derives insights into causal relationships among “biomarkers of AD.” This direct focus on disease biomarkers and clinical phenotypes places it squarely in the Healthcare/Biomedicine AI domain.",
    "prompt_tokens": 20844,
    "completion_tokens": 124,
    "total_tokens": 20968,
    "topic": "Causal Discovery - Multi-modal Data",
    "method": "Deep Structural Causal Models (DSCMs); Retrieval-augmented generation (RAG)",
    "application": "Causal graph discovery",
    "code_link": "https://anonymous.4open.science/r/causal_modelling_agent-F443/",
    "dataset_name": [
      "Alzheimer's Disease",
      "Arctic Sea Ice",
      "Sangiovese"
    ]
  },
  {
    "id": "GkJOCga62u",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Orbit-Equivariant Graph Neural Networks",
    "authors": [
      "Matthew Morris",
      "Bernardo Cuenca Grau",
      "Ian Horrocks"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Equivariance is an important structural property that is captured by architectures such as graph neural networks (GNNs). However, equivariant graph functions cannot produce different outputs for similar nodes, which may be undesirable when the function is trying to optimize some global graph property. In this paper, we define orbit-equivariance, a relaxation of equivariance which allows for such functions whilst retaining important structural inductive biases. We situate the property in the hierarchy of graph functions, define a taxonomy of orbit-equivariant functions, and provide four different ways to achieve non-equivariant GNNs. For each, we analyze their expressivity with respect to orbit-equivariance and evaluate them on two novel datasets, one of which stems from a real-world use-case of designing optimal bioisosteres.",
    "keywords": "graph neural networks, equivariance, expressivity, graph orbits",
    "pdf_url": "https://openreview.net/pdf?id=GkJOCga62u",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper evaluates its methods on a dataset “stemming from a real-world use-case of designing optimal bioisosteres.” Bioisostere design is a core task in medicinal chemistry and drug discovery, placing this work squarely in the Biomedicine AI domain.",
    "prompt_tokens": 20731,
    "completion_tokens": 113,
    "total_tokens": 20844,
    "topic": "Graph Neural Networks - Orbit-equivariance",
    "method": "Orbit-equivariant transformations; m-Orbit-Transform-GNNs; Orbit-Indiv-GNNs",
    "application": "Node labelling – molecular property optimization",
    "code_link": "N/A",
    "dataset_name": [
      "Bioisostere",
      "Alchemy-Max-Orbit"
    ]
  },
  {
    "id": "pzUhfQ74c5",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Conformal Language Modeling",
    "authors": [
      "Victor Quach",
      "Adam Fisch",
      "Tal Schuster",
      "Adam Yala",
      "Jae Ho Sohn",
      "Tommi S. Jaakkola",
      "Regina Barzilay"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In this paper, we propose a novel approach to conformal prediction for  language models (LMs) in which we produce prediction sets with performance guarantees. LM responses are typically sampled from a predicted distribution over the large, combinatorial output space of  language. Translating this to conformal prediction, we calibrate a stopping rule for sampling LM outputs  that get added to a growing set of candidates until we are confident that the set covers at least one acceptable response. Since some samples may be low-quality, we also simultaneously calibrate a rejection rule for removing candidates from the output set to reduce noise. Similar to conformal prediction, we  can prove that the final output set obeys certain desirable distribution-free guarantees. Within these sets of candidate responses, we also show that we can also identify subsets of individual components---such as phrases or sentences---that are each independently correct (e.g., that are not ``hallucinations''), again with guarantees. Our method can be applied to any LM API that supports sampling. Furthermore, we empirically demonstrate that we can achieve many desired coverage levels within a limited number of total samples when applying our method to  multiple tasks in open-domain question answering, text summarization, and radiology report generation using different LM variants.",
    "keywords": "conformal prediction, uncertainty estimation, language models, generative models, confidence, prediction sets, sampling",
    "pdf_url": "https://openreview.net/pdf?id=pzUhfQ74c5",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the core contribution is a general conformal prediction method for language models, the paper explicitly applies this technique to “radiology report generation,” which is a medical imaging and clinical documentation task. Radiology report generation is a recognized Healthcare AI application (medical vision–language modeling), qualifying this work for a Healthcare AI classification.",
    "prompt_tokens": 20776,
    "completion_tokens": 129,
    "total_tokens": 20905,
    "topic": "Language Models - Conformal Prediction",
    "method": "Conformal prediction; rejection sampling",
    "application": "Radiology report generation",
    "code_link": "https://github.com/Varal7/conformal-language-modeling",
    "dataset_name": [
      "MIMIC-CXR",
      "MIMIC-CXR-JPG",
      "TriviaQA",
      "CNN/DM"
    ]
  },
  {
    "id": "aGH43rjoe4",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Multi-modal Gaussian Process Variational Autoencoders for Neural and Behavioral Data",
    "authors": [
      "Rabia Gondur",
      "Usama Bin Sikandar",
      "Evan Schaffer",
      "Mikio Christian Aoi",
      "Stephen L Keeley"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Characterizing the relationship between neural population activity and behavioral data is a central goal of neuroscience. While latent variable models (LVMs) are successful in describing high-dimensional data, they are typically only designed for a single type of data, making it difficult to identify structure shared across different experimental data modalities. Here, we address this shortcoming by proposing an unsupervised LVM which extracts shared and independent latents for distinct, simultaneously recorded experimental modalities. We do this by combining Gaussian Process Factor Analysis (GPFA), an interpretable LVM for neural spiking data with temporally smooth latent space, with Gaussian Process Variational Autoencoders (GP-VAEs), which similarly use a GP prior to characterize correlations in a latent space, but admit rich expressivity due to a deep neural network mapping to observations. We achieve interpretability in our model by partitioning latent variability into components that are either shared between or independent to each modality. We parameterize the latents of our model in the Fourier domain, and show improved latent identification using this approach over standard GP-VAE methods. We validate our model on simulated multi-modal data consisting of Poisson spike counts and MNIST images that scale and rotate smoothly over time. We show that the multi-modal GP-VAE (MM-GPVAE) is able to not only identify the shared and independent latent structure across modalities accurately, but provides good reconstructions of both images and neural rates on held-out trials. Finally, we demonstrate our framework on two real world multi-modal experimental settings: Drosophila whole-brain calcium imaging alongside tracked limb positions, and Manduca sexta spike train measurements from ten wing muscles as the animal tracks a visual stimulus.",
    "keywords": "Gaussian Processes, Latent Variable Models, Variational Autoencoders, Neuroscience",
    "pdf_url": "https://openreview.net/pdf?id=aGH43rjoe4",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although this work focuses on insects, it develops methods for modeling neural population activity (e.g., “Drosophila whole-brain calcium imaging,” “Manduca sexta spike train measurements”) and behavior—topics expressly called out in the prompt as “neuroscience or neurobiological modeling.” Because the model addresses neural system dynamics, a key area of Biomedicine AI, it qualifies under the biomedicine domain.",
    "prompt_tokens": 20657,
    "completion_tokens": 126,
    "total_tokens": 20783,
    "topic": "Neuroscience - Multi-modal Representation Learning",
    "method": "Gaussian Process Variational Autoencoder (GPVAE); Fourier representation for latent space",
    "application": "Neural and behavioral data reconstruction and analysis",
    "code_link": "https://github.com/RabiaGondur/MM-GPVAE.git",
    "dataset_name": [
      "Drosophila calcium imaging dataset",
      "Hawkmoth tethered flight experiment"
    ]
  },
  {
    "id": "7UhxsmbdaQ",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Beam Enumeration: Probabilistic Explainability For Sample Efficient Self-conditioned Molecular Design",
    "authors": [
      "Jeff Guo",
      "Philippe Schwaller"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Generative molecular design has moved from proof-of-concept to real-world applicability, as marked by the surge in very recent papers reporting experimental validation. Key challenges in explainability and sample efficiency present opportunities to enhance generative design to directly optimize expensive high-fidelity oracles and provide actionable insights to domain experts. Here, we propose Beam Enumeration to exhaustively enumerate the most probable sub-sequences from language-based molecular generative models and show that molecular substructures can be extracted. When coupled with reinforcement learning, extracted substructures become meaningful, providing a source of explainability and improving sample efficiency through self-conditioned generation. Beam Enumeration is generally applicable to any language-based molecular generative model and notably further improves the performance of the recently reported Augmented Memory algorithm, which achieved the new state-of-the-art on the Practical Molecular Optimization benchmark for sample efficiency. The combined algorithm generates more high reward molecules and faster, given a fixed oracle budget. Beam Enumeration shows that improvements to explainability and sample efficiency for molecular design can be made synergistic.",
    "keywords": "Molecular generative models, reinforcement learning, natural language processing, drug discovery, sample-efficiency, explainability",
    "pdf_url": "https://openreview.net/pdf?id=7UhxsmbdaQ",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on generative molecular design and explicitly lists “drug discovery” as a keyword. It develops methods for language-based molecular generative models to optimize expensive oracles and extract molecular substructures, clearly situated in the domain of molecular modeling and drug discovery, a core topic in Biomedicine AI.",
    "prompt_tokens": 20897,
    "completion_tokens": 103,
    "total_tokens": 21000,
    "topic": "Drug Discovery - Molecular Design",
    "method": "Beam Enumeration; reinforcement learning",
    "application": "Molecule generation – drug discovery",
    "code_link": "https://github.com/schwallergroup/augmented_memory",
    "dataset_name": [
      "DRD2",
      "MK2",
      "AChE"
    ]
  },
  {
    "id": "oM7Jbxdk6Z",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Multimodal Molecular Pretraining via Modality Blending",
    "authors": [
      "Qiying Yu",
      "Yudi Zhang",
      "Yuyan Ni",
      "Shikun Feng",
      "Yanyan Lan",
      "Hao Zhou",
      "Jingjing Liu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Self-supervised learning has recently gained growing interest in molecular modeling for scientific tasks such as AI-assisted drug discovery. Current studies consider leveraging both 2D and 3D molecular structures for representation learning. However, relying on straightforward alignment strategies that treat each modality separately, these methods fail to exploit the intrinsic correlation between 2D and 3D representations that reflect the underlying structural characteristics of molecules, and only perform coarse-grained molecule-level alignment. To derive fine-grained alignment and promote structural molecule understanding, we introduce an atomic-relation level \"blend-then-predict\" self-supervised learning approach, MoleBLEND, which first blends atom relations represented by different modalities into one unified relation matrix for joint encoding, then recovers modality-specific information for 2D and 3D structures individually. By treating atom relationships as anchors, MoleBLEND organically aligns and integrates visually dissimilar 2D and 3D modalities of the same molecule at fine-grained atomic level, painting a more comprehensive depiction of each molecule. Extensive experiments show that MoleBLEND achieves state-of-the-art performance across major 2D/3D molecular benchmarks. We further provide theoretical insights from the perspective of mutual-information maximization, demonstrating that our method unifies contrastive, generative (cross-modality prediction) and mask-then-predict (single-modality prediction) objectives into one single cohesive framework.",
    "keywords": "multimodal molecular pretraining, molecular representation learning, modality blending",
    "pdf_url": "https://openreview.net/pdf?id=oM7Jbxdk6Z",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on self-supervised representation learning for molecular structures—specifically blending 2D and 3D atom relations—with the explicit motivation of improving “AI-assisted drug discovery.” Methods that model molecular geometry and chemistry for drug design are core to the Biomedicine AI domain.",
    "prompt_tokens": 20907,
    "completion_tokens": 103,
    "total_tokens": 21010,
    "topic": "Drug Discovery - Multimodal Molecular Alignment",
    "method": "Multimodal molecular pretraining; blend-then-predict training",
    "application": "Molecular property prediction",
    "code_link": "N/A",
    "dataset_name": [
      "PCQM4Mv2",
      "MoleculeNet",
      "QM9"
    ]
  },
  {
    "id": "xhEN0kJh4q",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Robust Model-Based Optimization for Challenging Fitness Landscapes",
    "authors": [
      "Saba Ghaffari",
      "Ehsan Saleh",
      "Alex Schwing",
      "Yu-Xiong Wang",
      "Martin D. Burke",
      "Saurabh Sinha"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Protein design, a grand challenge of the day, involves optimization on a fitness landscape, and leading methods adopt a model-based approach where a model is trained on a training set (protein sequences and fitness) and proposes candidates to explore next. These methods are challenged by sparsity of high-fitness samples in the training set, a problem that has been in the literature. A less recognized but equally important problem stems from the distribution of training samples in the design space: leading methods are not designed for scenarios where the desired optimum is in a region that is not only poorly represented in training data, but also relatively far from the highly represented low-fitness regions. We show that this problem of “separation” in the design space is a significant bottleneck in existing model-based optimization tools and propose a new approach that uses a novel VAE as its search model to overcome the problem. We demonstrate its advantage over prior methods in robustly finding improved samples, regardless of the imbalance and separation between low- and high-fitness samples. Our comprehensive benchmark on real and semi-synthetic protein datasets as well as solution design for physics-informed neural networks, showcases the generality of our approach in discrete and continuous design spaces. Our implementation is available at https://github.com/sabagh1994/PGVAE.",
    "keywords": "Model based optimization, protein engineering",
    "pdf_url": "https://openreview.net/pdf?id=xhEN0kJh4q",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “protein design,” which is a core problem in molecular and synthetic biology with direct applications in drug discovery and therapeutic development. It discusses optimization on protein “fitness landscapes” and benchmarks on “real and semi-synthetic protein datasets,” indicating a clear biomedical context. Therefore, it belongs to the Biomedicine AI domain.",
    "prompt_tokens": 21154,
    "completion_tokens": 108,
    "total_tokens": 21262,
    "topic": "Protein Design - Latent Space Optimization",
    "method": "PPGVAE; Model-based optimization; Latent space modeling",
    "application": "High-fitness protein sequence generation",
    "code_link": "N/A",
    "dataset_name": [
      "AAV",
      "GB1",
      "PhoQ",
      "PINN",
      "Toy MNIST"
    ]
  },
  {
    "id": "YIls9HEa52",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Parsing neural dynamics with infinite recurrent switching linear dynamical systems",
    "authors": [
      "Victor Geadah",
      "International Brain Laboratory",
      "Jonathan W. Pillow"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Unsupervised methods for dimensionality reduction of neural activity and behavior have provided unprecedented insights into the underpinnings of neural information processing. One popular approach involves the recurrent switching linear dynamical system (rSLDS) model, which describes the latent dynamics of neural spike train data using discrete switches between a finite number of low-dimensional linear dynamical systems. However, a few properties of rSLDS model limit its deployability on trial-varying data, such as a fixed number of states over trials, and no latent structure or organization of states. Here we overcome these limitations by endowing the rSLDS model with a semi-Markov discrete state process, with latent geometry, that captures key properties of stochastic processes over partitions with flexible state cardinality. We leverage partial differential equations (PDE) theory to derive an efficient, semi-parametric formulation for dynamical sufficient statistics to the discrete states. This process, combined with switching dynamics, defines our infinite recurrent switching linear dynamical system (irSLDS) model class. We first validate and demonstrate the capabilities of our model on synthetic data. Next, we turn to the analysis of mice electrophysiological data during decision-making, and uncover strong non-stationary processes underlying both within-trial and trial-averaged neural activity.",
    "keywords": "Markov switching processes, Neural data analysis, State-space models",
    "pdf_url": "https://openreview.net/pdf?id=YIls9HEa52",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on modeling and analyzing neural spiking data and electrophysiological recordings from mice, which falls squarely under neuroscience and neurobiological modeling—an established subfield of Biomedicine AI. It develops state‐space methods (infinite recurrent switching linear dynamical systems) to uncover latent dynamics in neural activity, and validates them on real neural data from decision‐making experiments. These characteristics align with “neuroscience or neurobiological modeling” as a strong indicator of Biomedicine AI.",
    "prompt_tokens": 20571,
    "completion_tokens": 108,
    "total_tokens": 20679,
    "topic": "Neural Data Analysis - State-space Models",
    "method": "Infinite recurrent SLDS; variational Laplace-EM",
    "application": "Behavioral dynamics modeling - Neuroscience",
    "code_link": "https://github.com/lindermanlab/ssm",
    "dataset_name": [
      "Neuropixels recordings",
      "Brainwide Map"
    ]
  },
  {
    "id": "UfBIxpTK10",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Deep Confident Steps to New Pockets: Strategies for Docking Generalization",
    "authors": [
      "Gabriele Corso",
      "Arthur Deng",
      "Nicholas Polizzi",
      "Regina Barzilay",
      "Tommi S. Jaakkola"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Accurate blind docking has the potential to lead to new biological breakthroughs, but for this promise to be realized, docking methods must generalize well across the proteome. Existing benchmarks, however, fail to rigorously assess generalizability. Therefore, we develop DockGen, a new benchmark based on the ligand-binding domains of proteins, and we show that existing machine learning-based docking models have very weak generalization abilities. We carefully analyze the scaling laws of ML-based docking and show that, by scaling data and model size, as well as integrating synthetic data strategies, we are able to significantly increase the generalization capacity and set new state-of-the-art performance across benchmarks.  Further, we propose Confidence Bootstrapping, a new training paradigm that solely relies on the interaction between diffusion and confidence models and exploits the multi-resolution generation process of diffusion models. We demonstrate that Confidence Bootstrapping significantly improves the ability of ML-based docking methods to dock to unseen protein classes, edging closer to accurate and generalizable blind docking methods.",
    "keywords": "generalization, molecular docking, protein-ligand binding, diffusion models, benchmark, bootstrapping, self-training",
    "pdf_url": "https://openreview.net/pdf?id=UfBIxpTK10",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper centers on improving molecular docking—“blind docking,” “ligand-binding domains of proteins,” and “protein-ligand binding”—which are core tasks in drug discovery and biochemical research. These topics fall squarely within Biomedicine AI’s scope of molecular modeling and therapeutic design.",
    "prompt_tokens": 20787,
    "completion_tokens": 101,
    "total_tokens": 20888,
    "topic": "Drug Discovery - Molecular Docking",
    "method": "Diffusion models; Confidence bootstrapping",
    "application": "Protein-ligand binding pose prediction",
    "code_link": "https://github.com/gcorso/DiffDock",
    "dataset_name": [
      "PDBBind",
      "DOCKGEN"
    ]
  },
  {
    "id": "6MRm3G4NiU",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "SaProt: Protein Language Modeling with Structure-aware Vocabulary",
    "authors": [
      "Jin Su",
      "Chenchen Han",
      "Yuyang Zhou",
      "Junjie Shan",
      "Xibin Zhou",
      "Fajie Yuan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Large-scale protein language models (PLMs), such as the ESM family, have achieved remarkable performance in various downstream tasks related to protein structure and function by undergoing unsupervised training on residue sequences. They have become essential tools for researchers and practitioners in biology.  However, a limitation of vanilla PLMs is their lack of explicit consideration for protein structure information, which suggests the potential for further improvement. Motivated by this, we introduce the concept of a ``structure-aware vocabulary\" that  integrates residue tokens with structure tokens.    The structure tokens are  derived  by encoding the 3D structure of proteins using Foldseek. We then propose SaProt, a large-scale general-purpose PLM trained on an extensive dataset comprising approximately 40 million protein sequences and structures. Through extensive evaluation, our SaProt model surpasses well-established and renowned baselines across 10 significant downstream tasks, demonstrating its exceptional capacity and broad applicability. We have made the code, pre-trained model, and all relevant materials available at https://github.com/westlake-repl/SaProt.",
    "keywords": "Protein Language Models, Universal Representations, Downstream Tasks, Protein Structure Modeling",
    "pdf_url": "https://openreview.net/pdf?id=6MRm3G4NiU",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work focuses on large‐scale protein language modeling that integrates 3D structure information to improve representations of proteins. Protein structure modeling, representation learning for protein function, and downstream tasks in molecular modeling are core topics in Biomedicine AI (e.g., “drug discovery,” “protein design,” “molecular modeling”). The abstract explicitly references “protein structure and function” and uses structural tokens from Foldseek, indicating relevance to biomedical research at the molecular level.",
    "prompt_tokens": 20837,
    "completion_tokens": 113,
    "total_tokens": 20950,
    "topic": "Bioinformatics - Protein Language Models",
    "method": "Protein sequence modeling; structure-aware vocabulary",
    "application": "Protein property prediction",
    "code_link": "https://github.com/westlake-repl/SaProt",
    "dataset_name": [
      "TAPE",
      "HumanPPI",
      "DeepLoc",
      "FLIP",
      "ProteinGym",
      "ClinVar"
    ]
  },
  {
    "id": "ixP76Y33y1",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "The Effect of Intrinsic Dataset Properties on Generalization: Unraveling Learning Differences Between Natural and Medical Images",
    "authors": [
      "Nicholas Konz",
      "Maciej A Mazurowski"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "This paper investigates discrepancies in how neural networks learn from different imaging domains, which are commonly overlooked when adopting computer vision techniques from the domain of natural images to other specialized domains such as medical images. Recent works have found that the generalization error of a trained network typically increases with the intrinsic dimension ($d_{data}$) of its training set. Yet, the steepness of this relationship varies significantly between medical (radiological) and natural imaging domains, with no existing theoretical explanation. We address this gap in knowledge by establishing and empirically validating a generalization scaling law with respect to $d_{data}$, and propose that the substantial scaling discrepancy between the two considered domains may be at least partially attributed to the higher intrinsic ``label sharpness'' ($K_\\mathcal{F}$) of medical imaging datasets, a metric which we propose. Next, we demonstrate an additional benefit of measuring the label sharpness of a training set: it is negatively correlated with the trained model's adversarial robustness, which notably leads to models for medical images having a substantially higher vulnerability to adversarial attack. Finally, we extend our $d_{data}$ formalism to the related metric of learned representation intrinsic dimension ($d_{repr}$), derive a generalization scaling law with respect to $d_{repr}$, and show that $d_{data}$ serves as an upper bound for $d_{repr}$. Our theoretical results are supported by thorough experiments with six models and eleven natural and medical imaging datasets over a range of training set sizes. Our findings offer insights into the influence of intrinsic dataset properties on generalization, representation learning, and robustness in deep neural networks. *Code link: https://github.com/mazurowski-lab/intrinsic-properties*",
    "keywords": "generalization, medical images, scaling law, intrinsic dimension, medical image analysis",
    "pdf_url": "https://openreview.net/pdf?id=ixP76Y33y1",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly studies “medical (radiological) … imaging domains” and compares learning on natural versus medical images. It proposes new metrics (intrinsic dimension, label sharpness) for medical imaging datasets and analyzes adversarial robustness of models trained on radiological data. These are clear indicators that the work is centered on medical image analysis, a core Healthcare AI application.",
    "prompt_tokens": 20324,
    "completion_tokens": 146,
    "total_tokens": 20470,
    "topic": "Medical Imaging - Adversarial Robustness",
    "method": "Scaling law derivation; empirical evaluation",
    "application": "Generalization ability analysis",
    "code_link": "https://github.com/mazurowski-lab/intrinsic-properties",
    "dataset_name": [
      "BraTS",
      "DBC",
      "Prostate MRI",
      "RSNA-IH-CT",
      "CheXpert",
      "MURA",
      "OAI",
      "ImageNet",
      "CIFAR10",
      "SVHN",
      "MNIST"
    ]
  },
  {
    "id": "rxlF2Zv8x0",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Improving protein optimization with smoothed fitness landscapes",
    "authors": [
      "Andrew Kirjner",
      "Jason Yim",
      "Raman Samusevich",
      "Shahar Bracha",
      "Tommi S. Jaakkola",
      "Regina Barzilay",
      "Ila R Fiete"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The ability to engineer novel proteins with higher fitness for a desired property would be revolutionary for biotechnology and medicine. Modeling the combinatorially large space of sequences is infeasible; prior methods often constrain optimization to a small mutational radius, but this drastically limits the design space. Instead of heuristics, we propose smoothing the fitness landscape to facilitate protein optimization. First, we formulate protein fitness as a graph signal then use Tikunov regularization to smooth the fitness landscape. We find optimizing in this smoothed landscape leads to improved performance across multiple methods in the GFP and AAV benchmarks. Second, we achieve state-of-the-art results utilizing discrete energy-based models and MCMC in the smoothed landscape. Our method, called Gibbs sampling with Graph-based Smoothing (GGS), demonstrates a unique ability to achieve 2.5 fold fitness improvement (with in-silico evaluation) over its training set. GGS demonstrates potential to optimize proteins in the limited data regime. Code: https://github.com/kirjner/GGS",
    "keywords": "protein design, discrete optimization, protein engineering, markov chain monte carlo, graph signal processing",
    "pdf_url": "https://openreview.net/pdf?id=rxlF2Zv8x0",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work centers on protein design and engineering—core tasks in biomedical research and biotechnology. The abstract explicitly frames “engineering novel proteins with higher fitness for a desired property” as revolutionary for “medicine,” and uses benchmarks on GFP and AAV (a viral vector for gene therapy). Optimizing proteins via graph‐smoothed fitness landscapes directly supports drug discovery and therapeutic development, situating this paper squarely within Biomedicine AI.",
    "prompt_tokens": 20848,
    "completion_tokens": 114,
    "total_tokens": 20962,
    "topic": "Bioinformatics - Protein Optimization",
    "method": "Graph-based smoothing; Gibbs With Gradients (GWG)",
    "application": "Protein sequence optimization for fitness improvement",
    "code_link": "https://github.com/kirjner/GGS",
    "dataset_name": [
      "Green Fluorescent Protein (GFP)",
      "Adeno-Associated Virus (AAV)"
    ]
  },
  {
    "id": "x5txICnnjC",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Synaptic Weight Distributions Depend on the Geometry of Plasticity",
    "authors": [
      "Roman Pogodin",
      "Jonathan Cornford",
      "Arna Ghosh",
      "Gauthier Gidel",
      "Guillaume Lajoie",
      "Blake Aaron Richards"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "A growing literature in computational neuroscience leverages gradient descent and learning algorithms that approximate it to study synaptic plasticity in the brain. However, the vast majority of this work ignores a critical underlying assumption: the choice of distance for synaptic changes - i.e. the geometry of synaptic plasticity. Gradient descent assumes that the distance is Euclidean, but many other distances are possible, and there is no reason that biology necessarily uses Euclidean geometry. Here, using the theoretical tools provided by mirror descent, we show that the distribution of synaptic weights will depend on the geometry of synaptic plasticity. We use these results to show that experimentally-observed log-normal weight distributions found in several brain areas are not consistent with standard gradient descent (i.e. a Euclidean geometry), but rather with non-Euclidean distances. Finally, we show that it should be possible to experimentally test for different synaptic geometries by comparing synaptic weight distributions before and after learning. Overall, our work shows that the current paradigm in theoretical work on synaptic plasticity that assumes Euclidean synaptic geometry may be misguided and that it should be possible to experimentally determine the true geometry of synaptic plasticity in the brain.",
    "keywords": "synaptic weight distributions, synaptic plasticity, biologically plausible learning, mirror descent",
    "pdf_url": "https://openreview.net/pdf?id=x5txICnnjC",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work focuses on synaptic plasticity and the distribution of synaptic weights in the brain—topics squarely within computational neuroscience and neurobiological modeling. Although it is theoretical, it proposes models of neural system dynamics (mirror descent for synaptic updates) rather than a purely abstract ML method. By modeling brain‐level phenomena (synaptic weight distributions, log-normal weight statistics in neural tissue), it falls under the “neuroscience or neurobiological modeling” category of Biomedicine AI.",
    "prompt_tokens": 20856,
    "completion_tokens": 111,
    "total_tokens": 20967,
    "topic": "Neuroscience - Synaptic Plasticity",
    "method": "Mirror descent; p-norm optimization; Negative entropy potential",
    "application": "Weight change modeling in neural networks",
    "code_link": "https://github.com/romanpogodin/synaptic-weight-distr",
    "dataset_name": [
      "MNIST",
      "Spine volumetric recordings"
    ]
  },
  {
    "id": "BqHaLnans2",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "LLM-CXR: Instruction-Finetuned LLM for CXR Image Understanding and Generation",
    "authors": [
      "Suhyeon Lee",
      "Won Jun Kim",
      "Jinho Chang",
      "Jong Chul Ye"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Following the impressive development of LLMs, vision-language alignment in LLMs is actively being researched to enable multimodal reasoning and visual input/output. This direction of research is particularly relevant to medical imaging because accurate medical image analysis and generation consist of a combination of reasoning based on visual features and prior knowledge. Many recent works have focused on training adapter networks that serve as an information bridge between image processing (encoding or generating) networks and LLMs; but presumably, in order to achieve maximum reasoning potential of LLMs on visual information as well, visual and language features should be allowed to interact more freely. This is especially important in the medical domain because understanding and generating medical images such as chest X-rays (CXR) require not only accurate visual and language-based reasoning but also a more intimate mapping between the two modalities. Thus, taking inspiration from previous work on the transformer and VQ-GAN combination for bidirectional image and text generation, we build upon this approach and develop a method for instruction-tuning an LLM pre-trained only on text to gain vision-language capabilities for medical images. Specifically, we leverage a pretrained LLM’s existing question-answering and instruction-following abilities to teach it to understand visual inputs by instructing it to answer questions about image inputs and, symmetrically, output both text and image responses appropriate to a given query by tuning the LLM with diverse tasks that encompass image-based text-generation and text-based image-generation. We show that our LLM-CXR trained in this approach shows better image-text alignment in both CXR understanding and generation tasks while being smaller in size compared to previously developed models that perform a narrower range of tasks.",
    "keywords": "large language model, multimodal, medical imaging, chest X-ray, bidirectional, instruction-tuning, vision-question answering",
    "pdf_url": "https://openreview.net/pdf?id=BqHaLnans2",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on chest X-ray (CXR) image understanding and generation, which is explicitly a medical imaging task. It describes a vision-language model tuned for CXR interpretation and generation, directly aligning with healthcare AI applications in radiology.",
    "prompt_tokens": 21206,
    "completion_tokens": 120,
    "total_tokens": 21326,
    "topic": "Medical Imaging - Multimodal Integration",
    "method": "Instruction fine-tuning; bidirectional multimodal capabilities with VQ-GAN",
    "application": "CXR-to-report generation; report-to-CXR generation; CXR-VQA",
    "code_link": "https://github.com/hyn2028/llm-cxr",
    "dataset_name": [
      "MIMIC-CXR-JPG"
    ]
  },
  {
    "id": "AhizIPytk4",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "How Well Do Supervised 3D Models Transfer to Medical Imaging Tasks?",
    "authors": [
      "Wenxuan Li",
      "Alan Yuille",
      "Zongwei Zhou"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The pre-training and fine-tuning paradigm has become prominent in transfer learning. For example, if the model is pre-trained on ImageNet and then fine-tuned to PASCAL, it can significantly outperform that trained on PASCAL from scratch. While ImageNet pre-training has shown enormous success, it is formed in 2D, and the learned features are for classification tasks; when transferring to more diverse tasks, like 3D image segmentation, its performance is inevitably compromised due to the deviation from the original ImageNet context. A significant challenge lies in the lack of large, annotated 3D datasets rivaling the scale of ImageNet for model pre-training. To overcome this challenge, we make two contributions. Firstly, we construct AbdomenAtlas 1.1 that comprises **9,262** three-dimensional computed tomography (CT) volumes with high-quality, per-voxel annotations of 25 anatomical structures and pseudo annotations of seven tumor types. Secondly, we develop a suite of models that are pre-trained on our AbdomenAtlas 1.1 for transfer learning. Our preliminary analyses indicate that the model trained only with 21 CT volumes, 672 masks, and 40 GPU hours has a transfer learning ability similar to the model trained with 5,050 (unlabeled) CT volumes and 1,152 GPU hours. More importantly, the transfer learning ability of supervised models can further scale up with larger annotated datasets, achieving significantly better performance than preexisting pre-trained models, irrespective of their pre-training methodologies or data sources. We hope this study can facilitate collective efforts in constructing larger 3D medical datasets and more releases of supervised pre-trained models.",
    "keywords": "Transfer Learning, Medical Image Analysis, Organ Segmentation",
    "pdf_url": "https://openreview.net/pdf?id=AhizIPytk4",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on 3D medical imaging—specifically CT volumes of the abdomen with per-voxel annotations of organs and tumors—and develops supervised pre-trained models for organ and tumor segmentation. It clearly targets a medical imaging task, which is a core aspect of Healthcare AI.",
    "prompt_tokens": 19994,
    "completion_tokens": 119,
    "total_tokens": 20113,
    "topic": "Medical Imaging - Abdominal CT",
    "method": "Supervised pre-training; CNN-based models; Transformer-based models",
    "application": "Organ and tumor segmentation",
    "code_link": "https://github.com/MrGiovanni/AbdomenAtlas",
    "dataset_name": [
      "AbdomenAtlas 1.1",
      "TotalSegmentator",
      "DAP Atlas",
      "AMOS22"
    ]
  },
  {
    "id": "FMMF1a9ifL",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Gradual Optimization Learning for Conformational Energy Minimization",
    "authors": [
      "Artem Tsypin",
      "Leonid Anatolievich Ugadiarov",
      "Kuzma Khrabrov",
      "Alexander Telepov",
      "Egor Rumiantsev",
      "Alexey Skrynnik",
      "Aleksandr Panov",
      "Dmitry P. Vetrov",
      "Elena Tutubalina",
      "Artur Kadurin"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Molecular conformation optimization is crucial to computer-aided drug discovery and materials design.\nTraditional energy minimization techniques rely on iterative optimization methods that use molecular forces calculated by a physical simulator (oracle) as anti-gradients.\nHowever, this is a computationally expensive approach that requires many interactions with a physical simulator.\nOne way to accelerate this procedure is to replace the physical simulator with a neural network.\nDespite recent progress in neural networks for molecular conformation energy prediction, such models are prone to errors due to distribution shift, leading to inaccurate energy minimization.\nWe find that the quality of energy minimization with neural networks can be improved by providing optimization trajectories as additional training data.\nStill, obtaining complete optimization trajectories demands a lot of additional computations.\nTo reduce the required additional data, we present the Gradual Optimization Learning Framework (GOLF) for energy minimization with neural networks.\nThe framework consists of an efficient data-collecting scheme and an external optimizer.\nThe external optimizer utilizes gradients from the energy prediction model to generate optimization trajectories, and the data-collecting scheme selects additional training data to be processed by the physical simulator. \nOur results demonstrate that the neural network trained with GOLF performs \\textit{on par} with the oracle on a benchmark of diverse drug-like molecules using significantly less additional data.",
    "keywords": "energy minimization, conformational optimization, geometry optimization",
    "pdf_url": "https://openreview.net/pdf?id=FMMF1a9ifL",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper addresses “molecular conformation optimization,” explicitly noting its importance for “computer-aided drug discovery and materials design.” Drug discovery is a core application area within Biomedicine AI, as it involves molecular‐level modeling for therapeutic development. Therefore, this work falls under the Biomedicine AI domain.",
    "prompt_tokens": 21012,
    "completion_tokens": 109,
    "total_tokens": 21121,
    "topic": "Molecular Modeling - Conformation Optimization",
    "method": "Neural Network Potentials (NNPs); Diffusion models; Active learning",
    "application": "Energy minimization - molecular conformations",
    "code_link": "https://github.com/AIRI-Institute/GOLF",
    "dataset_name": [
      "nablaDFT",
      "SPICE"
    ]
  },
  {
    "id": "3y1K6buO8c",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Brain decoding: toward real-time reconstruction of visual perception",
    "authors": [
      "Yohann Benchetrit",
      "Hubert Banville",
      "Jean-Remi King"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In the past five years, the use of generative and foundational AI systems has greatly improved the decoding of brain activity. Visual perception, in particular, can now be decoded from functional Magnetic Resonance Imaging (fMRI) with remarkable fidelity. This neuroimaging technique, however, suffers from a limited temporal resolution ($\\approx$0.5\\,Hz) and thus fundamentally constrains its real-time usage. Here, we propose an alternative approach based on magnetoencephalography (MEG), a neuroimaging device capable of measuring brain activity with high temporal resolution ($\\approx$5,000 Hz). For this, we develop an MEG decoding model trained with both contrastive and regression objectives and consisting of three modules: i) pretrained embeddings obtained from the image, ii) an MEG module trained end-to-end and iii) a pretrained image generator. Our results are threefold: Firstly, our MEG decoder shows a 7X improvement of image-retrieval over classic linear decoders. Second, late brain responses to images are best decoded with DINOv2, a recent foundational image model. Third, image retrievals and generations both suggest that high-level visual features can be decoded from MEG signals, although the same approach applied to 7T fMRI also recovers better low-level features. Overall, these results, while preliminary, provide an important step towards the decoding - in real-time - of the visual processes continuously unfolding within the human brain.",
    "keywords": "brain decoding, neuroimaging, image generation, visual perception",
    "pdf_url": "https://openreview.net/pdf?id=3y1K6buO8c",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work focuses on brain decoding using neuroimaging modalities (MEG and fMRI) to reconstruct visual perception. The use of “functional Magnetic Resonance Imaging (fMRI)” and “magnetoencephalography (MEG)” for decoding brain activity and the explicit task of “brain decoding” place it squarely within neuroscience/neurobiological modeling, which is a core sub‐area of Biomedicine AI.",
    "prompt_tokens": 20879,
    "completion_tokens": 98,
    "total_tokens": 20977,
    "topic": "Brain Decoding - Image Reconstruction",
    "method": "Latent diffusion model; Ridge regression; Brain embeddings alignment",
    "application": "Image generation from brain activity",
    "code_link": "N/A",
    "dataset_name": [
      "THINGS-MEG",
      "NSD (fMRI)"
    ]
  },
  {
    "id": "gxhRR8vUQb",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Diffeomorphic Mesh Deformation via Efficient Optimal Transport for Cortical Surface Reconstruction",
    "authors": [
      "Thanh Tung Le",
      "Khai Nguyen",
      "shanlin sun",
      "Kun Han",
      "Nhat Ho",
      "Xiaohui Xie"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Mesh deformation plays a pivotal role in many 3D vision tasks including dynamic simulations, rendering, and reconstruction. However, defining an efficient discrepancy between predicted and target meshes remains an open problem. A prevalent approach in current deep learning is the set-based approach which measures the discrepancy between two surfaces by comparing two randomly sampled point-clouds from the two meshes with Chamfer pseudo-distance. Nevertheless, the set-based approach still has limitations such as lacking a theoretical guarantee for choosing the number of points in sampled point-clouds, and the pseudo-metricity and the quadratic complexity of the Chamfer divergence. To address these issues, we propose a novel metric for learning mesh deformation. The metric is defined by sliced Wasserstein distance on meshes represented as probability measures that generalize the set-based approach. By leveraging probability measure space, we gain flexibility in encoding meshes using diverse forms of probability measures, such as continuous, empirical, and discrete measures via \\textit{varifold} representation. After having encoded probability measures, we can compare meshes by using the sliced Wasserstein distance which is an effective optimal transport distance with linear computational complexity and can provide a fast statistical rate for approximating the surface of meshes. To the end, we employ a neural ordinary differential equation (ODE) to deform the input surface into the target shape by modeling the trajectories of the points on the surface. Our experiments on cortical surface reconstruction demonstrate that our approach surpasses other competing methods in multiple datasets and metrics.",
    "keywords": "Mesh deformation, optimal transport, cortical surface reconstruction, computer vision, medical imaging.",
    "pdf_url": "https://openreview.net/pdf?id=gxhRR8vUQb",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper specifically addresses “cortical surface reconstruction,” which is a medical imaging task in neurology. Reconstructing the brain’s cortical surface from imaging data is directly relevant to healthcare and biomedical analysis. The abstract’s focus on cortical surface reconstruction using mesh deformation for 3D vision in medical imaging situates the work squarely within Healthcare AI.",
    "prompt_tokens": 20381,
    "completion_tokens": 103,
    "total_tokens": 20484,
    "topic": "Medical Imaging - Cortical Surface Reconstruction",
    "method": "Neural Ordinary Differential Equations (ODE); Sliced Wasserstein Distance",
    "application": "Cortical surface reconstruction from MRI",
    "code_link": "N/A",
    "dataset_name": [
      "ADNI",
      "OASIS",
      "TRT"
    ]
  },
  {
    "id": "okYdj8Ysru",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "A Lie Group Approach to Riemannian Batch Normalization",
    "authors": [
      "Ziheng Chen",
      "Yue Song",
      "Yunmei Liu",
      "Nicu Sebe"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Manifold-valued measurements exist in numerous applications within computer vision and machine learning. Recent studies have extended Deep Neural Networks (DNNs) to manifolds, and concomitantly, normalization techniques have also been adapted to several manifolds, referred to as Riemannian normalization. Nonetheless, most of the existing Riemannian normalization methods have been derived in an ad hoc manner and only apply to specific manifolds. This paper establishes a unified framework for Riemannian Batch Normalization (RBN) techniques on Lie groups. Our framework offers the theoretical guarantee of controlling both the Riemannian mean and variance. Empirically, we focus on Symmetric Positive Definite (SPD) manifolds, which possess three distinct types of Lie group structures. Using the deformation concept, we generalize the existing Lie groups on SPD manifolds into three families of parameterized Lie groups. Specific normalization layers induced by these Lie groups are then proposed for SPD neural networks. We demonstrate the effectiveness of our approach through three sets of experiments: radar recognition, human action recognition, and electroencephalography (EEG) classification. The code is available at https://github.com/GitZH-Chen/LieBN.git.",
    "keywords": "Lie Groups, Riemannian Batch Normalization, SPD Neural Networks",
    "pdf_url": "https://openreview.net/pdf?id=okYdj8Ysru",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the core contribution is a general Riemannian normalization method for Lie‐group‐based SPD neural networks, one of the three demonstration tasks is “electroencephalography (EEG) classification.” EEG is a time‐series biomedical signal used extensively in healthcare and neuroscience applications, which places this work within the scope of Healthcare/​Biomedicine AI.",
    "prompt_tokens": 20947,
    "completion_tokens": 126,
    "total_tokens": 21073,
    "topic": "Riemannian Geometry - Manifold Batch Normalization",
    "method": "Lie Algebra Normalization; Riemannian Batch Normalization (LieBN)",
    "application": "Radar recognition; Human action recognition; EEG classification",
    "code_link": "https://github.com/GitZH-Chen/LieBN.git",
    "dataset_name": [
      "Radar",
      "HDM05",
      "FPHA",
      "Hinss2021"
    ]
  },
  {
    "id": "RemfXx7ebP",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "RDesign: Hierarchical Data-efficient Representation Learning for Tertiary Structure-based RNA Design",
    "authors": [
      "Cheng Tan",
      "Yijie Zhang",
      "Zhangyang Gao",
      "Bozhen Hu",
      "Siyuan Li",
      "Zicheng Liu",
      "Stan Z. Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "While artificial intelligence has made remarkable strides in revealing the relationship between biological macromolecules' primary sequence and tertiary structure, designing RNA sequences based on specified tertiary structures remains challenging. Though existing approaches in protein design have thoroughly explored structure-to-sequence dependencies in proteins, RNA design still confronts difficulties due to structural complexity and data scarcity. Moreover, direct transplantation of protein design methodologies into RNA design fails to achieve satisfactory outcomes although sharing similar structural components. In this study, we aim to systematically construct a data-driven RNA design pipeline. We crafted a large, well-curated benchmark dataset and designed a comprehensive structural modeling approach to represent the complex RNA tertiary structure. More importantly, we proposed a hierarchical data-efficient representation learning framework that learns structural representations through contrastive learning at both cluster-level and sample-level to fully leverage the limited data. By constraining data representations within a limited hyperspherical space, the intrinsic relationships between data points could be explicitly imposed. Moreover, we incorporated extracted secondary structures with base pairs as prior knowledge to facilitate the RNA design process. Extensive experiments demonstrate the effectiveness of our proposed method, providing a reliable baseline for future RNA design tasks. The source code and benchmark dataset are available at https://github.com/A4Bio/RDesign.",
    "keywords": "Bioinformatics",
    "pdf_url": "https://openreview.net/pdf?id=RemfXx7ebP",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on designing RNA sequences based on specified tertiary structures, a classic molecular modeling and bioinformatics problem. It develops representation learning for “tertiary structure-based RNA design,” explicitly working with RNA structure and sequence data — a clear biomedicine application at the molecular level.",
    "prompt_tokens": 20730,
    "completion_tokens": 109,
    "total_tokens": 20839,
    "topic": "RNA Design - Tertiary Structure",
    "method": "Hierarchical Data-efficient Representation Learning; Contrastive Learning; Secondary Structure Constraining",
    "application": "RNA tertiary structure design",
    "code_link": "https://github.com/A4Bio/RDesign",
    "dataset_name": [
      "RNAsolo",
      "Protein Data Bank (PDB)"
    ]
  },
  {
    "id": "uH0FGECSEI",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Expected flow networks in stochastic environments and two-player zero-sum games",
    "authors": [
      "Marco Jiralerspong",
      "Bilun Sun",
      "Danilo Vucetic",
      "Tianyu Zhang",
      "Yoshua Bengio",
      "Gauthier Gidel",
      "Nikolay Malkin"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Generative flow networks (GFlowNets) are sequential sampling models trained to match a given distribution. GFlowNets have been successfully applied to various structured object generation tasks, sampling a diverse set of high-reward objects quickly. We propose expected flow networks (EFlowNets), which extend GFlowNets to stochastic environments. We show that EFlowNets outperform other GFlowNet formulations in stochastic tasks such as protein design. We then extend the concept of EFlowNets to adversarial environments, proposing adversarial flow networks (AFlowNets) for two-player zero-sum games. We show that AFlowNets learn to find above 80% of optimal moves in Connect-4 via self-play and outperform AlphaZero in tournaments. \nCode: https://github.com/GFNOrg/AdversarialFlowNetworks.",
    "keywords": "generative flow networks, GFlowNets, protein design, game theory, self-play, adversarial learning, stochastic environments, quantal response equilibrium, Luce agents, sequential decision making",
    "pdf_url": "https://openreview.net/pdf?id=uH0FGECSEI",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper’s methods are applied to “protein design,” which is a core task in molecular‐level biomedical research and drug discovery. The abstract explicitly cites “stochastic tasks such as protein design,” indicating relevance to biomedicine. While the paper also addresses game‐playing, the inclusion of protein design places it within the Biomedicine AI domain.",
    "prompt_tokens": 21298,
    "completion_tokens": 120,
    "total_tokens": 21418,
    "topic": "Reinforcement Learning - Stochastic & Adversarial Environments",
    "method": "Expected Flow Networks (EFlowNets); Adversarial Flow Networks (AFlowNets)",
    "application": "Stochastic generative modeling; Adversarial gameplay learning",
    "code_link": "https://github.com/GFNOrg/AdversarialFlowNetworks",
    "dataset_name": [
      "TFBind"
    ]
  },
  {
    "id": "uKB4cFNQFg",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "BEND: Benchmarking DNA Language Models on Biologically Meaningful Tasks",
    "authors": [
      "Frederikke Isa Marin",
      "Felix Teufel",
      "Marc Horlacher",
      "Dennis Madsen",
      "Dennis Pultz",
      "Ole Winther",
      "Wouter Boomsma"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The genome sequence contains the blueprint for governing cellular processes. \n  While the availability of genomes has vastly increased over the last decades, experimental annotation of the various functional, non-coding and regulatory elements encoded in the DNA sequence remains both expensive and challenging. This has sparked interest in unsupervised language modeling of genomic DNA, a paradigm that has seen great success for protein sequence data. \n  Although various DNA language models have been proposed, evaluation tasks often differ between individual works, and might not fully recapitulate the fundamental challenges of genome annotation, including the length, scale and sparsity of the data. In this study, we introduce **BEND**, a **BEN**chmark for **D**NA language models, featuring\n  a collection of realistic and biologically meaningful downstream tasks defined on the human genome.\n  We find that embeddings from current DNA LMs can approach performance of expert methods on some tasks, but only capture limited information about long-range features.\n  BEND is available at https://github.com/frederikkemarin/BEND.",
    "keywords": "Biological sequence analysis, enhancer annotation, gene finding, gene annotation, Language model, genome modelling, benchmark, LLM, embeddings, representations, DNA",
    "pdf_url": "https://openreview.net/pdf?id=uKB4cFNQFg",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This paper focuses on unsupervised language modeling of genomic DNA and downstream tasks such as “enhancer annotation,” “gene finding,” and “gene annotation,” which are core topics in genomics and molecular biology. It proposes a benchmark (BEND) for DNA language models applied to the human genome, directly placing it in the Biomedicine AI domain.",
    "prompt_tokens": 20859,
    "completion_tokens": 121,
    "total_tokens": 20980,
    "topic": "Bioinformatics - DNA Language Models",
    "method": "Self-supervised learning; DNA embeddings; zero-shot prediction",
    "application": "Noncoding variant effect prediction",
    "code_link": "https://github.com/frederikkemarin/BEND",
    "dataset_name": [
      "BEND",
      "ClinVar",
      "GENCODE",
      "DeepSEA",
      "1000 Genomes Project",
      "GRASP"
    ]
  },
  {
    "id": "RIEW6M9YoV",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Graph Generation with  $K^2$-trees",
    "authors": [
      "Yunhui Jang",
      "Dongwoo Kim",
      "Sungsoo Ahn"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Generating graphs from a target distribution is a significant challenge across many domains, including drug discovery and social network analysis. In this work, we introduce a novel graph generation method leveraging $K^2$ representation, originally designed for lossless graph compression. The $K^2$ representation enables compact generation while concurrently capturing an inherent hierarchical structure of a graph. In addition, we make contributions by (1) presenting a sequential $K^2$ representation that incorporates pruning, flattening, and tokenization processes and (2) introducing a Transformer-based architecture designed to generate the sequence by incorporating a specialized tree positional encoding scheme. Finally, we extensively evaluate our algorithm on four general and two molecular graph datasets to confirm its superiority for graph generation.",
    "keywords": "Graph generative models, graph neural networks",
    "pdf_url": "https://openreview.net/pdf?id=RIEW6M9YoV",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly cites “drug discovery” as a target application and evaluates its graph‐generation method on two molecular graph datasets. Molecular graph generation is a core task in computational drug design and molecular modeling, placing this work squarely in the Biomedicine AI domain.",
    "prompt_tokens": 20347,
    "completion_tokens": 101,
    "total_tokens": 20448,
    "topic": "Graph Generative Models - Hierarchical Representations",
    "method": "Transformer-based models; hierarchical graph generation; positional encoding",
    "application": "Molecular graph generation",
    "code_link": "https://github.com/yunhuijang/HGGT",
    "dataset_name": [
      "QM9",
      "ZINC250k"
    ]
  },
  {
    "id": "W2tCmRrj7H",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "A Flexible Generative Model for Heterogeneous Tabular EHR with Missing Modality",
    "authors": [
      "Huan He",
      "William hao",
      "Yuanzhe Xi",
      "Yong Chen",
      "Bradley Malin",
      "Joyce Ho"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Realistic synthetic electronic health records (EHRs) can be leveraged to acceler- ate methodological developments for research purposes while mitigating privacy concerns associated with data sharing. However, the training of Generative Ad- versarial Networks remains challenging, often resulting in issues like mode col- lapse. While diffusion models have demonstrated progress in generating qual- ity synthetic samples for tabular EHRs given ample denoising steps, their perfor- mance wanes when confronted with missing modalities in heterogeneous tabular EHRs data. For example, some EHRs contain solely static measurements, and some contain only contain temporal measurements, or a blend of both data types. To bridge this gap, we introduce FLEXGEN-EHR– a versatile diffusion model tai- lored for heterogeneous tabular EHRs, equipped with the capability of handling missing modalities in an integrative learning framework. We define an optimal transport module to align and accentuate the common feature space of hetero- geneity of EHRs. We empirically show that our model consistently outperforms existing state-of-the-art synthetic EHR generation methods both in fidelity by up to 3.10% and utility by up to 7.16%. Additionally, we show that our method can be successfully used in privacy-sensitive settings, where the original patient-level data cannot be shared.",
    "keywords": "Generative Model, Synthetic EHR",
    "pdf_url": "https://openreview.net/pdf?id=W2tCmRrj7H",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on generating realistic synthetic electronic health records (EHRs), explicitly mentioning “heterogeneous tabular EHRs,” “static measurements,” “temporal measurements,” and “privacy-sensitive settings where the original patient-level data cannot be shared.” This directly pertains to healthcare AI, as it deals with patient data modeling and synthesis for clinical and research applications.",
    "prompt_tokens": 20919,
    "completion_tokens": 97,
    "total_tokens": 21016,
    "topic": "EHR - Generative Models",
    "method": "Latent diffusion model; optimal transport module",
    "application": "Synthetic EHR generation – heterogeneous and missing data",
    "code_link": "N/A",
    "dataset_name": [
      "MIMIC-III",
      "eICU"
    ]
  },
  {
    "id": "8g26Yv1EOu",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Amortized Network Intervention to Steer the Excitatory Point Processes",
    "authors": [
      "Zitao Song",
      "Wendi Ren",
      "Shuang Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Excitatory point processes (i.e., event flows) occurring over dynamic graphs (i.e., evolving topologies) provide a fine-grained model to capture how discrete events may spread over time and space. How to effectively steer the event flows by modifying the dynamic graph structures presents an interesting problem, motivated by curbing the spread of infectious diseases through strategically locking down cities to mitigating traffic congestion via traffic light optimization. To address the intricacies of planning and overcome the high dimensionality inherent to such decision-making problems, we design an Amortized Network Interventions (ANI) framework, allowing for the pooling of optimal policies from history and other contexts while ensuring a permutation equivalent property. This property enables efficient knowledge transfer and sharing across diverse contexts. Each task is solved by an H-step lookahead model-based reinforcement learning, where neural ODEs are introduced to model the dynamics of the excitatory point processes. Instead of simulating rollouts from the dynamics model, we derive an analytical mean-field approximation for the event flows given the dynamics, making the online planning more efficiently solvable. We empirically illustrate that this ANI approach substantially enhances policy learning for unseen dynamics and exhibits promising outcomes in steering event flows through network intervention using synthetic and real COVID datasets.",
    "keywords": "Time series application, Point Process, Amortized Learning",
    "pdf_url": "https://openreview.net/pdf?id=8g26Yv1EOu",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the paper focuses on general ML methods for steering event flows on dynamic graphs, its primary motivation and empirical evaluation are in epidemiology—“curbing the spread of infectious diseases through strategically locking down cities” and experiments on “real COVID datasets.” These strong references to disease‐spread modeling and public‐health interventions place it firmly in the Healthcare AI domain.",
    "prompt_tokens": 20836,
    "completion_tokens": 98,
    "total_tokens": 20934,
    "topic": "Networked Systems - Temporal Dynamics Control",
    "method": "Amortized Network Interventions (ANI); Reinforcement Learning with Neural ODE",
    "application": "Dynamic network intervention",
    "code_link": "N/A",
    "dataset_name": [
      "SUMO traffic simulation",
      "NYTimes COVID-19 dataset"
    ]
  },
  {
    "id": "OUkZXbbwQr",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Reward Design for Justifiable Sequential Decision-Making",
    "authors": [
      "Aleksa Sukovic",
      "Goran Radanovic"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Equipping agents with the capacity to justify made decisions using supporting evidence represents a cornerstone of accountable decision-making. Furthermore, ensuring that justifications are in line with human expectations and societal norms is vital, especially in high-stakes situations such as healthcare. In this work, we propose the use of a debate-based reward model for reinforcement learning agents, where the outcome of a zero-sum debate game quantifies the justifiability of a decision in a particular state. This reward model is then used to train a justifiable policy, whose decisions can be more easily corroborated with supporting evidence. In the debate game, two argumentative agents take turns providing supporting evidence for two competing decisions. Given the proposed evidence, a proxy of a human judge evaluates which decision is better justified. We demonstrate the potential of our approach in learning policies for prescribing and justifying treatment decisions of septic patients. We show that augmenting the reward with the feedback signal generated by the debate-based reward model yields policies highly favored by the judge when compared to the policy obtained solely from the environment rewards, while hardly sacrificing any performance. Moreover, in terms of the overall performance and justifiability of trained policies, the debate-based feedback is comparable to the feedback obtained from an ideal judge proxy that evaluates decisions using the full information encoded in the state. This suggests that the debate game outputs key information contained in states that is most relevant for evaluating decisions, which in turn substantiates the practicality of combining our approach with human-in-the-loop evaluations. Lastly, we showcase that agents trained via multi-agent debate learn to propose evidence that is resilient to refutations and closely aligns with human preferences.",
    "keywords": "reinforcement learning, reward design, alignment, preference-based learning",
    "pdf_url": "https://openreview.net/pdf?id=OUkZXbbwQr",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper applies reinforcement learning to prescribe and justify treatment decisions for septic patients—a clear clinical decision-support task. The abstract explicitly discusses learning “policies for prescribing and justifying treatment decisions of septic patients,” which places it squarely in the Healthcare AI domain.",
    "prompt_tokens": 20995,
    "completion_tokens": 115,
    "total_tokens": 21110,
    "topic": "Reinforcement Learning - Reward Design",
    "method": "Debate-based reward modeling; Q-learning; Deep-Q networks",
    "application": "Treatment optimization – sepsis",
    "code_link": "https://github.com/aleksa-sukovic/iclr2024-reward-design-for-justifiable-rl",
    "dataset_name": [
      "MIMIC-III"
    ]
  },
  {
    "id": "xcMmebCT7s",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Learning to design protein-protein interactions with enhanced generalization",
    "authors": [
      "Anton Bushuiev",
      "Roman Bushuiev",
      "Petr Kouba",
      "Anatolii Filkin",
      "Marketa Gabrielova",
      "Michal Gabriel",
      "Jiri Sedlar",
      "Tomas Pluskal",
      "Jiri Damborsky",
      "Stanislav Mazurenko",
      "Josef Sivic"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Discovering mutations enhancing protein-protein interactions (PPIs) is critical for advancing biomedical research and developing improved therapeutics. While machine learning approaches have substantially advanced the field, they often struggle to generalize beyond training data in practical scenarios. The contributions of this work are three-fold. First, we construct PPIRef, the largest and non-redundant dataset of 3D protein-protein interactions, enabling effective large-scale learning. Second, we leverage the PPIRef dataset to pre-train PPIformer, a new SE(3)-equivariant model generalizing across diverse protein-binder variants. We fine-tune PPIformer to predict effects of mutations on protein-protein interactions via a thermodynamically motivated adjustment of the pre-training loss function. Finally, we demonstrate the enhanced generalization of our new PPIformer approach by outperforming other state-of-the-art methods on new, non-leaking splits of standard labeled PPI mutational data and independent case studies optimizing a human antibody against SARS-CoV-2 and increasing the thrombolytic activity of staphylokinase.",
    "keywords": "protein-protein interactions, protein design, generalization, self-supervised learning, equivariant 3D representations",
    "pdf_url": "https://openreview.net/pdf?id=xcMmebCT7s",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on protein–protein interactions and design of mutations to enhance binding, which is directly relevant to drug discovery and therapeutic development (e.g., “optimizing a human antibody against SARS-CoV-2” and “increasing the thrombolytic activity of staphylokinase”). It uses machine learning for protein design—a core Biomedicine AI application involving molecular modeling and therapeutic protein engineering.",
    "prompt_tokens": 20668,
    "completion_tokens": 112,
    "total_tokens": 20780,
    "topic": "Protein Design - Interaction Prediction",
    "method": "Self-supervised learning; SE(3)-equivariant model",
    "application": "Mutation effect prediction – Protein binding",
    "code_link": "https://github.com/anton-bushuiev/PPIRef",
    "dataset_name": [
      "PPIRef50K",
      "SKEMPI v2.0"
    ]
  },
  {
    "id": "kJFIH23hXb",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "SE(3)-Stochastic Flow Matching for Protein Backbone Generation",
    "authors": [
      "Joey Bose",
      "Tara Akhound-Sadegh",
      "Guillaume Huguet",
      "Kilian FATRAS",
      "Jarrid Rector-Brooks",
      "Cheng-Hao Liu",
      "Andrei Cristian Nica",
      "Maksym Korablyov",
      "Michael M. Bronstein",
      "Alexander Tong"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The computational design of novel protein structures has the potential to impact numerous scientific disciplines greatly. Toward this goal, we introduce \\foldflow, a series of novel generative models of increasing modeling power based on the flow-matching paradigm over $3\\mathrm{D}$ rigid motions---i.e. the group $\\mathrm{SE(3)}$---enabling accurate modeling of protein backbones. We first introduce $\\text{FoldFlow-Base}$, a simulation-free approach to learning deterministic continuous-time dynamics and matching invariant target distributions on $\\mathrm{SE(3)}$. We next accelerate training by incorporating Riemannian optimal transport to create $\\text{FoldFlow-OT}$, leading to the construction of both more simple and stable flows. Finally, we design \\foldflowsfm, coupling both Riemannian OT and simulation-free training to learn stochastic continuous-time dynamics over $\\mathrm{SE(3)}$. Our family of $\\text{FoldFlow}$, generative models offers several key advantages over previous approaches to the generative modeling of proteins: they are more stable and faster to train than diffusion-based approaches, and our models enjoy the ability to map any invariant source distribution to any invariant target distribution over $\\mathrm{SE(3)}$. Empirically, we validate $\\text{FoldFlow}$, on protein backbone generation of up to $300$ amino acids leading to high-quality designable, diverse, and novel samples.",
    "keywords": "Proteins; Equivariance; Riemannian; Flow Matching; Generative models",
    "pdf_url": "https://openreview.net/pdf?id=kJFIH23hXb",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on generative modeling of protein backbones (“Protein Backbone Generation”, “proteins; … protein backbones”), which directly relates to molecular modeling and protein design—key areas in biomedicine and drug discovery. The methods (SE(3) flow matching over 3D rigid motions) are applied to generate novel protein structures, a common task in therapeutic protein engineering and biomedicine.",
    "prompt_tokens": 21047,
    "completion_tokens": 98,
    "total_tokens": 21145,
    "topic": "Bioinformatics - Protein Generative Modeling",
    "method": "Flow matching; Riemannian optimal transport",
    "application": "Protein backbone generation",
    "code_link": "N/A",
    "dataset_name": [
      "Protein Data Bank (PDB)",
      "Swissprot",
      "AlphaFold2"
    ]
  },
  {
    "id": "itGkF993gz",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "MAPE-PPI: Towards Effective and Efficient Protein-Protein Interaction Prediction via Microenvironment-Aware Protein Embedding",
    "authors": [
      "Lirong Wu",
      "Yijun Tian",
      "Yufei Huang",
      "Siyuan Li",
      "Haitao Lin",
      "Nitesh V Chawla",
      "Stan Z. Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Protein-Protein Interactions (PPIs) are fundamental in various biological processes and play a key role in life activities. The growing demand and cost of experimental PPI assays require computational methods for efficient PPI prediction. While existing methods rely heavily on protein sequence for PPI prediction, it is the protein structure that is the key to determine the interactions. To take both protein modalities into account, we define the microenvironment of an amino acid residue by its sequence and structural contexts, which describe the surrounding chemical properties and geometric features. In addition, microenvironments defined in previous work are largely based on experimentally assayed physicochemical properties, for which the \"vocabulary\" is usually extremely small. This makes it difficult to cover the diversity and complexity of microenvironments. In this paper, we propose Microenvironment-Aware Protein Embedding for PPI prediction (MPAE-PPI), which encodes microenvironments into chemically meaningful discrete codes via a sufficiently large microenvironment \"vocabulary\" (i.e., codebook). Moreover, we propose a novel pre-training strategy, namely Masked Codebook Modeling (MCM), to capture the dependencies between different microenvironments by randomly masking the codebook and reconstructing the input. With the learned microenvironment codebook, we can reuse it as an off-the-shelf tool to efficiently and effectively encode proteins of different sizes and functions for large-scale PPI prediction. Extensive experiments show that MAPE-PPI can scale to PPI prediction with millions of PPIs with superior trade-offs between effectiveness and computational efficiency than the state-of-the-art competitors.",
    "keywords": "Bioinformatics, Protein-Protein Interaction, Protein Sequence-Structure Co-Modeling",
    "pdf_url": "https://openreview.net/pdf?id=itGkF993gz",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper develops a computational method for predicting protein–protein interactions (PPIs), a core task in molecular biology and bioinformatics directly relevant to drug discovery, disease mechanisms, and therapeutic design. Terms like “Protein-Protein Interaction,” “Microenvironment-Aware Protein Embedding,” and “Bioinformatics” point to a biomedical application rather than a purely general machine-learning method.",
    "prompt_tokens": 20879,
    "completion_tokens": 140,
    "total_tokens": 21019,
    "topic": "Bioinformatics - Protein-Protein Interaction Prediction",
    "method": "Graph Neural Networks (GNN); Masked Codebook Modeling (MCM); VQ-VAE",
    "application": "Protein-protein interaction (PPI) prediction",
    "code_link": "https://github.com/LirongWu/MAPE-PPI",
    "dataset_name": [
      "STRING",
      "SHS27k",
      "SHS148k"
    ]
  },
  {
    "id": "lKxL5zkssv",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "CLIP-MUSED: CLIP-Guided Multi-Subject Visual Neural Information Semantic Decoding",
    "authors": [
      "Qiongyi Zhou",
      "Changde Du",
      "Shengpei Wang",
      "Huiguang He"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The study of decoding visual neural information faces challenges in generalizing single-subject decoding models to multiple subjects, due to individual differences. Moreover, the limited availability of data from a single subject has a constraining impact on model performance. Although prior multi-subject decoding methods have made significant progress, they still suffer from several limitations, including difficulty in extracting global neural response features, linear scaling of model parameters with the number of subjects, and inadequate characterization of the relationship between neural responses of different subjects to various stimuli.\nTo overcome these limitations, we propose a CLIP-guided Multi-sUbject visual neural information SEmantic Decoding (CLIP-MUSED) method. Our method consists of a Transformer-based feature extractor to effectively model global neural representations. It also incorporates learnable subject-specific tokens that facilitates the aggregation of multi-subject data without a linear increase of parameters. Additionally, we employ representational similarity analysis (RSA) to guide token representation learning based on the topological relationship of visual stimuli in the representation space of CLIP, enabling full characterization of the relationship between neural responses of different subjects under different stimuli. Finally, token representations are used for multi-subject semantic decoding. Our proposed method outperforms single-subject decoding methods and achieves state-of-the-art performance among the existing multi-subject methods on two fMRI datasets. Visualization results provide insights into the effectiveness of our proposed method. Code is available at https://github.com/CLIP-MUSED/CLIP-MUSED.",
    "keywords": "Multi-subject visual neural decoding, representational similarity analysis, CLIP, transformer",
    "pdf_url": "https://openreview.net/pdf?id=lKxL5zkssv",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper centers on decoding visual neural information from multi-subject fMRI data, employing a transformer to model global neural representations and leveraging representational similarity analysis of brain responses. Its use of fMRI imaging and brain-decoding methods places it squarely in the realm of neuroimaging and neuroscience, which are core areas of Healthcare/​Biomedicine AI.",
    "prompt_tokens": 21102,
    "completion_tokens": 121,
    "total_tokens": 21223,
    "topic": "Neural Decoding - Multi-subject Semantic Decoding",
    "method": "Transformer-based fMRI feature extraction; CLIP-based feature guidance; Representational Similarity Analysis (RSA)",
    "application": "Multi-subject semantic decoding from neural responses",
    "code_link": "https://github.com/CLIP-MUSED/CLIP-MUSED",
    "dataset_name": [
      "HCP",
      "NSD"
    ]
  },
  {
    "id": "2Mo7v69otj",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Pooling Image Datasets with Multiple Covariate Shift and Imbalance",
    "authors": [
      "Sotirios Panagiotis Chytas",
      "Vishnu Suresh Lokhande",
      "Vikas Singh"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Small sample sizes are common in many disciplines, \nwhich necessitates pooling roughly similar datasets across \nmultiple sites/institutions to study weak but relevant \nassociations between images and disease incidence. Such \ndata often manifest shifts and imbalances in covariates \n(secondary non-imaging data). \nThese issues are well-studied for classical models, but \nthe ideas simply do not apply to overparameterized DNN models. \nConsequently, recent work has shown how strategies from \nfairness and invariant representation learning provides \na meaningful starting point, but the current repertoire \nof methods remains limited to accounting for shifts/imbalances in just a couple of covariates at a time. In this paper, we show how \nviewing this problem from the perspective of Category theory \nprovides a simple and effective solution that completely avoids \nelaborate multi-stage training pipelines that would otherwise be \nneeded. We show the effectiveness of this approach via \nextensive experiments on real datasets. Further, we \ndiscuss how our style of formulation offers a unified \nperspective on at least 5+ distinct \nproblem settings in vision, from self-supervised learning\nto matching problems in 3D reconstruction.",
    "keywords": "image harmonization, medical imaging",
    "pdf_url": "https://openreview.net/pdf?id=2Mo7v69otj",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract explicitly discusses pooling image datasets “to study weak but relevant associations between images and disease incidence,” and the keywords include “medical imaging.” This clearly places the work in the medical imaging subfield of Healthcare AI.",
    "prompt_tokens": 20674,
    "completion_tokens": 109,
    "total_tokens": 20783,
    "topic": "Neuroimaging Analysis - Data Harmonization",
    "method": "Invariant representation learning; Category-theory inspired constraints",
    "application": "Alzheimer's disease classification",
    "code_link": "https://github.com/SPChytas/CatHarm",
    "dataset_name": [
      "ADNI",
      "ADCP",
      "German",
      "Adult"
    ]
  },
  {
    "id": "sTYuRVrdK3",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Evaluating Representation Learning on the Protein Structure Universe",
    "authors": [
      "Arian Rokkum Jamasb",
      "Alex Morehead",
      "Chaitanya K. Joshi",
      "Zuobai Zhang",
      "Kieran Didi",
      "Simon V Mathis",
      "Charles Harris",
      "Jian Tang",
      "Jianlin Cheng",
      "Pietro Lio",
      "Tom Leon Blundell"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We introduce ProteinWorkshop, a comprehensive benchmark suite for representation learning on protein structures with Geometric Graph Neural Networks. We consider large-scale pre-training and downstream tasks on both experimental and predicted structures to enable the systematic evaluation of the quality of the learned structural representation and their usefulness in capturing functional relationships for downstream tasks. We find that: (1) large-scale pretraining on AlphaFold structures and auxiliary tasks consistently improve the performance of both rotation-invariant and equivariant GNNs, and (2) more expressive equivariant GNNs benefit from pretraining to a greater extent compared to invariant models.\nWe aim to establish a common ground for the machine learning and computational biology communities to rigorously compare and advance protein structure representation learning. Our open-source codebase reduces the barrier to entry for working with large protein structure datasets by providing: (1) storage-efficient dataloaders for large-scale structural databases including AlphaFoldDB and ESM Atlas, as well as (2) utilities for constructing new tasks from the entire PDB. ProteinWorkshop is available at: github.com/a-r-j/ProteinWorkshop.",
    "keywords": "Protein, Representation, Learning, Protein Structure",
    "pdf_url": "https://openreview.net/pdf?id=sTYuRVrdK3",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work focuses on representation learning for protein structures—a core molecular‐level task in biomedicine. It leverages large‐scale structural databases (AlphaFoldDB, PDB) and targets functional relationships in proteins, which are foundational for applications like drug discovery, protein design, and other biomedical research.",
    "prompt_tokens": 20936,
    "completion_tokens": 105,
    "total_tokens": 21041,
    "topic": "Bioinformatics - Protein Representation Learning",
    "method": "Sequence-structure co-denoising; masked attribute prediction; structure denoising",
    "application": "Protein fold prediction",
    "code_link": "N/A",
    "dataset_name": [
      "CATH",
      "PPI Site Prediction",
      "Metal Binding Site Prediction",
      "Gene Ontology Prediction"
    ]
  },
  {
    "id": "Y3BbxvAQS9",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "DecompOpt: Controllable and Decomposed Diffusion Models for Structure-based Molecular Optimization",
    "authors": [
      "Xiangxin Zhou",
      "Xiwei Cheng",
      "Yuwei Yang",
      "Yu Bao",
      "Liang Wang",
      "Quanquan Gu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Recently, 3D generative models have shown promising performances in structure-based drug design by learning to generate ligands given target binding sites. However, only modeling the target-ligand distribution can hardly fulfill one of the main goals in drug discovery -- designing novel ligands with desired properties, e.g., high binding affinity, easily synthesizable, etc. This challenge becomes particularly pronounced when the target-ligand pairs used for training do not align with these desired properties. Moreover, most existing methods aim at solving de novo design task, while many generative scenarios requiring flexible controllability, such as R-group optimization and scaffold hopping, have received little attention. In this work, we propose DecompOpt, a structure-based molecular optimization method based on a controllable and decomposed diffusion model. DecompOpt presents a new generation paradigm which combines optimization with conditional diffusion models to achieve desired properties while adhering to the molecular grammar. Additionally, DecompOpt offers a unified framework covering both de novo design and controllable generation. To achieve so, ligands are decomposed into substructures which allows fine-grained control and local optimization. Experiments show that DecompOpt can efficiently generate molecules with improved properties than strong de novo baselines, and demonstrate great potential in controllable generation tasks.",
    "keywords": "Structure-based drug design, molecule optimization, diffusion models, 3D molecule generation",
    "pdf_url": "https://openreview.net/pdf?id=Y3BbxvAQS9",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper targets structure-based drug design by generating and optimizing ligands for protein binding sites, explicitly aiming to improve properties such as binding affinity and synthesizability. This focus on molecular generation for drug discovery places it squarely in the Biomedicine AI domain.",
    "prompt_tokens": 21014,
    "completion_tokens": 85,
    "total_tokens": 21099,
    "topic": "Drug Discovery - Target-based",
    "method": "Controllable and decomposed diffusion models",
    "application": "Structure-based molecular optimization",
    "code_link": "N/A",
    "dataset_name": [
      "CrossDocked2020"
    ]
  },
  {
    "id": "pe0Vdv7rsL",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Graph Transformers on EHRs: Better Representation Improves Downstream Performance",
    "authors": [
      "Raphael Poulain",
      "Rahmatollah Beheshti"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Following the success of transformer-based methods across various machine learning applications, their adoption for healthcare predictive tasks using electronic health records (EHRs)  has also expanded extensively. Similarly, graph-based methods have been shown to be very effective in capturing inherent graph-type relationships in EHRs, leading to improved downstream performance. Although integrating these two families of approaches seems like a natural next step, in practice, creating such a design is challenging and has not been done. This is partly due to known EHR problems, such as high sparsity, making extracting meaningful temporal representations of medical visits challenging. In this study, we propose GT-BEHRT, a new approach that leverages temporal visit embeddings extracted from a graph transformer and uses a BERT-based model to obtain more robust patient representations, especially on longer EHR sequences. The graph-based approach allows GT-BEHRT to implicitly capture the intrinsic graphical relationships between medical observations, while the BERT model extracts the temporal relationships between visits, loosely mimicking the clinicians' decision-making process. As part of our method, we also present a two-step pre-training strategy for learning better graphical and temporal representations. Our proposed method achieves state-of-the-art performance in a variety of standard medical predictive tasks, demonstrating the versatility of our approach.",
    "keywords": "transformers, graph neural networks, electronic health records",
    "pdf_url": "https://openreview.net/pdf?id=pe0Vdv7rsL",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly focuses on “predictive tasks using electronic health records (EHRs)” and proposes a model (GT-BEHRT) that learns representations from temporal medical visits and intrinsic graph relationships among clinical observations. References to “medical visits,” “patient representations,” and achieving state-of-the-art performance on “standard medical predictive tasks” clearly situate this work in the Healthcare AI domain.",
    "prompt_tokens": 20859,
    "completion_tokens": 114,
    "total_tokens": 20973,
    "topic": "EHR - Visit-level representation",
    "method": "Graph Transformer; Transformer encoder",
    "application": "Mortality prediction – ICU; Prolonged length of stay prediction – ICU; Heart failure prediction",
    "code_link": "https://github.com/healthylaife/GT-BEHRT",
    "dataset_name": [
      "MIMIC-IV",
      "All of Us"
    ]
  },
  {
    "id": "xI4yNlkaqh",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Towards 3D Molecule-Text Interpretation in Language Models",
    "authors": [
      "Sihang Li",
      "Zhiyuan Liu",
      "Yanchen Luo",
      "Xiang Wang",
      "Xiangnan He",
      "Kenji Kawaguchi",
      "Tat-Seng Chua",
      "Qi Tian"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Language Models (LMs) have greatly influenced diverse domains. However, their inherent limitation in comprehending 3D molecular structures has considerably constrained their potential in the biomolecular domain. To bridge this gap, we focus on 3D molecule-text interpretation, and propose 3D-MoLM: 3D-Molecular Language Modeling. Specifically, 3D-MoLM enables an LM to interpret and analyze 3D molecules by equipping the LM with a 3D molecular encoder. This integration is achieved by a 3D molecule-text projector, bridging the 3D molecular encoder’s representation space and the LM’s input space. Moreover, to enhance 3D\u0002MoLM’s ability of cross-modal molecular understanding and instruction following, we meticulously curated a 3D molecule-centric instruction tuning dataset – 3D-MoIT. Through 3D molecule-text alignment and 3D molecule-centric instruction tuning, 3D-MoLM establishes an integration of 3D molecular encoder and LM. It significantly surpasses existing baselines on downstream tasks, including molecule\u0002text retrieval, molecule captioning, and more challenging open-text molecular QA tasks, especially focusing on 3D-dependent properties. We will release our codes and datasets at https://github.com/lsh0520/3D-MoLM.",
    "keywords": "3D molecules, Large Language Model, 3D-text interpretation",
    "pdf_url": "https://openreview.net/pdf?id=xI4yNlkaqh",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “3D molecular structures” in the “biomolecular domain,” proposing methods for 3D molecule-text interpretation and tasks such as “molecule-text retrieval,” “molecule captioning,” and “open-text molecular QA,” with emphasis on “3D-dependent properties.” This clearly situates it in molecular modeling and drug‐discovery-adjacent research, which falls under Biomedicine AI.",
    "prompt_tokens": 20501,
    "completion_tokens": 111,
    "total_tokens": 20612,
    "topic": "Drug Discovery - Molecule Representation",
    "method": "3D molecular encoding; instruction tuning; 3D molecule-text alignment",
    "application": "Molecule-text retrieval; molecule captioning; open-text molecular QA",
    "code_link": "N/A",
    "dataset_name": [
      "PubChem",
      "PubChemQC",
      "3D-MoIT"
    ]
  },
  {
    "id": "9W6KaAcYlr",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Most discriminative stimuli for functional cell type clustering",
    "authors": [
      "Max F Burg",
      "Thomas Zenkel",
      "Michaela Vystrčilová",
      "Jonathan Oesterle",
      "Larissa Höfling",
      "Konstantin Friedrich Willeke",
      "Jan Lause",
      "Sarah Müller",
      "Paul G. Fahey",
      "Zhiwei Ding",
      "Kelli Restivo",
      "Shashwat Sridhar",
      "Tim Gollisch",
      "Philipp Berens",
      "Andreas S. Tolias",
      "Thomas Euler",
      "Matthias Bethge",
      "Alexander S Ecker"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Identifying cell types and understanding their functional properties is crucial for unraveling the mechanisms underlying perception and cognition. In the retina, functional types can be identified by carefully selected stimuli, but this requires expert domain knowledge and biases the procedure towards previously known cell types. In the visual cortex, it is still unknown what functional types exist and how to identify them. Thus, for unbiased identification of the functional cell types in retina and visual cortex, new approaches are needed. Here we propose an optimization-based clustering approach using deep predictive models to obtain functional clusters of neurons using Most Discriminative Stimuli (MDS). Our approach alternates between stimulus optimization with cluster reassignment akin to an expectation-maximization algorithm. The algorithm recovers functional clusters in mouse retina, marmoset retina and macaque visual area V4. This demonstrates that our approach can successfully find discriminative stimuli across species, stages of the visual system and recording techniques. The resulting most discriminative stimuli can be used to assign functional cell types fast and on the fly, without the need to train complex predictive models or show a large natural scene dataset, paving the way for experiments that were previously limited by experimental time. Crucially, MDS are interpretable: they visualize the distinctive stimulus patterns that most unambiguously identify a specific type of neuron.",
    "keywords": "clustering, discriminative stimuli, interpretable, optimization, expectation-maximization, functional cell types, digital twins, feature visualization, pre-image search, maximally exciting image",
    "pdf_url": "https://openreview.net/pdf?id=9W6KaAcYlr",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on functional clustering of retinal and cortical neurons (“mouse retina, marmoset retina and macaque visual area V4”), which falls squarely within neurobiological modeling. Although it does not address a direct clinical application, it is a computational neuroscience method for identifying “functional cell types,” a topic listed under “neuroscience or neurobiological modeling” in the domain definitions.",
    "prompt_tokens": 21108,
    "completion_tokens": 119,
    "total_tokens": 21227,
    "topic": "Neuroscience - Functional Clustering",
    "method": "Expectation-Maximization Algorithm; Digital Twin Modeling",
    "application": "Neural activity-based clustering",
    "code_link": "https://github.com/ecker-lab/most-discriminative-stimuli",
    "dataset_name": [
      "Mouse RGC dataset",
      "Marmoset RGC dataset",
      "Macaque V4 dataset"
    ]
  },
  {
    "id": "cXbnGtO0NZ",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Latent 3D Graph Diffusion",
    "authors": [
      "Yuning You",
      "Ruida Zhou",
      "Jiwoong Park",
      "Haotian Xu",
      "Chao Tian",
      "Zhangyang Wang",
      "Yang Shen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Generating 3D graphs of symmetry-group equivariance is of intriguing potential in broad applications from machine vision to molecular discovery. Emerging approaches adopt diffusion generative models (DGMs) with proper re-engineering to capture 3D graph distributions. In this paper, we raise an orthogonal and fundamental question of in what (latent) space we should diffuse 3D graphs. ❶ We motivate the study with theoretical analysis showing that the performance bound of 3D graph diffusion can be improved in a latent space versus the original space, provided that the latent space is of (i) low dimensionality yet (ii) high quality (i.e., low reconstruction error) and DGMs have (iii) symmetry preservation as an inductive bias. ❷ Guided by the theoretical guidelines, we propose to perform 3D graph diffusion in a low-dimensional latent space, which is learned through cascaded 2D–3D graph autoencoders for low-error reconstruction and symmetry-group invariance. The overall pipeline is dubbed latent 3D graph diffusion. ❸ Motivated by applications in molecular discovery, we further extend latent 3D graph diffusion to conditional generation given SE(3)-invariant attributes or equivariant 3D objects. ❹ We also demonstrate empirically that out-of-distribution conditional generation can be further improved by regularizing the latent space via graph self-supervised learning. We validate through comprehensive experiments that our method generates 3D molecules of higher validity / drug-likeliness and comparable or better conformations / energetics, while being an order of magnitude faster in training. Codes are released at https://github.com/Shen-Lab/LDM-3DG.",
    "keywords": "3D graphs, latent diffusion models, in/equivariant representations",
    "pdf_url": "https://openreview.net/pdf?id=cXbnGtO0NZ",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on generating 3D molecular graphs and explicitly targets “molecular discovery” with metrics like “drug-likeliness,” “conformations” and “energetics.” Such work on 3D molecule generation for drug discovery firmly places it in the Biomedicine AI domain.",
    "prompt_tokens": 20658,
    "completion_tokens": 133,
    "total_tokens": 20791,
    "topic": "Drug Discovery - Molecular Graphs",
    "method": "Latent 3D graph diffusion; cascaded 2D–3D graph autoencoder; graph self-supervised learning (GSSL)",
    "application": "Molecular graph generation – drug discovery",
    "code_link": "https://github.com/Shen-Lab/LDM-3DG",
    "dataset_name": [
      "QM9",
      "CrossDocked",
      "ChEMBL",
      "PubChemQC"
    ]
  },
  {
    "id": "YrXHEb2qMb",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Posterior Sampling Based on Gradient Flows of the MMD with Negative Distance Kernel",
    "authors": [
      "Paul Hagemann",
      "Johannes Hertrich",
      "Fabian Altekrüger",
      "Robert Beinert",
      "Jannis Chemseddine",
      "Gabriele Steidl"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We propose conditional flows of the maximum mean discrepancy (MMD) with the negative distance kernel for posterior sampling and conditional generative modelling. This MMD, which is also known as energy distance, has several advantageous properties like efficient computation via slicing and sorting. We approximate the joint distribution of the ground truth and the observations using discrete Wasserstein gradient flows and establish an error bound for the posterior distributions. Further, we prove that our particle flow is indeed a Wasserstein gradient flow of an appropriate functional. The power of our method is demonstrated by numerical examples including conditional image generation and inverse problems like superresolution, inpainting and computed tomography in low-dose and limited-angle settings.",
    "keywords": "Bayesian inverse Problems, MMD, Gradient Flows, Deep Learning",
    "pdf_url": "https://openreview.net/pdf?id=YrXHEb2qMb",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly targets inverse‐problem methods for computed tomography (“computed tomography in low-dose and limited-angle settings”), which is a core medical imaging task in healthcare AI. While the methodology is general, the inclusion of CT reconstruction positions it within the Healthcare AI domain.",
    "prompt_tokens": 20933,
    "completion_tokens": 119,
    "total_tokens": 21052,
    "topic": "Inverse Problems - Conditional Generative Models",
    "method": "Conditional MMD flows; Wasserstein gradient flows",
    "application": "Posterior sampling – Bayesian inverse problems",
    "code_link": "https://github.com/FabianAltekrueger/Conditional_MMD_Flows",
    "dataset_name": [
      "MNIST",
      "FashionMNIST",
      "CIFAR10",
      "LoDoPaB"
    ]
  },
  {
    "id": "Fj7Fzm5lWL",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Let's do the time-warp-attend: Learning topological invariants of dynamical systems",
    "authors": [
      "Noa Moriel",
      "Matt Ricci",
      "Mor Nitzan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Dynamical systems across the sciences, from electrical circuits to ecological networks, undergo qualitative and often catastrophic changes in behavior, called bifurcations, when their underlying parameters cross a threshold. Existing methods predict oncoming catastrophes in individual systems but are primarily time-series-based and struggle both to categorize qualitative dynamical regimes across diverse systems and to generalize to real data. To address this challenge, we propose a data-driven, physically-informed deep-learning framework for classifying dynamical regimes and characterizing bifurcation boundaries based on the extraction of topologically invariant features. We focus on the paradigmatic case of the supercritical Hopf bifurcation, which is used to model periodic dynamics across a wide range of applications. Our convolutional attention method is trained with data augmentations that encourage the learning of topological invariants which can be used to detect bifurcation boundaries in unseen systems and to design models of biological systems like oscillatory gene regulatory networks. We further demonstrate our method's use in analyzing real data by recovering distinct proliferation and differentiation dynamics along pancreatic endocrinogenesis trajectory in gene expression space based on single-cell data. Our method provides valuable insights into the qualitative, long-term behavior of a wide range of dynamical systems, and can detect bifurcations or catastrophic transitions in large-scale physical and biological systems.",
    "keywords": "dynamical systems, bifurcations, topological invariance, Hopf bifurcation, physics-informed machine learning, augmentation, single-cell RNA-sequencing",
    "pdf_url": "https://openreview.net/pdf?id=Fj7Fzm5lWL",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the core contribution is a general physics-informed ML framework for classifying dynamical systems via topological invariants, the paper demonstrates a real‐data application on single‐cell RNA-sequencing (“single-cell data”) to recover proliferation and differentiation dynamics in pancreatic endocrinogenesis. References to “oscillatory gene regulatory networks,” “single-cell gene expression,” and “endocrinogenesis trajectory” indicate a direct application to biomedical research and genomics, qualifying it as Biomedicine AI.",
    "prompt_tokens": 20543,
    "completion_tokens": 170,
    "total_tokens": 20713,
    "topic": "Dynamical Systems - Bifurcation Analysis",
    "method": "Convolutional attention; topological data augmentation",
    "application": "Classification of long-term dynamical behavior; bifurcation boundary recovery",
    "code_link": "https://github.com/nitzanlab/time-warp-attend",
    "dataset_name": [
      "Simple Harmonic Oscillator (SO)",
      "Augmented SO",
      "Supercritical Hopf",
      "Lienard Polynomial",
      "Lienard Sigmoid",
      "Van der Pol",
      "Belousov-Zhabotinsky (BZ) Reaction",
      "Selkov Oscillator",
      "Pancreatic Endocrinogenesis Dataset"
    ]
  },
  {
    "id": "OHpvivXrQr",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Protein Multimer Structure Prediction via Prompt Learning",
    "authors": [
      "Ziqi Gao",
      "Xiangguo Sun",
      "Zijing Liu",
      "Yu Li",
      "Hong Cheng",
      "Jia Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Understanding the 3D structures of protein multimers is crucial, as they play a vital role in regulating various cellular processes. It has been empirically confirmed that the multimer structure prediction (MSP) can be well handled in a step-wise assembly fashion using provided dimer structures and predicted protein-protein interactions (PPIs). However, due to the biological gap in the formation of dimers and larger multimers, directly applying PPI prediction techniques can often cause a poor generalization to the MSP task. To address this challenge, we aim to extend the PPI knowledge to multimers of different scales (i.e., chain numbers). Specifically, we propose PromptMSP, a pre-training and Prompt tuning framework for Multimer Structure Prediction. First, we tailor the source and target tasks for effective PPI knowledge learning and efficient inference, respectively. We design PPI-inspired prompt learning to narrow the gaps of two task formats and generalize the PPI knowledge to multimers of different scales. We provide a meta-learning strategy to learn a reliable initialization of the prompt model, enabling our prompting framework to effectively adapt to limited data for large-scale multimers. Empirically, we achieve both significant accuracy (RMSD and TM-Score) and efficiency improvements compared to advanced MSP models.",
    "keywords": "docking path prediction, protein complex structure, prompt learning",
    "pdf_url": "https://openreview.net/pdf?id=OHpvivXrQr",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on predicting 3D structures of protein multimers and modeling protein–protein interactions (PPIs), which are core tasks in molecular modeling and drug discovery—key areas of Biomedicine AI. Terms like “protein complex structure”, “docking path prediction”, and leveraging PPI knowledge for structure prediction clearly place this work in the biomedical domain.",
    "prompt_tokens": 20892,
    "completion_tokens": 87,
    "total_tokens": 20979,
    "topic": "Protein Science - Multimer Structure Prediction",
    "method": "Graph Neural Networks (GNN); Prompt Learning",
    "application": "Multimer structure prediction",
    "code_link": "N/A",
    "dataset_name": [
      "PDB-M"
    ]
  },
  {
    "id": "gFR4QwK53h",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Gene Regulatory Network Inference in the Presence of Dropouts: a Causal View",
    "authors": [
      "Haoyue Dai",
      "Ignavier Ng",
      "Gongxu Luo",
      "Peter Spirtes",
      "Petar Stojanov",
      "Kun Zhang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Gene regulatory network inference (GRNI) is a challenging problem, particularly owing to the presence of zeros in single-cell RNA sequencing data: some are biological zeros representing no gene expression, while some others are technical zeros arising from the sequencing procedure (aka dropouts), which may bias GRNI by distorting the joint distribution of the measured gene expressions. Existing approaches typically handle dropout error via imputation, which may introduce spurious relations as the true joint distribution is generally unidentifiable. To tackle this issue, we introduce a causal graphical model to characterize the dropout mechanism, namely, Causal Dropout Model. We provide a simple yet effective theoretical result: interestingly, the conditional independence (CI) relations in the data with dropouts, after deleting the samples with zero values (regardless if technical or not) for the conditioned variables, are asymptotically identical to the CI relations in the original data without dropouts. This particular test-wise deletion procedure, in which we perform CI tests on the samples without zeros for the conditioned variables, can be seamlessly integrated with existing structure learning approaches including constraint-based and greedy score-based methods, thus giving rise to a principled framework for GRNI in the presence of dropouts. We further show that the causal dropout model can be validated from data, and many existing statistical models to handle dropouts fit into our model as specific parametric instances. Empirical evaluation on synthetic, curated, and real-world experimental transcriptomic data comprehensively demonstrate the efficacy of our method.",
    "keywords": "Gene regulatory network, Single-cell RNA-sequencing, Dropout, Zero-inflated data, Causal model, Causal discovery, Nonparametric",
    "pdf_url": "https://openreview.net/pdf?id=gFR4QwK53h",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on inferring gene regulatory networks from single-cell RNA-sequencing data—a core task in genomics and molecular biology. It addresses dropouts in transcriptomic measurements and proposes a causal model for “single-cell RNA sequencing,” “gene regulatory network inference,” and “zero-inflated data,” all of which are central to Biomedicine AI.",
    "prompt_tokens": 21069,
    "completion_tokens": 110,
    "total_tokens": 21179,
    "topic": "Biological Data - Causal Discovery",
    "method": "Testwise deletion; Causal discovery",
    "application": "Gene regulatory network inference",
    "code_link": "https://github.com/MarkDana/scRNA-Causal-Dropout",
    "dataset_name": [
      "BMDC",
      "HESC",
      "CMLC",
      "BEELINE"
    ]
  },
  {
    "id": "AZW3qlCGTe",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Enhancing Instance-Level Image Classification with Set-Level Labels",
    "authors": [
      "Renyu Zhang",
      "Aly A Khan",
      "Yuxin Chen",
      "Robert L. Grossman"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Instance-level image classification tasks have traditionally relied on single-instance labels to train models, e.g., few-shot learning and transfer learning. However, set-level coarse-grained labels that capture relationships among instances can provide richer information in real-world scenarios. In this paper, we present a novel approach to enhance instance-level image classification by leveraging set-level labels. We provide a theoretical analysis of the proposed method, including recognition conditions for fast excess risk rate, shedding light on the theoretical foundations of our approach. We conducted experiments on two distinct categories of datasets: natural image datasets and histopathology image datasets. Our experimental results demonstrate the effectiveness of our approach, showcasing improved classification performance compared to traditional single-instance label-based methods. Notably, our algorithm achieves 13\\% improvement in classification accuracy compared to the strongest baseline on the histopathology image classification benchmarks. Importantly, our experimental findings align with the theoretical analysis, reinforcing the robustness and reliability of our proposed method. This work bridges the gap between instance-level and set-level image classification, offering a promising avenue for advancing the capabilities of image classification models with set-level coarse-grained labels.",
    "keywords": "set-level labels, fast excess risk rate, representation learning, few-shot learning",
    "pdf_url": "https://openreview.net/pdf?id=AZW3qlCGTe",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper reports experiments on “histopathology image datasets” and achieves a 13% improvement on “histopathology image classification benchmarks.” Histopathology classification is a medical imaging task within pathology, placing this work squarely in the Healthcare/ Biomedicine AI domain.",
    "prompt_tokens": 20717,
    "completion_tokens": 139,
    "total_tokens": 20856,
    "topic": "Medical Imaging - Histopathology",
    "method": "Self-supervised learning; contrastive loss; instance-level label prediction",
    "application": "Fine-grained tissue classification",
    "code_link": "N/A",
    "dataset_name": [
      "PDAC",
      "NCT-CRC-HE-100K",
      "LC25000",
      "PAIP19",
      "TCGA"
    ]
  },
  {
    "id": "wg8NPfeMF9",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "$\\texttt{NAISR}$: A 3D Neural Additive Model for Interpretable Shape Representation",
    "authors": [
      "Yining Jiao",
      "Carlton Jude ZDANSKI",
      "Julia S Kimbell",
      "Andrew Prince",
      "Cameron P Worden",
      "Samuel Kirse",
      "Christopher Rutter",
      "Benjamin Shields",
      "William Alexander Dunn",
      "Jisan Mahmud",
      "Marc Niethammer"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Deep implicit functions (DIFs) have emerged as a powerful paradigm for many computer vision tasks such as 3D shape reconstruction, generation, registration, completion, editing, and understanding. However, given a set of 3D shapes with associated covariates there is at present no shape representation method which allows to precisely represent the shapes while capturing the individual dependencies on each covariate. Such a method would be of high utility to researchers to discover knowledge hidden in a population of shapes. For scientific shape discovery purpose, we propose a 3D Neural Additive Model for Interpretable Shape Representation ($\\texttt{NAISR}$) which describes individual shapes by deforming a shape atlas in accordance to the effect of disentangled covariates. Our approach captures shape population trends and allows for patient-specific predictions through shape transfer. $\\texttt{NAISR}$ is the first approach to combine the benefits of deep implicit shape representations with an atlas deforming according to specified covariates. We evaluate $\\texttt{NAISR}$ with respect to shape reconstruction, shape disentanglement, shape evolution, and shape transfer on three datasets, i.e. 1) $\\textit{Starman}$, a simulated 2D shape dataset; 2) ADNI hippocampus 3D shape dataset; 3) pediatric airway 3D shape dataset. Our experiments demonstrate that $\\texttt{NAISR}$ achieves competitive shape reconstruction performance while retaining interpretability. Our code is available at https://github.com/uncbiag/NAISR.",
    "keywords": "Shape Modeling, Medical Shape Analysis, Interpretable Representation, AI4Science",
    "pdf_url": "https://openreview.net/pdf?id=wg8NPfeMF9",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The approach is evaluated on medical imaging datasets (ADNI hippocampus 3D shapes and pediatric airway 3D shapes) and the keywords include “Medical Shape Analysis.” Modeling anatomical structures from MRI/CT scans for patient-specific predictions clearly situates this work in the Healthcare AI/Biomedicine AI domain.",
    "prompt_tokens": 20574,
    "completion_tokens": 107,
    "total_tokens": 20681,
    "topic": "Medical Shape Analysis - 3D Anatomy",
    "method": "Neural Additive Implicit Shape Representation (NAISR); Shape Disentanglement",
    "application": "Shape reconstruction and transfer – anatomical structures",
    "code_link": "N/A",
    "dataset_name": [
      "ADNI Hippocampus",
      "Pediatric Airway",
      "Starman"
    ]
  },
  {
    "id": "kzGuiRXZrQ",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Navigating the Design Space of Equivariant Diffusion-Based Generative Models for De Novo 3D Molecule Generation",
    "authors": [
      "Tuan Le",
      "Julian Cremer",
      "Frank Noe",
      "Djork-Arné Clevert",
      "Kristof T Schütt"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Deep generative diffusion models are a promising avenue for 3D de novo molecular design in materials science and drug discovery.\nHowever, their utility is still limited by suboptimal performance on large molecular structures and limited training data.\nTo address this gap, we explore the design space of E(3)-equivariant diffusion models, focusing on previously unexplored areas.  \nOur extensive comparative analysis evaluates the interplay between continuous and discrete state spaces.\nFrom this investigation, we present the EQGAT-diff model, which consistently outperforms established models for the QM9 and GEOM-Drugs datasets.  \nSignificantly, EQGAT-diff takes continuous atom positions, while chemical elements and bond types are categorical and uses time-dependent loss weighting, substantially increasing training convergence, the quality of generated samples, and inference time. We also showcase that including chemically motivated additional features like hybridization states in the diffusion process enhances the validity of generated molecules.  \nTo further strengthen the applicability of diffusion models to limited training data, we investigate the transferability of EQGAT-diff trained on the large PubChem3D dataset with implicit hydrogen atoms to target different data distributions. Fine-tuning EQGAT-diff for just a few iterations shows an efficient distribution shift, further improving performance throughout data sets.   \nFinally, we test our model on the Crossdocked data set for structure-based de novo ligand generation, underlining the importance of our findings showing state-of-the-art performance on Vina docking scores.",
    "keywords": "Generative Modelling, Molecule Design, Denoising Diffusion Probabilistic Models, Ablation Study, Equivariant Graph Neural Network, 3D Molecule Generation, Diffusion Model",
    "pdf_url": "https://openreview.net/pdf?id=kzGuiRXZrQ",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on 3D de novo molecular design for “drug discovery” and “structure-based de novo ligand generation” (Crossdocked data set, Vina docking scores). These are core tasks in Biomedicine AI related to computational drug design and molecular modeling.",
    "prompt_tokens": 21182,
    "completion_tokens": 117,
    "total_tokens": 21299,
    "topic": "Drug Discovery - Structure-based Design",
    "method": "Equivariant Graph Neural Networks; Diffusion model",
    "application": "De novo molecule generation",
    "code_link": "https://github.com/pfizer-opensource/eqgat-diff",
    "dataset_name": [
      "PubChem3D",
      "GEOM-Drugs",
      "QM9",
      "Crossdocked"
    ]
  },
  {
    "id": "C4BikKsgmK",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Str2Str: A Score-based Framework for Zero-shot Protein Conformation Sampling",
    "authors": [
      "Jiarui Lu",
      "Bozitao Zhong",
      "Zuobai Zhang",
      "Jian Tang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The dynamic nature of proteins is crucial for determining their biological functions and properties, for which Monte Carlo (MC) and molecular dynamics (MD) simulations stand as predominant tools to study such phenomena. By utilizing empirically derived force fields, MC or MD simulations explore the conformational space through numerically evolving the system via Markov chain or Newtonian mechanics. However, the high-energy barrier of the force fields can hamper the exploration of both methods by the rare event, resulting in inadequately sampled ensemble without exhaustive running. Existing learning-based approaches perform direct sampling yet heavily rely on target-specific simulation data for training, which suffers from high data acquisition cost and poor generalizability. Inspired by simulated annealing, we propose Str2Str, a novel structure-to-structure translation framework capable of zero-shot conformation sampling with roto-translation equivariant property. Our method leverages an amortized denoising score matching objective trained on general crystal structures and has no reliance on simulation data during both training and inference. Experimental results across several benchmarking protein systems demonstrate that Str2Str outperforms previous state-of-the-art generative structure prediction models and can be orders of magnitude faster compared with long MD simulations.",
    "keywords": "proteins, conformational sampling, diffusion models, score-based models, generative modeling, equivariant network",
    "pdf_url": "https://openreview.net/pdf?id=C4BikKsgmK",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This paper focuses on zero‐shot sampling of protein conformations, leveraging score‐based generative models for molecular modeling. Protein structure prediction and conformational sampling are core tasks in biomedicine (e.g., drug discovery, protein design). The abstract repeatedly references “proteins,” “conformational space,” and “molecular dynamics,” all hallmarks of biomedical research. As molecular modeling is explicitly listed as a key indicator of Biomedicine AI, this work falls squarely within that domain.",
    "prompt_tokens": 20960,
    "completion_tokens": 106,
    "total_tokens": 21066,
    "topic": "Protein Structure - Conformation Sampling",
    "method": "Score-based generative modeling; diffusion modeling",
    "application": "Protein conformation sampling",
    "code_link": "https://github.com/lujiarui/Str2Str",
    "dataset_name": [
      "Protein Data Bank (PDB)",
      "Apo/Holo dataset"
    ]
  },
  {
    "id": "CUfSCwcgqm",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Neural Atoms: Propagating Long-range Interaction in Molecular Graphs through Efficient Communication Channel",
    "authors": [
      "Xuan Li",
      "Zhanke Zhou",
      "Jiangchao Yao",
      "Yu Rong",
      "Lu Zhang",
      "Bo Han"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Graph Neural Networks (GNNs) have been widely adopted for drug discovery with molecular graphs. Nevertheless, current GNNs mainly excel in leveraging short-range interactions (SRI) but struggle to capture long-range interactions (LRI), both of which are crucial for determining molecular properties. To tackle this issue, we propose a method to abstract the collective information of atomic groups into a few $\\textit{Neural Atoms}$ by implicitly projecting the atoms of a molecular.\nSpecifically, we explicitly exchange the information among neural atoms and project them back to the atoms’ representations as an enhancement. With this mechanism, neural atoms establish the communication channels among distant nodes, effectively reducing the interaction scope of arbitrary node pairs into a single hop. \nTo provide an inspection of our method from a physical perspective, we reveal its connection to the traditional LRI calculation method, Ewald Summation. The Neural Atom can enhance GNNs to capture LRI by approximating the potential LRI of the molecular.\nWe conduct extensive experiments on four long-range graph benchmarks, covering graph-level and link-level tasks on molecular graphs. We achieve up to a 27.32% and 38.27% improvement in the 2D and 3D scenarios, respectively.\nEmpirically, our method can be equipped with an arbitrary GNN to help capture LRI. Code and datasets are publicly available in https://github.com/tmlr-group/NeuralAtom.",
    "keywords": "Long Range Interaction; Molecular Graph;",
    "pdf_url": "https://openreview.net/pdf?id=CUfSCwcgqm",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on graph neural network methods for modeling molecular graphs, explicitly citing “drug discovery” and molecular property prediction—core tasks in biomedicine AI. Its goal of capturing long-range interactions in molecules directly supports applications in therapeutic design and molecular modeling.",
    "prompt_tokens": 20648,
    "completion_tokens": 113,
    "total_tokens": 20761,
    "topic": "Drug Discovery - Molecular Interaction",
    "method": "Graph Neural Networks (GNN); Neural Atoms",
    "application": "Molecular property prediction",
    "code_link": "https://github.com/tmlr-group/NeuralAtom",
    "dataset_name": [
      "Peptides-func",
      "Peptides-struct",
      "PCQM-Contact",
      "OE62"
    ]
  },
  {
    "id": "WcOohbsF4H",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Guiding Masked Representation Learning to Capture Spatio-Temporal Relationship of Electrocardiogram",
    "authors": [
      "Yeongyeon Na",
      "Minje Park",
      "Yunwon Tae",
      "Sunghoon Joo"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Electrocardiograms (ECG) are widely employed as a diagnostic tool for monitoring electrical signals originating from a heart. Recent machine learning research efforts have focused on the application of screening various diseases using ECG signals. However, adapting to the application of screening disease is challenging in that labeled ECG data are limited. Achieving general representation through self-supervised learning (SSL) is a well-known approach to overcome the scarcity of labeled data; however, a naive application of SSL to ECG data, without considering the spatial-temporal relationships inherent in ECG signals, may yield suboptimal results. In this paper, we introduce ST-MEM (Spatio-Temporal Masked Electrocardiogram Modeling), designed to learn spatio-temporal features by reconstructing masked 12-lead ECG data. ST-MEM outperforms other SSL baseline methods in various experimental settings for arrhythmia classification tasks. Moreover, we demonstrate that ST-MEM is adaptable to various lead combinations. Through quantitative and qualitative analysis, we show a spatio-temporal relationship within ECG data. Our code is available at https://github.com/bakqui/ST-MEM.",
    "keywords": "Electrocardiogram, ECG, Cardiac signal, Biosignal, Self-supervised learning, Masked auto-encoder, Representation learning",
    "pdf_url": "https://openreview.net/pdf?id=WcOohbsF4H",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on learning representations from 12-lead ECG signals, a core clinical biosignal used for arrhythmia classification and cardiac monitoring. It explicitly targets “arrhythmia classification tasks” and works with ECG data—both clear indicators of a healthcare/biomedical AI application.",
    "prompt_tokens": 20596,
    "completion_tokens": 126,
    "total_tokens": 20722,
    "topic": "Time Series Analytics - ECG Representation Learning",
    "method": "Self-supervised learning; masked autoencoder",
    "application": "Arrhythmia and myocardial infarction classification",
    "code_link": "https://github.com/bakqui/ST-MEM",
    "dataset_name": [
      "Chapman",
      "Ningbo",
      "CODE-15",
      "PTB-XL",
      "CPSC2018",
      "PhysioNet2017"
    ]
  },
  {
    "id": "NialiwI2V6",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "MOTOR: A Time-to-Event Foundation Model For Structured Medical Records",
    "authors": [
      "Ethan Steinberg",
      "Jason Alan Fries",
      "Yizhe Xu",
      "Nigam Shah"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We present a self-supervised, time-to-event (TTE) foundation model called MOTOR (Many Outcome Time Oriented Representations) which is pretrained on timestamped sequences of events in electronic health records (EHR) and health insurance claims. TTE models are used for estimating the probability distribution of the time until a specific event occurs, which is an important task in medical settings. TTE models provide many advantages over classification using fixed time horizons, including naturally handling censored observations, but are challenging to train with limited labeled data. MOTOR addresses this challenge by pretraining on up to 55M patient records (9B clinical events). We evaluate MOTOR's transfer learning performance on 19 tasks, across 3 patient databases (a private EHR system, MIMIC-IV, and Merative claims data). Task-specific models adapted from MOTOR improve time-dependent C statistics by 4.6\\% over state-of-the-art, improve label efficiency by up to 95\\%, and are more robust to temporal distributional shifts. We further evaluate cross-site portability by adapting our MOTOR foundation model for six prediction tasks on the MIMIC-IV dataset, where it outperforms all baselines. MOTOR is the first foundation model for medical TTE predictions and we release a 143M parameter pretrained model for research use at https://huggingface.co/StanfordShahLab/motor-t-base.",
    "keywords": "foundation models, time-to-event, electronic health records, deep learning, self-supervised learning, transfer learning",
    "pdf_url": "https://openreview.net/pdf?id=NialiwI2V6",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper develops a time‐to‐event foundation model pretrained on “timestamped sequences of events in electronic health records (EHR) and health insurance claims,” evaluates on 19 clinical prediction tasks across EHR databases (including MIMIC-IV), and targets medical prognosis (“time until a specific event occurs,” handling censored observations). These are clear indicators of Healthcare AI.",
    "prompt_tokens": 20372,
    "completion_tokens": 94,
    "total_tokens": 20466,
    "topic": "EHR - Predictive Models",
    "method": "Transformer-based models; time-to-event modeling",
    "application": "Time-to-event prediction – clinical records",
    "code_link": "N/A",
    "dataset_name": [
      "STARR-OMOP",
      "MERATIVE"
    ]
  },
  {
    "id": "DsEhqQtfAG",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Decomposed Diffusion Sampler for Accelerating Large-Scale Inverse Problems",
    "authors": [
      "Hyungjin Chung",
      "Suhyeon Lee",
      "Jong Chul Ye"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Krylov subspace, which is generated by multiplying a given vector by the matrix of a linear transformation and its successive powers,  has been extensively studied in classical optimization literature to design algorithms that converge quickly for large linear inverse problems. For example, the conjugate gradient method (CG), one of the most popular Krylov subspace methods, is based on the idea of minimizing the residual error in the Krylov subspace. However, with the recent advancement of high-performance diffusion solvers for inverse problems, it is not clear how classical wisdom can be synergistically combined with modern diffusion models. In this study, we propose a novel and efficient diffusion sampling strategy that synergistically combines the diffusion sampling and Krylov subspace methods. Specifically, we prove that if the tangent space at a denoised sample by Tweedie's formula forms a  Krylov subspace, then the CG initialized with the denoised data ensures the data consistency update to remain in the tangent space. This negates the need to compute the manifold-constrained gradient (MCG), leading to a more efficient diffusion sampling method. Our method is applicable regardless of the parametrization and setting (i.e., VE, VP). Notably, we achieve state-of-the-art reconstruction quality on challenging real-world medical inverse imaging problems, including multi-coil MRI reconstruction and 3D CT reconstruction. Moreover, our proposed method achieves more than 80 times faster inference time than the previous state-of-the-art method. Code is available at https://github.com/HJ-harry/DDS",
    "keywords": "Diffusion models; Inverse problems; Krylov subspace",
    "pdf_url": "https://openreview.net/pdf?id=DsEhqQtfAG",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper specifically demonstrates state-of-the-art results on real-world medical inverse imaging problems, including multi-coil MRI reconstruction and 3D CT reconstruction. These are core medical imaging tasks within Healthcare AI, directly involving clinical modalities (MRI, CT) and patient data.",
    "prompt_tokens": 21123,
    "completion_tokens": 116,
    "total_tokens": 21239,
    "topic": "Medical Imaging - Reconstruction",
    "method": "Diffusion model; Krylov subspace methods; Conjugate gradient",
    "application": "Multi-coil MRI reconstruction and 3D CT reconstruction",
    "code_link": "https://github.com/HJ-harry/DDS",
    "dataset_name": [
      "fastMRI knee",
      "AAPM 2016 CT low-dose grand challenge"
    ]
  },
  {
    "id": "AXbN2qMNiW",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Protein-ligand binding representation learning from fine-grained interactions",
    "authors": [
      "Shikun Feng",
      "Minghao Li",
      "Yinjun Jia",
      "Wei-Ying Ma",
      "Yanyan Lan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The binding between proteins and ligands plays a crucial role in the realm of drug discovery. Previous deep learning approaches have shown promising results over traditional computationally intensive methods, but resulting in poor generalization due to limited supervised data. In this paper, we propose to learn protein-ligand binding representation in a self-supervised learning manner. Different from existing pre-training approaches which treat proteins and ligands individually, we emphasize to discern the intricate binding patterns from fine-grained interactions. Specifically, this self-supervised learning problem is formulated as a prediction of the conclusive binding complex structure given a pocket and ligand with a Transformer based interaction module, which naturally emulates the binding process. To ensure the representation of rich binding information, we introduce two pre-training tasks, i.e. atomic pairwise distance map prediction and mask ligand reconstruction, which comprehensively model the fine-grained interactions from both structure and feature space. Extensive experiments have demonstrated the superiority of our method across various binding tasks, including protein-ligand affinity prediction, virtual screening and protein-ligand docking.",
    "keywords": "Protein-ligand binding, representation learning, self-supervised",
    "pdf_url": "https://openreview.net/pdf?id=AXbN2qMNiW",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “protein-ligand binding,” “drug discovery,” “protein-ligand affinity prediction,” “virtual screening,” and “docking,” all of which are central to biomedical research for therapeutic development. These tasks involve molecular modeling and representation learning specifically aimed at drug discovery, making it a clear application of Biomedicine AI.",
    "prompt_tokens": 20702,
    "completion_tokens": 113,
    "total_tokens": 20815,
    "topic": "Drug Discovery - Protein-ligand interactions",
    "method": "Transformer-based interaction module; self-supervised learning",
    "application": "Protein-ligand binding affinity prediction; virtual screening; molecular docking",
    "code_link": "N/A",
    "dataset_name": [
      "BioLip",
      "DUD-E",
      "PDBBind",
      "CASF-2016"
    ]
  },
  {
    "id": "WQwV7Y8qwa",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Modeling state-dependent communication between brain regions with switching nonlinear dynamical systems",
    "authors": [
      "Orren Karniol-Tambour",
      "David M. Zoltowski",
      "E. Mika Diamanti",
      "Lucas Pinto",
      "Carlos D Brody",
      "David W. Tank",
      "Jonathan W. Pillow"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Understanding how multiple brain regions interact to produce behavior is a major challenge in systems neuroscience, with many regions causally implicated in common tasks such as sensory processing and decision making. A precise description of interactions between regions remains an open problem. Moreover, neural dynamics are nonlinear and non-stationary. Here, we propose MR-SDS, a multiregion, switching nonlinear state space model that decomposes global dynamics into local and cross-communication components in the latent space. MR-SDS includes directed interactions between brain regions, allowing for estimation of state-dependent communication signals, and accounts for sensory inputs effects. We show that our model accurately recovers latent trajectories, vector fields underlying switching nonlinear dynamics, and cross-region communication profiles in three simulations. We then apply our method to two large-scale, multi-region neural datasets involving mouse decision making. The first includes hundreds of neurons per region, recorded simultaneously at single-cell-resolution across 3 distant cortical regions. The second is a mesoscale widefield dataset of 8 adjacent cortical regions imaged across both hemispheres. On these multi-region datasets, our model outperforms existing piece-wise linear multi-region models and reveals multiple distinct dynamical states and a rich set of cross-region communication profiles.",
    "keywords": "neuroscience, neural dynamics, dynamical systems, decision making",
    "pdf_url": "https://openreview.net/pdf?id=WQwV7Y8qwa",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work focuses on modeling interactions between brain regions (“multiregion, switching nonlinear state space model,” “cross-region communication profiles”) using neural recordings (single-cell resolution and widefield imaging in mouse cortex). It falls squarely under neurobiological modeling of neural system dynamics, a strong indicator of the Biomedicine AI domain.",
    "prompt_tokens": 20794,
    "completion_tokens": 91,
    "total_tokens": 20885,
    "topic": "Neuroscience - Neural Dynamics",
    "method": "Switching nonlinear state-space models; Transformers",
    "application": "Cross-region neural communication modeling",
    "code_link": "N/A",
    "dataset_name": [
      "Mesoscope dataset",
      "Widefield dataset"
    ]
  },
  {
    "id": "PnR1MNen7u",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Deep Geodesic Canonical Correlation Analysis for Covariance-Based Neuroimaging Data",
    "authors": [
      "Ce Ju",
      "Reinmar J Kobler",
      "Liyao Tang",
      "Cuntai Guan",
      "Motoaki Kawanabe"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In human neuroimaging, multi-modal imaging techniques are frequently combined to enhance our comprehension of whole-brain dynamics and improve diagnosis in clinical practice. Modalities like electroencephalography and functional magnetic resonance imaging provide distinct views to the brain dynamics due to diametral spatiotemporal sensitivities and underlying neurophysiological coupling mechanisms. These distinct views pose a considerable challenge to learning a shared representation space, especially when dealing with covariance-based data characterized by their geometric structure. To capitalize on the geometric structure, we introduce a measure called geodesic correlation which expands traditional correlation consistency to covariance-based data on the symmetric positive definite (SPD) manifold. This measure is derived from classical canonical correlation analysis and serves to evaluate the consistency of latent representations obtained from paired views. For multi-view, self-supervised learning where one or both latent views are SPD we propose an innovative geometric deep learning framework termed DeepGeoCCA. Its primary objective is to enhance the geodesic correlation of unlabeled, paired data, thereby generating novel representations while retaining the geometric structures. In simulations and experiments with multi-view and multi-modal human neuroimaging data, we find that DeepGeoCCA learns latent representations with high geodesic correlation for unseen data while retaining relevant information for downstream tasks.",
    "keywords": "Geometric Deep Learning, Self-Supervised Learning, Brain-Computer Interfaces, Neuroimaging, Neuroscience",
    "pdf_url": "https://openreview.net/pdf?id=PnR1MNen7u",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on multi-modal neuroimaging data (EEG and fMRI), explicitly aiming to “enhance our comprehension of whole-brain dynamics and improve diagnosis in clinical practice.” It develops representation‐learning methods for covariance‐based brain imaging data—clear indicators of a healthcare‐oriented AI application in neuroimaging and clinical diagnosis.",
    "prompt_tokens": 20455,
    "completion_tokens": 111,
    "total_tokens": 20566,
    "topic": "Neuroimaging - Multimodal Fusion",
    "method": "Deep Canonical Correlation Analysis (DeepCCA); Riemannian deep learning",
    "application": "Latent space representation learning for EEG-fMRI integration",
    "code_link": "N/A",
    "dataset_name": [
      "Korean University Dataset",
      "BNCI2015001 Dataset"
    ]
  },
  {
    "id": "9rPyHyjfwP",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Domain-Agnostic Molecular Generation with Chemical Feedback",
    "authors": [
      "Yin Fang",
      "Ningyu Zhang",
      "Zhuo Chen",
      "Lingbing Guo",
      "Xiaohui Fan",
      "Huajun Chen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The generation of molecules with desired properties has become increasingly popular, revolutionizing the way scientists design molecular structures and providing valuable support for chemical and drug design. However, despite the potential of language models in molecule generation, they face challenges such as generating syntactically or chemically flawed molecules, having narrow domain focus, and struggling to create diverse and feasible molecules due to limited annotated data or external molecular databases.\nTo tackle these challenges, we introduce MolGen, a pre-trained molecular language model tailored specifically for molecule generation. Through the reconstruction of over 100 million molecular SELFIES, MolGen internalizes structural and grammatical insights. This is further enhanced by domain-agnostic molecular prefix tuning, fostering robust knowledge transfer across diverse domains. Importantly, our chemical feedback paradigm steers the model away from \"molecular hallucinations\", ensuring alignment between the model's estimated probabilities and real-world chemical preferences. Extensive experiments on well-known benchmarks underscore MolGen's optimization capabilities in properties such as penalized logP, QED, and molecular docking. Additional analyses confirm its proficiency in accurately capturing molecule distributions, discerning intricate structural patterns, and efficiently exploring the chemical space (https://github.com/zjunlp/MolGen).",
    "keywords": "molecule generation, pre-trained language models, SELFIES, natural products, self-feedback",
    "pdf_url": "https://openreview.net/pdf?id=9rPyHyjfwP",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on pre-training a language model for molecule generation with benchmarks like penalized logP, QED, and molecular docking—core tasks in drug discovery and chemical design. These applications fall squarely within Biomedicine AI’s domain of “drug discovery” and “molecular modeling.”",
    "prompt_tokens": 20883,
    "completion_tokens": 110,
    "total_tokens": 20993,
    "topic": "Drug Discovery - Molecular Generation",
    "method": "Transformer-based models; pre-training; chemical feedback paradigm",
    "application": "Molecule generation",
    "code_link": "https://huggingface.co/zjunlp/MolGen-large",
    "dataset_name": [
      "ZINC250K",
      "MOSES",
      "Natural Product Dataset",
      "PubChem"
    ]
  },
  {
    "id": "uMAujpVi9m",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Self-supervised Pocket Pretraining via Protein Fragment-Surroundings Alignment",
    "authors": [
      "Bowen Gao",
      "Yinjun Jia",
      "YuanLe Mo",
      "Yuyan Ni",
      "Wei-Ying Ma",
      "Zhi-Ming Ma",
      "Yanyan Lan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Pocket representations play a vital role in various biomedical applications, such as druggability estimation, ligand affinity prediction, and de novo drug design. While existing geometric features and pretrained representations have demonstrated promising results, they usually treat pockets independent of ligands, neglecting the fundamental interactions between them. However, the limited pocket-ligand complex structures available in the PDB database (less than 100 thousand non-redundant pairs) hampers large-scale pretraining endeavors for interaction modeling. To address this constraint, we propose a novel pocket pretraining approach that leverages knowledge from high-resolution atomic protein structures, assisted by highly effective pretrained small molecule representations. By segmenting protein structures into drug-like fragments and their corresponding pockets, we obtain a reasonable simulation of ligand-receptor interactions, resulting in the generation of over 5 million complexes. Subsequently, the pocket encoder is trained in a contrastive manner to align with the representation of pseudo-ligand furnished by some pretrained small molecule encoders. Our method, named ProFSA, achieves state-of-the-art performance across various tasks, including pocket druggability prediction, pocket matching, and ligand binding affinity prediction. Notably, ProFSA surpasses other pretraining methods by a substantial margin. Moreover, our work opens up a new avenue for mitigating the scarcity of protein-ligand complex data through the utilization of high-quality and diverse protein structure databases.",
    "keywords": "Drug Discovery, Pretraining",
    "pdf_url": "https://openreview.net/pdf?id=uMAujpVi9m",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on learning protein pocket representations for tasks such as druggability estimation, ligand affinity prediction, and de novo drug design—all core activities in drug discovery. It leverages protein–ligand interaction modeling and small‐molecule encoders, which are central to biomedicine AI and molecular modeling for therapeutic development.",
    "prompt_tokens": 20629,
    "completion_tokens": 121,
    "total_tokens": 20750,
    "topic": "Drug Discovery - Protein-ligand Interaction",
    "method": "Contrastive learning; Pretraining with molecular/pocket encoders",
    "application": "Binding affinity prediction",
    "code_link": "https://github.com/bowen-gao/ProFSA",
    "dataset_name": [
      "PDBBind(v2019)",
      "Uni-Mol",
      "TOUGH-M1",
      "Kahraman"
    ]
  },
  {
    "id": "mpqMVWgqjn",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "KW-Design: Pushing the Limit of Protein Design via Knowledge Refinement",
    "authors": [
      "Zhangyang Gao",
      "Cheng Tan",
      "Xingran Chen",
      "Yijie Zhang",
      "Jun Xia",
      "Siyuan Li",
      "Stan Z. Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Recent studies have shown competitive performance in protein inverse folding, while most of them disregard the importance of predictive confidence, fail to cover the vast protein space, and do not incorporate common protein knowledge. Given the great success of pretrained models on diverse protein-related tasks and the fact that recovery is highly correlated with confidence, we wonder whether this knowledge can push the limits of protein design further. As a solution, we propose a knowledge-aware module that refines low-quality residues. We also introduce a memory-retrieval mechanism to save more than 50\\% of the training time. We extensively evaluate our proposed method on the CATH, TS50, TS500, and PDB datasets and our results show that our KW-Design method outperforms the previous PiFold method by approximately 9\\% on the CATH dataset. KW-Design is the first method that achieves 60+\\% recovery on all these benchmarks. We also provide additional analysis to demonstrate the effectiveness of our proposed method. The code is publicly available via \\href{https://github.com/A4Bio/ProteinInvBench}{GitHub}.",
    "keywords": "Protein Design, Graph, Finetuning",
    "pdf_url": "https://openreview.net/pdf?id=mpqMVWgqjn",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on protein inverse folding and protein design—key tasks in molecular modeling and drug discovery. It discusses refining low-quality residues, benchmarks on CATH and PDB, and improving sequence recovery, all of which are central to biomedical research and synthetic biology.",
    "prompt_tokens": 20244,
    "completion_tokens": 116,
    "total_tokens": 20360,
    "topic": "Drug Discovery - Protein Design",
    "method": "Graph Neural Networks; multimodal fusion; confidence-aware tuning",
    "application": "Protein sequence design",
    "code_link": "https://github.com/A4Bio/ProteinInvBench",
    "dataset_name": [
      "CATH4.2",
      "CATH4.3",
      "TS50",
      "TS500",
      "PDB"
    ]
  },
  {
    "id": "1mNFsbvo2P",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Domain constraints improve risk prediction when outcome data is missing",
    "authors": [
      "Sidhika Balachandar",
      "Nikhil Garg",
      "Emma Pierson"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Machine learning models are often trained to predict the outcome resulting from a human decision. For example, if a doctor decides to test a patient for disease, will the patient test positive? A challenge is that historical decision-making determines whether the outcome is observed: we only observe test outcomes for patients doctors historically tested. Untested patients, for whom outcomes are unobserved, may differ from tested patients along observed and unobserved dimensions. We propose a Bayesian model class which captures this setting. The purpose of the model is to accurately estimate risk for both tested and untested patients. Estimating this model is challenging due to the wide range of possibilities for untested patients. To address this, we propose two domain constraints which are plausible in health settings: a prevalence constraint, where the overall disease prevalence is known, and an expertise constraint, where the human decision-maker deviates from purely risk-based decision-making only along a constrained feature set. We show theoretically and on synthetic data that domain constraints improve parameter inference. We apply our model to a case study of cancer risk prediction, showing that the model's inferred risk predicts cancer diagnoses, its inferred testing policy captures known public health policies, and it can identify suboptimalities in test allocation. Though our case study is in healthcare, our analysis reveals a general class of domain constraints which can improve model estimation in many settings.",
    "keywords": "Bayesian model, health, selective labels, distribution shift, domain constraint, biomedicine",
    "pdf_url": "https://openreview.net/pdf?id=1mNFsbvo2P",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on predicting disease risk and testing decisions in a medical context (e.g., “if a doctor decides to test a patient for disease, will the patient test positive?”), applies its model to “cancer risk prediction,” and discusses domain constraints like known disease prevalence and clinician expertise. These are clear indicators of a healthcare AI application.",
    "prompt_tokens": 20548,
    "completion_tokens": 96,
    "total_tokens": 20644,
    "topic": "Healthcare - Breast Cancer Risk Prediction",
    "method": "Bayesian inference; domain-constrained modeling",
    "application": "Disease risk prediction – Breast cancer",
    "code_link": "https://github.com/sidhikabalachandar/domain_constraints",
    "dataset_name": [
      "UK Biobank"
    ]
  },
  {
    "id": "ox2ATRM90I",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Yet Another ICU Benchmark: A Flexible Multi-Center Framework for Clinical ML",
    "authors": [
      "Robin van de Water",
      "Hendrik Nils Aurel Schmidt",
      "Paul Elbers",
      "Patrick Thoral",
      "Bert Arnrich",
      "Patrick Rockenschaub"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Medical applications of machine learning (ML) have experienced a surge in popularity in recent years. Given the abundance of available data from electronic health records, the intensive care unit (ICU) is a natural habitat for ML. Models have been proposed to address numerous ICU prediction tasks like the early detection of complications. While authors frequently report state-of-the-art performance, it is challenging to verify claims of superiority. Datasets and code are not always published, and cohort definitions, preprocessing pipelines, and training setups are difficult to reproduce. This work introduces Yet Another ICU Benchmark (YAIB), a modular framework that allows researchers to define reproducible and comparable clinical ML experiments; we offer an end-to-end solution from cohort definition to model evaluation. The framework natively supports most open-access ICU datasets (MIMIC III/IV, eICU, HiRID, AUMCdb) and is easily adaptable to future ICU datasets. Combined with a transparent preprocessing pipeline and extensible training code for multiple ML and deep learning models, YAIB enables unified model development, transfer, and evaluation. Our benchmark comes with five predefined established prediction tasks (mortality, acute kidney injury, sepsis, kidney function, and length of stay) developed in collaboration with clinicians. Adding further tasks is straightforward by design. Using YAIB, we demonstrate that the choice of dataset, cohort definition, and preprocessing have a major impact on the prediction performance — often more so than model class — indicating an urgent need for YAIB as a holistic benchmarking tool. We provide our work to the clinical ML community to accelerate method development and enable real-world clinical implementations.",
    "keywords": "ICU, Intensive Care Unit, EHR, ML, Time Series, Patient Monitoring, Clinical ML, Benchmark, Multi-Center, MIMIC, eICU, HiRID, AmsterdamUMCdb",
    "pdf_url": "https://openreview.net/pdf?id=ox2ATRM90I",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on machine learning for intensive care unit (ICU) data (MIMIC-III/IV, eICU, HiRID, AUMCdb) and defines clinical prediction tasks such as mortality, sepsis, acute kidney injury, and length of stay. It explicitly addresses EHR‐based patient monitoring and clinical ML benchmark development, making it squarely a Healthcare AI contribution.",
    "prompt_tokens": 21279,
    "completion_tokens": 120,
    "total_tokens": 21399,
    "topic": "Time Series - Imputation",
    "method": "Score-based Diffusion Models; Conditional Generative Models; Transformer-based attention",
    "application": "Data imputation for ICU time-series",
    "code_link": "https://github.com/ermongroup/CSDI/tree/main",
    "dataset_name": [
      "MIMIC-IV",
      "eICU",
      "HiRID",
      "AUMCdb"
    ]
  },
  {
    "id": "nqlymMx42E",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Searching for High-Value Molecules Using Reinforcement Learning and Transformers",
    "authors": [
      "Raj Ghugare",
      "Santiago Miret",
      "Adriana Hugessen",
      "Mariano Phielipp",
      "Glen Berseth"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Reinforcement learning (RL) over text representations can be effective for finding high-value policies that can search over graphs. However, RL requires careful structuring of the search space and algorithm design to be effective in this challenge. Through extensive experiments, we explore how different design choices for text grammar and algorithmic choices for training can affect an RL policy's ability to generate molecules with desired properties. We arrive at a new RL-based molecular design algorithm (ChemRLformer) and perform a thorough analysis using 25 molecule design tasks, including computationally complex protein docking simulations. From this analysis, we discover unique insights in this problem space and show that ChemRLformer achieves state-of-the-art performance while being more straightforward than prior work by demystifying which design choices are actually helpful for text-based molecule design.",
    "keywords": "chemistry, reinforcement learning, language models",
    "pdf_url": "https://openreview.net/pdf?id=nqlymMx42E",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “molecule design” using reinforcement learning and transformers and evaluates on “protein docking simulations,” which are core tasks in drug discovery and molecular modeling. These are strong indicators of Biomedicine AI, as they involve designing potential therapeutic compounds.",
    "prompt_tokens": 20532,
    "completion_tokens": 127,
    "total_tokens": 20659,
    "topic": "Drug Discovery - Molecular Optimization",
    "method": "Reinforcement Learning; Transformers; REINFORCE algorithm; Replay buffer; SMILES-based molecular generation",
    "application": "Molecular property optimization and generation",
    "code_link": "N/A",
    "dataset_name": [
      "CHEMBL",
      "ZINC 250K",
      "ZINC 1M",
      "ZINC 10M",
      "ZINC 100M"
    ]
  },
  {
    "id": "RwI7ZEfR27",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "BrainLM: A foundation model for brain activity recordings",
    "authors": [
      "Josue Ortega Caro",
      "Antonio Henrique de Oliveira Fonseca",
      "Syed A Rizvi",
      "Matteo Rosati",
      "Christopher Averill",
      "James L Cross",
      "Prateek Mittal",
      "Emanuele Zappala",
      "Rahul Madhav Dhodapkar",
      "Chadi Abdallah",
      "David van Dijk"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We introduce the Brain Language Model (BrainLM), a foundation model for brain activity dynamics trained on 6,700 hours of fMRI recordings. Utilizing self-supervised masked-prediction training, BrainLM demonstrates proficiency in both fine-tuning and zero-shot inference tasks. Fine-tuning allows for the accurate prediction of clinical variables like age, anxiety, and PTSD as well as forecasting of future brain states. Critically, the model generalizes well to entirely new external cohorts not seen during training. In zero-shot inference mode, BrainLM can identify intrinsic functional networks directly from raw fMRI data without any network-based supervision during training. The model also generates interpretable latent representations that reveal relationships between brain activity patterns and cognitive states. Overall, BrainLM offers a versatile and interpretable framework for elucidating the complex spatiotemporal dynamics of human brain activity. It serves as a powerful \"lens\" through which massive repositories of fMRI data can be analyzed in new ways, enabling more effective interpretation and utilization at scale. The work demonstrates the potential of foundation models to advance computational neuroscience research.",
    "keywords": "foundation model, fMRI",
    "pdf_url": "https://openreview.net/pdf?id=RwI7ZEfR27",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on a foundation model trained on fMRI recordings—a medical imaging modality—to predict clinical variables such as age, anxiety, and PTSD, as well as forecast future brain states. It also generalizes to new cohorts and identifies intrinsic functional networks from raw fMRI data. These characteristics (use of fMRI, clinical prediction tasks, brain decoding) strongly align with Healthcare AI and neurobiological modeling.",
    "prompt_tokens": 20614,
    "completion_tokens": 101,
    "total_tokens": 20715,
    "topic": "Neuroscience - Functional MRI",
    "method": "Transformer masked autoencoder; self-supervised learning",
    "application": "Clinical variable prediction – age, anxiety, PTSD",
    "code_link": "N/A",
    "dataset_name": [
      "UKB (UK Biobank)",
      "HCP (Human Connectome Project)"
    ]
  },
  {
    "id": "lUYY2qsRTI",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Delphic Offline Reinforcement Learning under Nonidentifiable Hidden Confounding",
    "authors": [
      "Alizée Pace",
      "Hugo Yèche",
      "Bernhard Schölkopf",
      "Gunnar Ratsch",
      "Guy Tennenholtz"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "A prominent challenge of offline reinforcement learning (RL) is the issue of hidden confounding: unobserved variables may influence both the actions taken by the agent and the observed outcomes. Hidden confounding can compromise the validity of any causal conclusion drawn from data and presents a major obstacle to effective offline RL. In the present paper, we tackle the problem of hidden confounding in the nonidentifiable setting. We propose a definition of uncertainty due to hidden confounding bias, termed delphic uncertainty, which uses variation over world models compatible with the observations, and differentiate it from the well-known epistemic and aleatoric uncertainties. We derive a practical method for estimating the three types of uncertainties, and construct a pessimistic offline RL algorithm to account for them. Our method does not assume identifiability of the unobserved confounders, and attempts to reduce the amount of confounding bias. We demonstrate through extensive experiments and ablations the efficacy of our approach on a sepsis management benchmark, as well as on electronic health records. Our results suggest that nonidentifiable hidden confounding bias can be mitigated to improve offline RL solutions in practice.",
    "keywords": "offline reinforcement learning, hidden confounding, uncertainty quantification, causal inference, healthcare, vasopressor and fluid administration",
    "pdf_url": "https://openreview.net/pdf?id=lUYY2qsRTI",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly applies its offline RL method to a “sepsis management benchmark” and “electronic health records,” and keywords include “healthcare” and “vasopressor and fluid administration,” all of which indicate a clinical treatment planning and patient management context in medicine.",
    "prompt_tokens": 20820,
    "completion_tokens": 103,
    "total_tokens": 20923,
    "topic": "Offline Learning - Medical Decision Support",
    "method": "Delphic uncertainty; offline reinforcement learning; conservative Q-learning",
    "application": "Optimizing vasopressor and fluid administration",
    "code_link": "https://github.com/clinicalml/gumbel-max-scm",
    "dataset_name": [
      "HiRID"
    ]
  },
  {
    "id": "YEPlTU5mZC",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Implicit Gaussian process representation of vector fields over arbitrary latent manifolds",
    "authors": [
      "Robert Peach",
      "Matteo Vinao-Carl",
      "Nir Grossman",
      "Michael David",
      "Emma Mallas",
      "David J. Sharp",
      "Paresh A. Malhotra",
      "Pierre Vandergheynst",
      "Adam Gosztolai"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Gaussian processes (GPs) are popular nonparametric statistical models for learning unknown functions and quantifying the spatiotemporal uncertainty in data. Recent works have extended GPs to model scalar and vector quantities distributed over non-Euclidean domains, including smooth manifolds, appearing in numerous fields such as computer vision, dynamical systems, and neuroscience. However, these approaches assume that the manifold underlying the data is known, limiting their practical utility. We introduce RVGP, a generalisation of GPs for learning vector signals over latent Riemannian manifolds. Our method uses positional encoding with eigenfunctions of the connection Laplacian, associated with the tangent bundle, readily derived from common graph-based approximation of data. We demonstrate that RVGP possesses global regularity over the manifold, which allows it to super-resolve and inpaint vector fields while preserving singularities. Furthermore, we use RVGP to reconstruct high-density neural dynamics derived from low-density EEG recordings in healthy individuals and Alzheimer's patients. We show that vector field singularities are important disease markers and that their reconstruction leads to a comparable classification accuracy of disease states to high-density recordings. Thus, our method overcomes a significant practical limitation in experimental and clinical applications.",
    "keywords": "Gaussian processes, neuroscience, vector field, tangent bundle, connection Laplacian, EEG, Alzheimer's disease",
    "pdf_url": "https://openreview.net/pdf?id=YEPlTU5mZC",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper applies its method to reconstruct “high-density neural dynamics derived from low-density EEG recordings in healthy individuals and Alzheimer's patients,” explicitly using EEG (a biomedical signal) and Alzheimer’s disease markers for classification. This direct application to neurological disease diagnosis and patient data makes it relevant to Healthcare/Biomedicine AI.",
    "prompt_tokens": 21071,
    "completion_tokens": 87,
    "total_tokens": 21158,
    "topic": "Neuroscience - EEG Analysis",
    "method": "Gaussian Processes; Connection Laplacian",
    "application": "Binary classification – Alzheimer's disease",
    "code_link": "N/A",
    "dataset_name": [
      "Resting State EEG Dataset"
    ]
  },
  {
    "id": "qH9nrMNTIW",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Protein-Ligand Interaction Prior for Binding-aware 3D Molecule Diffusion Models",
    "authors": [
      "Zhilin Huang",
      "Ling Yang",
      "Xiangxin Zhou",
      "Zhilong Zhang",
      "Wentao Zhang",
      "Xiawu Zheng",
      "Jie Chen",
      "Yu Wang",
      "Bin CUI",
      "Wenming Yang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Generating 3D ligand molecules that bind to specific protein targets via diffusion models has shown great promise for structure-based drug design. The key idea is to disrupt molecules into noise through a fixed forward process and learn its reverse process to generate molecules from noise in a denoising way. However, existing diffusion models primarily focus on incorporating protein-ligand interaction information solely in the reverse process, and neglect the interactions in the forward process. The inconsistency between forward and reverse processes may impair the binding affinity of generated molecules towards target protein. In this paper, we propose a novel Interaction Prior-guided Diffusion model (IPDiff) for the protein-specific 3D molecular generation by introducing geometric protein-ligand interactions into both diffusion and sampling process. Specifically, we begin by pretraining a protein-ligand interaction prior network (IPNet) by utilizing the binding affinity signals as supervision. Subsequently, we leverage the pretrained prior network to (1) integrate interactions between the target protein and the molecular ligand into the forward process for adapting the molecule diffusion trajectories (prior-shifting), and (2) enhance the binding-aware molecule sampling process (prior-conditioning). Empirical studies on CrossDocked2020 dataset show IPDiff can generate molecules with more realistic 3D structures and state-of-the-art binding affinities towards the protein targets, with up to -6.42 Avg. Vina Score, while maintaining proper molecular properties. https://github.com/YangLing0818/IPDiff",
    "keywords": "Diffusion Models, Structure-Based Drug Design, Molecule Generation",
    "pdf_url": "https://openreview.net/pdf?id=qH9nrMNTIW",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work focuses on structure-based drug design by generating 3D ligand molecules that bind to protein targets, leveraging protein–ligand interaction priors and diffusion models. The abstract explicitly mentions “drug design,” “binding affinity,” “protein-ligand interactions,” and “3D molecular generation,” all of which are core tasks in biomedicine AI, specifically in computational drug discovery.",
    "prompt_tokens": 21153,
    "completion_tokens": 106,
    "total_tokens": 21259,
    "topic": "Drug Discovery - Structure-based Design",
    "method": "Diffusion model; Interaction Prior-guided Modifications",
    "application": "3D molecular generation",
    "code_link": "https://github.com/YangLing0818/IPDiff",
    "dataset_name": [
      "PDBbind v2016",
      "CrossDocked2020"
    ]
  },
  {
    "id": "yRrPfKyJQ2",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Conversational Drug Editing Using Retrieval and Domain Feedback",
    "authors": [
      "Shengchao Liu",
      "Jiongxiao Wang",
      "Yijin Yang",
      "Chengpeng Wang",
      "Ling Liu",
      "Hongyu Guo",
      "Chaowei Xiao"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Recent advancements in conversational large language models (LLMs), such as ChatGPT, have demonstrated remarkable promise in various domains, including drug discovery. However, existing works mainly focus on investigating the capabilities of conversational LLMs on chemical reactions and retrosynthesis. While drug editing, a critical task in the drug discovery pipeline, remains largely unexplored. To bridge this gap, we propose ChatDrug, a framework to facilitate the systematic investigation of drug editing using LLMs. ChatDrug jointly leverages a prompt module, a retrieval and domain feedback module, and a conversation module to streamline effective drug editing. We empirically show that ChatDrug reaches the best performance on all 39 drug editing tasks, encompassing small molecules, peptides, and proteins. We further demonstrate, through 10 case studies, that ChatDrug can successfully identify the key substructures for manipulation, generating diverse and valid suggestions for drug editing. Promisingly, we also show that ChatDrug can offer insightful explanations from a domain-specific perspective, enhancing interpretability and enabling informed decision-making.",
    "keywords": "Large Language Models, prompt, retrieval, domain feedback, conversation, drug editing, drug optimization, controllable generation, small molecule, peptide, protein",
    "pdf_url": "https://openreview.net/pdf?id=yRrPfKyJQ2",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “drug editing” and “drug discovery” using large language models, specifically targeting small molecules, peptides, and proteins—core tasks in biomedical research. References to “key substructures for manipulation,” “drug optimization,” and “domain‐specific perspective” all indicate applications in pharmaceutical and therapeutic development, placing this work squarely within the Biomedicine AI domain.",
    "prompt_tokens": 20832,
    "completion_tokens": 104,
    "total_tokens": 20936,
    "topic": "Drug Discovery - Multi-modal Drug Editing",
    "method": "Conversational LLM; retrieval and domain feedback (ReDF)",
    "application": "Drug editing and optimization",
    "code_link": "https://github.com/chao1224/ChatDrug",
    "dataset_name": [
      "ZINC",
      "MHCflurry"
    ]
  },
  {
    "id": "buC4E91xZE",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly Detection",
    "authors": [
      "Qihang Zhou",
      "Guansong Pang",
      "Yu Tian",
      "Shibo He",
      "Jiming Chen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Zero-shot anomaly detection (ZSAD) requires detection models trained using auxiliary\ndata to detect anomalies without any training sample in a target dataset. It\nis a crucial task when training data is not accessible due to various concerns, e.g.,\ndata privacy, yet it is challenging since the models need to generalize to anomalies\nacross different domains where the appearance of foreground objects, abnormal\nregions, and background features, such as defects/tumors on different products/\norgans, can vary significantly. Recently large pre-trained vision-language\nmodels (VLMs), such as CLIP, have demonstrated strong zero-shot recognition\nability in various vision tasks, including anomaly detection. However, their ZSAD\nperformance is weak since the VLMs focus more on modeling the class semantics\nof the foreground objects rather than the abnormality/normality in the images. In\nthis paper we introduce a novel approach, namely AnomalyCLIP, to adapt CLIP\nfor accurate ZSAD across different domains. The key insight of AnomalyCLIP\nis to learn object-agnostic text prompts that capture generic normality and abnormality\nin an image regardless of its foreground objects. This allows our model to\nfocus on the abnormal image regions rather than the object semantics, enabling\ngeneralized normality and abnormality recognition on diverse types of objects.\nLarge-scale experiments on 17 real-world anomaly detection datasets show that\nAnomalyCLIP achieves superior zero-shot performance of detecting and segmenting\nanomalies in datasets of highly diverse class semantics from various defect\ninspection and medical imaging domains. Code will be made available at https://github.com/zqhang/AnomalyCLIP.",
    "keywords": "Anomaly detection, Zero-shot anomaly detection, CLIP, Industrial defect inspection",
    "pdf_url": "https://openreview.net/pdf?id=buC4E91xZE",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although AnomalyCLIP is presented as a general zero‐shot anomaly detection method for both industrial defect inspection and other domains, the abstract explicitly mentions its use in “medical imaging domains” (e.g., detecting “tumors on different … organs”) and reports experiments on datasets that include medical images. Those applications to tumor detection in organs place this work within Healthcare/Medical Imaging AI.",
    "prompt_tokens": 21158,
    "completion_tokens": 147,
    "total_tokens": 21305,
    "topic": "Anomaly Detection - Medical Imaging",
    "method": "Zero-shot anomaly detection; Vision-language models; Prompt learning",
    "application": "Anomaly classification and segmentation – Medical images",
    "code_link": "https://github.com/zqhang/AnomalyCLIP",
    "dataset_name": [
      "ISIC",
      "CVC-ClinicDB",
      "CVC-ColonDB",
      "Kvasir",
      "Endo",
      "TN3K",
      "HeadCT",
      "BrainMRI",
      "Br35H",
      "COVID-19"
    ]
  },
  {
    "id": "ZwhHSOHMTM",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Learning dynamic representations of the functional connectome in neurobiological networks",
    "authors": [
      "Luciano Dyballa",
      "Samuel Lang",
      "Alexandra Haslund-Gourley",
      "Eviatar Yemini",
      "Steven W. Zucker"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The static synaptic connectivity of neuronal circuits stands in direct contrast to the dynamics of their function. As in changing community interactions, different neurons can participate actively in various combinations to effect behaviors at different times. We introduce an unsupervised approach to learn the dynamic affinities between neurons in live, behaving animals, and to reveal which communities form among neurons at different times. The inference occurs in two major steps. First, pairwise non-linear affinities between  neuronal traces from brain-wide calcium activity are organized by non-negative tensor factorization (NTF). Each factor specifies which groups of neurons are most likely interacting for an inferred interval in time, and for which animals. Finally, a generative model that allows for weighted community detection is applied to the functional motifs produced by NTF to reveal a dynamic functional connectome. Since time codes the different experimental variables (e.g., application of chemical stimuli), this provides an atlas of neural motifs active during separate stages of an experiment (e.g., stimulus application or spontaneous behaviors). Results from our analysis are experimentally validated, confirming that our method is able to robustly predict causal interactions between neurons to generate behavior.",
    "keywords": "neural networks, non-negative tensor factorization, dynamic community detection, functional connectome",
    "pdf_url": "https://openreview.net/pdf?id=ZwhHSOHMTM",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper develops an unsupervised method to learn dynamic neuronal affinities and communities from brain-wide calcium imaging in live, behaving animals, producing a “dynamic functional connectome.” This clearly falls under neurobiological modeling and analysis of neural system dynamics—a strong indicator of Biomedicine AI (neuroscience context).",
    "prompt_tokens": 21022,
    "completion_tokens": 113,
    "total_tokens": 21135,
    "topic": "Neuroscience - Dynamic Connectomes",
    "method": "Non-negative tensor factorization (NTF); stochastic block model (SBM)",
    "application": "Community detection - neural activity",
    "code_link": "https://github.com/dyballa/dynamic-connectomes",
    "dataset_name": [
      "NeuroPAL",
      "Yemini et al. dataset"
    ]
  },
  {
    "id": "DGez4B2a6Y",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "A Plug-and-Play Image Registration Network",
    "authors": [
      "Junhao Hu",
      "Weijie Gan",
      "Zhixin Sun",
      "Hongyu An",
      "Ulugbek Kamilov"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Deformable image registration (DIR) is an active research topic in biomedical imaging. There is a growing interest in developing DIR methods based on deep learning (DL). A traditional DL approach to DIR is based on training a convolutional neural network (CNN) to estimate the registration field between two input images. While conceptually simple, this approach comes with a limitation that it exclusively relies on a pre-trained CNN without explicitly enforcing fidelity between the registered image and the reference. We present plug-and-play image registration network (PIRATE) as a new DIR method that addresses this issue by integrating an explicit data-fidelity penalty and a CNN prior. PIRATE pre-trains a CNN denoiser on the registration field and \"plugs\" it into an iterative method as a regularizer. We additionally present PIRATE+ that fine-tunes the CNN prior in PIRATE using deep equilibrium models (DEQ). PIRATE+ interprets the fixed-point iteration of PIRATE as a network with effectively infinite layers and then trains the resulting network end-to-end, enabling it to learn more task-specific information and boosting its performance. Our numerical results on OASIS and CANDI datasets show that our methods achieve state-of-the-art performance on DIR.",
    "keywords": "deformable image registration, plug-and-play priors, deep equilibrium models, iterative algorithms",
    "pdf_url": "https://openreview.net/pdf?id=DGez4B2a6Y",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper addresses deformable image registration in biomedical imaging (abstract: “an active research topic in biomedical imaging”) and evaluates on medical datasets (OASIS and CANDI are brain MRI collections). This is a core medical imaging task, placing it squarely in the Healthcare/ Biomedicine AI domain.",
    "prompt_tokens": 20928,
    "completion_tokens": 111,
    "total_tokens": 21039,
    "topic": "Medical Imaging - Deformable Registration",
    "method": "Deep equilibrium models (DEQ); Plug-and-play (PnP); Convolutional neural networks (CNN)",
    "application": "Deformable image registration",
    "code_link": "N/A",
    "dataset_name": [
      "OASIS",
      "CANDI"
    ]
  },
  {
    "id": "liKkG1zcWq",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Sliced Denoising: A Physics-Informed Molecular Pre-Training Method",
    "authors": [
      "Yuyan Ni",
      "Shikun Feng",
      "Wei-Ying Ma",
      "Zhi-Ming Ma",
      "Yanyan Lan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "While molecular pre-training has shown great potential in enhancing drug discovery, the lack of a solid physical interpretation in current methods raises concerns about whether the learned representation truly captures the underlying explanatory factors in observed data, ultimately resulting in limited generalization and robustness. Although denoising methods offer a physical interpretation, their accuracy is often compromised by ad-hoc noise design, leading to inaccurate learned force fields. To address this limitation, this paper proposes a new method for molecular pre-training, called sliced denoising (SliDe), which is based on the classical mechanical intramolecular potential theory. SliDe utilizes a novel noise strategy that perturbs bond lengths, angles, and torsion angles to achieve better sampling over conformations. Additionally, it introduces a random slicing approach that circumvents the computationally expensive calculation of the Jacobian matrix, which is otherwise essential for estimating the force field. By aligning with physical principles, SliDe shows a 42\\% improvement in the accuracy of estimated force fields compared to current state-of-the-art denoising methods, and thus outperforms traditional baselines on various molecular property prediction tasks.",
    "keywords": "Molecule Representation; Pretraining; Denoising; Force Field",
    "pdf_url": "https://openreview.net/pdf?id=liKkG1zcWq",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly frames its contribution in the context of “enhancing drug discovery” by learning physics-informed molecular representations and improving force-field estimation. These topics—molecular modeling, conformational sampling, and molecular property prediction—are core to AI-driven drug discovery, which falls under Biomedicine AI.",
    "prompt_tokens": 20770,
    "completion_tokens": 108,
    "total_tokens": 20878,
    "topic": "Drug Discovery - Molecular Property Prediction",
    "method": "Sliced denoising; equivariant molecular representation; transformer-based models",
    "application": "Molecular property prediction",
    "code_link": "https://github.com/fengshikun/SliDe",
    "dataset_name": [
      "QM9",
      "MD17",
      "ANI-1x"
    ]
  },
  {
    "id": "NSVtmmzeRB",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Unified Generative Modeling of 3D Molecules with Bayesian Flow Networks",
    "authors": [
      "Yuxuan Song",
      "Jingjing Gong",
      "Hao Zhou",
      "Mingyue Zheng",
      "Jingjing Liu",
      "Wei-Ying Ma"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Advanced generative model (\\textit{e.g.}, diffusion model) derived from simplified continuity assumptions of data distribution, though showing promising progress, has been difficult to apply directly to geometry generation applications due to the \\textit{multi-modality} and \\textit{noise-sensitive} nature of molecule geometry. \nThis work introduces Geometric Bayesian Flow Networks (GeoBFN), which naturally fits molecule geometry by modeling diverse modalities in the differentiable parameter space of distributions. GeoBFN maintains the SE-(3) invariant density modeling property by incorporating equivariant inter-dependency modeling on parameters of distributions and unifying the probabilistic modeling of different modalities. \nThrough optimized training and sampling techniques, we demonstrate that GeoBFN achieves state-of-the-art performance on multiple 3D molecule generation benchmarks in terms of generation quality (90.87\\% molecule stability in QM9 and 85.6\\% atom stability in GEOM-DRUG\\footnote{The scores are reported at 1k sampling steps for fair comparison, and our scores could be further improved if sampling sufficiently longer steps.}). GeoBFN can also conduct sampling with any number of steps to reach an optimal trade-off between efficiency and quality (\\textit{e.g.}, 20$\\times$ speedup without sacrificing performance).",
    "keywords": "Drug Design, Molecule Generation, Deep Learning, Computational Biology",
    "pdf_url": "https://openreview.net/pdf?id=NSVtmmzeRB",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on 3D molecule generation and explicitly cites “Drug Design” and benchmarks like QM9 and GEOM-DRUG. Generative modeling of molecular structures is a core task in drug discovery and computational biology, placing it within the Biomedicine AI domain.",
    "prompt_tokens": 20804,
    "completion_tokens": 91,
    "total_tokens": 20895,
    "topic": "Drug Discovery - Molecular Geometry",
    "method": "Bayesian Flow Network; Equivariant modeling",
    "application": "3D molecular generation",
    "code_link": "N/A",
    "dataset_name": [
      "QM9",
      "GEOM-DRUG"
    ]
  },
  {
    "id": "zgQ0PHeGnL",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Rigid Protein-Protein Docking via Equivariant Elliptic-Paraboloid Interface Prediction",
    "authors": [
      "Ziyang Yu",
      "Wenbing Huang",
      "Yang Liu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The study of rigid protein-protein docking plays an essential role in a variety of tasks such as drug design and protein engineering. Recently, several learning-based methods have been proposed for the task, exhibiting much faster docking speed than those computational methods. In this paper, we propose a novel learning-based method called ElliDock, which predicts an elliptic paraboloid to represent the protein-protein docking interface. To be specific, our model estimates elliptic paraboloid interfaces for the two input proteins respectively, and obtains the roto-translation transformation for docking by making two interfaces coincide. By its design, ElliDock is independently equivariant with respect to arbitrary rotations/translations of the proteins, which is an indispensable property to ensure the generalization of the docking process. Experimental evaluations show that ElliDock achieves the fastest inference time among all compared methods, and outperforms state-of-the-art learning-based methods, like DiffDock-PP and Alphafold-Multimer, for particularly antibody-antigen docking.",
    "keywords": "Equivariant Graph Neural Network, rigid body protein-protein docking, interface fitting",
    "pdf_url": "https://openreview.net/pdf?id=zgQ0PHeGnL",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on rigid protein–protein docking—a core task in molecular modeling for “drug design and protein engineering” as stated in the abstract. Predicting docking interfaces and transformations between proteins is directly relevant to drug discovery and therapeutic protein design. These are hallmark applications of Biomedicine AI.",
    "prompt_tokens": 21132,
    "completion_tokens": 122,
    "total_tokens": 21254,
    "topic": "Bioinformatics - Protein Docking",
    "method": "SE(3)-equivariant GNN; elliptic paraboloid interface prediction",
    "application": "Rigid protein docking",
    "code_link": "https://github.com/yaledeus/ElliDock",
    "dataset_name": [
      "Docking Benchmark Version 5 (DB5.5)",
      "SAbDab (Structural Antibody Database)"
    ]
  },
  {
    "id": "cUSNs8nGaV",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "GlucoBench: Curated List of Continuous Glucose Monitoring Datasets with Prediction Benchmarks",
    "authors": [
      "Renat Sergazinov",
      "Elizabeth Chun",
      "Valeriya Rogovchenko",
      "Nathaniel J Fernandes",
      "Nicholas Kasman",
      "Irina Gaynanova"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The rising rates of diabetes necessitate innovative methods for its management. Continuous glucose monitors (CGM) are small medical devices that measure blood glucose levels at regular intervals providing insights into daily patterns of glucose variation. Forecasting of glucose trajectories based on CGM data  holds the potential to substantially improve diabetes management, by both refining artificial pancreas systems and enabling individuals to make adjustments based on  predictions to maintain optimal glycemic range. Despite numerous methods proposed for CGM-based glucose trajectory prediction, these methods are typically evaluated on small, private datasets, impeding reproducibility, further research, and practical adoption. The absence of standardized prediction tasks and systematic comparisons between methods has led to uncoordinated research efforts, obstructing the identification of optimal tools for tackling specific challenges. As a result, only a limited number of prediction methods have been implemented in clinical practice.  \n\nTo address these challenges, we present a comprehensive resource that provides (1) a consolidated repository of curated publicly available CGM datasets to foster reproducibility and accessibility; (2) a standardized task list to unify research objectives and facilitate coordinated efforts; (3) a set of benchmark models with established baseline performance, enabling the research community to objectively gauge new methods' efficacy; and (4) a detailed analysis of performance-influencing factors for model development. We anticipate these resources to propel collaborative research endeavors in the critical domain of CGM-based glucose predictions. Our code is available online at github.com/IrinaStatsLab/GlucoBench.",
    "keywords": "diabetes management, continuous glucose monitors (CGM), glucose trajectory prediction, artificial pancreas systems, public datasets, standardized tasks, benchmark models, glycemic control",
    "pdf_url": "https://openreview.net/pdf?id=cUSNs8nGaV",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work focuses on forecasting blood glucose trajectories from continuous glucose monitor (CGM) data to improve diabetes management and refine artificial pancreas systems. It deals directly with patient monitoring (“CGM are small medical devices that measure blood glucose levels”), clinical prediction (“glucose trajectory prediction”), and glycemic control, all of which fall squarely under Healthcare AI.",
    "prompt_tokens": 20782,
    "completion_tokens": 155,
    "total_tokens": 20937,
    "topic": "Diabetes Prediction - CGM-based Glucose Monitoring",
    "method": "Latent ODE; Transformer; Temporal Fusion Transformer; Classical Time Series Models",
    "application": "Blood glucose trajectory forecasting",
    "code_link": "https://github.com/IrinaStatsLab/GlucoBench",
    "dataset_name": [
      "Broll et al. (2021)",
      "Colás et al. (2019)",
      "Dubosson et al. (2018)",
      "Hall et al. (2018)",
      "Weinstock et al. (2016)"
    ]
  },
  {
    "id": "7TOs9gjAg1",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Removing Biases from Molecular Representations via Information Maximization",
    "authors": [
      "Chenyu Wang",
      "Sharut Gupta",
      "Caroline Uhler",
      "Tommi S. Jaakkola"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "High-throughput drug screening -- using cell imaging or gene expression measurements as readouts of drug effect -- is a critical tool in biotechnology to assess and understand the relationship between the chemical structure and biological activity of a drug. Since large-scale screens have to be divided into multiple experiments, a key difficulty is dealing with batch effects, which can introduce systematic errors and non-biological associations in the data. We propose InfoCORE, an Information maximization approach for COnfounder REmoval, to effectively deal with batch effects and obtain refined molecular representations. InfoCORE establishes a variational lower bound on the conditional mutual information of the latent representations given a batch identifier. It adaptively reweights samples to equalize their implied batch distribution. Extensive experiments on drug screening data reveal InfoCORE's superior performance in a multitude of tasks including molecular property prediction and molecule-phenotype retrieval. Additionally, we show results for how InfoCORE offers a versatile framework and resolves general distribution shifts and issues of data fairness by minimizing correlation with spurious features or removing sensitive attributes.",
    "keywords": "Molecular Representation, Batch Effect, Contrastive Learning, Information Maximization, Drug Discovery",
    "pdf_url": "https://openreview.net/pdf?id=7TOs9gjAg1",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on high-throughput drug screening and molecular representations for drug discovery (“drug screening data,” “molecular property prediction,” “molecule-phenotype retrieval”), which are core tasks in Biomedicine AI. The proposed method, InfoCORE, specifically addresses batch effects in drug screening experiments and is evaluated on drug discovery benchmarks, clearly situating it within the biomedical domain.",
    "prompt_tokens": 39041,
    "completion_tokens": 141,
    "total_tokens": 39182,
    "topic": "Drug Discovery - Representation Learning",
    "method": "Multimodal contrastive learning; conditional mutual information maximization",
    "application": "Molecule-phenotype retrieval; molecular property prediction",
    "code_link": "https://github.com/uhlerlab/InfoCORE",
    "dataset_name": [
      "L1000 Gene Expression Profiles",
      "Cell Painting Assay",
      "UCI Adult",
      "Compas",
      "Law School"
    ]
  },
  {
    "id": "qg2boc2AwU",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "EBMDock: Neural Probabilistic Protein-Protein Docking via a Differentiable Energy Model",
    "authors": [
      "Huaijin Wu",
      "Wei Liu",
      "Yatao Bian",
      "Jiaxiang Wu",
      "Nianzu Yang",
      "Junchi Yan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Protein complex formation, a pivotal challenge in contemporary biology, has recently gained interest from the machine learning community, particularly concerning protein-ligand docking tasks. In this paper, we delve into the equally crucial but comparatively under-investigated domain of protein-protein docking. Specifically, we propose a geometric deep learning framework, termed EBMDock,  which employs statistical potential as its energy function. This approach produces a probability distribution over docking poses, such that the identified docking pose aligns with a minimum point in the energy landscape. We employ a differential algorithm grounded in Langevin dynamics to efficiently sample from the docking pose distribution. Additionally, we incorporate energy-based training using contrastive divergence, enhancing both performance and stability. Empirical results demonstrate that our approach achieves superior performance on two benchmark datasets DIPS and DB5.5. Furthermore, the results suggest EBMDock can serve as an orthogonal enhancement to existing methods.",
    "keywords": "protein-protein docking, energy-based model, geometric deep learning, energy-function",
    "pdf_url": "https://openreview.net/pdf?id=qg2boc2AwU",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on protein–protein docking and employs statistical potential energy functions for modeling protein complex formation. Protein docking and molecular modeling are central to drug discovery and other biomedical research applications, placing this work squarely in the Biomedicine AI domain.",
    "prompt_tokens": 20987,
    "completion_tokens": 103,
    "total_tokens": 21090,
    "topic": "Bioinformatics - Protein-Protein Docking",
    "method": "Energy-based models with Langevin dynamics; Geometric deep learning",
    "application": "Protein docking pose prediction",
    "code_link": "https://github.com/wuhuaijin/EBMDock",
    "dataset_name": [
      "DIPS-Het",
      "DB5.5"
    ]
  },
  {
    "id": "DqziS8DG4M",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Point2SSM: Learning Morphological Variations of Anatomies from Point Clouds",
    "authors": [
      "Jadie Adams",
      "Shireen Elhabian"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We present Point2SSM, a novel unsupervised learning approach for constructing correspondence-based statistical shape models (SSMs) directly from raw point clouds. SSM is crucial in clinical research, enabling population-level analysis of morphological variation in bones and organs. Traditional methods of SSM construction have limitations, including the requirement of noise-free surface meshes or binary volumes, reliance on assumptions or templates, and prolonged inference times due to simultaneous optimization of the entire cohort. Point2SSM overcomes these barriers by providing a data-driven solution that infers SSMs directly from raw point clouds, reducing inference burdens and increasing applicability as point clouds are more easily acquired. While deep learning on 3D point clouds has seen success in unsupervised representation learning and shape correspondence, its application to anatomical SSM construction is largely unexplored. We conduct a benchmark of state-of-the-art point cloud deep networks on the SSM task, revealing their limited robustness to clinical challenges such as noisy, sparse, or incomplete input and limited training data. Point2SSM addresses these issues through an attention-based module, providing effective correspondence mappings from learned point features. Our results demonstrate that the proposed method significantly outperforms existing networks in terms of accurate surface sampling and correspondence, better capturing population-level statistics. The source code is provided at https://github.com/jadie1/Point2SSM.",
    "keywords": "Unsupervised learning, global correspondence, point cloud, statsitical shape modeling",
    "pdf_url": "https://openreview.net/pdf?id=DqziS8DG4M",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on constructing statistical shape models (SSMs) of anatomical structures (“bones and organs”) from point cloud data, explicitly noting its importance for “clinical research” and “population-level analysis of morphological variation.” This direct application to anatomical modeling in a medical context makes it part of Healthcare/Biomedicine AI.",
    "prompt_tokens": 20978,
    "completion_tokens": 115,
    "total_tokens": 21093,
    "topic": "Medical Imaging - 3D Shape Modeling",
    "method": "Unsupervised learning; Point cloud processing",
    "application": "Morphological variation analysis",
    "code_link": "https://github.com/jadie1/Point2SSM",
    "dataset_name": [
      "Pancreas Dataset",
      "Spleen Dataset",
      "Left Atrium Dataset"
    ]
  },
  {
    "id": "cKAUvMePUN",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Exploring Effective Stimulus Encoding via Vision System Modeling for Visual Prostheses",
    "authors": [
      "Chuanqing Wang",
      "Di Wu",
      "Chaoming Fang",
      "Jie Yang",
      "Mohamad Sawan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Visual prostheses are potential devices to restore vision for blind people, which highly depends on the quality of stimulation patterns of the implanted electrode array. However, existing processing frameworks prioritize the generation of stimulation while disregarding the potential impact of restoration effects and fail to assess the quality of the generated stimulation properly. In this paper, we propose for the first time an end-to-end visual prosthesis framework (StimuSEE) that generates stimulation patterns with proper quality verification using V1 neuron spike patterns as supervision. StimuSEE consists of a retinal network to predict the stimulation pattern, a phosphene model, and a primary vision system network (PVS-net) to simulate the signal processing from the retina to the visual cortex and predict the firing rate of V1 neurons. Experimental results show that the predicted stimulation shares similar patterns to the original scenes, whose different stimulus amplitudes contribute to a similar firing rate with normal cells. Numerically, the predicted firing rate and the recorded response of normal neurons achieve a Pearson correlation coefficient of 0.78.",
    "keywords": "Visual prostheses, Spiking recurrent neural network, Dynamic vision sensor, Biological phosphene model",
    "pdf_url": "https://openreview.net/pdf?id=cKAUvMePUN",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper describes an end-to-end framework for visual prostheses aimed at restoring sight in blind patients by modeling retinal stimulation and V1 neuron responses. It focuses on a neuroengineering application (“visual prostheses,” “phosphene model,” “V1 neuron spike patterns”) with clear medical/clinical relevance in vision restoration, fitting squarely within Healthcare AI.",
    "prompt_tokens": 20715,
    "completion_tokens": 94,
    "total_tokens": 20809,
    "topic": "Medical Devices - Visual Prostheses",
    "method": "Spiking recurrent neural network (SRNN); phosphene simulation; PVS-net",
    "application": "Visual stimulation pattern prediction",
    "code_link": "N/A",
    "dataset_name": [
      "DVS-V1"
    ]
  },
  {
    "id": "2UnCj3jeao",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation",
    "authors": [
      "Luca Eyring",
      "Dominik Klein",
      "Théo Uscidda",
      "Giovanni Palla",
      "Niki Kilbertus",
      "Zeynep Akata",
      "Fabian J Theis"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In optimal transport (OT), a Monge map is known as a mapping that transports a source distribution to a target distribution in the most cost-efficient way. Recently, multiple neural estimators for Monge maps have been developed and applied in diverse unpaired domain translation tasks, e.g. in single-cell biology and computer vision. However, the classic OT framework enforces mass conservation, which\nmakes it prone to outliers and limits its applicability in real-world scenarios. The latter can be particularly harmful in OT domain translation tasks, where the relative position of a sample within a distribution is explicitly taken into account. While unbalanced OT tackles this challenge in the discrete setting, its integration into neural Monge map estimators has received limited attention. We propose a theoretically\ngrounded method to incorporate unbalancedness into any Monge map estimator. We improve existing estimators to model cell trajectories over time and to predict cellular responses to perturbations. Moreover, our approach seamlessly integrates with the OT flow matching (OT-FM) framework. While we show that OT-FM performs competitively in image translation, we further improve performance by\nincorporating unbalancedness (UOT-FM), which better preserves relevant features. We hence establish UOT-FM as a principled method for unpaired image translation.",
    "keywords": "optimal transport, domain translation, image translation, flow matching",
    "pdf_url": "https://openreview.net/pdf?id=2UnCj3jeao",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the paper develops general optimal-transport methods, it explicitly targets “single-cell biology” applications—modeling cell trajectories over time and predicting cellular responses to perturbations—which are core tasks in biomedical research. These domain‐specific use cases (“cell trajectories,” “cellular responses”) place it squarely in the Biomedicine AI category.",
    "prompt_tokens": 21086,
    "completion_tokens": 125,
    "total_tokens": 21211,
    "topic": "Optimal Transport - Neural Estimators",
    "method": "Unbalanced Monge maps; OT Flow Matching (OT-FM); UOT-ICNN",
    "application": "Unpaired domain translation",
    "code_link": "https://github.com/ExplainableML/uot-fm",
    "dataset_name": [
      "EMNIST",
      "CelebA",
      "CIFAR-10",
      "sciPlex"
    ]
  },
  {
    "id": "RJDjSXNuAZ",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Weakly Supervised Virus Capsid Detection with Image-Level Annotations in Electron Microscopy Images",
    "authors": [
      "Hannah Kniesel",
      "Leon Sick",
      "Tristan Payer",
      "Tim Bergner",
      "Kavitha Shaga Devan",
      "Clarissa Read",
      "Paul Walther",
      "Timo Ropinski",
      "Pedro Hermosilla"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Current state-of-the-art methods for object detection rely on annotated bounding boxes of large data sets for training. However, obtaining such annotations is expensive and can require up to hundreds of hours of manual labor. This poses a challenge, especially since such annotations can only be provided by experts, as they require knowledge about the scientific domain. To tackle this challenge, we propose a domain-specific weakly supervised object detection algorithm that only relies on image-level annotations, which are significantly easier to acquire. Our method  distills the knowledge of a pre-trained model, on the task of predicting the presence or absence of a virus in an image, to obtain a set of pseudo-labels that can be used to later train a state-of-the-art object detection model. To do so, we use an optimization approach with a shrinking receptive field to extract virus particles directly without specific network architectures. Through a set of extensive studies, we show how the proposed pseudo-labels are easier to obtain, and, more importantly, are able to outperform other existing weak labeling methods, and even ground truth labels, in cases where the time to obtain the annotation is limited.",
    "keywords": "Weakly Supervised Object Detection, Limited Annotation Time, Bounding Box Regression, Electron Microscopy",
    "pdf_url": "https://openreview.net/pdf?id=RJDjSXNuAZ",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on detecting virus capsids in electron microscopy images—a clearly biomedical imaging application. It addresses “virus particles” and “electron microscopy,” which are core topics in virology and biomedical research. The task of identifying viral structures from microscopy data situates this work squarely within the Biomedicine AI domain.",
    "prompt_tokens": 20687,
    "completion_tokens": 117,
    "total_tokens": 20804,
    "topic": "Virus Detection - Weak Supervision",
    "method": "Gaussian masking; GradCAM initialization; weak supervision",
    "application": "Virus particle detection – Electron Microscopy (EM)",
    "code_link": "https://github.com/HannahKniesel/WSCD",
    "dataset_name": [
      "Herpes",
      "Adeno",
      "Noro",
      "Papilloma",
      "Rota"
    ]
  },
  {
    "id": "4MsfQ2H0lP",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Deep Reinforcement Learning for Modelling Protein Complexes",
    "authors": [
      "Ziqi Gao",
      "Tao Feng",
      "Jiaxuan You",
      "Chenyi Zi",
      "Yan Zhou",
      "Chen Zhang",
      "Jia Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Structure prediction of large protein complexes (a.k.a., protein multimer mod-\nelling, PMM) can be achieved through the one-by-one assembly using provided\ndimer structures and predicted docking paths. However, existing PMM methods\nstruggle with vast search spaces and generalization challenges: (1) The assembly\nof a N -chain multimer can be depicted using graph structured data, with each\nchain represented as a node and assembly actions as edges. Thus the assembly\ngraph can be arbitrary acyclic undirected connected graph, leading to the com-\nbinatorial optimization space of N^(N −2) for the PMM problem. (2) Knowledge\ntransfer in the PMM task is non-trivial. The gradually limited data availability as\nthe chain number increases necessitates PMM models that can generalize across\nmultimers of various chains. To address these challenges, we propose GAPN, a\nGenerative Adversarial Policy Network powered by domain-specific rewards and\nadversarial loss through policy gradient for automatic PMM prediction. Specifi-\ncally, GAPN learns to efficiently search through the immense assembly space and\noptimize the direct docking reward through policy gradient. Importantly, we de-\nsign a adversarial reward function to enhance the receptive field of our model. In\nthis way, GAPN will simultaneously focus on a specific batch of multimers and\nthe global assembly rules learned from multimers with varying chain numbers.\nEmpirically, we have achieved both significant accuracy (measured by RMSD\nand TM-Score) and efficiency improvements compared to leading complex mod-\neling software. GAPN outperforms the state-of-the-art method (MoLPC) with up\nto 27% improvement in TM-Score, with a speed-up of 600×.",
    "keywords": "protein complex structure prediction, docking path prediction, policy network, reinforcement learning",
    "pdf_url": "https://openreview.net/pdf?id=4MsfQ2H0lP",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “protein complex structure prediction,” “docking path prediction,” and “molecular modelling” of protein multimers. These tasks are central to biomedical research and drug discovery, as accurately modelling protein–protein interactions underpins understanding of biological mechanisms and therapeutic design. Keywords like “protein complex structure prediction,” “docking,” RMSD and TM‐Score metrics further confirm its relevance to Biomedicine AI.",
    "prompt_tokens": 20553,
    "completion_tokens": 114,
    "total_tokens": 20667,
    "topic": "Bioinformatics - Protein Complex Modelling",
    "method": "Deep reinforcement learning (DRL); Generative adversarial policy network (GAPN)",
    "application": "Protein complex assembly prediction",
    "code_link": "N/A",
    "dataset_name": [
      "PDB",
      "AlphaFold-Multimer Predicted Dimers",
      "ESMFold Predicted Dimers"
    ]
  },
  {
    "id": "otHZ8JAIgh",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Prototypical Information Bottlenecking and Disentangling for Multimodal Cancer Survival Prediction",
    "authors": [
      "Yilan Zhang",
      "Yingxue Xu",
      "Jianqi Chen",
      "Fengying Xie",
      "Hao Chen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Multimodal learning significantly benefits cancer survival prediction, especially the integration of pathological images and genomic data. Despite advantages of multimodal learning for cancer survival prediction, massive redundancy in multimodal data prevents it from extracting discriminative and compact information: (1) An extensive amount of intra-modal task-unrelated information blurs discriminability, especially for gigapixel whole slide images (WSIs) with many patches in pathology and thousands of pathways in genomic data, leading to an \"intra-modal redundancy\" issue. (2) Duplicated information among modalities dominates the representation of multimodal data, which makes modality-specific information prone to being ignored, resulting in an \"inter-modal redundancy\" issue. To address these, we propose a new framework, Prototypical Information Bottlenecking and Disentangling (PIBD), consisting of Prototypical Information Bottleneck (PIB) module for intra-modal redundancy and Prototypical Information Disentanglement (PID) module for inter-modal redundancy. Specifically, a variant of information bottleneck, PIB, is proposed to model prototypes approximating a bunch of instances for different risk levels, which can be used for selection of discriminative instances within modality. PID module decouples entangled multimodal data into compact distinct components: modality-common and modality-specific knowledge, under the guidance of the joint prototypical distribution. Extensive experiments on five cancer benchmark datasets demonstrated our superiority over other methods. The code is released.",
    "keywords": "multimodal survival prediction, computational pathology",
    "pdf_url": "https://openreview.net/pdf?id=otHZ8JAIgh",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “multimodal cancer survival prediction” by integrating “pathological images” and “genomic data,” which are core biomedical and clinical tasks. It addresses tumor prognostication—a healthcare application—using AI methods tailored to pathology (WSIs) and genomics, firmly placing it in the Healthcare/​Biomedicine AI domain.",
    "prompt_tokens": 20671,
    "completion_tokens": 122,
    "total_tokens": 20793,
    "topic": "Cancer Prognosis - Multimodal Learning",
    "method": "Prototypical Information Bottleneck; Prototypical Information Disentanglement",
    "application": "Cancer survival prediction",
    "code_link": "https://github.com/zylbuaa/PIBD.git",
    "dataset_name": [
      "BRCA",
      "BLCA",
      "COADREAD",
      "STAD",
      "HNSC"
    ]
  },
  {
    "id": "770DetV8He",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "RetroBridge: Modeling Retrosynthesis with Markov Bridges",
    "authors": [
      "Ilia Igashov",
      "Arne Schneuing",
      "Marwin Segler",
      "Michael M. Bronstein",
      "Bruno Correia"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Retrosynthesis planning is a fundamental challenge in chemistry which aims at designing multi-step reaction pathways from commercially available starting materials to a target molecule. Each step in multi-step retrosynthesis planning requires accurate prediction of possible precursor molecules given the target molecule and confidence estimates to guide heuristic search algorithms. We model single-step retrosynthesis as a distribution learning problem in a discrete state space. First, we introduce the Markov Bridge Model, a generative framework aimed to approximate the dependency between two intractable discrete distributions accessible via a finite sample of coupled data points. Our framework is based on the concept of a Markov bridge, a Markov process pinned at its endpoints. Unlike diffusion-based methods, our Markov Bridge Model does not need a tractable noise distribution as a sampling proxy and directly operates on the input product molecules as samples from the intractable prior distribution. We then address the retrosynthesis planning problem with our novel framework and introduce RetroBridge, a template-free retrosynthesis modeling approach that achieves state-of-the-art results on standard evaluation benchmarks.",
    "keywords": "Retrosynthesis, Reactions, Chemistry, Drug Discovery, Markov Bridge",
    "pdf_url": "https://openreview.net/pdf?id=770DetV8He",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on retrosynthesis planning for designing multi-step reaction pathways, with explicit mention of “Drug Discovery” in the keywords. Retrosynthesis is a core tool in medicinal chemistry and pharmaceutical development. The methodology directly supports drug discovery by generating precursor molecules for target compounds, placing it squarely within the Biomedicine AI domain.",
    "prompt_tokens": 20893,
    "completion_tokens": 97,
    "total_tokens": 20990,
    "topic": "Drug Discovery - Retrosynthesis Modeling",
    "method": "Markov Bridge Model; probabilistic framework",
    "application": "Retrosynthesis prediction",
    "code_link": "https://github.com/igashov/RetroBridge",
    "dataset_name": [
      "USPTO-50k"
    ]
  },
  {
    "id": "QzTpTRVtrP",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Large Brain Model for Learning Generic Representations with Tremendous EEG Data in BCI",
    "authors": [
      "Weibang Jiang",
      "Liming Zhao",
      "Bao-liang Lu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The current electroencephalogram (EEG) based deep learning models are typically designed for specific datasets and applications in brain-computer interaction (BCI), limiting the scale of the models and thus diminishing their perceptual capabilities and generalizability. Recently, Large Language Models (LLMs) have achieved unprecedented success in text processing, prompting us to explore the capabilities of Large EEG Models (LEMs). We hope that LEMs can break through the limitations of different task types of EEG datasets, and obtain universal perceptual capabilities of EEG signals through unsupervised pre-training. Then the models can be fine-tuned for different downstream tasks. However, compared to text data, the volume of EEG datasets is generally small and the format varies widely. For example, there can be mismatched numbers of electrodes, unequal length data samples, varied task designs, and low signal-to-noise ratio. To overcome these challenges, we propose a unified foundation model for EEG called Large Brain Model (LaBraM). LaBraM enables cross-dataset learning by segmenting the EEG signals into EEG channel patches. Vector-quantized neural spectrum prediction is used to train a semantically rich neural tokenizer that encodes continuous raw EEG channel patches into compact neural codes. We then pre-train neural Transformers by predicting the original neural codes for the masked EEG channel patches. The LaBraMs were pre-trained on about 2,500 hours of various types of EEG signals from around 20 datasets and validated on multiple different types of downstream tasks. Experiments on abnormal detection, event type classification, emotion recognition, and gait prediction show that our LaBraM outperforms all compared SOTA methods in their respective fields. Our code is available at https://github.com/935963004/LaBraM.",
    "keywords": "EEG, brain-computer interface, representation learning",
    "pdf_url": "https://openreview.net/pdf?id=QzTpTRVtrP",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on representation learning for EEG signals—a form of time-series biomedical data. EEG is listed among “health-related datasets or tasks” in the domain definitions, and the work addresses tasks such as abnormal detection, event classification, emotion recognition, and gait prediction from EEG. Training large models on EEG for downstream health-relevant tasks (e.g., detecting abnormalities) clearly aligns with Healthcare AI.",
    "prompt_tokens": 20243,
    "completion_tokens": 203,
    "total_tokens": 20446,
    "topic": "EEG Analysis - Foundation Models",
    "method": "Neural Transformer; vector-quantized neural spectrum prediction",
    "application": "Generic EEG representation learning",
    "code_link": "https://github.com/935963004/LaBraM",
    "dataset_name": [
      "BCI Competition IV-1",
      "Emobrain",
      "Grasp and Lift EEG Challenge",
      "Inria BCI Challenge",
      "EEG Motor Movement/Imagery Dataset",
      "Raw EEG Data",
      "Resting State EEG Data",
      "SEED Series",
      "Siena Scalp EEG Database",
      "SPIS Resting State Dataset",
      "Target Versus Non-Target",
      "TUAR",
      "TUEP",
      "TUSZ",
      "TUSL",
      "Self-collected EEG Data",
      "SEED-V",
      "MoBI"
    ]
  },
  {
    "id": "BKXvPDekud",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "CellPLM: Pre-training of Cell Language Model Beyond Single Cells",
    "authors": [
      "Hongzhi Wen",
      "Wenzhuo Tang",
      "Xinnan Dai",
      "Jiayuan Ding",
      "Wei Jin",
      "Yuying Xie",
      "Jiliang Tang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The current state-of-the-art single-cell pre-trained models are greatly inspired by the success of large language models. They trained transformers by treating genes as tokens and cells as sentences. However, three fundamental differences between single-cell data and natural language data are overlooked: (1) scRNA-seq data are presented as bag-of-genes instead of sequences of RNAs; (2) Cell-cell relations are more intricate and important than inter-sentence relations; and (3) The quantity of single-cell data is considerably inferior to text data, and they are very noisy. In light of these characteristics, we propose a new pre-trained model, $\\textit{CellPLM}$, which takes cells as tokens and tissues as sentences. In addition, we leverage spatially-resolved transcriptomic data in pre-training to facilitate learning cell-cell relationships and introduce a Gaussian prior distribution as an additional inductive bias to overcome data limitations. $\\textit{CellPLM}$ is the first single-cell pre-trained transformer that encodes cell-cell relations and it consistently outperforms existing pre-trained and non-pre-trained models in diverse downstream tasks, with 100 times higher inference speed on generating cell embeddings than previous pre-trained models.",
    "keywords": "Single-cell analysis, Pretrained models, AI for science",
    "pdf_url": "https://openreview.net/pdf?id=BKXvPDekud",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on single-cell RNA sequencing (“scRNA-seq”) and spatial transcriptomic data—core technologies in molecular and cellular biology—and proposes a transformer model (“CellPLM”) for single-cell analysis. These topics (genomics, transcriptomics, cell-cell relations) fall squarely under Biomedicine AI.",
    "prompt_tokens": 20926,
    "completion_tokens": 155,
    "total_tokens": 21081,
    "topic": "Bioinformatics - Single-cell Transcriptomics",
    "method": "Transformer-based models; masked language modeling; Gaussian mixture priors",
    "application": "Cell representation learning and denoising",
    "code_link": "https://github.com/OmicsML/CellPLM",
    "dataset_name": [
      "PBMC 5K",
      "Jurkat",
      "Lung2",
      "Liver2",
      "GSE131907",
      "GSE151530",
      "Adamson Perturb-Seq",
      "Norman Perturb-Seq"
    ]
  },
  {
    "id": "9UIGyJJpay",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "De novo Protein Design Using Geometric Vector Field Networks",
    "authors": [
      "Weian Mao",
      "Muzhi Zhu",
      "Zheng Sun",
      "Shuaike Shen",
      "Lin Yuanbo Wu",
      "Hao Chen",
      "Chunhua Shen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Advances like protein diffusion have marked revolutionary progress in $\\textit{de novo}$ protein design, a central topic in life science. These methods typically depend on protein structure encoders to model residue backbone frames, where atoms do not exist. Most prior encoders rely on atom-wise features, such as angles and distances between atoms, which are not available in this context. Only a few basic encoders, like IPA, have been proposed for this scenario, exposing the frame modeling as a bottleneck. In this work, we introduce the Vector Field Network (VFN), that enables network layers to perform learnable vector computations between coordinates of frame-anchored virtual atoms, thus achieving a higher capability for modeling frames. The vector computation operates in a manner similar to a linear layer, with each input channel receiving 3D virtual atom coordinates instead of scalar values. The multiple feature vectors output by the vector computation are then used to update the residue representations and virtual atom coordinates via attention aggregation. Remarkably, VFN also excels in modeling both frames and atoms, as the real atoms can be treated as the virtual atoms for modeling, positioning VFN as a potential $\\textit{universal encoder}$. In protein diffusion (frame modeling), VFN exhibits a impressive performance advantage over IPA, excelling in terms of both designability ($\\textbf{67.04}$\\% vs. 53.58\\%) and diversity ($\\textbf{66.54}$\\% vs. 51.98\\%). In inverse folding(frame and atom modeling), VFN outperforms the previous SoTA model, PiFold ($\\textbf{54.7}$\\% vs. 51.66\\%), on sequence recovery rate; we also propose a method of equipping VFN with the ESM model, which significantly surpasses the previous ESM-based SoTA ($\\textbf{62.67}$\\% vs. 55.65\\%), LM-Design, by a substantial margin. Code is available at https://github.com/aim-uofa/VFN",
    "keywords": "Protein design, Protein structure encoder, Inverse folding, Protein diffusion",
    "pdf_url": "https://openreview.net/pdf?id=9UIGyJJpay",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “de novo protein design” and “inverse folding,” which are core tasks in molecular modeling and drug discovery—key areas of biomedicine AI. It introduces a Vector Field Network (VFN) for modeling protein backbone frames and atoms, directly relating to “protein structure encoder” and “protein diffusion,” both critical in therapeutic protein engineering and drug design.",
    "prompt_tokens": 20657,
    "completion_tokens": 121,
    "total_tokens": 20778,
    "topic": "Protein Design - Inverse Folding and Diffusion",
    "method": "Vector Field Network (VFN); Diffusion model; Inverse folding models",
    "application": "De novo protein sequence and structure optimization",
    "code_link": "https://github.com/aim-uofa/VFN",
    "dataset_name": [
      "PDB",
      "CATH 4.2",
      "TS50",
      "TS500"
    ]
  },
  {
    "id": "Tlsdsb6l9n",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models",
    "authors": [
      "Yin Fang",
      "Xiaozhuan Liang",
      "Ningyu Zhang",
      "Kangwei Liu",
      "Rui Huang",
      "Zhuo Chen",
      "Xiaohui Fan",
      "Huajun Chen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Large Language Models (LLMs), with their remarkable task-handling capabilities and innovative outputs, have catalyzed significant advancements across a spectrum of fields. However, their proficiency within specialized domains such as biomolecular studies remains limited. To address this challenge, we introduce Mol-Instructions, a comprehensive instruction dataset designed for the biomolecular domain. Mol-Instructions encompasses three key components: molecule-oriented instructions, protein-oriented instructions, and biomolecular text instructions. Each component aims to improve the understanding and prediction capabilities of LLMs concerning biomolecular features and behaviors. Through extensive instruction tuning experiments on LLMs, we demonstrate the effectiveness of Mol-Instructions in enhancing large models' performance in the intricate realm of biomolecular studies, thus fostering progress in the biomolecular research community. Mol-Instructions is publicly available for ongoing research and will undergo regular updates to enhance its applicability (https://github.com/zjunlp/Mol-Instructions).",
    "keywords": "instruction dataset, large language models, biomolecular studies, molecule, protein",
    "pdf_url": "https://openreview.net/pdf?id=Tlsdsb6l9n",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper introduces Mol-Instructions, an instruction dataset specifically for biomolecular studies, covering molecule-oriented and protein-oriented tasks as well as biomolecular text. It aims to improve LLM understanding of “biomolecular features and behaviors,” directly aligning with biomedicine AI applications such as molecular modeling, protein analysis, and drug discovery.",
    "prompt_tokens": 20734,
    "completion_tokens": 139,
    "total_tokens": 20873,
    "topic": "Bioinformatics - Task-specific Instruction Tuning",
    "method": "Instruction tuning; Large Language Models",
    "application": "Molecular property prediction; Protein function prediction",
    "code_link": "https://github.com/zjunlp/Mol-Instructions",
    "dataset_name": [
      "Mol-Instructions",
      "PubChem",
      "USSPO 500MT",
      "UniProtKB",
      "MedMCQA",
      "BC4CHEMD",
      "USPTO"
    ]
  },
  {
    "id": "j8hdRqOUhN",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Solving Inverse Problems with Latent Diffusion Models via Hard Data Consistency",
    "authors": [
      "Bowen Song",
      "Soo Min Kwon",
      "Zecheng Zhang",
      "Xinyu Hu",
      "Qing Qu",
      "Liyue Shen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Latent diffusion models have been demonstrated to generate high-quality images, while offering efficiency in model training compared to diffusion models operating in the pixel space. However, incorporating latent diffusion models to solve inverse problems remains a challenging problem due to the nonlinearity of the encoder and decoder. To address these issues, we propose ReSample, an algorithm that can solve general inverse problems with pre-trained latent diffusion models. Our algorithm incorporates data consistency by solving an optimization problem during the reverse sampling process, a concept that we term as hard data consistency. Upon solving this optimization problem, we propose a novel resampling scheme to map the measurement-consistent sample back onto the noisy data manifold and theoretically demonstrate its benefits. Lastly, we apply our algorithm to solve a wide range of linear and nonlinear inverse problems in both natural and medical images, demonstrating that our approach outperforms existing state-of-the-art approaches, including those based on pixel-space diffusion models.",
    "keywords": "Diffusion models, inverse problems",
    "pdf_url": "https://openreview.net/pdf?id=j8hdRqOUhN",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the paper develops a general latent diffusion approach for inverse problems, it explicitly states that the method is applied to “a wide range of linear and nonlinear inverse problems in both natural and medical images.” Solving inverse problems in medical images (e.g., CT or MRI reconstruction) is a core Healthcare AI task (medical imaging reconstruction). Therefore, this work falls within the Healthcare AI domain.",
    "prompt_tokens": 21110,
    "completion_tokens": 100,
    "total_tokens": 21210,
    "topic": "Medical Imaging - CT Reconstruction",
    "method": "Latent Diffusion Models (LDM); Resampling with hard data consistency",
    "application": "CT reconstruction",
    "code_link": "https://github.com/soominkwon/resample",
    "dataset_name": [
      "AAPM LDCT"
    ]
  },
  {
    "id": "PoDkdFQIu3",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "A Linear Algebraic Framework for Counterfactual Generation",
    "authors": [
      "Jong-Hoon Ahn",
      "Akshay Vashist"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Estimating individual treatment effects in clinical data is essential for understanding how different patients uniquely respond to treatments and identifying the most effective interventions for specific patient subgroups, thereby enhancing the precision and personalization of healthcare. However, counterfactual data are not accessible, and the true calculation of causal effects cannot be performed at the individual level. This paper proposes a linear algebraic framework to generate counterfactual longitudinal data that exactly matches pre-treatment factual data. Because causation travels forward in time, not in reverse, counterfactual predictability is further strengthened by blocking causal effects from flowing back to the past, thus limiting counterfactual dependence on the future. Using simulated LDL cholesterol datasets, we show that our method significantly outperforms the most cited methods of counterfactual generation. We also provide a formula that can estimate the time-varying variance of individual treatment effects, interpreted as a confidence level in the generated counterfactuals compared to true values.",
    "keywords": "counterfactual generation, individual treatment effect, synthetic data, Gaussian mixture model",
    "pdf_url": "https://openreview.net/pdf?id=PoDkdFQIu3",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly targets “individual treatment effects in clinical data” for “precision and personalization of healthcare” and evaluates on “simulated LDL cholesterol datasets,” making it directly relevant to Healthcare AI through causal inference in a medical context.",
    "prompt_tokens": 20818,
    "completion_tokens": 95,
    "total_tokens": 20913,
    "topic": "Causal Inference - Counterfactual Generation",
    "method": "Gaussian Mixture Model; Synthetic Control",
    "application": "Individual treatment effect estimation",
    "code_link": "N/A",
    "dataset_name": [
      "Simulated LDL cholesterol dataset",
      "California cigarette consumption data"
    ]
  },
  {
    "id": "ztpy1gsUpT",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
    "authors": [
      "Xinlu Zhang",
      "Shiyang Li",
      "Xianjun Yang",
      "Chenxin Tian",
      "Yao Qin",
      "Linda Ruth Petzold"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
    "keywords": "natural language processing, large language model prompting, application in healthcare, privacy",
    "pdf_url": "https://openreview.net/pdf?id=ztpy1gsUpT",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**:",
    "prompt_tokens": 20674,
    "completion_tokens": 124,
    "total_tokens": 20798,
    "topic": "Medical NLP - Context Integration",
    "method": "Keyword-based LLM prompting; Fine-tuning SLMs",
    "application": "Medical question answering – Privacy-restricted scenarios",
    "code_link": "https://github.com/XZhang97666/PrivacyBoost-SLM",
    "dataset_name": [
      "MedQA",
      "HEADQA",
      "MedMCQA",
      "MMLU - professional medicine"
    ]
  },
  {
    "id": "jJCeMiwHdH",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "BioBridge: Bridging Biomedical Foundation Models via Knowledge Graphs",
    "authors": [
      "Zifeng Wang",
      "Zichen Wang",
      "Balasubramaniam Srinivasan",
      "Vassilis N. Ioannidis",
      "Huzefa Rangwala",
      "RISHITA ANUBHAI"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Foundation models (FMs) learn from large volumes of unlabeled data to demonstrate superior performance across a wide range of tasks. However, FMs developed for biomedical domains have largely remained unimodal, i.e., independently trained and used for tasks on protein sequences alone, small molecule structures alone, or clinical data alone.\nTo overcome this limitation, we present BioBridge, a parameter-efficient learning framework, to bridge independently trained unimodal FMs to establish multimodal behavior. BioBridge achieves it by utilizing Knowledge Graphs (KG) to learn transformations between one unimodal FM and another without fine-tuning any underlying unimodal FMs.\nOur results demonstrate that BioBridge can\nbeat the best baseline KG embedding methods (on average by ~ 76.3%) in cross-modal retrieval tasks. We also identify BioBridge demonstrates out-of-domain generalization ability by extrapolating to unseen modalities or relations. Additionally, we also show that BioBridge presents itself as a general-purpose retriever that can aid biomedical multimodal question answering as well as enhance the guided generation of novel drugs. Code is at https://github.com/RyanWangZf/BioBridge.",
    "keywords": "drug discovery, foundation model, multi-modal learning, knowledge graph",
    "pdf_url": "https://openreview.net/pdf?id=jJCeMiwHdH",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper centers on “drug discovery,” “protein sequences,” “small molecule structures,” and “clinical data,” all core to biomedical research. It develops a framework (BioBridge) to tie together unimodal biomedical foundation models via a knowledge graph. The explicit references to drug discovery and molecular/clinical modalities confirm its placement in the Biomedicine AI domain.",
    "prompt_tokens": 19355,
    "completion_tokens": 122,
    "total_tokens": 19477,
    "topic": "Bioinformatics - Cross-modal Knowledge Representation",
    "method": "Contrastive learning; Knowledge graph embedding; Modality-specific transformation",
    "application": "Cross-modality prediction and retrieval",
    "code_link": "https://github.com/RyanWangZf/BioBridge",
    "dataset_name": [
      "PrimeKG",
      "MGI",
      "HPO",
      "SHS27K",
      "SHS148K"
    ]
  },
  {
    "id": "ZYm1Ql6udy",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Bayesian Bi-clustering of Neural Spiking Activity with Latent Structures",
    "authors": [
      "Ganchao Wei"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Modern neural recording techniques allow neuroscientists to obtain spiking activity of multiple neurons from different brain regions over long time periods, which requires new statistical methods to be developed for understanding structure of the large-scale data. In this paper, we develop a bi-clustering method to cluster the neural spiking activity spatially and temporally, according to their low-dimensional latent structures. The spatial (neuron) clusters are defined by the latent trajectories within each neural population, while the temporal (state) clusters are defined by (populationally) synchronous local linear dynamics shared with different periods. To flexibly extract the bi-clustering structure, we build the model non-parametrically, and develop an efficient Markov chain Monte Carlo (MCMC) algorithm to sample the posterior distributions of model parameters. Validating our proposed MCMC algorithm through simulations, we find the method can recover unknown parameters and true bi-clustering structures successfully. We then apply the proposed bi-clustering method to multi-regional neural recordings under different experiment settings, where we find that simultaneously considering latent trajectories and spatial-temporal clustering structures can provide us with a more accurate and interpretable result. Overall, the proposed method provides scientific insights for large-scale (counting) time series with elongated recording periods, and it can potentially have application beyond neuroscience.",
    "keywords": "neural spikes, spatio-temporal statistics, Bayesian nonparametric, bi-clustering",
    "pdf_url": "https://openreview.net/pdf?id=ZYm1Ql6udy",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on modeling neural spiking activity and multi‐regional neural recordings (“spatial (neuron) clusters… temporal (state) clusters… latent trajectories within each neural population”), which falls squarely in the domain of neuroscience or neurobiological modeling—a recognized subfield of Biomedicine AI. There is no mention of purely engineering or generic time-series analysis; instead, the application is explicitly on brain activity data, making it relevant to Biomedicine AI.",
    "prompt_tokens": 20701,
    "completion_tokens": 127,
    "total_tokens": 20828,
    "topic": "Neuroscience - Neural Activity Clustering",
    "method": "Bi-clustering model; Bayesian inference; Markov Chain Monte Carlo (MCMC); Negative Binomial dynamic generalized linear model (NB-DGLM)",
    "application": "Neural spike clustering – multi-region brain recordings",
    "code_link": "https://github.com/weigcdsb/bi_clustering",
    "dataset_name": [
      "Allen Institute Visual Coding Neuropixels"
    ]
  },
  {
    "id": "uwO71a8wET",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Bayesian Neural Controlled Differential Equations for Treatment Effect Estimation",
    "authors": [
      "Konstantin Hess",
      "Valentyn Melnychuk",
      "Dennis Frauen",
      "Stefan Feuerriegel"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Treatment effect estimation in continuous time is crucial for personalized medicine. However, existing methods for this task are limited to point estimates of the potential outcomes, whereas uncertainty estimates have been ignored. Needless to say, uncertainty quantification is crucial for reliable decision-making in medical applications. To fill this gap, we propose a novel Bayesian neural controlled differential equation (BNCDE) for treatment effect estimation in continuous time. In our BNCDE, the time dimension is modeled through a coupled system of neural controlled differential equations and neural stochastic differential equations, where the neural stochastic differential equations allow for tractable variational Bayesian inference. Thereby, for an assigned sequence of treatments, our BNCDE provides meaningful posterior predictive distributions of the potential outcomes. To the best of our knowledge, ours is the first tailored neural method to provide uncertainty estimates of treatment effects in continuous time. As such, our method is of direct practical value for promoting reliable decision-making in medicine.",
    "keywords": "treatment effect estimation, neural differential equation, variational Bayes, medicine",
    "pdf_url": "https://openreview.net/pdf?id=uwO71a8wET",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “treatment effect estimation in continuous time” and explicitly mentions its application to “personalized medicine” and “medical applications.” It develops a Bayesian neural CDE model to provide uncertainty quantification for potential outcomes under different treatment sequences—clearly aimed at clinical decision‐making and reliable treatment planning. Therefore, it falls squarely within Healthcare AI.",
    "prompt_tokens": 20978,
    "completion_tokens": 124,
    "total_tokens": 21102,
    "topic": "Causal Inference - Treatment Effect Estimation",
    "method": "Bayesian Neural Controlled Differential Equations; Neural Stochastic Differential Equations",
    "application": "Treatment effect estimation – continuous time",
    "code_link": "https://github.com/konstantinhess/Bayesian-Neural-CDE",
    "dataset_name": [
      "MIMIC-III",
      "eICU",
      "Salzburg Intensive Care Database"
    ]
  },
  {
    "id": "zMPHKOmQNb",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Protein Discovery with Discrete Walk-Jump Sampling",
    "authors": [
      "Nathan C. Frey",
      "Dan Berenberg",
      "Karina Zadorozhny",
      "Joseph Kleinhenz",
      "Julien Lafrance-Vanasse",
      "Isidro Hotzel",
      "Yan Wu",
      "Stephen Ra",
      "Richard Bonneau",
      "Kyunghyun Cho",
      "Andreas Loukas",
      "Vladimir Gligorijevic",
      "Saeed Saremi"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We resolve difficulties in training and sampling from a discrete generative model by learning a smoothed energy function, sampling from the smoothed data manifold with Langevin Markov chain Monte Carlo (MCMC), and projecting back to the true data manifold with one-step denoising. Our $\\textit{Discrete Walk-Jump Sampling}$ formalism combines the contrastive divergence training of an energy-based model and improved sample quality of a score-based model, while simplifying training and sampling by requiring only a single noise level. We evaluate the robustness of our approach on generative modeling of antibody proteins and introduce the $\\textit{distributional conformity score}$ to benchmark protein generative models. By optimizing and sampling from our models for the proposed distributional conformity score, 97-100\\% of generated samples are successfully expressed and purified and 70\\% of functional designs show equal or improved binding affinity compared to known functional antibodies on the first attempt in a single round of laboratory experiments. We also report the first demonstration of long-run fast-mixing MCMC chains where diverse antibody protein classes are visited in a single MCMC chain.",
    "keywords": "generative modeling, langevin mcmc, energy-based models, score-based models, protein design, protein discovery",
    "pdf_url": "https://openreview.net/pdf?id=zMPHKOmQNb",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on generative modeling for antibody proteins, introducing methods for “protein discovery” and “protein design” with laboratory validation (expression, purification, binding affinity). These are core tasks in drug discovery and biomedicine, specifically involving antibodies, which places it squarely in the Biomedicine AI domain.",
    "prompt_tokens": 20784,
    "completion_tokens": 116,
    "total_tokens": 20900,
    "topic": "Bioinformatics - Antibody Design",
    "method": "Energy-based models; generative modeling; discrete Walk-Jump Sampling (dWJS)",
    "application": "Therapeutic antibody design",
    "code_link": "https://github.com/prescient-design/walk-jump",
    "dataset_name": [
      "Mason Antibody Dataset",
      "Paired Observed Antibody Space"
    ]
  },
  {
    "id": "tVTN7Zs0ml",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "GraphCare: Enhancing Healthcare Predictions with Personalized Knowledge Graphs",
    "authors": [
      "Pengcheng Jiang",
      "Cao Xiao",
      "Adam Richard Cross",
      "Jimeng Sun"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Clinical predictive models often rely on patients’ electronic health records (EHR), but integrating medical knowledge to enhance predictions and decision-making is challenging. This is because personalized predictions require personalized knowledge\ngraphs (KGs), which are difficult to generate from patient EHR data. To address this, we propose GraphCare, an open-world framework that uses external KGs to improve EHR-based predictions. Our method extracts knowledge from large language models (LLMs) and external biomedical KGs to build patient-specific KGs, which are then used to train our proposed Bi-attention AugmenTed\n(BAT) graph neural network (GNN) for healthcare predictions. On two public datasets, MIMIC-III and MIMIC-IV, GraphCare surpasses baselines in four vital healthcare prediction tasks: mortality, readmission, length of stay (LOS), and drug recommendation. On MIMIC-III, it boosts AUROC by 17.6% and 6.6% for mortality and readmission, and F1-score by 7.9% and 10.8% for LOS and drug recommendation, respectively. Notably, GraphCare demonstrates a substantial edge in scenarios with limited data availability. Our findings highlight the potential of using external KGs in healthcare prediction tasks and demonstrate the promise of GraphCare in generating personalized KGs for promoting personalized medicine.",
    "keywords": "EHR Prediction, Personalized Knowledge Graph, Graph Neural Network",
    "pdf_url": "https://openreview.net/pdf?id=tVTN7Zs0ml",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on clinical prediction tasks using patients’ electronic health records (EHR) and external biomedical knowledge graphs. It evaluates on MIMIC-III and MIMIC-IV datasets for healthcare outcomes such as mortality, readmission, length of stay, and drug recommendation—clear indicators of a Healthcare AI application.",
    "prompt_tokens": 20605,
    "completion_tokens": 134,
    "total_tokens": 20739,
    "topic": "EHR - Personalized Knowledge Graphs",
    "method": "Knowledge graph extraction and generation using LLM prompts; Bi-attention augmented Graph Neural Networks (GNN)",
    "application": "Predictive healthcare tasks – mortality prediction, readmission prediction, length-of-stay (LOS) prediction, drug recommendation",
    "code_link": "https://github.com/pat-jj/GraphCare",
    "dataset_name": [
      "MIMIC-III",
      "MIMIC-IV"
    ]
  },
  {
    "id": "oMLQB4EZE1",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species Genomes",
    "authors": [
      "Zhihan Zhou",
      "Yanrong Ji",
      "Weijian Li",
      "Pratik Dutta",
      "Ramana V Davuluri",
      "Han Liu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Decoding the linguistic intricacies of the genome is a crucial problem in biology, and pre-trained foundational models such as DNABERT and Nucleotide Transformer have made significant strides in this area. Existing works have largely hinged on k-mer, fixed-length permutations of A, T, C, and G, as the token of the genome language due to its simplicity. However, we argue that the computation and sample inefficiencies introduced by k-mer tokenization are primary obstacles in developing large genome foundational models. We provide conceptual and empirical insights into genome tokenization, building on which we propose to replace k-mer tokenization with Byte Pair Encoding (BPE), a statistics-based data compression algorithm that constructs tokens by iteratively merging the most frequent co-occurring genome segment in the corpus. We demonstrate that BPE not only overcomes the limitations of k-mer tokenization but also benefits from the computational efficiency of non-overlapping tokenization.\nBased on these insights, we introduce DNABERT-2, a refined genome foundation model that adapts an efficient tokenizer and employs multiple strategies to overcome input length constraints, reduce time and memory expenditure, and enhance model capability. Furthermore, we identify the absence of a comprehensive and standardized benchmark for genome understanding as another significant impediment to fair comparative analysis. In response, we propose the Genome Understanding Evaluation (GUE), a comprehensive multi-species genome classification dataset that amalgamates $36$ distinct datasets across $9$ tasks, with input lengths ranging from $70$ to $10000$. Through comprehensive experiments on the GUE benchmark, we demonstrate that DNABERT-2 achieves comparable performance to the state-of-the-art model with $21 \\times$ fewer parameters and approximately $92 \\times$ less GPU time in pre-training. \nCompared to DNABERT, while being $3 \\times$ more efficient, DNABERT-2 outperforms it on $23$ out of $28$ datasets, with an average improvement of $6$ absolute scores on GUE.\nThe code, data, and pre-trained model are available at \\url{https://github.com/MAGICS-LAB/DNABERT_2}.",
    "keywords": "DNA, Genome, Language Model, Foundation Model, Benchmark",
    "pdf_url": "https://openreview.net/pdf?id=oMLQB4EZE1",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work develops large‐scale language models for DNA (“genome tokenization,” “multi‐species genomes,” “DNABERT‐2”), focusing on genomic sequence modeling and classification. Genomics is a core subfield of Biomedicine AI (molecular‐level data analysis of genes), so this paper falls squarely in the Biomedicine AI domain.",
    "prompt_tokens": 20809,
    "completion_tokens": 141,
    "total_tokens": 20950,
    "topic": "Bioinformatics - Genome Analysis",
    "method": "Transformer-based models; Byte Pair Encoding; Attention with Linear Biases (ALiBi)",
    "application": "Genome classification and functional understanding",
    "code_link": "https://github.com/MAGICS-LAB/DNABERT_2",
    "dataset_name": [
      "GUE Benchmark",
      "GUE+ Benchmark",
      "EpiCoV database",
      "ENCODE ChIP-seq",
      "Eukaryotic Promoter Database",
      "GenBank"
    ]
  },
  {
    "id": "pC3WJHf51j",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Large-scale Training of Foundation Models for Wearable Biosignals",
    "authors": [
      "Salar Abbaspourazad",
      "Oussama Elachqar",
      "Andrew Miller",
      "Saba Emrani",
      "Udhyakumar Nallasamy",
      "Ian Shapiro"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Tracking biosignals is crucial for monitoring wellness and preempting the development of severe medical conditions. Today, wearable devices can conveniently record various biosignals, creating the opportunity to monitor health status without disruption to one's daily routine. Despite widespread use of wearable devices and existing digital biomarkers, the absence of curated data with annotated medical labels hinders the development of new biomarkers to measure common health conditions. In fact, medical datasets are usually small in comparison to other domains, which is an obstacle for developing neural network models for biosignals. To address this challenge, we have employed self-supervised learning using the unlabeled sensor data collected under informed consent from the large longitudinal Apple Heart and Movement Study (AHMS) to train foundation models for two common biosignals: photoplethysmography (PPG) and electrocardiogram (ECG) recorded on Apple Watch. We curated PPG and ECG datasets from AHMS that include data from ${\\sim} 141$K participants spanning ${\\sim} 3$ years. Our self-supervised learning framework includes participant level positive pair selection, stochastic augmentation module and a regularized contrastive loss optimized with momentum training, and generalizes well to both PPG and ECG modalities. We show that the pre-trained foundation models readily encode information regarding participants' demographics and health conditions. To the best of our knowledge, this is the first study that builds foundation models using large-scale PPG and ECG data collected via wearable consumer devices $\\textendash$ prior works have commonly used smaller-size datasets collected in clinical and experimental settings. We believe PPG and ECG foundation models can enhance future wearable devices by reducing the reliance on labeled data and hold the potential to help the users improve their health.",
    "keywords": "Self-supervised learning, Representation learning, Foundation models, Biosignals, Wearable devices, Health, Photoplethysmography, PPG, Electrocardiogram, ECG",
    "pdf_url": "https://openreview.net/pdf?id=pC3WJHf51j",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on self-supervised learning of PPG and ECG biosignals collected from consumer wearables (Apple Watch) to monitor wellness and preempt medical conditions. It explicitly targets “tracking biosignals… for monitoring wellness and preempting the development of severe medical conditions,” leverages digital biomarkers, and uses time-series ECG/PPG data from the Apple Heart and Movement Study. These are core components of wearable-based health monitoring and clinical biosignal analysis, classifying it as Healthcare AI.",
    "prompt_tokens": 20918,
    "completion_tokens": 97,
    "total_tokens": 21015,
    "topic": "Wearables - Self-supervised Learning",
    "method": "Self-supervised learning; contrastive learning; momentum training",
    "application": "Demographic and health condition prediction",
    "code_link": "N/A",
    "dataset_name": [
      "Apple Heart and Movement Study (AHMS)"
    ]
  },
  {
    "id": "6cFcw1Rxww",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Local Search GFlowNets",
    "authors": [
      "Minsu Kim",
      "Taeyoung Yun",
      "Emmanuel Bengio",
      "Dinghuai Zhang",
      "Yoshua Bengio",
      "Sungsoo Ahn",
      "Jinkyoo Park"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Generative Flow Networks (GFlowNets) are amortized sampling methods that learn a distribution over discrete objects proportional to their rewards. GFlowNets exhibit a remarkable ability to generate diverse samples, yet occasionally struggle to consistently produce samples with high rewards due to over-exploration on wide sample space. \nThis paper proposes to train GFlowNets with local search, which focuses on exploiting high-rewarded sample space to resolve this issue. Our main idea is to explore the local neighborhood via backtracking and reconstruction guided by backward and forward policies, respectively. This allows biasing the samples toward high-reward solutions, which is not possible for a typical GFlowNet solution generation scheme, which uses the forward policy to generate the solution from scratch. Extensive experiments demonstrate a remarkable performance improvement in several biochemical tasks. Source code is available: \\url{https://github.com/dbsxodud-11/ls_gfn}.",
    "keywords": "GFlowNet, molecule optimization, biological sequence design, local search, reinforcement learning",
    "pdf_url": "https://openreview.net/pdf?id=6cFcw1Rxww",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper’s keywords and abstract focus on “molecule optimization” and “biological sequence design,” and it reports experiments on “several biochemical tasks.” These topics—designing molecules and biological sequences—are central to drug discovery and protein engineering in the biomedicine domain.",
    "prompt_tokens": 21032,
    "completion_tokens": 140,
    "total_tokens": 21172,
    "topic": "Scientific Discovery - Molecule and Sequence Design",
    "method": "Local search; GFlowNet",
    "application": "Mode discovery for biochemical optimization and sequence design",
    "code_link": "https://github.com/dbsxodud-11/ls_gfn",
    "dataset_name": [
      "QM9",
      "TFBind8",
      "L14-RNA1",
      "L14-RNA2",
      "L14-RNA3",
      "sEH"
    ]
  },
  {
    "id": "k581sTMyPt",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Diagnosing Transformers: Illuminating Feature Spaces for Clinical Decision-Making",
    "authors": [
      "Aliyah R. Hsu",
      "Yeshwanth Cherapanamjeri",
      "Briton Park",
      "Tristan Naumann",
      "Anobel Odisho",
      "Bin Yu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Pre-trained transformers are often fine-tuned to aid clinical decision-making using limited clinical notes. Model interpretability is crucial, especially in high-stakes domains like medicine, to establish trust and ensure safety, which requires human engagement. We introduce SUFO, a systematic framework that enhances interpretability of fine-tuned transformer feature spaces. SUFO utilizes a range of analytic and visualization techniques, including Supervised probing, Unsupervised similarity analysis, Feature dynamics, and Outlier analysis to address key questions about model trust and interpretability (e.g. model suitability for a task, feature space evolution during fine-tuning, and interpretation of fine-tuned features and failure modes). We conduct a case study investigating the impact of pre-training data where we focus on real-world pathology classification tasks, and validate our findings on MedNLI. We evaluate five 110M-sized pre-trained transformer models, categorized into general-domain (BERT, TNLR), mixed-domain (BioBERT, Clinical BioBERT), and domain-specific (PubMedBERT) groups. Our SUFO analyses reveal that: (1) while PubMedBERT, the domain-specific model, contains valuable information for fine-tuning, it can overfit to minority classes when class imbalances exist. In contrast, mixed-domain models exhibit greater resistance to overfitting, suggesting potential improvements in domain-specific model robustness; (2) in-domain pre-training accelerates feature disambiguation during fine-tuning; and (3) feature spaces undergo significant sparsification during this process, enabling clinicians to identify common outlier modes among fine-tuned models as demonstrated in this paper. These findings showcase the utility of SUFO in enhancing trust and safety when using transformers in medicine, and we believe SUFO can aid practitioners in evaluating fine-tuned language models (LMs) for other applications in medicine and in more critical domains.",
    "keywords": "fine-tuning, transformer-based language models, feature analysis, interpretation, clinical classification",
    "pdf_url": "https://openreview.net/pdf?id=k581sTMyPt",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on fine-tuning transformer models for “clinical decision-making” using “limited clinical notes,” evaluates on pathology classification tasks, and validates findings on the MedNLI dataset (a medical natural language inference benchmark). These are all clear indicators of a Healthcare AI application.",
    "prompt_tokens": 20583,
    "completion_tokens": 114,
    "total_tokens": 20697,
    "topic": "Clinical NLP - Pathology Analysis",
    "method": "Transformers; Representational Similarity Analysis (RSA); Supervised Probing; Feature Dynamics",
    "application": "clinical classification – pathology notes",
    "code_link": "https://github.com/adelaidehsu/path_model_evaluation",
    "dataset_name": [
      "Prostate Cancer Pathology Reports",
      "MedNLI"
    ]
  },
  {
    "id": "X41c4uB4k0",
    "year": 2024,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Training-free Multi-objective Diffusion Model for 3D Molecule Generation",
    "authors": [
      "Xu Han",
      "Caihua Shan",
      "Yifei Shen",
      "Can Xu",
      "Han Yang",
      "Xiang Li",
      "Dongsheng Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Searching for novel and diverse molecular candidates is a critical undertaking in drug and material discovery. Existing approaches have successfully adapted the diffusion model, the most effective generative model in image generation, to create 1D SMILES strings, 2D chemical graphs, or 3D molecular conformers. However, these methods are not efficient and flexible enough to generate 3D molecules with multiple desired properties, as they require additional training for the models for each new property or even a new combination of existing properties. Moreover, some properties may potentially conflict, making it impossible to find a molecule that satisfies all of them simultaneously. To address these challenges, we present a training-free conditional 3D molecular generation algorithm based on off-the-shelf unconditional diffusion models and property prediction models. The key techniques include modeling the loss of property prediction models as energy functions, considering the property relation between multiple conditions as a probabilistic graph, and developing a stable posterior estimation for computing the conditional score function. We conducted experiments on both single-objective and multi-objective 3D molecule generation, focusing on quantum properties, and compared our approach with the trained or fine-tuned diffusion models. Our proposed model achieves superior performance in generating molecules that meet the conditions, without any additional training cost.",
    "keywords": "Multi-objective Diffusion Model, 3D Molecule",
    "pdf_url": "https://openreview.net/pdf?id=X41c4uB4k0",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on 3D molecule generation for “drug and material discovery,” explicitly targeting molecular candidate design with desirable properties. Generative models for molecular design fall squarely under AI-driven drug discovery, a core Biomedicine AI application.",
    "prompt_tokens": 20567,
    "completion_tokens": 90,
    "total_tokens": 20657,
    "topic": "Drug Discovery - Molecular Generation",
    "method": "Diffusion model; Monte Carlo sampling; Posterior approximation",
    "application": "3D molecule generation with desired quantum properties",
    "code_link": "N/A",
    "dataset_name": [
      "QM9"
    ]
  },
  {
    "id": "fv9XU7CyN2",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "CL-MFAP: A Contrastive Learning-Based Multimodal Foundation Model for Molecular Property Prediction and Antibiotic Screening",
    "authors": [
      "Gen Zhou",
      "Sugitha Janarthanan",
      "Yutong Lu",
      "Pingzhao Hu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Due to the rise in antimicrobial resistance, identifying novel compounds with antibiotic potential is crucial for combatting this global health issue. However, traditional drug development methods are costly and inefficient. Recognizing the pressing need for more effective solutions, researchers have turned to machine learning techniques to streamline the prediction and development of novel antibiotic compounds. While foundation models have shown promise in antibiotic discovery, current mainstream efforts still fall short of fully leveraging the potential of multimodal molecular data. Recent studies suggest that contrastive learning frameworks utilizing multimodal data exhibit excellent performance in representation learning across various domains. Building upon this, we introduce CL-MFAP, an unsupervised contrastive learning (CL)-based multimodal foundation (MF) model specifically tailored for discovering small molecules with potential antibiotic properties (AP) using three types of molecular data. This model employs 1.6 million bioactive molecules with drug-like properties from the ChEMBL dataset to jointly pretrain three encoders: (1) a transformer-based encoder with rotary position embedding for processing SMILES strings; (2) another transformer-based encoder, incorporating a novel bi-level routing attention mechanism to handle molecular graph representations; and (3) a Morgan fingerprint encoder using a multilayer perceptron, to achieve the contrastive learning purpose. The CL-MFAP outperforms baseline models in antibiotic property prediction by effectively utilizing different molecular modalities and demonstrates superior domain-specific performance when fine-tuned for antibiotic-related property prediction tasks.",
    "keywords": "Contrastive Learning, Multimodal Foundation Model, Antibiotic Property Prediction, Bi-level Routing Attention, Transformer",
    "pdf_url": "https://openreview.net/pdf?id=fv9XU7CyN2",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on drug discovery and antibiotic screening—core tasks in biomedical research. It develops a multimodal model for predicting molecular properties and identifying antibiotic candidates (“discovering small molecules with potential antibiotic properties”), uses a large bioactive molecule dataset (ChEMBL), and addresses “antimicrobial resistance,” all of which are clear indicators of a biomedicine AI application.",
    "prompt_tokens": 21046,
    "completion_tokens": 163,
    "total_tokens": 21209,
    "topic": "Drug Discovery - Antibiotic Prediction",
    "method": "Contrastive learning; multimodal foundation models; transformer encoder",
    "application": "Antibiotic property prediction",
    "code_link": "https://github.com/CLMFAP/CLMFAP",
    "dataset_name": [
      "ChEMBL",
      "ZINC250k",
      "Blood-Brain Barrier Penetration (BBBP)",
      "Parallel Artificial Membrane Permeability Assay (PAMPA)",
      "Bioavailability"
    ]
  },
  {
    "id": "gHLWTzKiZV",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Composing Unbalanced Flows for Flexible Docking and Relaxation",
    "authors": [
      "Gabriele Corso",
      "Vignesh Ram Somnath",
      "Noah Getz",
      "Regina Barzilay",
      "Tommi Jaakkola",
      "Andreas Krause"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Diffusion models have emerged as a successful approach for molecular docking, but they often cannot model protein flexibility or generate nonphysical poses. We argue that both these challenges can be tackled by framing the problem as a transport between distributions. Still, existing paradigms lack the flexibility to define effective maps between such complex distributions. To address this limitation, we propose Unbalanced Flow Matching, a generalization of Flow Matching (FM) that allows trading off sample efficiency with approximation accuracy and enables more accurate transport. Empirically, we apply Unbalanced FM on flexible docking and structure relaxation, demonstrating our ability to model protein flexibility and generate energetically favorable poses. On the PDBBind docking benchmark, our method FlexDock improves the docking performance while increasing the proportion of energetically favorable poses from 30% to 73%.",
    "keywords": "molecular docking, flow matching, structure relaxation, unbalanced transport",
    "pdf_url": "https://openreview.net/pdf?id=gHLWTzKiZV",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on molecular docking and structure relaxation—core techniques in drug discovery and molecular modeling (“molecular docking,” “protein flexibility,” “energetically favorable poses,” “PDBBind docking benchmark”). These tasks are fundamental to biomedical research aimed at identifying and optimizing protein–ligand interactions, placing this work squarely in the Biomedicine AI domain.",
    "prompt_tokens": 20700,
    "completion_tokens": 97,
    "total_tokens": 20797,
    "topic": "Drug Discovery - Docking",
    "method": "Unbalanced Flow Matching; generative docking models",
    "application": "Flexible protein-ligand docking",
    "code_link": "https://github.com/vsomnath/flexdock",
    "dataset_name": [
      "PDBBind",
      "PoseBusters"
    ]
  },
  {
    "id": "WwmtcGr4lP",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "GANDALF: Generative AttentioN based Data Augmentation and predictive modeLing Framework for personalized cancer treatment",
    "authors": [
      "Aishwarya Jayagopal",
      "Yanrong Zhang",
      "Robert John Walsh",
      "Tuan Zea Tan",
      "Anand D Jeyasekharan",
      "Vaibhav Rajan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Effective treatment of cancer is a major challenge faced by healthcare providers, due to the highly individualized nature of patient responses to treatment. This is caused by the heterogeneity seen in cancer-causing alterations (mutations) across patient genomes. Limited availability of response data in patients makes it difficult to train personalized treatment recommendation models on mutations from clinical genomic sequencing reports. Prior methods tackle this by utilising larger, labelled pre-clinical laboratory datasets (‘cell lines’), via transfer learning. These methods augment patient data by learning a shared, domain-invariant representation, between the cell line and patient domains, which is then used to train a downstream drug response prediction (DRP) model. This approach augments data in the shared space but fails to model patient-specific characteristics, which have a strong influence on their drug response. We propose a novel generative attention-based data augmentation and predictive modeling framework, GANDALF, to tackle this crucial shortcoming of prior methods. GANDALF not only augments patient genomic data directly, but also accounts for its domain-specific characteristics. GANDALF outperforms state-of-the-art DRP models on publicly available patient datasets and emerges as the front-runner amongst SOTA cancer DRP models.",
    "keywords": "personalized drug response prediction, cancer, genomic data augmentation, diffusion model, pseudolabelling",
    "pdf_url": "https://openreview.net/pdf?id=WwmtcGr4lP",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on personalized cancer treatment by predicting patient‐specific drug response using genomic data (“patient genomic data”, “clinical genomic sequencing reports”), a clear biomedical application. It proposes a generative attention–based augmentation framework for drug response prediction in oncology, directly aligning with biomedicine and healthcare AI tasks.",
    "prompt_tokens": 21013,
    "completion_tokens": 132,
    "total_tokens": 21145,
    "topic": "Drug Discovery - Genomic Data Augmentation",
    "method": "Generative models (diffusion models, VAE); transformers; multi-task learning",
    "application": "Drug response prediction – cancer genomics",
    "code_link": "https://github.com/ajayago/GANDALF",
    "dataset_name": [
      "Cancer Cell Line Encyclopedia (CCLE)",
      "GDSCv2",
      "TCGA",
      "CbioPortal",
      "Moores Cancer",
      "GENIE"
    ]
  },
  {
    "id": "Io9yFt7XH7",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "NeuroLM: A Universal Multi-task Foundation Model for Bridging the Gap between Language and EEG Signals",
    "authors": [
      "Weibang Jiang",
      "Yansen Wang",
      "Bao-liang Lu",
      "Dongsheng Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Recent advancements for large-scale pre-training with neural signals such as electroencephalogram (EEG) have shown promising results, significantly boosting the development of brain-computer interfaces (BCIs) and healthcare. However, these pre-trained models often require full fine-tuning on each downstream task to achieve substantial improvements, limiting their versatility and usability, and leading to considerable resource wastage. To tackle these challenges, we propose NeuroLM, the first multi-task foundation model that leverages the capabilities of Large Language Models (LLMs) by regarding EEG signals as a foreign language, endowing the model with multi-task learning and inference capabilities. Our approach begins with learning a text-aligned neural tokenizer through vector-quantized temporal-frequency prediction, which encodes EEG signals into discrete neural tokens. These EEG tokens, generated by the frozen vector-quantized (VQ) encoder, are then fed into an LLM that learns causal EEG information via multi-channel autoregression. Consequently, NeuroLM can understand both EEG and language modalities. Finally, multi-task instruction tuning adapts NeuroLM to various downstream tasks. We are the first to demonstrate that, by specific incorporation with LLMs, NeuroLM unifies diverse EEG tasks within a single model through instruction tuning. The largest variant NeuroLM-XL has record-breaking 1.7B parameters for EEG signal processing, and is pre-trained on a large-scale corpus comprising approximately 25,000-hour EEG data. When evaluated on six diverse downstream datasets, NeuroLM showcases the huge potential of this multi-task learning paradigm.",
    "keywords": "EEG, large language model, multi-task learning",
    "pdf_url": "https://openreview.net/pdf?id=Io9yFt7XH7",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on processing EEG signals—a key form of time-series biomedical data used in brain–computer interfaces (BCIs) and healthcare applications. It explicitly mentions improving “BCIs and healthcare” and deals with neural signal analysis, fitting squarely in the Healthcare/Neuroscience AI domain.",
    "prompt_tokens": 20897,
    "completion_tokens": 131,
    "total_tokens": 21028,
    "topic": "Neuroimaging - EEG Signal Processing",
    "method": "Vector-quantized temporal-frequency prediction; VQ-VAE; Multi-task instruction tuning",
    "application": "Unified multi-task learning for EEG signal analysis",
    "code_link": "https://github.com/935963004/NeuroLM",
    "dataset_name": [
      "TUAB",
      "TUEV",
      "SEED",
      "HMC",
      "Workload",
      "TUSL"
    ]
  },
  {
    "id": "i5MrJ6g5G1",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Simple Guidance Mechanisms for Discrete Diffusion Models",
    "authors": [
      "Yair Schiff",
      "Subham Sekhar Sahoo",
      "Hao Phung",
      "Guanghan Wang",
      "Sam Boshar",
      "Hugo Dalla-torre",
      "Bernardo P de Almeida",
      "Alexander M Rush",
      "Thomas PIERROT",
      "Volodymyr Kuleshov"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Diffusion models for continuous data gained widespread adoption owing to their high quality generation and control mechanisms. However, controllable diffusion on discrete data faces challenges given that continuous guidance methods do not directly apply to discrete diffusion. Here, we provide a straightforward derivation of classifier-free and classifier-based guidance for discrete diffusion, as well as a new class of diffusion models that leverage uniform noise and that are more guidable because they can continuously edit their outputs. We improve the quality of these models with a novel continuous-time variational lower bound that yields state-of-the-art performance, especially in settings involving guidance or fast generation. Empirically, we demonstrate that our guidance mechanisms combined with uniform noise diffusion improve controllable generation relative to autoregressive and diffusion baselines on several discrete data domains, including genomic sequences, small molecule design, and discretized image generation.",
    "keywords": "Discrete Diffusion, Guidance",
    "pdf_url": "https://openreview.net/pdf?id=i5MrJ6g5G1",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the paper primarily develops a general ML method (discrete diffusion with guidance), it explicitly evaluates on “genomic sequences” and “small molecule design,” both core tasks in biomedical research (e.g., genomics analysis and drug discovery). These domain‐specific applications indicate clear relevance to Biomedicine AI.",
    "prompt_tokens": 21272,
    "completion_tokens": 110,
    "total_tokens": 21382,
    "topic": "Drug Discovery - Small Molecules",
    "method": "Discrete diffusion models; Classifier-based guidance",
    "application": "Molecular property maximization – QED and ring count",
    "code_link": "N/A",
    "dataset_name": [
      "QM9",
      "Species10",
      "CIFAR10",
      "text8",
      "Amazon Review",
      "LM1B"
    ]
  },
  {
    "id": "5FXKgOxmb2",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "MAGNet: Motif-Agnostic Generation of Molecules from Scaffolds",
    "authors": [
      "Leon Hetzel",
      "Johanna Sommer",
      "Bastian Rieck",
      "Fabian J Theis",
      "Stephan Günnemann"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Recent advances in machine learning for molecules exhibit great potential for facilitating drug discovery from in silico predictions.\nMost models for molecule generation rely on the decomposition of molecules into frequently occurring substructures (motifs), from which they generate novel compounds. \nWhile motif representations greatly aid in learning molecular distributions, such methods fail to represent substructures beyond their known motif set, posing a fundamental limitation for discovering novel compounds.\nTo address this limitation and enhance structural expressivity, we propose to separate structure from features by abstracting motifs to scaffolds and, subsequently, allocating atom and bond types. \nTo this end, we introduce a novel factorisation of the molecules' data distribution that considers the entire molecular context and facilitates learning adequate assignments of atoms and bonds to scaffolds. Complementary to this, we propose MAGNet, the first model to freely learn motifs. Importantly, we demonstrate that MAGNet's improved expressivity leads to molecules with more structural diversity and, at the same time, diverse atom and bond assignments.",
    "keywords": "graph generative models, 2d molecules",
    "pdf_url": "https://openreview.net/pdf?id=5FXKgOxmb2",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on machine learning methods for generating novel molecular structures and explicitly mentions “facilitating drug discovery from in silico predictions.” Designing molecules for potential therapeutic applications places it squarely in the realm of Biomedicine AI, as it addresses a core task in biomedical research (drug discovery and molecular modeling).",
    "prompt_tokens": 21009,
    "completion_tokens": 116,
    "total_tokens": 21125,
    "topic": "Drug Discovery - Structure-based",
    "method": "Variational autoencoder; Graph transformer; Scaffold-based generation",
    "application": "Molecular graph generation",
    "code_link": "https://www.cs.cit.tum.de/daml/magnet",
    "dataset_name": [
      "ZINC",
      "QM9",
      "GuacaMol",
      "CheMBL",
      "L1000"
    ]
  },
  {
    "id": "YuHQTo6G9S",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Interpretable Bilingual Multimodal Large Language Model for Diverse Biomedical Tasks",
    "authors": [
      "Lehan Wang",
      "Haonan Wang",
      "Honglong Yang",
      "Jiaji Mao",
      "Zehong Yang",
      "Jun Shen",
      "Xiaomeng Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Several medical Multimodal Large Languange Models (MLLMs) have been developed to address tasks involving visual images with textual instructions across various medical modalities, achieving impressive results. \nMost current medical generalist models are region-agnostic, treating the entire image as a holistic representation. However, they struggle to identify which specific regions they are focusing on when generating a sentence.\nTo mimic the behavior of doctors, who typically begin by reviewing the entire image before concentrating on specific regions for a thorough evaluation, we aim to enhance the capability of medical MLLMs in understanding anatomical regions within entire medical scans.\nTo achieve it, we first formulate \\textbf{Region-Centric tasks} and construct a \\textbf{large-scale dataset, MedRegInstruct,} to incorporate regional information into training. Combining our collected dataset with other medical multimodal corpora for training, we propose a \\textbf{Region-Aware medical MLLM, MedRegA}, which is the first bilingual generalist medical AI system to simultaneously handle image-level and region-level medical vision-language tasks across a broad range of modalities. Our MedRegA not only enables three region-centric tasks, but also achieves the best performance for visual question answering, report generation and medical image classification over 8 modalities, showcasing significant versatility. Experiments demonstrate that our model can not only accomplish powerful performance across various medical vision-language tasks in bilingual settings, but also recognize and detect structures in multimodal medical scans, boosting the interpretability and user interactivity of medical MLLMs. The codes and model will be made publicly available.",
    "keywords": "Multimodal Large Language Model, Biomedicine, Region-Text",
    "pdf_url": "https://openreview.net/pdf?id=YuHQTo6G9S",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper develops a multimodal large language model specifically for medical imaging tasks—e.g., “visual question answering,” “report generation,” and “medical image classification” across multiple scan modalities. It explicitly targets medical vision-language applications, handling “image-level and region-level medical vision-language tasks” in clinical scans, which clearly situates it in the Healthcare/​Biomedicine AI domain.",
    "prompt_tokens": 20344,
    "completion_tokens": 140,
    "total_tokens": 20484,
    "topic": "Medical Imaging - Multimodal Region Recognition",
    "method": "Region-to-Text identification; Text-to-Region detection; Grounded Report Generation; Multimodal chain-of-thought reasoning",
    "application": "Grounded report generation",
    "code_link": "N/A",
    "dataset_name": [
      "MedRegInstruct",
      "Region-Text Dataset",
      "Report-Grounded Dataset",
      "MIMIC-CXR",
      "VinDr Series Dataset",
      "SA-Med2D-20M"
    ]
  },
  {
    "id": "KHkBpvmYVI",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "EVA: Geometric Inverse Design for Fast Protein Motif-Scaffolding with Coupled Flow",
    "authors": [
      "Yufei Huang",
      "Yunshu Liu",
      "Lirong Wu",
      "Haitao Lin",
      "Cheng Tan",
      "Odin Zhang",
      "Zhangyang Gao",
      "Siyuan Li",
      "Zicheng Liu",
      "Yunfan Liu",
      "Tailin Wu",
      "Stan Z. Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Motif-scaffolding is a fundamental component of protein design, which aims to construct the scaffold structure that stabilizes motifs conferring desired functions. Recent advances in generative models are promising for designing scaffolds, with two main approaches: training-based and sampling-based methods. Training-based methods are resource-heavy and slow, while training-free sampling-based methods are flexible but require numerous sampling steps and costly, unstable guidance. To speed up and improve sampling-based methods, we analyzed failure cases and found that errors stem from the trade-off between generation and guidance. Thus we proposed to exploit the spatial context and adjust the generative direction to be consistent with guidance to overcome this trade-off. Motivated by this, we formulate motif-scaffolding as a Geometric Inverse Design task inspired by the image inverse problem, and present Evolution-ViA-reconstruction (EVA), a novel sampling-based coupled flow framework on geometric manifolds, which starts with a pretrained flow-based generative model. EVA uses motif-coupled priors to leverage spatial contexts, guiding the generative process along a straighter probability path, with generative directions aligned with guidance in the early sampling steps. EVA is 70× faster than SOTA model RFDiffusion with competitive and even better performance on benchmark tests. Further experiments on real-world cases including vaccine design, multi-motif scaffolding and motif optimal placement searching demonstrate EVA's superior efficiency and effectiveness.",
    "keywords": "Generative Model, Protein Structure Generation, Training-free Conditional Generation",
    "pdf_url": "https://openreview.net/pdf?id=KHkBpvmYVI",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on protein motif‐scaffolding and generative design of protein structures, explicitly mentioning applications such as “vaccine design,” “multi‐motif scaffolding,” and “motif optimal placement searching.” Protein design and vaccine development are core tasks in biomedical research and drug discovery, making this work directly relevant to the Biomedicine AI domain.",
    "prompt_tokens": 20868,
    "completion_tokens": 91,
    "total_tokens": 20959,
    "topic": "Bioinformatics - Protein Design",
    "method": "Flow matching; geometric inverse design",
    "application": "Motif-scaffolding for protein design",
    "code_link": "N/A",
    "dataset_name": [
      "RFDiffusion benchmark dataset",
      "Vaccine design dataset"
    ]
  },
  {
    "id": "TXfzH933qV",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Reliable and Diverse Evaluation of LLM Medical Knowledge Mastery",
    "authors": [
      "Yuxuan Zhou",
      "Xien Liu",
      "Chen Ning",
      "Xiao Zhang",
      "Ji Wu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Mastering medical knowledge is crucial for medical-specific LLMs. However, despite the existence of medical benchmarks like MedQA, a unified framework that fully leverages existing knowledge bases to evaluate LLMs' mastery of medical knowledge is still lacking. We propose PretexEval, a novel framework that dynamically generates reliable and diverse test samples to evaluate LLMs for any given medical knowledge base. We notice that test samples produced directly from knowledge bases by templates or LLMs may introduce factual errors and also lack diversity. To address these issues, our framework employs predicate equivalence transformations to produce a series of variants for any given medical knowledge point. Finally, these produced predicate variants are converted into textual language, resulting in a series of reliable and diverse test samples. Here, we use our proposed framework to systematically investigate the mastery of medical factual knowledge of 12 well-known LLMs, based on two knowledge bases that are crucial for clinical diagnosis and treatment. The evaluation results illustrate that current LLMs still exhibit significant deficiencies in fully mastering medical knowledge, despite achieving considerable success on some famous public benchmarks. These new findings provide valuable insights for developing medical-specific LLMs, highlighting that current LLMs urgently need to strengthen their comprehensive and in-depth mastery of medical knowledge before being applied to real-world medical scenarios.",
    "keywords": "LLM Evaluation, Medical Evaluation, Large Language Model",
    "pdf_url": "https://openreview.net/pdf?id=TXfzH933qV",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper centers on evaluating large language models’ mastery of medical knowledge, explicitly referencing “medical-specific LLMs,” “medical benchmarks like MedQA,” and “knowledge bases that are crucial for clinical diagnosis and treatment.” This focus on medical facts, clinical diagnosis, and treatment planning places it squarely in the Healthcare AI domain.",
    "prompt_tokens": 21193,
    "completion_tokens": 100,
    "total_tokens": 21293,
    "topic": "Clinical NLP - Medical Evaluation Framework",
    "method": "Predicate-to-text transformation; prototype-based sample generation",
    "application": "Medical knowledge evaluation",
    "code_link": "https://github.com/THUMLP/PretexEval",
    "dataset_name": [
      "MedLAMA",
      "DiseK"
    ]
  },
  {
    "id": "4ktJJBvvUd",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Multi-objective antibody design with constrained preference optimization",
    "authors": [
      "Milong Ren",
      "ZaiKai He",
      "Haicang Zhang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Antibody design is crucial for developing therapies against diseases such as cancer and viral infections. Recent deep generative models have significantly advanced computational antibody design, particularly in enhancing binding affinity to target antigens. However, beyond binding affinity, antibodies should exhibit other favorable biophysical properties such as non-antigen binding specificity and low self-association, which are important for antibody developability and clinical safety. To address this challenge, we propose AbNovo, a framework that leverages constrained preference optimization for multi-objective antibody design. First, we pre-train an antigen-conditioned generative model for antibody structure and sequence co-design. Then, we fine-tune the model using binding affinity as a reward while enforcing explicit constraints on other biophysical properties. Specifically, we model the physical binding energy with continuous rewards rather than pairwise preferences and explore a primal-and-dual approach for constrained optimization. Additionally, we incorporate a structure-aware protein language model to mitigate the issue of limited training data. Evaluated on independent test sets, AbNovo outperforms existing methods in metrics of binding affinity such as Rosetta binding energy and evolutionary plausibility, as well as in metrics for other biophysical properties like stability and specificity.",
    "keywords": "antibody design, diffusion generative model, preference optimization",
    "pdf_url": "https://openreview.net/pdf?id=4ktJJBvvUd",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on computational design of therapeutic antibodies (“antibody design,” “binding affinity,” “biophysical properties,” “developability and clinical safety”), which falls squarely within drug discovery and protein engineering. These topics are core to Biomedicine AI, as they involve molecular modeling and generation of biologics for treating diseases.",
    "prompt_tokens": 21198,
    "completion_tokens": 104,
    "total_tokens": 21302,
    "topic": "Drug Discovery - Antibody Design",
    "method": "Constrained Preference Optimization; Structure-aware language model",
    "application": "Antibody sequence and structure co-design",
    "code_link": "https://github.com/CarbonMatrixLab/AbNovo",
    "dataset_name": [
      "SAbDab",
      "RAbD"
    ]
  },
  {
    "id": "s5epFPdIW6",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language Models",
    "authors": [
      "Peng Xia",
      "Kangyu Zhu",
      "Haoran Li",
      "Tianze Wang",
      "Weijia Shi",
      "Sheng Wang",
      "Linjun Zhang",
      "James Zou",
      "Huaxiu Yao"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Artificial Intelligence (AI) has demonstrated significant potential in healthcare, particularly in disease diagnosis and treatment planning. Recent progress in Medical Large Vision-Language Models (Med-LVLMs) has opened up new possibilities for interactive diagnostic tools. However, these models often suffer from factual hallucination, which can lead to incorrect diagnoses. Fine-tuning and retrieval-augmented generation (RAG) have emerged as methods to address these issues. However, the amount of high-quality data and distribution shifts between training data and deployment data limit the application of fine-tuning methods. Although RAG is lightweight and effective, existing RAG-based approaches are not sufficiently general to different medical domains and can potentially cause misalignment issues, both between modalities and between the model and the ground truth. In this paper, we propose a versatile multimodal RAG system, MMed-RAG, designed to enhance the factuality of Med-LVLMs. Our approach introduces a domain-aware retrieval mechanism, an adaptive retrieved contexts selection, and a provable RAG-based preference fine-tuning strategy. These innovations make the RAG process sufficiently general and reliable, significantly improving alignment when introducing retrieved contexts. Experimental results across five medical datasets (involving radiology, ophthalmology, pathology) on medical VQA and report generation demonstrate that MMed-RAG can achieve an average improvement of 43.8% in factual accuracy in the factual accuracy of Med-LVLMs.",
    "keywords": "medical vision-language model, retrieval-augmented generation",
    "pdf_url": "https://openreview.net/pdf?id=s5epFPdIW6",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on Medical Vision-Language Models (Med-LVLMs) for tasks like radiology, ophthalmology, and pathology, explicitly mentioning “disease diagnosis,” “treatment planning,” “medical VQA,” and “report generation.” These are core Healthcare AI applications in medical imaging and clinical decision support.",
    "prompt_tokens": 21195,
    "completion_tokens": 125,
    "total_tokens": 21320,
    "topic": "Medical Vision Language Models",
    "method": "RAG-based preference fine-tuning",
    "application": "Medical VQA and report generation",
    "code_link": "https://github.com/richard-peng-xia/MMed-RAG",
    "dataset_name": [
      "MIMIC-CXR",
      "IU-Xray",
      "Harvard-FairVLMed",
      "PMC-OA",
      "Quilt-1M"
    ]
  },
  {
    "id": "PSiijdQjNU",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Steering Protein Family Design through Profile Bayesian Flow",
    "authors": [
      "Jingjing Gong",
      "Yu Pei",
      "Siyu Long",
      "Yuxuan Song",
      "Zhe Zhang",
      "Wenhao Huang",
      "Ziyao Cao",
      "Shuyi Zhang",
      "Hao Zhou",
      "Wei-Ying Ma"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Protein family design emerges as a promising alternative by combining the advantages of de novo protein design and mutation-based directed evolution.In this paper, we propose ProfileBFN, the Profile Bayesian Flow Networks, for specifically generative modeling of protein families. ProfileBFN extends the discrete Bayesian Flow Network from an MSA profile perspective, which can be trained on single protein sequences by regarding it as a degenerate profile, thereby achieving efficient protein family design by avoiding large-scale MSA data construction and training. Empirical results show that ProfileBFN has a profound understanding of proteins. When generating diverse and novel family proteins, it can accurately capture the structural characteristics of the family. The enzyme produced by this method is more likely than the previous approach to have the corresponding function, offering better odds of generating diverse proteins with the desired functionality.",
    "keywords": "protein family generation, homologous protein generation, protein design, bayesian flow",
    "pdf_url": "https://openreview.net/pdf?id=PSiijdQjNU",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on generative modeling of protein families and enzyme design—core tasks in molecular-level biomedical research. It proposes “ProfileBFN” for “protein family generation,” “homologous protein generation,” and “protein design,” all of which are strong indicators of Biomedicine AI under “molecular modeling” and “protein design” for potential therapeutic or functional enzyme applications.",
    "prompt_tokens": 20943,
    "completion_tokens": 118,
    "total_tokens": 21061,
    "topic": "Bioinformatics - Protein Family Design",
    "method": "Bayesian Flow Networks; generative modeling",
    "application": "Family protein generation",
    "code_link": "N/A",
    "dataset_name": [
      "CAMEO",
      "enzyme families",
      "phage lysozyme families"
    ]
  },
  {
    "id": "i2r7LDjba3",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "ECHOPulse: ECG Controlled Echocardio-gram Video Generation",
    "authors": [
      "Yiwei Li",
      "Sekeun Kim",
      "Zihao Wu",
      "Hanqi Jiang",
      "Yi Pan",
      "Pengfei Jin",
      "Sifan Song",
      "Yucheng Shi",
      "Xiaowei Yu",
      "Tianze Yang",
      "Tianming Liu",
      "Quanzheng Li",
      "Xiang Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Echocardiography (ECHO) is essential for cardiac assessments, but its video quality and interpretation heavily relies on manual expertise, leading to inconsistent results from clinical and portable devices. ECHO video generation offers a solution by improving automated monitoring through synthetic data and generating high-quality videos from routine health data. However, existing models often face high computational costs, slow inference, and rely on complex conditional prompts that require experts' annotations. To address these challenges, we propose ECHOPulse, an ECG-conditioned ECHO video generation model. ECHOPulse introduces two key advancements: (1) it accelerates ECHO video generation by leveraging VQ-VAE tokenization and masked visual token modeling for fast decoding, and (2) it conditions on readily accessible ECG signals, which are highly coherent with ECHO videos, bypassing complex conditional prompts. To the best of our knowledge, this is the first work to use time-series prompts like ECG signals for ECHO video generation. ECHOPulse not only enables controllable synthetic ECHO data generation but also provides updated cardiac function information for disease monitoring and prediction beyond ECG alone. Evaluations on three public and private datasets demonstrate state-of-the-art performance in ECHO video generation across both qualitative and quantitative measures. Additionally, ECHOPulse can be easily generalized to other modality generation tasks, such as cardiac MRI, fMRI, and 3D CT generation. We will make the synthetic ECHO dataset, along with the code and model, publicly available upon acceptance.",
    "keywords": "Medical video generation, ECHO synthesis, Multimodality, Wearable device, Medical foundation model",
    "pdf_url": "https://openreview.net/pdf?id=i2r7LDjba3",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on generating echocardiogram (ECHO) videos conditioned on ECG signals for cardiac assessment and disease monitoring, explicitly addressing medical imaging, patient monitoring, and synthetic data for healthcare. Terms like “Echocardiography,” “ECG,” “cardiac function,” and “disease monitoring” directly place it in the Healthcare AI domain.",
    "prompt_tokens": 20755,
    "completion_tokens": 112,
    "total_tokens": 20867,
    "topic": "Medical Imaging - Cardiac Video Generation",
    "method": "VQ-VAE tokenization; masked generative Transformers",
    "application": "Ejection fraction estimation and ECHO video generation",
    "code_link": "N/A",
    "dataset_name": [
      "CAMUS",
      "EchoNet-Dynamic",
      "Private Dataset"
    ]
  },
  {
    "id": "6LtdZCyuZR",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "NutriBench: A Dataset for Evaluating Large Language Models in Nutrition Estimation from Meal Descriptions",
    "authors": [
      "Mehak Preet Dhaliwal",
      "Andong Hua",
      "Laya Pullela",
      "Ryan Burke",
      "Yao Qin"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Accurate nutrition estimation helps people make informed dietary choices and is essential in the prevention of serious health complications. We present NutriBench, the first publicly available natural language meal description nutrition benchmark. NutriBench consists of 11,857 meal descriptions generated from real-world global dietary intake data. The data is human-verified and annotated with macro-nutrient labels, including carbohydrates, proteins, fats, and calories. We conduct an extensive evaluation of Nutribench on the task of carbohydrate estimation, testing twelve leading Large Language Models (LLMs), including GPT-4o, Llama3.1, Qwen2, Gemma2, and OpenBioLLM models, using standard, Chain-of-Thought and Retrieval-Augmented Generation strategies. Additionally, we present a study involving professional nutritionists, finding that LLMs can provide comparable but significantly faster estimates. Finally, we perform a real-world risk assessment by simulating the effect of carbohydrate predictions on the blood glucose levels of individuals with type 1 diabetes. Our work highlights the opportunities and challenges of using LLMs for nutrition estimation, demonstrating their potential to aid professionals and laypersons and improve health outcomes. Our benchmark is publicly available at: https://mehak126.github.io/nutribench.html",
    "keywords": "Large Language Models, Nutrition Estimation, Dataset and Benchmark, AI for healthcare",
    "pdf_url": "https://openreview.net/pdf?id=6LtdZCyuZR",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper presents NutriBench, a benchmark for estimating macronutrients (carbohydrates, proteins, fats, calories) from meal descriptions, explicitly targeting “nutrition estimation” to help prevent “serious health complications” and simulating effects on “blood glucose levels of individuals with type 1 diabetes.” This is a direct healthcare application supporting patient monitoring and dietary decision-making.",
    "prompt_tokens": 20808,
    "completion_tokens": 128,
    "total_tokens": 20936,
    "topic": "Nutrition - Estimation using LLMs",
    "method": "Chain-of-Thought prompting; Retrieval-Augmented Generation (RAG)",
    "application": "Carbohydrate estimation from meal descriptions",
    "code_link": "https://mehak126.github.io/nutribench.html",
    "dataset_name": [
      "NUTRIBENCH",
      "FAO/WHO GIFT",
      "What We Eat in America (WWEIA)"
    ]
  },
  {
    "id": "AoIKgHu9Si",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "L-WISE: Boosting Human Visual Category Learning Through Model-Based Image Selection and Enhancement",
    "authors": [
      "Morgan Bruce Talbot",
      "Gabriel Kreiman",
      "James J. DiCarlo",
      "Guy Gaziv"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The currently leading artificial neural network models of the visual ventral stream - which are derived from a combination of performance optimization and robustification methods - have demonstrated a remarkable degree of behavioral alignment with humans on visual categorization tasks. We show that image perturbations generated by these models can enhance the ability of humans to accurately report the ground truth class. Furthermore, we find that the same models can also be used out-of-the-box to predict the proportion of correct human responses to individual images, providing a simple, human-aligned estimator of the relative difficulty of each image. Motivated by these observations, we propose to augment visual learning in humans in a way that improves human categorization accuracy at test time. Our learning augmentation approach consists of (i) selecting images based on their model-estimated recognition difficulty, and (ii) applying image perturbations that aid recognition for novice learners. We find that combining these model-based strategies leads to categorization accuracy gains of 33-72% relative to control subjects without these interventions, on unmodified, randomly selected held-out test images. Beyond the accuracy gain, the training time for the augmented learning group was also shortened by 20-23%, despite both groups completing the same number of training trials. We demonstrate the efficacy of our approach in a fine-grained categorization task with natural images, as well as two tasks in clinically relevant image domains - histology and dermoscopy - where visual learning is notoriously challenging. To the best of our knowledge, our work is the first application of artificial neural networks to increase visual learning performance in humans by enhancing category-specific image features.",
    "keywords": "Human-aligned models, robust neural networks, visual perception, perceptual learning, medical machine learning",
    "pdf_url": "https://openreview.net/pdf?id=AoIKgHu9Si",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the core methodology is general-purpose (model‐based image selection and perturbation), the paper explicitly demonstrates efficacy on “two tasks in clinically relevant image domains – histology and dermoscopy,” both of which are medical imaging specialties. This application to pathology (histology) and skin‐lesion (dermoscopy) image classification places it firmly within Healthcare AI.",
    "prompt_tokens": 20539,
    "completion_tokens": 113,
    "total_tokens": 20652,
    "topic": "Human Learning - Image Augmentation",
    "method": "Model-based image enhancement; robustified neural networks",
    "application": "Improving human visual category learning",
    "code_link": "https://github.com/MorganBDT/L-WISE",
    "dataset_name": [
      "ImageNet",
      "iNaturalist 2021",
      "HAM10000",
      "MHIST"
    ]
  },
  {
    "id": "5z9GjHgerY",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "DPLM-2: A Multimodal Diffusion Protein Language Model",
    "authors": [
      "Xinyou Wang",
      "Zaixiang Zheng",
      "Fei YE",
      "Dongyu Xue",
      "Shujian Huang",
      "Quanquan Gu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Proteins are essential macromolecules defined by their amino acid sequences, which determine their three-dimensional structures and, consequently, their functions in all living organisms. Therefore, generative protein modeling necessitates a multimodal approach to simultaneously model, understand, and generate both sequences and structures. However, existing methods typically use separate models for each modality, limiting their ability to capture the intricate relationships between sequence and structure. This results in suboptimal performance in tasks that requires joint understanding and generation of both modalities.\nIn this paper, we introduce DPLM-2, a multimodal protein foundation model that extends discrete diffusion protein language model (DPLM) to accommodate both sequences and structures.\nTo enable structural learning with the language model, 3D coordinates are converted to discrete tokens using a lookup-free quantization-based tokenizer.\nBy training on both experimental and high-quality synthetic structures, DPLM-2 learns the joint distribution of sequence and structure, as well as their marginals and conditionals.\nWe also implement an efficient warm-up strategy to exploit the connection between large-scale evolutionary data and structural inductive biases from pre-trained sequence-based protein language models.\nEmpirical evaluation shows that DPLM-2 can simultaneously generate highly compatible amino acid sequences and their corresponding 3D structures eliminating the need for a two-stage generation approach.\nMoreover, DPLM-2 demonstrates competitive performance in various conditional generation tasks, including folding, inverse folding, and scaffolding with multimodal motif inputs.",
    "keywords": "protein foundation model, diffusion language model, multimodal language model",
    "pdf_url": "https://openreview.net/pdf?id=5z9GjHgerY",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on generative modeling of proteins, jointly learning amino‐acid sequences and 3D structures. This falls squarely under “molecular modeling” and “protein design,” which are core topics in Biomedicine AI (e.g., drug discovery and synthetic biology). The abstract’s emphasis on “multimodal protein foundation model,” “experimental and synthetic structures,” and tasks like “inverse folding” and “scaffolding with multimodal motif inputs” further underscores its relevance to biomedical research rather than general ML.",
    "prompt_tokens": 20656,
    "completion_tokens": 88,
    "total_tokens": 20744,
    "topic": "Bioinformatics - Protein Co-Generation",
    "method": "Diffusion model; Tokenization",
    "application": "Protein structure and sequence generation",
    "code_link": "N/A",
    "dataset_name": [
      "PDB",
      "SwissProt"
    ]
  },
  {
    "id": "lvw3UgeVxS",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "gRNAde: Geometric Deep Learning for 3D RNA inverse design",
    "authors": [
      "Chaitanya K. Joshi",
      "Arian Rokkum Jamasb",
      "Ramon Viñas Torné",
      "Charles Harris",
      "Simon V Mathis",
      "Alex Morehead",
      "Rishabh Anand",
      "Pietro Lio"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Computational RNA design tasks are often posed as inverse problems, where sequences are designed based on adopting a single desired secondary structure without considering 3D conformational diversity. We introduce gRNAde, a geometric RNA design pipeline operating on 3D RNA backbones to design sequences that explicitly account for structure and dynamics. gRNAde uses a multi-state Graph Neural Network and autoregressive decoding to generates candidate RNA sequences conditioned on one or more 3D backbone structures where the identities of the bases are unknown. On a single-state fixed backbone re-design benchmark of 14 RNA structures from the PDB identified by Das et al. (2010), gRNAde obtains higher native sequence recovery rates (56% on average) compared to Rosetta (45% on average), taking under a second to produce designs compared to the reported hours for Rosetta. We further demonstrate the utility of gRNAde on a new benchmark of multi-state design for structurally flexible RNAs, as well as zero-shot ranking of mutational fitness landscapes in a retrospective analysis of a recent ribozyme. Experimental wet lab validation on 10 different structured RNA backbones finds that gRNAde has a success rate of 50% at designing pseudoknotted RNA structures, a significant advance over 35% for Rosetta. Open source code and tutorials are available at: github.com/chaitjo/geometric-rna-design",
    "keywords": "RNA Structure, RNA Design, Geometric Deep Learning, Graph Neural Networks",
    "pdf_url": "https://openreview.net/pdf?id=lvw3UgeVxS",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This paper focuses on designing RNA sequences using geometric deep learning on 3D RNA backbones, directly addressing “RNA Structure,” “RNA Design,” and “molecular modeling,” all of which are core tasks in biomedical research. Techniques for inverse‐design of structured RNAs (including pseudoknots and ribozymes) are key to synthetic biology and drug discovery efforts. Therefore, it fits squarely within the Biomedicine AI domain.",
    "prompt_tokens": 20723,
    "completion_tokens": 115,
    "total_tokens": 20838,
    "topic": "Bioinformatics - RNA Design",
    "method": "Multi-state Graph Neural Network; Autoregressive Decoding",
    "application": "RNA sequence design",
    "code_link": "https://github.com/chaitjo/geometric-rna-design",
    "dataset_name": [
      "RNASolo"
    ]
  },
  {
    "id": "LbgIZpSUCe",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Nonlinear multiregion neural dynamics with parametric impulse response communication channels",
    "authors": [
      "Matthew Dowling",
      "Cristina Savin"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Cognition arises from the coordinated interaction of brain regions with distinct computational roles. Despite improvements in our ability to extract the dynamics underlying circuit computation from population activity recorded in individual areas, understanding how multiple areas jointly support distributed computation remains a challenge. As part of this effort, we propose a multi-region neural dynamics model composed of two building blocks:  _i)_ within-region (potentially driven) nonlinear dynamics and _ii)_ communication channels between regions, parameterized through their impulse response. Together, these choices make it possible to learn nonlinear neural population dynamics and understand the flow of information between regions by drawing from the rich literature of linear systems theory.  We develop a state noise inversion free variational filtering and learning algorithm for our model and show, through neuroscientifically inspired numerical experiments, how the proposed model can reveal interpretable characterizations of the local computations within and the flow of information between neural populations.  We further validate the efficacy of our approach using simultaneous population recordings from areas V1 and V2.",
    "keywords": "neural dynamics, multiregion, variational inference",
    "pdf_url": "https://openreview.net/pdf?id=LbgIZpSUCe",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper develops a model of “multiregion neural dynamics” and applies it to simultaneous recordings from visual cortical areas V1 and V2. This work falls under neurobiological modeling—specifically, neural system dynamics—which is a core part of Biomedicine AI. It focuses on understanding how brain regions interact and process information, aligning with the category “neuroscience or neurobiological modeling.”",
    "prompt_tokens": 21059,
    "completion_tokens": 98,
    "total_tokens": 21157,
    "topic": "Neuroscience - Multi-region Neural Dynamics",
    "method": "Multi-region state-space modeling; variational inference",
    "application": "Multi-region neural communication analysis",
    "code_link": "N/A",
    "dataset_name": [
      "Zandvakili dataset V1/V2 spiking activity"
    ]
  },
  {
    "id": "DTatjJTDl1",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Trivialized Momentum Facilitates Diffusion Generative Modeling on Lie Groups",
    "authors": [
      "Yuchen Zhu",
      "Tianrong Chen",
      "Lingkai Kong",
      "Evangelos Theodorou",
      "Molei Tao"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The generative modeling of data on manifolds is an important task, for which diffusion models in flat spaces typically need nontrivial adaptations. This article demonstrates how a technique called `trivialization' can transfer the effectiveness of diffusion models in Euclidean spaces to Lie groups. In particular, an auxiliary momentum variable was algorithmically introduced to help transport the position variable between data distribution and a fixed, easy-to-sample distribution. Normally, this would incur further difficulty for manifold data because momentum lives in a space that changes with the position. However, our trivialization technique creates a new momentum variable that stays in a simple fixed vector space. This design, together with a manifold preserving integrator, simplifies implementation and avoids inaccuracies created by approximations such as projections to tangent space and manifold, which were typically used in prior work, hence facilitating generation with high-fidelity and efficiency. The resulting method achieves state-of-the-art performance on protein and RNA torsion angle generation and sophisticated torus datasets. We also, arguably for the first time, tackle the generation of data on high-dimensional Special Orthogonal and Unitary groups, the latter essential for quantum problems. Code is available at https://github.com/yuchen-zhu-zyc/TDM.",
    "keywords": "non-Euclidean generative modeling, denoising diffusion, Lie group",
    "pdf_url": "https://openreview.net/pdf?id=DTatjJTDl1",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper applies its diffusion-on-Lie‐groups methodology to “protein and RNA torsion angle generation,” which is a clear molecular modeling task in biomedicine. Although the core contribution is a general generative modeling technique on manifolds, the demonstrated applications to protein and RNA structures place it firmly within the Biomedicine AI domain.",
    "prompt_tokens": 20954,
    "completion_tokens": 162,
    "total_tokens": 21116,
    "topic": "Generative Modelling - Lie Groups",
    "method": "Trivialized Diffusion Model; manifold-preserving integration",
    "application": "Generative modeling - protein/RNA torsion angles; Quantum system evolution",
    "code_link": "https://github.com/yuchen-zhu-zyc/TDM",
    "dataset_name": [
      "Protein torsion angle datasets",
      "RNA torsion angle datasets",
      "Pacman",
      "Special Orthogonal group SO(n)",
      "Unitary group U(n)"
    ]
  },
  {
    "id": "FVuqJt3c4L",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Population Transformer: Learning Population-level Representations of Neural Activity",
    "authors": [
      "Geeling Chau",
      "Christopher Wang",
      "Sabera J Talukder",
      "Vighnesh Subramaniam",
      "Saraswati Soedarmadji",
      "Yisong Yue",
      "Boris Katz",
      "Andrei Barbu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We present a self-supervised framework that learns population-level codes for arbitrary ensembles of neural recordings at scale. We address key challenges in scaling models with neural time-series data, namely, sparse and variable electrode distribution across subjects and datasets. The Population Transformer (PopT) stacks on top of pretrained temporal embeddings and enhances downstream decoding by enabling learned aggregation of multiple spatially-sparse data channels. The pretrained PopT lowers the amount of data required for downstream decoding experiments, while increasing accuracy, even on held-out subjects and tasks. Compared to end-to-end methods, this approach is computationally lightweight, while achieving similar or better decoding performance. We further show how our framework is generalizable to multiple time-series embeddings and neural data modalities. Beyond decoding, we interpret the pretrained and fine-tuned PopT models to show how they can be used to extract neuroscience insights from large amounts of data. We release our code as well as a pretrained PopT to enable off-the-shelf improvements in multi-channel intracranial data decoding and interpretability. Code is available at https://github.com/czlwang/PopulationTransformer.",
    "keywords": "representation learning, neuroscience, self supervised learning",
    "pdf_url": "https://openreview.net/pdf?id=FVuqJt3c4L",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper develops self-supervised representation learning for multi-channel neural time-series (“arbitrary ensembles of neural recordings,” “multi-channel intracranial data decoding”) to improve downstream decoding and interpretability of brain signals. These intracranial/neural recordings and brain decoding tasks fall squarely under neuroscience and biomedical AI (biomedical signal processing), making this work relevant to Healthcare/Biomedicine AI.",
    "prompt_tokens": 20404,
    "completion_tokens": 114,
    "total_tokens": 20518,
    "topic": "Time Series - Neural Activity Representation",
    "method": "Self-supervised learning; Transformer-based models",
    "application": "Decoding high-temporal-resolution neural data",
    "code_link": "https://github.com/czlwang/PopulationTransformer",
    "dataset_name": [
      "BrainBERT",
      "EEG TUAB",
      "various iEEG and scalp EEG datasets"
    ]
  },
  {
    "id": "mMhZS7qt0U",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Fragment and Geometry Aware Tokenization of Molecules for Structure-Based Drug Design Using Language Models",
    "authors": [
      "Cong Fu",
      "Xiner Li",
      "Blake Olson",
      "Heng Ji",
      "Shuiwang Ji"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Structure-based drug design (SBDD) is crucial for developing specific and effective therapeutics against protein targets but remains challenging due to complex protein-ligand interactions and vast chemical space. Although language models (LMs) have excelled in natural language processing, their application in SBDD is underexplored. To bridge this gap, we introduce a method, known as Frag2Seq, to apply LMs to SBDD by generating molecules in a fragment-based manner in which fragments correspond to functional modules. We transform 3D molecules into fragment-informed sequences using $SE(3)$-equivariant molecule and fragment local frames, extracting $SE(3)$-invariant sequences that preserve geometric information of 3D fragments. Furthermore, we incorporate protein pocket embeddings obtained from a pre-trained inverse folding model into the LMs via cross-attention to capture protein-ligand interaction, enabling effective target-aware molecule generation. Benefiting from employing LMs with fragment-based generation and effective protein context encoding, our model achieves the best performance on binding vina score and chemical properties such as QED and Lipinski, which shows our model’s efficacy in generating drug-like ligands with higher binding affinity against target proteins. Moreover, our method also exhibits higher sampling efficiency compared to atom-based autoregressive and diffusion baselines with at most $\\times 300$ speedup. The code will be made publicly available at https://github.com/divelab/AIRS/tree/main/OpenMI/Frag2Seq.",
    "keywords": "Generative models, language models, molecule tokenization, structure-based drug design, fragment",
    "pdf_url": "https://openreview.net/pdf?id=mMhZS7qt0U",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper directly addresses structure-based drug design (“SBDD”) and fragment-based molecule generation for improved binding affinity to protein targets, which falls under the strong “drug discovery” indicator in Biomedicine AI. It focuses on protein–ligand interactions and generating drug-like ligands, making it a clear application in biomedicine.",
    "prompt_tokens": 21060,
    "completion_tokens": 101,
    "total_tokens": 21161,
    "topic": "Drug Discovery - Structure-based Design",
    "method": "Fragment-based generation; protein embedding integration",
    "application": "Target-aware molecule generation",
    "code_link": "https://github.com/divelab/AIRS/tree/main/OpenMI/Frag2Seq",
    "dataset_name": [
      "CrossDocked2020"
    ]
  },
  {
    "id": "uNomADvF3s",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Lift Your Molecules: Molecular Graph Generation in Latent Euclidean Space",
    "authors": [
      "Mohamed Amine Ketata",
      "Nicholas Gao",
      "Johanna Sommer",
      "Tom Wollschläger",
      "Stephan Günnemann"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We introduce a new framework for 2D molecular graph generation using 3D molecule generative models. Our Synthetic Coordinate Embedding (SyCo) framework maps 2D molecular graphs to 3D Euclidean point clouds via synthetic coordinates and learns the inverse map using an E($n$)-Equivariant Graph Neural Network (EGNN). The induced point cloud-structured latent space is well-suited to apply existing 3D molecule generative models. This approach simplifies the graph generation problem into a point cloud generation problem followed by node and edge classification tasks, without relying on molecular fragments nor autoregressive decoding. Further, we propose a novel similarity-constrained optimization scheme for 3D diffusion models based on inpainting and guidance. As a concrete implementation of our framework, we develop EDM-SyCo based on the E(3) Equivariant Diffusion Model (EDM). EDM-SyCo achieves state-of-the-art performance in distribution learning of molecular graphs, outperforming the best non-autoregressive methods by more than 26\\% on ZINC250K and 16\\% on the GuacaMol dataset while improving conditional generation by up to 3.9 times.",
    "keywords": "Drug Design, Computational Biology, Molecule Generation, Graph Generation, Latent Diffusion Models",
    "pdf_url": "https://openreview.net/pdf?id=uNomADvF3s",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on molecular graph generation and lists “Drug Design” and “Computational Biology” as keywords. Generative models for molecules are a core technology in drug discovery and other biomedical research. Although the abstract frames the work in terms of graph and point‐cloud generation, the explicit mention of drug design and molecular modeling tasks places it squarely within Biomedicine AI.",
    "prompt_tokens": 20965,
    "completion_tokens": 100,
    "total_tokens": 21065,
    "topic": "Drug Discovery - Molecule Generation",
    "method": "Equivariant Graph Neural Networks (EGNN); Diffusion Model; Autoencoder",
    "application": "Molecule generation and optimization",
    "code_link": "N/A",
    "dataset_name": [
      "ZINC250K",
      "GuacaMol"
    ]
  },
  {
    "id": "rnL3OafDdw",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Bayesian Image Regression with Soft-thresholded Conditional Autoregressive Prior",
    "authors": [
      "Yuliang Xu",
      "Jian Kang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In the analysis of brain functional MRI (fMRI) data using regression models, Bayesian methods are highly valued for their flexibility and ability to quantify uncertainty. However, these methods face computational challenges in high-dimensional settings typical of brain imaging, and the often pre-specified correlation structures may not accurately capture the true spatial relationships within the brain. To address these issues, we develop a general prior specifically designed for regression models with large-scale imaging data. We introduce the Soft-Thresholded Conditional AutoRegressive (ST-CAR) prior, which reduces instability to pre-fixed correlation structures and provides inclusion probabilities to account for the uncertainty in choosing active voxels in the brain. We apply the ST-CAR prior to scalar-on-image (SonI) and image-on-scalar (IonS) regression models—both critical in brain imaging studies—and develop efficient computational algorithms using variational inference (VI) and stochastic subsampling techniques. Simulation studies demonstrate that the ST-CAR prior outperforms existing methods in identifying active brain regions with complex correlation patterns, while our VI algorithms offer superior computational performance. We further validate our approach by applying the ST-CAR to working memory fMRI data from the Adolescent Brain Cognitive Development (ABCD) study, highlighting its effectiveness in practical brain imaging applications.",
    "keywords": "Brain fMRI Image, Variational Inference, Scalar-on-Image Regression, Image-on-Scalar Regression",
    "pdf_url": "https://openreview.net/pdf?id=rnL3OafDdw",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on regression models for brain functional MRI (fMRI) data—“scalar-on-image (SonI) and image-on-scalar (IonS) regression models” applied to “working memory fMRI data from the Adolescent Brain Cognitive Development (ABCD) study.” fMRI is a medical imaging modality used in neuroscience and clinical research, clearly situating the work within Healthcare AI/Biomedicine AI.",
    "prompt_tokens": 21010,
    "completion_tokens": 126,
    "total_tokens": 21136,
    "topic": "Medical Imaging - Brain fMRI",
    "method": "Variational Inference (CAVI, SSVI); Bayesian modeling; Soft-thresholded conditional autoregressive prior (ST-CAR)",
    "application": "Regression modeling – Brain imaging",
    "code_link": "https://github.com/yuliangxu/STCAR",
    "dataset_name": [
      "ABCD"
    ]
  },
  {
    "id": "n8O0trhost",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "cryoSPHERE: Single-Particle HEterogeneous REconstruction from cryo EM",
    "authors": [
      "Gabriel Ducrocq",
      "Lukas Grunewald",
      "Sebastian Westenhoff",
      "Fredrik Lindsten"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The three-dimensional structure of proteins plays a crucial role in determining their function. Protein structure prediction methods, like AlphaFold, offer rapid access to a protein’s structure. However, large protein complexes cannot be reliably predicted, and proteins are dynamic, making it important to resolve their full conformational distribution. Single-particle cryo-electron microscopy (cryo-EM) is a powerful tool for determining the structures of large protein complexes. Importantly, the numerous images of a given protein contain underutilized information about conformational heterogeneity. These images are very noisy projections of the protein, and traditional methods for cryo-EM reconstruction are limited to recovering only one or a few consensus conformations.\n\nIn this paper, we introduce cryoSPHERE, which is a deep learning method that uses a nominal protein structure (e.g., from AlphaFold) as input, learns how to divide it into segments, and moves these segments as approximately rigid bodies to fit the different conformations present in the cryo-EM dataset. This approach provides enough constraints to enable meaningful reconstructions of single protein structural ensembles. We demonstrate this with two synthetic datasets featuring varying levels of noise, as well as two real dataset. We show that cryoSPHERE is very resilient to the high levels of noise typically encountered in experiments, where we see consistent improvements over the current state-of-the-art for heterogeneous reconstruction.",
    "keywords": "cryoEM; protein structure; Deep Learning; Machine Learning; generative modelling",
    "pdf_url": "https://openreview.net/pdf?id=n8O0trhost",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work develops a deep‐learning method for reconstructing protein conformations from cryo‐EM data—a core problem in molecular‐level biomedical research. The abstract discusses “the three‐dimensional structure of proteins,” “single-particle cryo-electron microscopy,” and “protein structural ensembles,” all of which fall squarely under biomedicine AI (molecular modeling and protein structure determination), a strong indicator of relevance to Biomedicine AI.",
    "prompt_tokens": 20733,
    "completion_tokens": 128,
    "total_tokens": 20861,
    "topic": "Bioinformatics - Cryo-EM Reconstruction",
    "method": "Variational Auto-Encoder (VAE); Gaussian Mixture Models (GMM)",
    "application": "Structure reconstruction from cryo-EM datasets",
    "code_link": "https://github.com/Gabriel-Ducrocq/cryoSPHERE",
    "dataset_name": [
      "EMPIAR-12093",
      "Molecular Dynamics Dataset"
    ]
  },
  {
    "id": "gQlxd3Mtru",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Learning stochastic dynamics from snapshots through regularized unbalanced optimal transport",
    "authors": [
      "Zhenyi Zhang",
      "Tiejun Li",
      "Peijie Zhou"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Reconstructing dynamics using samples from sparsely time-resolved snapshots is an important problem in both natural sciences and machine learning. Here, we introduce a new deep learning approach for solving regularized unbalanced optimal transport (RUOT) and inferring continuous unbalanced stochastic dynamics from observed snapshots. Based on the RUOT form, our method models these dynamics without requiring prior knowledge of growth and death processes or additional information, allowing them to be learned directly from data.  Theoretically, we explore the connections between the RUOT and Schrödinger bridge problem and discuss the key challenges and potential solutions. The effectiveness of our method is demonstrated with a synthetic gene regulatory network, high-dimensional Gaussian Mixture Model, and single-cell RNA-seq data from blood development. Compared with other methods, our approach accurately identifies growth and transition patterns, eliminates false transitions, and constructs the Waddington developmental landscape. Our code is available at: [https://github.com/zhenyiizhang/DeepRUOT](https://github.com/zhenyiizhang/DeepRUOT).",
    "keywords": "optimal transport, Schrödinger bridge, trajectory inference, single-cell",
    "pdf_url": "https://openreview.net/pdf?id=gQlxd3Mtru",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper demonstrates its method on “single-cell RNA-seq data from blood development” and a “synthetic gene regulatory network,” which are clear instances of biomedical data and tasks (trajectory inference in developmental biology, Waddington landscape). Single-cell analysis and gene regulatory modeling fall squarely within Biomedicine AI.",
    "prompt_tokens": 20871,
    "completion_tokens": 120,
    "total_tokens": 20991,
    "topic": "Single-Cell Analysis - Time Series Dynamics",
    "method": "Regularized unbalanced optimal transport; Neural network modeling",
    "application": "Reconstructing cellular population dynamics",
    "code_link": "https://github.com/zhenyiizhang/DeepRUOT",
    "dataset_name": [
      "Mouse Hematopoiesis",
      "scRNA-seq A549 EMT",
      "Synthetic Gaussian Mixtures"
    ]
  },
  {
    "id": "KXrgDM3mVD",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Distilling Structural Representations into Protein Sequence Models",
    "authors": [
      "Jeffrey Ouyang-Zhang",
      "Chengyue Gong",
      "Yue Zhao",
      "Philipp Kraehenbuehl",
      "Adam Klivans",
      "Daniel Jesus Diaz"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Protein language (or sequence) models, like the popular ESM2, are now widely used tools for extracting evolution-based protein representations and have achieved significant success on core downstream biological tasks.\nA major open problem is how to obtain representations that best capture both the sequence evolutionary history and the atomic structural properties of proteins in general. \nWe introduce **I**mplicit **S**equence **M**odel, a sequence-only input model with structurally-enriched representations that outperforms state-of-the-art sequence models on several well-studied benchmarks including mutation stability assessment and structure prediction. \nOur key innovations are a microenvironment-based Autoencoder for generating structure tokens and a self-supervised training objective that distills these tokens into ESM2's pre-trained model. \nNotably, we make ISM's structure-enriched weights easily accessible for any application using the ESM2 framework.",
    "keywords": "biology, proteins, sequence, structure, autoencoder, esm",
    "pdf_url": "https://openreview.net/pdf?id=KXrgDM3mVD",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This paper focuses on protein language models and structural representations, with applications in “mutation stability assessment” and “structure prediction.” These tasks are core to molecular modeling and protein design, which are key areas in Biomedicine AI (e.g., drug discovery, protein engineering).",
    "prompt_tokens": 20867,
    "completion_tokens": 120,
    "total_tokens": 20987,
    "topic": "Bioinformatics - Protein Sequence Models",
    "method": "Structure-tuning; Masked language modeling; Graph Transformer",
    "application": "Thermodynamic stability prediction of proteins",
    "code_link": "https://github.com/jozhang97/ISM",
    "dataset_name": [
      "Protein Data Bank (PDB)",
      "UniClust30",
      "AlphaFold"
    ]
  },
  {
    "id": "BbZy8nI1si",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Learning Molecular Representation in a Cell",
    "authors": [
      "Gang Liu",
      "Srijit Seal",
      "John Arevalo",
      "Zhenwen Liang",
      "Anne E Carpenter",
      "Meng Jiang",
      "Shantanu Singh"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Predicting drug efficacy and safety in vivo requires information on biological responses (e.g., cell morphology and gene expression) to small molecule perturbations. However, current molecular representation learning methods do not provide a comprehensive view of cell states under these perturbations and struggle to remove noise, hindering model generalization. We introduce the Information Alignment (InfoAlign) approach to learn molecular representations through the information bottleneck method in cells. We integrate molecules and cellular response data as nodes into a context graph, connecting them with weighted edges based on chemical, biological, and computational criteria. For each molecule in a training batch, InfoAlign optimizes the encoder's latent representation with a minimality objective to discard redundant structural information. A sufficiency objective decodes the representation to align with different feature spaces from the molecule's neighborhood in the context graph. We demonstrate that the proposed sufficiency objective for alignment is tighter than existing encoder-based contrastive methods. Empirically, we validate representations from InfoAlign in two downstream applications: molecular property prediction against up to 27 baseline methods across four datasets, plus zero-shot molecule-morphology matching. The code and model are available at https://github.com/liugangcode/InfoAlign.",
    "keywords": "Molecular Representation Learning, Drug Discovery, Cell Morphology, Gene Expression",
    "pdf_url": "https://openreview.net/pdf?id=BbZy8nI1si",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on molecular representation learning for drug discovery and safety assessment, explicitly using cell morphology and gene expression data to predict biological responses to small‐molecule perturbations. Key phrases such as “drug efficacy and safety in vivo,” “small molecule perturbations,” “cell morphology and gene expression,” and “molecular property prediction” place this work squarely in the Biomedicine AI domain.",
    "prompt_tokens": 21026,
    "completion_tokens": 119,
    "total_tokens": 21145,
    "topic": "Drug Discovery - Representation Learning",
    "method": "Graph Neural Networks (GNN); Multi-modal alignment; Information Bottleneck",
    "application": "Molecular property prediction – Drug Discovery",
    "code_link": "https://github.com/liugangcode/InfoAlign",
    "dataset_name": [
      "ChEMBL2K",
      "Broad6K",
      "ToxCast",
      "Biogen3K"
    ]
  },
  {
    "id": "CoQw1dXtGb",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "SPDIM: Source-Free Unsupervised Conditional and Label Shift Adaptation in EEG",
    "authors": [
      "Shanglin Li",
      "Motoaki Kawanabe",
      "Reinmar J Kobler"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The non-stationary nature of electroencephalography (EEG) introduces distribution shifts across domains (e.g., days and subjects), posing a significant challenge to EEG-based neurotechnology generalization.\nWithout labeled calibration data for target domains, the problem is a source-free unsupervised domain adaptation (SFUDA) problem.\nFor scenarios with constant label distribution, Riemannian geometry-aware statistical alignment frameworks on the symmetric positive definite (SPD) manifold are considered state-of-the-art.\nHowever, many practical scenarios, including EEG-based sleep staging, exhibit label shifts.\nHere, we propose a geometric deep learning framework for SFUDA problems under specific distribution shifts, including label shifts.\nWe introduce a novel, realistic generative model and show that prior Riemannian statistical alignment methods on the SPD manifold can compensate for specific marginal and conditional distribution shifts but hurt generalization under label shifts.\nAs a remedy, we propose a parameter-efficient manifold optimization strategy termed SPDIM.\nSPDIM uses the information maximization principle to learn a single SPD-manifold-constrained parameter per target domain.\nIn simulations, we demonstrate that SPDIM can compensate for the shifts under our generative model.\nMoreover, using public EEG-based brain-computer interface and sleep staging datasets, we show that SPDIM outperforms prior approaches.",
    "keywords": "geometric deep learning, transfer learning, source-free adaptation, electroencephalography, neurology, brain-computer interfaces",
    "pdf_url": "https://openreview.net/pdf?id=CoQw1dXtGb",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on domain adaptation for EEG-based brain–computer interfaces and sleep staging, both of which involve time-series biomedical signals. EEG is a clinical neurophysiological modality, and sleep staging is a medical diagnostic task. These strong indicators (EEG, brain–computer interface, sleep staging) place the work squarely in Healthcare AI.",
    "prompt_tokens": 21085,
    "completion_tokens": 134,
    "total_tokens": 21219,
    "topic": "EEG - Source-Free Domain Adaptation",
    "method": "Geometric deep learning; Information maximization; Domain adaptation",
    "application": "EEG signal classification – Sleep staging and BCI",
    "code_link": "N/A",
    "dataset_name": [
      "BNCI2014001",
      "BNCI2015001",
      "Zhou2016",
      "BNCI2014004",
      "CAP",
      "Dreem",
      "HMC",
      "ISRUC"
    ]
  },
  {
    "id": "QG31By6S6w",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Unleashing the Potential of Vision-Language Pre-Training for 3D Zero-Shot Lesion Segmentation via Mask-Attribute Alignment",
    "authors": [
      "Yankai Jiang",
      "Wenhui Lei",
      "Xiaofan Zhang",
      "Shaoting Zhang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Recent advancements in medical vision-language pre-training models have driven significant progress in zero-shot disease recognition. However, transferring image-level knowledge to pixel-level tasks, such as lesion segmentation in 3D CT scans, remains a critical challenge. Due to the complexity and variability of pathological visual characteristics, existing methods struggle to align fine-grained lesion features not encountered during training with disease-related textual representations. In this paper, we present Malenia, a novel multi-scale lesion-level mask-attribute alignment framework, specifically designed for 3D zero-shot lesion segmentation. Malenia improves the compatibility between mask representations and their associated elemental attributes, explicitly linking the visual features of unseen lesions with the extensible knowledge learned from previously seen ones. Furthermore, we design a Cross-Modal Knowledge Injection module to enhance both visual and textual features with mutually beneficial information, effectively guiding the generation of segmentation results. Comprehensive experiments across three datasets and 12 lesion categories validate the superior performance of Malenia.",
    "keywords": "Medical Image Segmentation, Vision-Language Pre-Training, Zero-Shot Segmentation",
    "pdf_url": "https://openreview.net/pdf?id=QG31By6S6w",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “3D zero-shot lesion segmentation” in CT scans—a clear medical imaging task. It targets identifying and segmenting pathological lesions in 3D medical (CT) volumes, which directly falls under Healthcare AI for diagnostic imaging.",
    "prompt_tokens": 20671,
    "completion_tokens": 159,
    "total_tokens": 20830,
    "topic": "Medical Imaging - Zero-shot Lesion Segmentation",
    "method": "Vision-language pretraining; Multi-scale mask-attribute alignment; Cross-Modal Knowledge Injection",
    "application": "Lesion segmentation",
    "code_link": "https://github.com/Yankai96/Malenia",
    "dataset_name": [
      "KiTS23",
      "MSD-Colon Tumor",
      "MSD-Liver Tumor",
      "MSD-Hepatic Vessel Tumor",
      "MSD-Lung Tumor",
      "MSD-Pancreas Tumor",
      "MSD-Pancreas Cyst"
    ]
  },
  {
    "id": "j7cyANIAxV",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Rethinking the generalization of drug target affinity prediction algorithms via similarity aware evaluation",
    "authors": [
      "Chenbin Zhang",
      "Zhiqiang Hu",
      "Jiang Chuchu",
      "Wen Chen",
      "JIE XU",
      "Shaoting Zhang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Drug-target binding affinity prediction is a fundamental task for drug discovery. It has been extensively explored in literature and promising results are reported. However, in this paper, we demonstrate that the results may be misleading and cannot be well generalized to real practice. The core observation is that the canonical randomized split of a test set in conventional evaluation leaves the test set dominated by samples with high similarity to the training set. The performance of models is severely degraded on samples with lower similarity to the training set but the drawback is highly overlooked in current evaluation. As a result, the performance can hardly be trusted when the model meets low-similarity samples in real practice. To address this problem, we propose a framework of similarity aware evaluation in which a novel split methodology is proposed to adapt to any desired distribution. This is achieved by a formulation of optimization problems which are approximately and efficiently solved by gradient descent. We perform extensive experiments across five representative methods in four datasets for two typical target evaluations and compare them with various counterpart methods. Results demonstrate that the proposed split methodology can significantly better fit desired distributions and guide the development of models.",
    "keywords": "Drug-Target Affinity Prediction, Similarity-Aware Evaluation",
    "pdf_url": "https://openreview.net/pdf?id=j7cyANIAxV",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “drug-target binding affinity prediction,” a core task in drug discovery and molecular modeling. It explicitly addresses evaluation for algorithms used in predicting how drug compounds interact with biological targets, which is squarely within the biomedicine AI domain.",
    "prompt_tokens": 20999,
    "completion_tokens": 121,
    "total_tokens": 21120,
    "topic": "Drug Discovery - Binding Affinity Prediction",
    "method": "Similarity Aware Evaluation (SAE); Stratified Split; Scaffold Split; Dissimilar Split",
    "application": "Drug-target binding affinity prediction",
    "code_link": "https://github.com/Amshoreline/SAE/tree/main",
    "dataset_name": [
      "IC50 - EGFR",
      "Ki - Carbonic Anhydrase II"
    ]
  },
  {
    "id": "ua5MHdsbck",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Data Distillation for extrapolative protein design through exact preference optimization",
    "authors": [
      "Mostafa Karimi",
      "Sharmi Banerjee",
      "Tommi Jaakkola",
      "Bella Dubrov",
      "Shang Shang",
      "Ron Benson"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The goal of protein design typically involves increasing fitness (extrapolating) beyond what is seen during training (e.g., towards higher stability, stronger binding affinity, etc.). State-of-the-art methods assume that one can safely steer proteins towards such extrapolated regions by learning from pairs alone. We hypothesize that noisy training pairs are not sufficiently informative to capture the fitness gradient and that models learned from pairs specifically may fail to capture three-way relations important for search, e.g., how two alternatives fair relative to a seed. Building on the success of preference alignment models in large language models, we introduce a progressive search method for extrapolative protein design by directly distilling into the model relevant triplet relations. We evaluated our model's performance in designing AAV and GFP proteins and demonstrated that the proposed framework significantly improves effectiveness in extrapolation tasks.",
    "keywords": "Protein design, Protein Language Models, Preference Learning, Extrapolation, Data distillation",
    "pdf_url": "https://openreview.net/pdf?id=ua5MHdsbck",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “protein design” and “extrapolative protein design” with applications to AAV and GFP proteins—topics squarely in the realm of molecular modeling and synthetic biology for potential therapeutic or biotechnological use. Such work is a core component of Biomedicine AI (drug discovery, protein engineering).",
    "prompt_tokens": 20462,
    "completion_tokens": 90,
    "total_tokens": 20552,
    "topic": "Bioinformatics - Protein Design",
    "method": "Preference learning; Triplet ranking",
    "application": "Extrapolative protein design",
    "code_link": "N/A",
    "dataset_name": [
      "AAV",
      "GFP"
    ]
  },
  {
    "id": "qeXcMutEZY",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Ambient Diffusion Posterior Sampling: Solving Inverse Problems with Diffusion Models Trained on Corrupted Data",
    "authors": [
      "Asad Aali",
      "Giannis Daras",
      "Brett Levac",
      "Sidharth Kumar",
      "Alex Dimakis",
      "Jon Tamir"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We provide a framework for solving inverse problems with diffusion models learned from linearly corrupted data. Firstly, we extend the Ambient Diffusion framework to enable training directly from measurements corrupted in the Fourier domain. Subsequently, we train diffusion models for MRI with access only to Fourier subsampled multi-coil measurements at acceleration factors R$=2, 4, 6, 8$. Secondly, we propose $\\textit{Ambient Diffusion Posterior Sampling}$ (A-DPS), a reconstruction algorithm that leverages generative models pre-trained on one type of corruption (e.g. image inpainting) to perform posterior sampling on measurements from a different forward process (e.g. image blurring). For MRI reconstruction in high acceleration regimes, we observe that A-DPS models trained on subsampled data are better suited to solving inverse problems than models trained on fully sampled data. We also test the efficacy of A-DPS on natural image datasets (CelebA, FFHQ, and AFHQ) and show that A-DPS can sometimes outperform models trained on clean data for several image restoration tasks in both speed and performance.",
    "keywords": "generative models, inverse problems, ambient diffusion, mri",
    "pdf_url": "https://openreview.net/pdf?id=qeXcMutEZY",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper specifically develops diffusion‐based reconstruction methods for MRI (“train diffusion models for MRI with access only to Fourier subsampled multi‐coil measurements”), which is a medical imaging task. MRI reconstruction is directly relevant to healthcare AI.",
    "prompt_tokens": 20239,
    "completion_tokens": 101,
    "total_tokens": 20340,
    "topic": "Medical Imaging - MRI Reconstruction",
    "method": "Diffusion Posterior Sampling (DPS); Ambient Diffusion",
    "application": "Accelerated MRI reconstruction",
    "code_link": "https://github.com/utcsilab/ambient-diffusion-mri",
    "dataset_name": [
      "FastMRI"
    ]
  },
  {
    "id": "96beVMeHh9",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Causal Identification for Complex Functional Longitudinal Studies",
    "authors": [
      "Andrew Ying"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Real-time monitoring in modern medical research introduces functional longitudinal data, characterized by continuous-time measurements of outcomes, treatments, and confounders. This complexity leads to uncountably infinite treatment-confounder feedbacks, which traditional causal inference methodologies cannot handle. Inspired by the coarsened data framework, we adopt stochastic process theory, measure theory, and net convergence to propose a nonparametric causal identification framework. This framework generalizes classical g-computation, inverse probability weighting, and doubly robust formulas, accommodating time-varying outcomes subject to mortality and censoring for functional longitudinal data. We examine our framework through Monte Carlo simulations. Our approach addresses significant gaps in current methodologies, providing a solution for functional longitudinal data and paving the way for future estimation work in this domain.",
    "keywords": "Causal Inference, Stochastic Process, Longitudinal Data; Functional Data, Continuous Time.",
    "pdf_url": "https://openreview.net/pdf?id=96beVMeHh9",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper develops causal‐inference methods for “functional longitudinal data” arising in “modern medical research,” explicitly handling “time‐varying outcomes subject to mortality and censoring” and “continuous‐time measurements of outcomes, treatments, and confounders.” These are core concepts in clinical studies and patient monitoring, indicating a clear healthcare/biomedical application context.",
    "prompt_tokens": 20781,
    "completion_tokens": 112,
    "total_tokens": 20893,
    "topic": "Causal Inference - Functional Longitudinal Data",
    "method": "Nonparametric framework; g-computation formula; Monte Carlo simulations",
    "application": "Causal identification for real-time monitoring data",
    "code_link": "N/A",
    "dataset_name": [
      "MIMIC-IV",
      "Continuous Glucose Monitoring (CGM)"
    ]
  },
  {
    "id": "WBUVagRgsd",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Salvage: Shapley-distribution Approximation Learning Via Attribution Guided Exploration for Explainable Image Classification",
    "authors": [
      "Mehdi Naouar",
      "Hanne Raum",
      "Jens Rahnfeld",
      "Yannick Vogt",
      "Joschka Boedecker",
      "Gabriel Kalweit",
      "Maria Kalweit"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The integration of deep learning into critical vision application areas has given rise to a necessity for techniques that can explain the rationale behind predictions. In this paper, we address this need by introducing Salvage, a novel removal-based explainability method for image classification. Our approach involves training an explainer model that learns the prediction distribution of the classifier on masked images. We first introduce the concept of Shapley-distributions, which offers a more accurate approximation of classification probability distributions than existing methods. Furthermore, we address the issue of unbalanced important and unimportant features. In such settings, naive uniform sampling of feature subsets often results in a highly unbalanced ratio of samples with high and low prediction likelihoods, which can hinder effective learning. To mitigate this, we propose an informed sampling strategy that leverages approximated feature importance scores, thereby reducing imbalance and facilitating the estimation of underrepresented features. After incorporating these two principles into our method, we conducted an extensive analysis on the ImageNette, MURA, WBC, and Pet datasets. The results show that Salvage outperforms various baseline explainability methods, including attention-, gradient-, and removal-based approaches, both qualitatively and quantitatively. Furthermore, we demonstrate that our explainer model can serve as a fully explainable classifier without a major decrease in classification performance, paving the way for fully explainable image classification.",
    "keywords": "Explainability, XAI, feature attribution",
    "pdf_url": "https://openreview.net/pdf?id=WBUVagRgsd",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although Salvage proposes a general explainability method for image classification, the authors specifically evaluate it on medical imaging datasets such as MURA (musculoskeletal radiographs) and WBC (white blood cell) classification. Use of these clinical radiology and pathology data indicates direct relevance to healthcare/biomedicine applications.",
    "prompt_tokens": 20562,
    "completion_tokens": 96,
    "total_tokens": 20658,
    "topic": "Explainability - Image Classification",
    "method": "Shapley value approximation; removal-based methods",
    "application": "Explainable image classification",
    "code_link": "N/A",
    "dataset_name": [
      "ImageNette",
      "MURA",
      "WBC",
      "Pet"
    ]
  },
  {
    "id": "nYjAzwor9R",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Tree-Wasserstein Distance for High Dimensional Data with a Latent Feature Hierarchy",
    "authors": [
      "Ya-Wei Eileen Lin",
      "Ronald R. Coifman",
      "Gal Mishne",
      "Ronen Talmon"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Finding meaningful distances between high-dimensional data samples is an important scientific task. To this end, we propose a new tree-Wasserstein distance (TWD) for high-dimensional data with two key aspects. First, our TWD is specifically designed for data with a latent feature hierarchy, i.e., the features lie in a hierarchical space, in contrast to the usual focus on embedding samples in hyperbolic space. Second, while the conventional use of TWD is to speed up the computation of the Wasserstein distance, we use its inherent tree as a means to learn the latent feature hierarchy. The key idea of our method is to embed the features into a multi-scale hyperbolic space using diffusion geometry and then present a new tree decoding method by establishing analogies between the hyperbolic embedding and trees. We show that our TWD computed based on data observations provably recovers the TWD defined with the latent feature hierarchy and that its computation is efficient and scalable. We showcase the usefulness of the proposed TWD in applications to word-document and single-cell RNA-sequencing datasets, demonstrating its advantages over existing TWDs and methods based on pre-trained models.",
    "keywords": "diffusion geometry, hyperbolic geometry, tree-Wasserstein distance, high-dimensional hyperbolic tree decoding",
    "pdf_url": "https://openreview.net/pdf?id=nYjAzwor9R",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the paper develops a general Tree-Wasserstein distance for high-dimensional data, one of the key example applications is on single-cell RNA-sequencing datasets, which is clearly a genomics/biomedical domain task. Single-cell RNA-seq is a core tool in modern biomedical research, so the work’s direct application to that data makes it relevant to Biomedicine AI.",
    "prompt_tokens": 20715,
    "completion_tokens": 131,
    "total_tokens": 20846,
    "topic": "Metric Learning - Latent Hierarchical Features",
    "method": "Tree-Wasserstein Distance (TWD); Hyperbolic Embedding",
    "application": "Document classification; Cell classification",
    "code_link": "https://github.com/ya-wei-eileen-lin/TWDwithLatentFeatureHierarchy",
    "dataset_name": [
      "BBCSPORT",
      "TWITTER",
      "CLASSIC",
      "AMAZON",
      "Zeisel",
      "CBMC"
    ]
  },
  {
    "id": "DpLFmc09pC",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "DEPfold: RNA Secondary Structure Prediction as Dependency Parsing.",
    "authors": [
      "KE WANG",
      "Shay B Cohen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "RNA secondary structure prediction is critical for understanding RNA function\nbut remains challenging due to complex structural elements like pseudoknots and\nlimited training data. We introduce DEPfold, a novel deep learning approach that\nre-frames RNA secondary structure prediction as a dependency parsing problem.\nDEPfold presents three key innovations: (1) a biologically motivated transformation of RNA structures into labeled dependency trees, (2) a biaffine attention\nmechanism for joint prediction of base pairings and their types, and (3) an optimal\ntree decoding algorithm that enforces valid RNA structural constraints. Unlike traditional energy-based methods, DEPfold learns directly from annotated data and\nleverages pretrained language models to predict RNA structure. We evaluate DEPfold on both within-family and cross-family RNA datasets, demonstrating significant performance improvements over existing methods. DEPfold shows strong\nperformance in cross-family generalization when trained on data augmented by\ntraditional energy-based models, outperforming existing methods on the bpRNAnew dataset. This demonstrates DEPfold’s ability to effectively learn structural\ninformation beyond what traditional methods capture. Our approach bridges natural language processing (NLP) with RNA biology, providing a computationally\nefficient and adaptable tool for advancing RNA structure prediction and analysis",
    "keywords": "RNA secondary structure prediction, Dependency parsing, Biaffine attention, Pseudoknots, Pretrained Model, Deep learning",
    "pdf_url": "https://openreview.net/pdf?id=DpLFmc09pC",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on predicting RNA secondary structure—a core problem in molecular biology and genomics. It develops a deep-learning model for RNA folding, explicitly addressing pseudoknots and leveraging annotated RNA datasets. RNA structure prediction is fundamental to understanding gene regulation and drug design, placing this work squarely in the **Biomedicine AI** domain.",
    "prompt_tokens": 20997,
    "completion_tokens": 118,
    "total_tokens": 21115,
    "topic": "Bioinformatics - RNA Structure Prediction",
    "method": "Dependency Parsing; Biaffine Parsing; Foundation Model Embedding",
    "application": "RNA secondary structure prediction",
    "code_link": "https://github.com/Vicky-0256/DEPfold.git",
    "dataset_name": [
      "RNAStrAlign",
      "ArchiveII",
      "bpRNA-1m",
      "bpRNA-new"
    ]
  },
  {
    "id": "9qS3HzSDNv",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Integrating Protein Dynamics into Structure-Based Drug Design via Full-Atom Stochastic Flows",
    "authors": [
      "Xiangxin Zhou",
      "Yi Xiao",
      "Haowei Lin",
      "Xinheng He",
      "Jiaqi Guan",
      "Yang Wang",
      "Qiang Liu",
      "Feng Zhou",
      "Liang Wang",
      "Jianzhu Ma"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The dynamic nature of proteins, influenced by ligand interactions, is essential for comprehending protein function and progressing drug discovery. Traditional structure-based drug design (SBDD) approaches typically target binding sites with rigid structures, limiting their practical application in drug development. While molecular dynamics simulation can theoretically capture all the biologically relevant conformations, the transition rate is dictated by the intrinsic energy barrier between them, making the sampling process computationally expensive. To overcome the aforementioned challenges, we propose to use generative modeling for SBDD considering conformational changes of protein pockets. We curate a dataset of apo and multiple holo states of protein-ligand complexes, simulated by molecular dynamics, and propose a full-atom flow model (and a stochastic version), named DynamicFlow, that learns to transform apo pockets and noisy ligands into holo pockets and corresponding 3D ligand molecules. Our method uncovers promising ligand molecules and corresponding holo conformations of pockets. Additionally, the resultant holo-like states provide superior inputs for traditional SBDD approaches, playing a significant role in practical drug discovery.",
    "keywords": "flow matching, structure-based drug design, protein dynamics",
    "pdf_url": "https://openreview.net/pdf?id=9qS3HzSDNv",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on structure-based drug design (SBDD) by modeling protein dynamics and ligand interactions (“apo and multiple holo states of protein-ligand complexes,” “DynamicFlow”) to uncover novel candidate molecules. This is directly relevant to drug discovery and molecular modeling, which are core topics in Biomedicine AI.",
    "prompt_tokens": 20578,
    "completion_tokens": 88,
    "total_tokens": 20666,
    "topic": "Drug Discovery - Structure-based Design",
    "method": "Diffusion model; flow matching",
    "application": "Drug binding prediction and ligand generation",
    "code_link": "N/A",
    "dataset_name": [
      "MISATO"
    ]
  },
  {
    "id": "HAwZGLcye3",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "BioDiscoveryAgent: An AI Agent for Designing Genetic Perturbation Experiments",
    "authors": [
      "Yusuf H Roohani",
      "Andrew H. Lee",
      "Qian Huang",
      "Jian Vora",
      "Zachary Steinhart",
      "Kexin Huang",
      "Alexander Marson",
      "Percy Liang",
      "Jure Leskovec"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Agents based on large language models have shown great potential in accelerating scientific discovery by leveraging their rich background knowledge and reasoning capabilities. In this paper, we introduce BioDiscoveryAgent, an agent that designs new experiments, reasons about their outcomes, and efficiently navigates the hypothesis space to reach desired solutions. We demonstrate our agent on the problem of designing genetic perturbation experiments, where the aim is to find a small subset out of many possible genes that, when perturbed, result in a specific phenotype (e.g., cell growth). Utilizing its biological knowledge, BioDiscoveryAgent can uniquely design new experiments without the need to train a machine learning model or explicitly design an acquisition function as in Bayesian optimization. Moreover, BioDiscoveryAgent using Claude 3.5 Sonnet achieves an average of 21% improvement in predicting relevant genetic perturbations across six datasets, and a 46% improvement in the harder task of non-essential gene perturbation, compared to existing Bayesian optimization baselines specifically trained for this task. Our evaluation includes one dataset that is unpublished, ensuring it is not part of the language model's training data. Additionally, BioDiscoveryAgent predicts gene combinations to perturb more than twice as accurately as a random baseline, a task so far not explored in the context of closed-loop experiment design. The agent also has access to tools for searching the biomedical literature, executing code to analyze biological datasets, and prompting another agent to critically evaluate its predictions. Overall, BioDiscoveryAgent is interpretable at every stage, representing an accessible new paradigm in the computational design of biological experiments with the potential to augment scientists' efficacy.",
    "keywords": "large language models, agents, computational biology, genomics, AI for scientific discovery",
    "pdf_url": "https://openreview.net/pdf?id=HAwZGLcye3",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on designing genetic perturbation experiments to identify gene subsets that cause specific cellular phenotypes. It involves genomics, perturbing genes to study cell growth, and uses computational biology tools—clear indicators of Biomedicine AI. The keywords “genomics,” “genetic perturbation,” and references to “phenotype” and “biological datasets” confirm its relevance to biomedical research.",
    "prompt_tokens": 20626,
    "completion_tokens": 166,
    "total_tokens": 20792,
    "topic": "Bioinformatics - Genetic Perturbation Experiment Design",
    "method": "Large Language Model (LLM)-based agent; Gene search using Reactome pathways; Bayesian optimizations in baselines",
    "application": "Design and prediction of genetic perturbations in biological experiments",
    "code_link": "https://www.github.com/snap-stanford/BioDiscoveryAgent",
    "dataset_name": [
      "Schmidt1 IFNG",
      "Schmidt2 IL-2",
      "CAR-T",
      "Scharenberg lysosomal choline recycling",
      "Carnevale adenosine immunosuppressive resist",
      "Sanchez tau protein neurons"
    ]
  },
  {
    "id": "8fLgt7PQza",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Reasoning-Enhanced Healthcare Predictions with Knowledge Graph Community Retrieval",
    "authors": [
      "Pengcheng Jiang",
      "Cao Xiao",
      "Minhao Jiang",
      "Parminder Bhatia",
      "Taha Kass-Hout",
      "Jimeng Sun",
      "Jiawei Han"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Large language models (LLMs) have demonstrated significant potential in clinical decision support. Yet LLMs still suffer from hallucinations and lack fine-grained contextual medical knowledge, limiting their high-stake healthcare applications such as clinical diagnosis. Traditional retrieval-augmented generation (RAG) methods attempt to address these limitations but frequently retrieve sparse or irrelevant information, undermining prediction accuracy. We introduce KARE, a novel framework that integrates knowledge graph (KG) community-level retrieval with LLM reasoning to enhance healthcare predictions. KARE constructs a comprehensive multi-source KG by integrating biomedical databases, clinical literature, and LLM-generated insights, and organizes it using hierarchical graph community detection and summarization for precise and contextually relevant information retrieval. Our key innovations include: (1) a dense medical knowledge structuring approach enabling accurate retrieval of relevant information; (2) a dynamic knowledge retrieval mechanism that enriches patient contexts with focused, multi-faceted medical insights; and (3) a reasoning-enhanced prediction framework that leverages these enriched contexts to produce both accurate and interpretable clinical predictions. Extensive experiments demonstrate that KARE outperforms leading models by up to 10.8-15.0\\% on MIMIC-III and 12.6-12.7\\% on MIMIC-IV for mortality and readmission predictions. In addition to its impressive prediction accuracy, our framework leverages the reasoning capabilities of LLMs, enhancing the trustworthiness of clinical predictions.",
    "keywords": "EHR Prediction, Large Language Models, Knowledge Graphs",
    "pdf_url": "https://openreview.net/pdf?id=8fLgt7PQza",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on clinical decision support and EHR-based prediction tasks (mortality and readmission) using MIMIC-III and MIMIC-IV data, integrates biomedical knowledge graphs, and targets healthcare outcomes. These clearly place it within the Healthcare AI domain.",
    "prompt_tokens": 20474,
    "completion_tokens": 117,
    "total_tokens": 20591,
    "topic": "EHR - Predictive Models",
    "method": "Graph community retrieval; Knowledge graph indexing; Context augmentation with knowledge graphs; LLM reasoning; Fine-tuning",
    "application": "Mortality prediction; Readmission prediction",
    "code_link": "https://github.com/pat-jj/KARE",
    "dataset_name": [
      "MIMIC-III",
      "MIMIC-IV"
    ]
  },
  {
    "id": "9htTvHkUhh",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Beyond Sequence: Impact of Geometric Context for RNA Property Prediction",
    "authors": [
      "Junjie Xu",
      "Artem Moskalev",
      "Tommaso Mansi",
      "Mangal Prakash",
      "Rui Liao"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Accurate prediction of RNA properties, such as stability and interactions, is crucial for advancing our understanding of biological processes and developing RNA-based therapeutics. RNA structures can be represented as 1D sequences, 2D topological graphs, or 3D all-atom models, each offering different insights into its function. Existing works predominantly focus on 1D sequence-based models, which overlook the geometric context provided by 2D and 3D geometries. This study presents the first systematic evaluation of incorporating explicit 2D and 3D geometric information into RNA property prediction, considering not only performance but also real-world challenges such as limited data availability, partial labeling, sequencing noise, and computational efficiency. To this end, we introduce a newly curated set of RNA datasets with enhanced 2D and 3D structural annotations, providing a resource for model evaluation on RNA data. Our findings reveal that models with explicit geometry encoding generally outperform sequence-based models, with an average prediction RMSE reduction of around 12% across all various RNA tasks and excelling in low-data and partial labeling regimes, underscoring the value of explicitly incorporating geometric context. On the other hand, geometry-unaware sequence-based models are more robust under sequencing noise but often require around 2-5x training data to match the performance of geometry-aware models. Our study offers further insights into the trade-offs between different RNA representations in practical applications and addresses a significant gap in evaluating deep learning models for RNA tasks.",
    "keywords": "Geometric deep learning, Graph Neural Networks, GNNs, RNA property prediction, Datasets and Benchmarks",
    "pdf_url": "https://openreview.net/pdf?id=9htTvHkUhh",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work centers on predicting RNA properties such as stability and interactions, leveraging 2D and 3D RNA structural information. RNA modeling and “RNA-based therapeutics” are key aspects of biomedical research and drug discovery. The focus on “molecular modeling,” “RNA structure,” and therapeutic applications clearly places it within the Biomedicine AI domain.",
    "prompt_tokens": 20843,
    "completion_tokens": 103,
    "total_tokens": 20946,
    "topic": "Bioinformatics - RNA Structure Prediction",
    "method": "Geometric neural networks; Transformer-based models",
    "application": "RNA property prediction",
    "code_link": "N/A",
    "dataset_name": [
      "Tc-Riboswitches",
      "Open Vaccine COVID-19",
      "Ribonanza",
      "Fungal"
    ]
  },
  {
    "id": "H9UnNgdq0g",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "MediConfusion: Can you trust your AI radiologist? Probing the reliability of multimodal medical foundation models",
    "authors": [
      "Mohammad Shahab Sepehri",
      "Zalan Fabian",
      "Maryam Soltanolkotabi",
      "Mahdi Soltanolkotabi"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Multimodal Large Language Models (MLLMs) have tremendous potential to improve the accuracy, availability, and cost-effectiveness of healthcare by providing automated solutions or serving as aids to medical professionals. Despite promising first steps in developing medical MLLMs in the past few years, their capabilities and limitations are not well understood. Recently, many benchmark datasets have been proposed that test the general medical knowledge of such models across a variety of medical areas. However, the systematic failure modes and vulnerabilities of such models are severely underexplored with most medical benchmarks failing to expose the shortcomings of existing models in this safety-critical domain. In this paper, we introduce MediConfusion, a challenging medical Visual Question Answering (VQA) benchmark dataset, that probes the failure modes of medical MLLMs from a vision perspective. We reveal that state-of-the-art models are easily confused by image pairs that are otherwise visually dissimilar and clearly distinct for medical experts. Strikingly, all available models (open-source or proprietary) achieve performance below random guessing on MediConfusion, raising serious concerns about the reliability of existing medical MLLMs for healthcare deployment. We also extract common patterns of model failure that may help the design of a new generation of more trustworthy and reliable MLLMs in healthcare.",
    "keywords": "Medical foundation models, Benchmarking, Vision encoding, Radiology",
    "pdf_url": "https://openreview.net/pdf?id=H9UnNgdq0g",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper proposes a benchmark (“MediConfusion”) for testing multimodal medical foundation models on Visual Question Answering (VQA) in radiology images. It explicitly targets “AI radiologist” reliability and medical image understanding, which falls squarely within Healthcare AI (medical imaging).",
    "prompt_tokens": 20873,
    "completion_tokens": 104,
    "total_tokens": 20977,
    "topic": "Medical Imaging - Multimodal Evaluation",
    "method": "Contrastive pretraining; vision encoder refinement",
    "application": "Medical visual question answering (VQA)",
    "code_link": "https://github.com/AIF4S/MediConfusion",
    "dataset_name": [
      "MediConfusion",
      "ROCO"
    ]
  },
  {
    "id": "iezDdA9oeB",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Fast and Accurate Blind Flexible Docking",
    "authors": [
      "Zizhuo Zhang",
      "Lijun Wu",
      "Kaiyuan Gao",
      "Jiangchao Yao",
      "Tao Qin",
      "Bo Han"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Molecular docking that predicts the bound structures of small molecules (ligands) to their protein targets, plays a vital role in drug discovery. However, existing docking methods often face limitations: they either overlook crucial structural changes by assuming protein rigidity or suffer from low computational efficiency due to their reliance on generative models for structure sampling. To address these challenges, we propose FABFlex, a fast and accurate regression-based multi-task learning model designed for realistic blind flexible docking scenarios, where proteins exhibit flexibility and binding pocket sites are unknown (blind). Specifically, FABFlex's architecture comprises three specialized modules working in concert: (1) A pocket prediction module that identifies potential binding sites, addressing the challenges inherent in blind docking scenarios. (2) A ligand docking module that predicts the bound (holo) structures of ligands from their unbound (apo) states. (3) A pocket docking module that forecasts the holo structures of protein pockets from their apo conformations. Notably, FABFlex incorporates an iterative update mechanism that serves as a conduit between the ligand and pocket docking modules, enabling continuous structural refinements. This approach effectively integrates the three subtasks of blind flexible docking—pocket identification, ligand conformation prediction, and protein flexibility modeling—into a unified, coherent framework. Extensive experiments on public benchmark datasets demonstrate that FABFlex not only achieves superior effectiveness in predicting accurate binding modes but also exhibits a significant speed advantage (208$\\times$) compared to existing state-of-the-art methods. Our code is released at~\\url{https://github.com/tmlr-group/FABFlex}.",
    "keywords": "Blind Flexible Molecular Docking, Structure Prediction, AI4Science, Ligand-Protein Graph",
    "pdf_url": "https://openreview.net/pdf?id=iezDdA9oeB",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on molecular docking for predicting how small molecules bind to protein targets—a core problem in drug discovery and molecular modeling. Terms like “ligand-protein graph,” “blind flexible docking,” and “pocket prediction” indicate direct relevance to biomedical research and drug design, which firmly places it within the Biomedicine AI domain.",
    "prompt_tokens": 20237,
    "completion_tokens": 111,
    "total_tokens": 20348,
    "topic": "Drug Discovery - Flexible Docking",
    "method": "Regression-based multi-task learning; E(3)-equivariant graph neural networks",
    "application": "Molecular docking – ligand and protein binding structure prediction",
    "code_link": "https://github.com/tmlr-group/FABFlex",
    "dataset_name": [
      "PDBBind v2020"
    ]
  },
  {
    "id": "RyWypcIMiE",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Reframing Structure-Based Drug Design Model Evaluation via Metrics Correlated to Practical Needs",
    "authors": [
      "Bowen Gao",
      "Haichuan Tan",
      "Yanwen Huang",
      "Minsi Ren",
      "Xiao Huang",
      "Wei-Ying Ma",
      "Ya-Qin Zhang",
      "Yanyan Lan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Recent advances in structure-based drug design (SBDD) have produced surprising results, with models often generating molecules that achieve better Vina docking scores than actual ligands. However, these results are frequently overly optimistic due to the limitations of docking score accuracy and the challenges of wet-lab validation. While generated molecules may demonstrate high QED (drug-likeness) and SA (synthetic accessibility) scores, they often lack true drug-like properties or synthesizability. To address these limitations, we propose a model-level evaluation framework that emphasizes practical metrics aligned with real-world applications. Inspired by recent findings on the utility of generated molecules in ligand-based virtual screening, our framework evaluates SBDD models by their ability to produce molecules that effectively retrieve active compounds from chemical libraries via similarity-based searches. This approach provides a direct indication of therapeutic potential, bridging the gap between theoretical performance and real-world utility. Our experiments reveal that while SBDD models may excel in theoretical metrics like Vina scores, they often fall short in these practical metrics. By introducing this new evaluation strategy, we aim to enhance the relevance and impact of SBDD models for pharmaceutical research and development.",
    "keywords": "Stucture-Based Drug Design, Model Evaluation, Benchmark",
    "pdf_url": "https://openreview.net/pdf?id=RyWypcIMiE",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on structure-based drug design (SBDD) and evaluates models by their ability to generate and retrieve active compounds for therapeutic use. It deals explicitly with drug discovery, docking scores, QED/SA metrics, and ligand-based virtual screening—clear indicators of a biomedicine AI application in pharmaceutical research.",
    "prompt_tokens": 21011,
    "completion_tokens": 113,
    "total_tokens": 21124,
    "topic": "Drug Discovery - Structure-Based Development",
    "method": "Deep generative models; Virtual screening metrics",
    "application": "Binding affinity estimation",
    "code_link": "https://github.com/bowen-gao/sbdd_practical_evaluation",
    "dataset_name": [
      "PDBbind",
      "CrossDocked",
      "DUD-E",
      "LIT-PCBA"
    ]
  },
  {
    "id": "rQyg6MnsDb",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Biologically Plausible Brain Graph Transformer",
    "authors": [
      "Ciyuan Peng",
      "Yuelong Huang",
      "Qichao Dong",
      "Shuo Yu",
      "Feng Xia",
      "Chengqi Zhang",
      "Yaochu Jin"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "State-of-the-art brain graph analysis methods fail to fully encode the small-world architecture of brain graphs (accompanied by the presence of hubs and functional modules), and therefore lack biological plausibility to some extent. This limitation hinders their ability to accurately represent the brain's structural and functional properties, thereby restricting the effectiveness of machine learning models in tasks such as brain disorder detection. In this work, we propose a novel Biologically Plausible Brain Graph Transformer (BioBGT) that encodes the small-world architecture inherent in brain graphs. Specifically, we present a network entanglement-based node importance encoding technique that captures the structural importance of nodes in global information propagation during brain graph communication, highlighting the biological properties of the brain structure. Furthermore, we introduce a functional module-aware self-attention to preserve the functional segregation and integration characteristics of brain graphs in the learned representations. Experimental results on three benchmark datasets demonstrate that BioBGT outperforms state-of-the-art models, enhancing biologically plausible brain graph representations for various brain graph analytical tasks",
    "keywords": "brain, graph learning, transformer, graph representation, brain networks",
    "pdf_url": "https://openreview.net/pdf?id=rQyg6MnsDb",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This paper focuses on modeling and analyzing brain graphs—“small-world architecture of brain graphs,” “functional modules,” and “brain disorder detection”—which clearly situates it in the neurobiological/neuroscience domain. Its goal of improving representations for tasks like detecting brain disorders aligns with Healthcare AI and Biomedicine AI, particularly in neuroimaging and brain network analysis.",
    "prompt_tokens": 39406,
    "completion_tokens": 118,
    "total_tokens": 39524,
    "topic": "Brain Graph Analysis - Disease Detection",
    "method": "Graph Transformers; Functional Module-aware Self-attention",
    "application": "Disease classification – Neurological disorders",
    "code_link": "N/A",
    "dataset_name": [
      "ABIDE",
      "ADNI",
      "ADHD-200"
    ]
  },
  {
    "id": "hWmwL9gizZ",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Immunogenicity Prediction with Dual Attention Enables Vaccine Target Selection",
    "authors": [
      "Song Li",
      "Yang Tan",
      "Song Ke",
      "Liang Hong",
      "Bingxin Zhou"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Immunogenicity prediction is a central topic in reverse vaccinology for finding candidate vaccines that can trigger protective immune responses. Existing approaches typically rely on highly compressed features and simple model architectures, leading to limited prediction accuracy and poor generalizability. To address these challenges, we introduce VenusVaccine, a novel deep learning solution with a dual attention mechanism that integrates pre-trained latent vector representations of protein sequences and structures. We also compile the most comprehensive immunogenicity dataset to date, encompassing over 7000 antigen sequences, structures, and immunogenicity labels from bacteria, viruses, and tumors. Extensive experiments demonstrate that VenusVaccine outperforms existing methods across a wide range of evaluation metrics. Furthermore, we establish a post-hoc validation protocol to assess the practical significance of deep learning models in tackling vaccine design challenges. Our work provides an effective tool for vaccine design and sets valuable benchmarks for future research. The implementation is at \\url{https://github.com/songleee/VenusVaccine}.",
    "keywords": "protein language model, protein representation learning, immunogenicity prediction",
    "pdf_url": "https://openreview.net/pdf?id=hWmwL9gizZ",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on immunogenicity prediction for vaccine target selection, integrating protein sequence and structure representations to identify antigen candidates. Terms such as “reverse vaccinology,” “immunogenicity labels,” “antigen sequences, structures, and immunogenicity,” and “vaccine design” clearly place it in the biomedicine domain, specifically computational immunology and vaccine development.",
    "prompt_tokens": 20750,
    "completion_tokens": 117,
    "total_tokens": 20867,
    "topic": "Immunology - Vaccine Design",
    "method": "Dual attention mechanism; pre-trained protein language models; physicochemical descriptors",
    "application": "Immunogenicity prediction",
    "code_link": "https://github.com/songleee/VenusVaccine",
    "dataset_name": [
      "Immuno-Bacteria",
      "Immuno-Virus",
      "Immuno-Tumor"
    ]
  },
  {
    "id": "xayT1nn8Mg",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Deep Signature: Characterization of Large-Scale Molecular Dynamics",
    "authors": [
      "Tiexin Qin",
      "Mengxu ZHU",
      "Chunyang Li",
      "Terry Lyons",
      "Hong Yan",
      "Haoliang Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Understanding protein dynamics are essential for deciphering protein functional mechanisms and developing molecular therapies. However, the complex high-dimensional dynamics and interatomic interactions of biological processes pose significant challenge for existing computational techniques. In this paper, we approach this problem for the first time by introducing Deep Signature, a novel computationally tractable framework that characterizes complex dynamics and interatomic interactions based on their evolving trajectories. Specifically, our approach incorporates soft spectral clustering that locally aggregates cooperative dynamics to reduce the size of the system, as well as signature transform that collects iterated integrals to provide a global characterization of the non-smooth interactive dynamics. Theoretical analysis demonstrates that Deep Signature exhibits several desirable properties, including invariance to translation, near invariance to rotation, equivariance to permutation of atomic coordinates, and invariance under time reparameterization. Furthermore, experimental results on three benchmarks of biological processes verify that our approach can achieve superior performance compared to baseline methods.",
    "keywords": "Molecular dynamics; representation learning; graph neural network; path signature",
    "pdf_url": "https://openreview.net/pdf?id=xayT1nn8Mg",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on modeling “protein dynamics” and “interatomic interactions” in “biological processes” with direct implications for “understanding protein functional mechanisms and developing molecular therapies.” It leverages representation learning on molecular dynamics trajectories, a core task in biomedicine AI (e.g., drug discovery and molecular modeling).",
    "prompt_tokens": 20962,
    "completion_tokens": 111,
    "total_tokens": 21073,
    "topic": "Bioinformatics - Molecular Dynamics Analysis",
    "method": "Graph Neural Networks (GNN); Deep spectral clustering; Path signature transform",
    "application": "Protein property prediction",
    "code_link": "https://github.com/patrick-kidger/signatory",
    "dataset_name": [
      "Gene Regulatory Dynamics",
      "EGFR Mutation Dynamics",
      "GPCR Dynamics"
    ]
  },
  {
    "id": "OmpTdjl7RV",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Fast Direct: Query-Efficient  Online Black-box Guidance  for Diffusion-model Target Generation",
    "authors": [
      "Kim Yong Tan",
      "Yueming Lyu",
      "Ivor Tsang",
      "Yew-Soon Ong"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Guided diffusion-model generation is a promising direction for customizing the generation process of a pre-trained diffusion model to address specific downstream tasks. Existing guided diffusion models either rely on training the guidance model with pre-collected datasets or require the objective functions to be differentiable. However, for most real-world tasks, offline datasets are often unavailable, and their objective functions are often not differentiable, such as image generation with human preferences, molecular generation for drug discovery, and material design. Thus, we need an **online** algorithm capable of collecting data during runtime and supporting a **black-box** objective function. Moreover, the **query efficiency** of the algorithm is also critical because the objective evaluation of the query is often expensive in real-world scenarios. In this work, we propose a novel and simple algorithm, **Fast Direct**, for query-efficient online black-box target generation. Our Fast Direct builds a pseudo-target on the data manifold to update the noise sequence of the diffusion model with a universal direction, which is promising to perform query-efficient guided generation. Extensive experiments on twelve high-resolution ($\\small {1024 \\times 1024}$) image target generation tasks and six 3D-molecule target generation tasks show $\\textbf{6}\\times$ up to $\\textbf{10}\\times$ query efficiency improvement and $\\textbf{11}\\times$ up to $\\textbf{44}\\times$ query efficiency improvement, respectively.",
    "keywords": "Diffusion model, Black-box target generation, Online guided diffusion model, Query-efficient",
    "pdf_url": "https://openreview.net/pdf?id=OmpTdjl7RV",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the core contribution is a generic, query-efficient guidance algorithm for diffusion models, the paper explicitly motivates and evaluates on “molecular generation for drug discovery” and reports results on “six 3D-molecule target generation tasks.” These tasks fall squarely under AI-driven drug discovery, a key area of Biomedicine AI.",
    "prompt_tokens": 20752,
    "completion_tokens": 102,
    "total_tokens": 20854,
    "topic": "Image Generation - Prompt Alignment",
    "method": "Diffusion model; Gaussian process surrogate; Pseudo-target optimization",
    "application": "Image-prompt alignment",
    "code_link": "https://huggingface.co/ByteDance/SDXL-Lightning",
    "dataset_name": [
      "CrossDocked2020"
    ]
  },
  {
    "id": "LvTSvdiSwG",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "On the Fourier analysis in the SO(3) space : the EquiLoPO Network",
    "authors": [
      "Dmitrii Zhemchuzhnikov",
      "Sergei Grudinin"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Analyzing volumetric data with rotational invariance or equivariance is currently an active research topic. Existing deep-learning approaches utilize either group convolutional networks limited to discrete rotations or steerable convolutional networks with constrained filter structures. This work proposes a novel equivariant neural network architecture that achieves analytical Equivariance to Local Pattern Orientation on the continuous SO(3) group while allowing unconstrained trainable filters - EquiLoPO Network. Our key innovations are a group convolutional operation leveraging irreducible representations as the Fourier basis and a local activation function in the SO(3) space that provides a well-defined mapping from input to output functions, preserving equivariance. By integrating these operations into a ResNet-style architecture, we propose a model that overcomes the limitations of prior methods. A comprehensive evaluation on diverse 3D medical imaging datasets from MedMNIST3D demonstrates the effectiveness of our approach, which consistently outperforms state of the art. This work suggests the benefits of true rotational equivariance on SO(3) and flexible unconstrained filters enabled by the local activation function, providing a flexible framework for equivariant deep learning on volumetric data with potential applications across domains. Our code is publicly available at https://gricad-gitlab.univ-grenoble-alpes.fr/GruLab/ILPO/-/tree/main/EquiLoPO.",
    "keywords": "Equivariance, Fourier Analysis, SO(3), MedMNIST3D, Local Activation, CNN, Group Convolution, Computer Vision, 3D Medical Images",
    "pdf_url": "https://openreview.net/pdf?id=LvTSvdiSwG",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper specifically evaluates its method on “diverse 3D medical imaging datasets from MedMNIST3D,” indicating that the application domain is medical imaging. Techniques for volumetric data analysis with true rotational equivariance on SO(3) are applied to 3D medical scans, a core Healthcare AI task.",
    "prompt_tokens": 20818,
    "completion_tokens": 127,
    "total_tokens": 20945,
    "topic": "Medical Imaging - Volumetric Data Equivariance",
    "method": "Group convolutional networks; local activation functions",
    "application": "Binary and multi-class classification – 3D medical imaging",
    "code_link": "https://gricad-gitlab.univ-grenoble-alpes.fr/GruLab/ILPO/-/tree/main/EquiLoPO",
    "dataset_name": [
      "MedMNIST v2"
    ]
  },
  {
    "id": "XsgHl54yO7",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Unlocking Guidance for Discrete State-Space Diffusion and Flow Models",
    "authors": [
      "Hunter Nisonoff",
      "Junhao Xiong",
      "Stephan Allenspach",
      "Jennifer Listgarten"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Generative models on discrete state-spaces have a wide range of potential applications, particularly in the domain of natural sciences. In continuous state-spaces, controllable and flexible generation of samples with desired properties has been realized using guidance on diffusion and flow models. However, these guidance approaches are not readily amenable to discrete state-space models. Consequently, we introduce a general and principled method for applying guidance on such models. Our method depends on leveraging continuous-time Markov processes on discrete state-spaces, which unlocks computational tractability for sampling from a desired guided distribution. We demonstrate the utility of our approach, Discrete Guidance, on a range of applications including guided generation of small-molecules, DNA sequences and protein sequences.",
    "keywords": "discrete state-space generative models, diffusion, flow-matching, flow models, guidance, protein design",
    "pdf_url": "https://openreview.net/pdf?id=XsgHl54yO7",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on generative modeling for “small-molecules, DNA sequences and protein sequences,” and explicitly mentions applications in protein design. These are core tasks in molecular modeling, drug discovery, and synthetic biology, which fall squarely within Biomedicine AI.",
    "prompt_tokens": 20730,
    "completion_tokens": 118,
    "total_tokens": 20848,
    "topic": "Generative Models - Discrete State-Spaces",
    "method": "Discrete Guidance; continuous-time Markov chain; flow matching; diffusion models",
    "application": "Small-molecule generation; protein and DNA sequence design",
    "code_link": "https://github.com/andrew-cr/discrete_flow_models",
    "dataset_name": [
      "QMugs",
      "ChEMBL"
    ]
  },
  {
    "id": "6Hz1Ko087B",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Reading Your Heart: Learning ECG Words and Sentences via Pre-training ECG Language Model",
    "authors": [
      "Jiarui Jin",
      "Haoyu Wang",
      "Hongyan Li",
      "Jun Li",
      "Jiahui Pan",
      "Shenda Hong"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Electrocardiogram (ECG) is essential for the clinical diagnosis of arrhythmias and other heart diseases, but deep learning methods based on ECG often face limitations due to the need for high-quality annotations. Although previous ECG self-supervised learning (eSSL) methods have made significant progress in representation learning from unannotated ECG data, they typically treat ECG signals as ordinary time-series data, segmenting the signals using fixed-size and fixed-step time windows, which often ignore the form and rhythm characteristics and latent semantic relationships in ECG signals. In this work, we introduce a novel perspective on ECG signals, treating heartbeats as words and rhythms as sentences. Based on this perspective, we first designed the QRS-Tokenizer, which generates semantically meaningful ECG sentences from the raw ECG signals. Building on these, we then propose HeartLang, a novel self-supervised learning framework for ECG language processing, learning general representations at form and rhythm levels. Additionally, we construct the largest heartbeat-based ECG vocabulary to date, which will further advance the development of ECG language processing. We evaluated HeartLang across six public ECG datasets, where it demonstrated robust competitiveness against other eSSL methods. Our data and code are publicly available at https://github.com/PKUDigitalHealth/HeartLang.",
    "keywords": "Electrocardiogram, ECG, Cardiac signal, Self-supervised learning, ECG language processing",
    "pdf_url": "https://openreview.net/pdf?id=6Hz1Ko087B",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on processing electrocardiogram (ECG) signals—clinical time-series data used for arrhythmia and heart disease diagnosis—by treating heartbeats as “words” and rhythms as “sentences.” It introduces a QRS-Tokenizer and evaluates on six public ECG datasets, which clearly situates it within healthcare/biomedical AI.",
    "prompt_tokens": 20517,
    "completion_tokens": 139,
    "total_tokens": 20656,
    "topic": "ECG Analysis - Representation Learning",
    "method": "Self-supervised learning; Transformer-based models",
    "application": "ECG classification and diagnosis",
    "code_link": "https://github.com/PKUDigitalHealth/HeartLang",
    "dataset_name": [
      "MIMIC-IV-ECG",
      "PTB-XL",
      "CPSC2018",
      "Chapman-Shaoxing-Ningbo (CSN)"
    ]
  },
  {
    "id": "WQV9kB1qSU",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Transition Path Sampling with Improved Off-Policy Training of Diffusion Path Samplers",
    "authors": [
      "Kiyoung Seong",
      "Seonghyun Park",
      "Seonghwan Kim",
      "Woo Youn Kim",
      "Sungsoo Ahn"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Understanding transition pathways between two meta-stable states of a molecular system is crucial to advance drug discovery and material design. However, unbiased molecular dynamics (MD) simulations are computationally infeasible because of the high energy barriers that separate these states. Although recent machine learning techniques are proposed to sample rare events, they are often limited to simple systems and rely on collective variables (CVs) derived from costly domain expertise. In this paper, we introduce a novel approach that trains diffusion path samplers (DPS) to address the transition path sampling (TPS) problem without requiring CVs. We reformulate the problem as an amortized sampling from the transition path distribution by minimizing the log-variance divergence between the path distribution induced by DPS and the transition path distribution. Based on the log-variance divergence, we propose learnable control variates to reduce the variance of gradient estimators and the off-policy training objective with replay buffers and simulated annealing techniques to improve sample efficiency and diversity. We also propose a scale-based equivariant parameterization of the bias forces to ensure scalability for large systems. We extensively evaluate our approach, termed TPS-DPS, on a synthetic system, small peptide, and challenging fast-folding proteins, demonstrating that it produces more realistic and diverse transition pathways than existing baselines. We also provide links to [project page](https://kiyoung98.github.io/tps-dps/) and [code](https://github.com/kiyoung98/tps-dps).",
    "keywords": "molecular dynamics, transition path sampling",
    "pdf_url": "https://openreview.net/pdf?id=WQV9kB1qSU",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the paper focuses on a general molecular‐dynamics sampling method, it explicitly motivates the work in the context of drug discovery (“understand transition pathways … to advance drug discovery and material design”) and applies the approach to biomolecular systems (peptides and fast‐folding proteins). Sampling rare conformational transitions in proteins is a core task in biomedicine and pharmaceutical research. Therefore, this work falls within the Biomedicine AI domain.",
    "prompt_tokens": 20147,
    "completion_tokens": 127,
    "total_tokens": 20274,
    "topic": "Molecular Dynamics - Transition Path Sampling",
    "method": "Diffusion path samplers; SE(3)-equivariant parameterization; Log-variance divergence minimization",
    "application": "Sampling molecular transition paths",
    "code_link": "N/A",
    "dataset_name": [
      "Double-well data",
      "Alanine Dipeptide",
      "Chignolin",
      "Trp-cage",
      "BBA",
      "BBL"
    ]
  },
  {
    "id": "10JOlFIPjt",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "In vivo cell-type and brain region classification via multimodal contrastive learning",
    "authors": [
      "Han Yu",
      "Hanrui Lyu",
      "YiXun Xu",
      "Charlie Windolf",
      "Eric Kenji Lee",
      "Fan Yang",
      "Andrew M Shelton",
      "Olivier Winter",
      "International Brain Laboratory",
      "Eva L Dyer",
      "Chandramouli Chandrasekaran",
      "Nicholas A. Steinmetz",
      "Liam Paninski",
      "Cole Lincoln Hurwitz"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Current electrophysiological approaches can track the activity of many neurons, yet it is usually unknown which cell-types or brain areas are being recorded without further molecular or histological analysis. Developing accurate and scalable algorithms for identifying the cell-type and brain region of recorded neurons is thus crucial for improving our understanding of neural computation. In this work, we develop a multimodal contrastive learning approach for neural data that can be fine-tuned for different downstream tasks, including inference of cell-type and brain location. We utilize multimodal contrastive learning to jointly embed the activity autocorrelations and extracellular waveforms of individual neurons. We demonstrate that our embedding approach, Neuronal Embeddings via MultimOdal Contrastive Learning (NEMO), paired with supervised fine-tuning, achieves state-of-the-art cell-type classification for two opto-tagged datasets and brain region classification for the public International Brain Laboratory Brain-wide Map dataset. Our method represents a promising step towards accurate cell-type and brain region classification from electrophysiological recordings.",
    "keywords": "contrastive learning, electrophysiology, extracellular, multimodal, neuroscience, cell type, brain region, Neuropixels, deep learning",
    "pdf_url": "https://openreview.net/pdf?id=10JOlFIPjt",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on classifying neuronal cell types and brain regions from electrophysiological recordings, which is a form of neurobiological modeling. It specifically addresses “in vivo cell-type and brain region classification” using multimodal contrastive learning on neural data—falling squarely under biomedical research in neuroscience (e.g., “neuron type classification,” “brain region classification,” “extracellular waveforms,” “Neuropixels”). These are strong indicators of a Biomedicine AI application.",
    "prompt_tokens": 20673,
    "completion_tokens": 121,
    "total_tokens": 20794,
    "topic": "Neuroscience - Multimodal Data Classification",
    "method": "Multimodal contrastive learning; CLIP-based pretraining",
    "application": "Cell-type classification; Brain region classification",
    "code_link": "https://ibl-nemo.github.io/",
    "dataset_name": [
      "NP Ultra opto-tagged mouse data",
      "C4 cerebellum dataset",
      "IBL Brain-wide Map dataset"
    ]
  },
  {
    "id": "zmmfsJpYcq",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "IgGM: A Generative Model for Functional Antibody and Nanobody Design",
    "authors": [
      "Rubo Wang",
      "Fandi Wu",
      "Xingyu Gao",
      "Jiaxiang Wu",
      "Peilin Zhao",
      "Jianhua Yao"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Immunoglobulins are crucial proteins produced by the immune system to identify and bind to foreign substances, playing an essential role in shielding organisms from infections and diseases. Designing specific antibodies opens new pathways for disease treatment. With the rise of deep learning, AI-driven drug design has become possible, leading to several methods for antibody design. However, many of these approaches require additional conditions that differ from real-world scenarios, making it challenging to incorporate them into existing antibody design processes. Here, we introduce IgGM, a generative model for the de novo design of immunoglobulins with functional specificity. IgGM simultaneously generates antibody sequences and structures for a given antigen, consisting of three core components: a pre-trained language model for extracting sequence features, a feature learning module for identifying pertinent features, and a prediction module that outputs designed antibody sequences and the predicted complete antibody-antigen complex structure. IgGM effectively predicts structures and designs novel antibodies and nanobodies. This makes it highly applicable in a wide range of practical situations related to antibody and nanobody design. Code is available at: https://github.com/TencentAI4S/IgGM.",
    "keywords": "de novo antibody design, complex structure prediction, protein design",
    "pdf_url": "https://openreview.net/pdf?id=zmmfsJpYcq",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on de novo design of immunoglobulins (antibodies and nanobodies) with functional specificity against antigens, a clear application in protein design for therapeutic antibodies. It describes “complex structure prediction” and “antibody design,” both central to drug discovery and biomedicine.",
    "prompt_tokens": 20750,
    "completion_tokens": 119,
    "total_tokens": 20869,
    "topic": "Protein Design - Antibody Generation",
    "method": "Generative Modeling; Consistency Models",
    "application": "Antibody and Nanobody Structure Prediction and Design",
    "code_link": "https://github.com/TencentAI4S/IgGM",
    "dataset_name": [
      "SAb-23H2-Ab",
      "SAb-2023H2-Nano"
    ]
  },
  {
    "id": "iuxaCU3DI7",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Recognize Any Surgical Object: Unleashing the Power of Weakly-Supervised Data",
    "authors": [
      "Jiajie Li",
      "Brian R Quaranto",
      "Chenhui Xu",
      "Ishan Mishra",
      "Ruiyang Qin",
      "Dancheng Liu",
      "Peter C W Kim",
      "Jinjun Xiong"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We present RASO, a foundation model designed to Recognize Any Surgical Object, offering robust open-set recognition capabilities across a broad range of surgical procedures and object classes, in both surgical images and videos. RASO leverages a novel weakly-supervised learning framework that generates tag-image-text pairs automatically from large-scale unannotated surgical lecture videos, significantly reducing the need for manual annotations. Our scalable data generation pipeline gathers 2,200 surgical procedures and produces 3.6 million tag annotations across 2,066 unique surgical tags. Our experiments show that RASO achieves improvements of 2.9 mAP, 4.5 mAP, 10.6 mAP, and 7.2 mAP on four standard surgical benchmarks respectively in zero-shot settings, and surpasses state-of-the-art models in supervised surgical action recognition tasks. We will open-source our code, model, and dataset to facilitate further research.",
    "keywords": "Image Recognition, Vision-Language Pretraining, Image Tagging, Medical Imaging, Surgery",
    "pdf_url": "https://openreview.net/pdf?id=iuxaCU3DI7",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper develops a vision‐language foundation model specifically for recognizing surgical objects and actions in medical imaging and video. It leverages “large‐scale unannotated surgical lecture videos,” targets “surgical procedures and object classes,” and reports performance on “standard surgical benchmarks,” all of which clearly situate it in the healthcare AI domain.",
    "prompt_tokens": 20855,
    "completion_tokens": 107,
    "total_tokens": 20962,
    "topic": "Surgical AI - Object Recognition",
    "method": "Vision-language pretraining; Temporal-attention fusion",
    "application": "Surgical object recognition",
    "code_link": "N/A",
    "dataset_name": [
      "CholecT50",
      "Cholec80",
      "RSS (EndoVis18)",
      "GraSP"
    ]
  },
  {
    "id": "NkGDNM8LB0",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Hyperbolic Genome Embeddings",
    "authors": [
      "Raiyan R. Khan",
      "Philippe Chlenski",
      "Itsik Pe'er"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Current approaches to genomic sequence modeling often struggle to align the inductive biases of machine learning models with the evolutionarily-informed structure of biological systems. To this end, we formulate a novel application of hyperbolic CNNs that exploits this structure, enabling more expressive DNA sequence representations. Our strategy circumvents the need for explicit phylogenetic mapping while discerning key properties of sequences pertaining to core functional and regulatory behavior. Across 37 out of 42 genome interpretation benchmark datasets, our hyperbolic models outperform their Euclidean equivalents. Notably, our approach even surpasses state-of-the-art performance on seven GUE benchmark datasets, consistently outperforming many DNA language models while using orders of magnitude fewer parameters and avoiding pretraining. Our results include a novel set of benchmark datasets---the Transposable Elements Benchmark---which explores a major but understudied component of the genome with deep evolutionary significance. We further motivate our work by exploring how our hyperbolic models recognize genomic signal under various data-generating conditions and by constructing an empirical method for interpreting the hyperbolicity of dataset embeddings. Throughout these assessments, we find persistent evidence highlighting the potential of our hyperbolic framework as a robust paradigm for genome representation learning. Our code and benchmark datasets are available at https://github.com/rrkhan/HGE.",
    "keywords": "genomics, representation learning, hyperbolic geometry",
    "pdf_url": "https://openreview.net/pdf?id=NkGDNM8LB0",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “genomic sequence modeling,” “DNA sequence representations,” and introduces a “Transposable Elements Benchmark,” all of which are squarely in the domain of computational genomics. Genomics is a core aspect of biomedical research, making this work a clear fit for Biomedicine AI.",
    "prompt_tokens": 20897,
    "completion_tokens": 121,
    "total_tokens": 21018,
    "topic": "Bioinformatics - Sequence Representations",
    "method": "Fully hyperbolic CNN",
    "application": "Genome sequence classification",
    "code_link": "https://github.com/rrkhan/HGE",
    "dataset_name": [
      "Genome Understanding Evaluation (GUE)",
      "Transposable Elements Benchmark (TEB)",
      "Genomic Benchmarks (GB)"
    ]
  },
  {
    "id": "jlzNb1iWs3",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "The OMG dataset: An Open MetaGenomic corpus for mixed-modality genomic language modeling",
    "authors": [
      "Andre Cornman",
      "Jacob West-Roberts",
      "Antonio Pedro Camargo",
      "Simon Roux",
      "Martin Beracochea",
      "Milot Mirdita",
      "Sergey Ovchinnikov",
      "Yunha Hwang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Biological language model performance depends heavily on pretraining data quality, diversity, and size. While metagenomic datasets feature enormous biological diversity, their utilization as pretraining data has been limited due to challenges in data accessibility, quality filtering and deduplication. Here, we present the Open MetaGenomic (OMG) corpus, a genomic pretraining dataset totalling 3.1T base pairs and 3.3B protein coding sequences, obtained by combining two largest metagenomic dataset repositories (JGI's IMG and EMBL's MGnify). We first document the composition of the dataset and describe the quality filtering steps taken to remove poor quality data. We make the OMG corpus available as a mixed-modality genomic sequence dataset that represents multi-gene encoding genomic sequences with translated amino acids for protein coding sequences, and nucleic acids for intergenic sequences. We train the first mixed-modality genomic language model (gLM2) that leverages genomic context information to learn robust functional representations, as well as coevolutionary signals in protein-protein interfaces and genomic regulatory syntax. Furthermore, we show that deduplication in embedding space can be used to balance the corpus, demonstrating improved performance on downstream tasks. The OMG dataset is publicly hosted on the Hugging Face Hub at https://huggingface.co/datasets/tattabio/OMG and gLM2 is available at https://huggingface.co/tattabio/gLM2_650M.",
    "keywords": "metagenomics, pretraining dataset, genomic language model",
    "pdf_url": "https://openreview.net/pdf?id=jlzNb1iWs3",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This paper focuses on building large‐scale genomic language models using metagenomic sequence data (“Open MetaGenomic corpus,” “3.1T base pairs and 3.3B protein coding sequences”) and aims to learn “robust functional representations” of proteins and regulatory DNA. Genomics and protein function modeling are core topics in biomedical AI, even if not directly tied to clinical datasets, and are explicitly listed under “biomedical research” contexts (e.g., genomics, protein design).",
    "prompt_tokens": 20777,
    "completion_tokens": 119,
    "total_tokens": 20896,
    "topic": "Bioinformatics - Genomic Language Models",
    "method": "Mixed-modality genomic language modeling; Semantic deduplication",
    "application": "Genomic sequence representation learning",
    "code_link": "https://huggingface.co/tattabio/gLM2_650M",
    "dataset_name": [
      "Open MetaGenome (OMG)",
      "OMG_prot50",
      "Open Genome (OG)"
    ]
  },
  {
    "id": "TVQLu34bdw",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Proteina: Scaling Flow-based Protein Structure Generative Models",
    "authors": [
      "Tomas Geffner",
      "Kieran Didi",
      "Zuobai Zhang",
      "Danny Reidenbach",
      "Zhonglin Cao",
      "Jason Yim",
      "Mario Geiger",
      "Christian Dallago",
      "Emine Kucukbenli",
      "Arash Vahdat",
      "Karsten Kreis"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Recently, diffusion- and flow-based generative models of protein structures have emerged as a powerful tool for de novo protein design. Here, we develop *Proteina*, a new large-scale flow-based protein backbone generator that utilizes hierarchical fold class labels for conditioning and relies on a tailored scalable transformer architecture with up to $5\\times$ as many parameters as previous models. To meaningfully quantify performance, we introduce a new set of metrics that directly measure the distributional similarity of generated proteins with reference sets, complementing existing metrics. We further explore scaling training data to millions of synthetic protein structures and explore improved training and sampling recipes adapted to protein backbone generation. This includes fine-tuning strategies like LoRA for protein backbones, new guidance methods like classifier-free guidance and autoguidance for protein backbones, and new adjusted training objectives. Proteina achieves state-of-the-art performance on de novo protein backbone design and produces diverse and designable proteins at unprecedented length, up to 800 residues. The hierarchical conditioning offers novel control, enabling high-level secondary-structure guidance as well as low-level fold-specific generation.",
    "keywords": "protein structure generation, de novo protein design, flow matching, fold class conditioning",
    "pdf_url": "https://openreview.net/pdf?id=TVQLu34bdw",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “protein structure generation” and “de novo protein design,” which are core tasks in biomedicine and drug discovery. It proposes a large-scale flow‐based model for generating synthetic protein backbones—a method directly relevant to molecular modeling and protein engineering in biomedical research. The use of millions of synthetic protein structures and hierarchical fold conditioning further underscores its application to biomedical protein design rather than purely abstract ML.",
    "prompt_tokens": 20526,
    "completion_tokens": 94,
    "total_tokens": 20620,
    "topic": "Bioinformatics - Protein Generation",
    "method": "Diffusion model; Transformer-based models",
    "application": "Protein backbone generation",
    "code_link": "https://github.com/Wangchentong/Proteus",
    "dataset_name": [
      "DFS",
      "D21M"
    ]
  },
  {
    "id": "CGON8Btleu",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "BrainACTIV: Identifying visuo-semantic properties driving cortical selectivity using diffusion-based image manipulation",
    "authors": [
      "Diego Garcia Cerdas",
      "Christina Sartzetaki",
      "Magnus Petersen",
      "Gemma Roig",
      "Pascal Mettes",
      "Iris Groen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The human brain efficiently represents visual inputs through specialized neural populations that selectively respond to specific categories. Advancements in generative modeling have enabled data-driven discovery of neural selectivity using brain-optimized image synthesis. However, current methods independently generate one sample at a time, without enforcing structural constraints on the generations; thus, these individual images have no explicit point of comparison, making it hard to discern which image features drive neural response selectivity. To address this issue, we introduce Brain Activation Control Through Image Variation (BrainACTIV), a method for manipulating a reference image to enhance or decrease activity in a target cortical region using pretrained diffusion models. Starting from a reference image allows for fine-grained and reliable offline identification of optimal visuo-semantic properties, as well as producing controlled stimuli for novel neuroimaging studies. We show that our manipulations effectively modulate predicted fMRI responses and agree with hypothesized preferred categories in established regions of interest, while remaining structurally close to the reference image.  Moreover, we demonstrate how our method accentuates differences between brain regions that are selective to the same category, and how it could be used to explore neural representation of brain regions with unknown selectivities. Hence, BrainACTIV holds the potential to formulate robust hypotheses about brain representation and to facilitate the production of naturalistic stimuli for neuroscientific experiments.",
    "keywords": "brain, selectivity, visual cortex, fMRI, manipulation, variation, diffusion, neuroscience",
    "pdf_url": "https://openreview.net/pdf?id=CGON8Btleu",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work centers on manipulating visual stimuli to probe and modulate fMRI responses in specific cortical regions (“enhance or decrease activity in a target cortical region using pretrained diffusion models,” “predicted fMRI responses,” “brain regions that are selective to the same category”). It is firmly rooted in neuroimaging and neuroscience research, which falls under the Biomedicine AI domain.",
    "prompt_tokens": 21055,
    "completion_tokens": 108,
    "total_tokens": 21163,
    "topic": "Neuroscience - Visual Cortex Selectivity",
    "method": "Diffusion model; Brain encoders",
    "application": "Image manipulation for brain activation modulation",
    "code_link": "https://github.com/diegogcerdas/BrainACTIV",
    "dataset_name": [
      "Natural Scenes Dataset (NSD)",
      "MS COCO"
    ]
  },
  {
    "id": "IwgmgidYPS",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "MedTrinity-25M: A Large-scale Multimodal Dataset with Multigranular Annotations for Medicine",
    "authors": [
      "Yunfei Xie",
      "Ce Zhou",
      "Lang Gao",
      "Juncheng Wu",
      "Xianhang Li",
      "Hong-Yu Zhou",
      "Sheng Liu",
      "Lei Xing",
      "James Zou",
      "Cihang Xie",
      "Yuyin Zhou"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "This paper introduces MedTrinity-25M, a comprehensive, large-scale multimodal dataset for medicine, covering over 25 million images across 10 modalities with multigranular annotations for more than 65 diseases. These multigranular annotations encompass both global information, such as modality and organ detection, and local information like ROI analysis, lesion texture, and region-wise correlations. Unlike the existing multimodal datasets, which are limited by the availability of image-text pairs, we have developed the first automated pipeline that scales up multimodal data by generating multigranular visual and textual annotations in the form of image-ROI-description triplets without the need for any paired text descriptions. Specifically, data from over 30 different sources have been collected, preprocessed, and grounded using domain-specific expert models to identify ROIs related to abnormal regions. We then build a comprehensive knowledge base and prompt multimodal large language models to perform retrieval-augmented generation with the identified ROIs as guidance, resulting in multigranular textual descriptions. Compared to existing datasets, MedTrinity-25M provides the most enriched annotations, supporting a comprehensive range of multimodal tasks such as captioning and report generation, as well as vision-centric tasks like classification and segmentation. We propose LLaVA-Tri by pretraining LLaVA on MedTrinity-25M, achieving state-of-the-art performance on VQA-RAD, SLAKE, and PathVQA, surpassing representative SOTA multimodal large language models. Furthermore, MedTrinity-25M can also be utilized to support large-scale pre-training of multimodal medical AI models, contributing to the development of future foundation models in the medical domain. We will make our dataset available. The dataset is publicly available at https://yunfeixie233.github.io/MedTrinity-25M/.",
    "keywords": "Medical Foundation Model, Multimodal Dataset, Vision-Language Pretraining.",
    "pdf_url": "https://openreview.net/pdf?id=IwgmgidYPS",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper introduces MedTrinity-25M, a massive multimodal medical imaging dataset annotated for over 65 diseases across 10 clinical modalities. It explicitly targets medical vision-language tasks (e.g., report generation, VQA-RAD, SLAKE, PathVQA), ROI lesion analysis, and foundation model pretraining for “medical AI models” in the “medical domain.” These strong references to CT/MRI/ultrasound, disease detection, radiology report generation, and clinical imaging clearly place it in the Healthcare AI / Biomedicine AI domain.",
    "prompt_tokens": 20366,
    "completion_tokens": 108,
    "total_tokens": 20474,
    "topic": "Medical Vision Language Models - VQA Alignment",
    "method": "Vision-language pretraining; retrieval-augmented generation",
    "application": "Medical visual question answering",
    "code_link": "N/A",
    "dataset_name": [
      "MedTrinity-25M",
      "VQA-RAD",
      "SLAKE",
      "PathVQA"
    ]
  },
  {
    "id": "oCHsDpyawq",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "ZAPBench: A Benchmark for Whole-Brain Activity Prediction in Zebrafish",
    "authors": [
      "Jan-Matthis Lueckmann",
      "Alexander Immer",
      "Alex Bo-Yuan Chen",
      "Peter H. Li",
      "Mariela D Petkova",
      "Nirmala A Iyer",
      "Luuk Willem Hesselink",
      "Aparna Dev",
      "Gudrun Ihrke",
      "Woohyun Park",
      "Alyson Petruncio",
      "Aubrey Weigel",
      "Wyatt Korff",
      "Florian Engert",
      "Jeff Lichtman",
      "Misha Ahrens",
      "Michal Januszewski",
      "Viren Jain"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Data-driven benchmarks have led to significant progress in key scientific modeling domains including weather and structural biology. Here, we introduce the Zebrafish Activity Prediction Benchmark (ZAPBench) to measure progress on the problem of predicting cellular-resolution neural activity throughout an entire vertebrate brain. The benchmark is based on a novel dataset containing 4d light-sheet microscopy recordings of over 70,000 neurons in a larval zebrafish brain, along with motion stabilized and voxel-level cell segmentations of these data that facilitate development of a variety of forecasting methods. Initial results from a selection of time series and volumetric video modeling approaches achieve better performance than naive baseline methods, but also show room for further improvement. The specific brain used in the activity recording is also undergoing synaptic-level anatomical mapping, which will enable future integration of detailed structural information into forecasting methods.",
    "keywords": "neuroscience, zebrafish, forecasting, benchmark, timeseries, lightsheet microscopy, calcium imaging",
    "pdf_url": "https://openreview.net/pdf?id=oCHsDpyawq",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work focuses on whole-brain neural activity prediction in a vertebrate model (larval zebrafish), using 4D light-sheet microscopy and cell-level segmentations. It falls squarely under neurobiological modeling—“predicting cellular-resolution neural activity” and “synaptic-level anatomical mapping” are strong indicators of a biomedical AI application in the neuroscience domain.",
    "prompt_tokens": 21030,
    "completion_tokens": 98,
    "total_tokens": 21128,
    "topic": "Neuroscience - Whole-brain Activity Forecasting",
    "method": "Time series models; Volumetric video modeling",
    "application": "Neural activity prediction",
    "code_link": "https://github.com/google-research/zapbench",
    "dataset_name": [
      "ZAPBench"
    ]
  },
  {
    "id": "B5VEi5d3p2",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "SleepSMC: Ubiquitous Sleep Staging via Supervised Multimodal Coordination",
    "authors": [
      "Shuo Ma",
      "Yingwei Zhang",
      "Yiqiang Chen",
      "Hualei Wang",
      "Yuan Jin",
      "Wei Zhang",
      "Ziyu Jia"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Sleep staging is critical for assessing sleep quality and tracking health. Polysomnography (PSG) provides comprehensive multimodal sleep-related information, but its complexity and impracticality limit its practical use in daily and ubiquitous monitoring. Conversely, unimodal devices offer more convenience but less accuracy. Existing multimodal learning paradigms typically assume that the data types remain consistent between the training and testing phases. This makes it challenging to leverage information from other modalities in ubiquitous scenarios (e.g., at home) where only one modality is available. To address this issue, we introduce a novel framework for ubiquitous Sleep staging via Supervised Multimodal Coordination, called SleepSMC. To capture category-related consistency and complementarity across modality-level instances, we propose supervised modality-level instance contrastive coordination. Specifically, modality-level instances within the same category are considered positive pairs, while those from different categories are considered negative pairs. To explore the varying reliability of auxiliary modalities, we calculate uncertainty estimates based on the variance in confidence scores for correct predictions during multiple rounds of random masks. These uncertainty estimates are employed to assign adaptive weights to multiple auxiliary modalities during contrastive learning, ensuring that the primary modality learns from high-quality, category-related features. Experimental results on four public datasets, ISRUC-S3, MASS-SS3, Sleep-EDF-78, and ISRUC-S1, show that SleepSMC achieves state-of-the-art cross-subject performance. SleepSMC significantly improves performance when only one modality is present during testing, making it suitable for ubiquitous sleep monitoring.",
    "keywords": "Sleep staging, Multimodal coordination, Ubiquitous computing",
    "pdf_url": "https://openreview.net/pdf?id=B5VEi5d3p2",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on sleep staging using polysomnography (PSG) and wearable modalities (e.g., EEG, EOG) to assess sleep quality and support ubiquitous sleep monitoring. Sleep staging is a clinical task in sleep medicine for patient monitoring and health assessment, and the datasets (ISRUC-S3, MASS-SS3, Sleep-EDF) are biomedical signal datasets. This clearly falls under Healthcare AI.",
    "prompt_tokens": 20529,
    "completion_tokens": 106,
    "total_tokens": 20635,
    "topic": "Time Series - Sleep Stage Classification",
    "method": "Uncertainty-based feature weighting; Supervised modality-level contrastive learning",
    "application": "Sleep stage classification",
    "code_link": "N/A",
    "dataset_name": [
      "ISRUC-S1",
      "ISRUC-S3",
      "MASS-SS3",
      "Sleep-EDF-78"
    ]
  },
  {
    "id": "JQtuCumAFD",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Conformalized Survival Analysis for General Right-Censored Data",
    "authors": [
      "Hen Davidov",
      "Shai Feldman",
      "Gil Shamai",
      "Ron Kimmel",
      "Yaniv Romano"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We develop a framework to quantify predictive uncertainty in survival analysis, providing a reliable lower predictive bound (LPB) for the true, unknown patient survival time. Recently, conformal prediction has been used to construct such valid LPBs for *type-I right-censored data*, with the guarantee that the bound holds with high probability. Crucially, under the type-I setting, the censoring time is observed for all data points. As such, informative LPBs can be constructed by framing the calibration as an estimation task with covariate shift, relying on the conditionally independent censoring assumption. This paper expands the conformal toolbox for survival analysis, with the goal of handling the ubiquitous *general right-censored setting*, in which either the censoring or survival time is observed, but not both. The key challenge here is that the calibration cannot be directly formulated as a covariate shift problem anymore. Yet, we show how to construct LPBs with distribution-free finite-sample guarantees, under the same assumptions as conformal approaches for type-I censored data. Experiments demonstrate the informativeness and validity of our methods in simulated settings and showcase their practical utility using several real-world datasets.",
    "keywords": "conformal prediction, survival analysis, PAC, covariate shift, uncertainty quantification",
    "pdf_url": "https://openreview.net/pdf?id=JQtuCumAFD",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper develops conformal prediction methods for survival analysis and explicitly refers to “the true, unknown patient survival time.” Survival analysis with right‐censored data is a core technique in clinical prognosis and healthcare outcome modeling. By providing valid predictive bounds for patient survival, the work addresses a fundamental healthcare AI task—quantifying uncertainty in patient time-to-event predictions.",
    "prompt_tokens": 20499,
    "completion_tokens": 124,
    "total_tokens": 20623,
    "topic": "Survival Analysis - Calibration Methods",
    "method": "Conformal prediction; Focused calibration; Fused calibration",
    "application": "Lower predictive bounds for survival time - Survival Analysis",
    "code_link": "N/A",
    "dataset_name": [
      "Northern Alberta Cancer Dataset (NACD)",
      "GBSG",
      "METABRIC",
      "SUPPORT",
      "Customer churn prediction dataset",
      "TCGA-BRCA"
    ]
  },
  {
    "id": "L07zWidgdW",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Finding Shared Decodable Concepts and their Negations in the Brain",
    "authors": [
      "Cory Daniel Efird",
      "Alex Murphy",
      "Joel Zylberberg",
      "Alona Fyshe"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Prior work has offered evidence for functional localization in the brain; different anatomical regions preferentially activate for certain types of visual input. For example, the fusiform face area preferentially activates for visual stimuli that include a face. However, the spectrum of visual semantics is extensive, and only a few semantically-tuned patches of cortex have so far been identified in the human brain. Using a multimodal (natural language and image) neural network architecture (CLIP, \\cite{CLIP}, we train a highly accurate contrastive model that maps brain responses during naturalistic image viewing to CLIP embeddings. We then use a novel adaptation of the DBSCAN clustering algorithm to cluster the parameters of these participant-specific contrastive models. This reveals what we call Shared Decodable Concepts (SDCs): clusters in CLIP space that are decodable from common sets of voxels across multiple participants.\n\nExamining the images most and least associated with each SDC cluster gives us additional insight into the semantic properties of each SDC. We note SDCs for previously reported visual features (e.g. orientation tuning in early visual cortex) as well as visual semantic concepts such as faces, places and bodies. In cases where our method finds multiple clusters for a visuo-semantic concept, the least associated images allow us to dissociate between confounding factors. For example, we discovered two clusters of food images, one driven by color, the other by shape. We also uncover previously unreported areas with visuo-semantic sensitivity such as regions of extrastriate body area (EBA) tuned for legs/hands and sensitivity to numerosity in right intraparietal sulcus, sensitivity associated with visual perspective (close/far) and more. Thus, our contrastive-learning methodology better characterizes new and existing visuo-semantic representations in the brain by leveraging multimodal neural network representations and a novel adaptation of clustering algorithms.",
    "keywords": "fMRI, decoding, computer vision, neuroscience",
    "pdf_url": "https://openreview.net/pdf?id=L07zWidgdW",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The work uses fMRI (a biomedical neuroimaging modality) to decode brain activity (“maps brain responses during naturalistic image viewing to CLIP embeddings”) and uncovers visuo-semantic representations in specific cortical regions. According to the guidelines, “fMRI” and “brain decoding” are strong indicators of relevance to Healthcare AI/Biomedicine AI under neuroscience or neurobiological modeling.",
    "prompt_tokens": 20971,
    "completion_tokens": 105,
    "total_tokens": 21076,
    "topic": "Neuroscience - Multimodal Brain Decoding",
    "method": "Contrastive learning; DBSCAN clustering",
    "application": "Concept recognition in fMRI neural data",
    "code_link": "https://github.com/fyshelab/contrastive-decoding-iclr2025",
    "dataset_name": [
      "NSD (Natural Scenes Dataset)"
    ]
  },
  {
    "id": "jqmptcSNVG",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Hotspot-Driven Peptide Design via Multi-Fragment Autoregressive Extension",
    "authors": [
      "Jiahan Li",
      "Tong Chen",
      "Shitong Luo",
      "Chaoran Cheng",
      "Jiaqi Guan",
      "Ruihan Guo",
      "Sheng Wang",
      "Ge Liu",
      "Jian Peng",
      "Jianzhu Ma"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Peptides, short chains of amino acids, interact with target proteins, making them a unique class of protein-based therapeutics for treating human diseases. Recently, deep generative models have shown great promise in peptide generation. However, several challenges remain in designing effective peptide binders. First, not all residues contribute equally to peptide-target interactions. Second, the generated peptides must adopt valid geometries due to the constraints of peptide bonds. Third, realistic tasks for peptide drug development are still lacking.\nTo address these challenges, we introduce PepHAR, a hot-spot-driven autoregressive generative model for designing peptides targeting specific proteins. Building on the observation that certain hot spot residues have higher interaction potentials, we first use an energy-based density model to fit and sample these key residues. Next, to ensure proper peptide geometry, we autoregressively extend peptide fragments by estimating dihedral angles between residue frames. Finally, we apply an optimization process to iteratively refine fragment assembly, ensuring correct peptide structures.\nBy combining hot spot sampling with fragment-based extension, our approach enables \\textit{de novo} peptide design tailored to a target protein and allows the incorporation of key hot spot residues into peptide scaffolds. Extensive experiments, including peptide design and peptide scaffold generation, demonstrate the strong potential of PepHAR in computational peptide binder design. The source code will be available at https://github.com/Ced3-han/PepHAR.",
    "keywords": "AI for Science; Protein Design; Generative Models;",
    "pdf_url": "https://openreview.net/pdf?id=jqmptcSNVG",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on de novo peptide design for binding specific proteins with therapeutic aims, explicitly addressing “peptide-based therapeutics” and “drug development.” It leverages protein design and molecular modeling—key bioinformatics tasks in biomedicine AI.",
    "prompt_tokens": 20393,
    "completion_tokens": 111,
    "total_tokens": 20504,
    "topic": "Bioinformatics - Peptide Design",
    "method": "Autoregressive generative modeling; energy-based modeling; dihedral angle optimization",
    "application": "Peptide binder generation and scaffold generation",
    "code_link": "https://github.com/Ced3-han/PepHAR",
    "dataset_name": [
      "PepBDB",
      "Q-BioLip"
    ]
  },
  {
    "id": "1vrpdV9U3i",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Variational Search Distributions",
    "authors": [
      "Daniel M. Steinberg",
      "Rafael Oliveira",
      "Cheng Soon Ong",
      "Edwin V. Bonilla"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We develop VSD, a method for conditioning a generative model of discrete, combinatorial designs on a rare desired class by efficiently evaluating a black-box (e.g. experiment, simulation) in a batch sequential manner. We call this task active generation; we formalize active generation's requirements and desiderata, and formulate a solution via variational inference. VSD uses off-the-shelf gradient based optimization routines, can learn powerful generative models for desirable designs, and can take advantage of scalable predictive models. We derive asymptotic convergence rates for learning the true conditional generative distribution of designs with certain configurations of our method. After illustrating the generative model on images, we empirically demonstrate that VSD can outperform existing baseline methods on a set of real sequence-design problems in various protein and DNA/RNA engineering tasks.",
    "keywords": "black box optimization, Bayesian optimization, variational inference, generative models, level set estimation, biological sequence design, protein engineering, fine tuning",
    "pdf_url": "https://openreview.net/pdf?id=1vrpdV9U3i",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper applies its variational search method to “real sequence‐design problems in various protein and DNA/RNA engineering tasks.” Protein engineering and DNA/RNA sequence design are central to biomedical research (e.g., drug discovery, synthetic biology), so this work falls under Biomedicine AI.",
    "prompt_tokens": 20993,
    "completion_tokens": 140,
    "total_tokens": 21133,
    "topic": "Bioinformatics - Sequence Design",
    "method": "Variational Inference; Variational Search Distributions (VSD)",
    "application": "Biological sequence generation",
    "code_link": "https://github.com/csiro-funml/variationalsearch",
    "dataset_name": [
      "TFBIND8",
      "TrpB",
      "DHFR",
      "AAV",
      "GFP",
      "Ehrlich-15",
      "Ehrlich-32",
      "Ehrlich-64"
    ]
  },
  {
    "id": "6EUtjXAvmj",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Variational Diffusion Posterior Sampling with Midpoint Guidance",
    "authors": [
      "Badr MOUFAD",
      "Yazid Janati",
      "Lisa Bedin",
      "Alain Oliviero Durmus",
      "randal douc",
      "Eric Moulines",
      "Jimmy Olsson"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Diffusion models have recently shown considerable potential in solving Bayesian inverse problems when used as priors. However, sampling from the resulting denoising posterior distributions remains a challenge as it involves intractable terms. To tackle this issue, state-of-the-art approaches formulate the problem as that of sampling from a surrogate diffusion model targeting the posterior and decompose its scores into two terms: the prior score and an intractable guidance term. While the former is replaced by the pre-trained score of the considered diffusion model, the guidance term has to be estimated. In this paper, we propose a novel approach that utilises a decomposition of the transitions which, in contrast to previous methods, allows a trade-off between the complexity of the intractable guidance term and that of the prior transitions. We validate the proposed approach through extensive experiments on linear and nonlinear inverse problems, including challenging cases with latent diffusion models as priors, and demonstrate its effectiveness in reconstructing electrocardiogram (ECG) from partial measurements for accurate cardiac diagnosis.",
    "keywords": "Diffusion models, Inverse problems, posterior sampling",
    "pdf_url": "https://openreview.net/pdf?id=6EUtjXAvmj",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly validates its method by “reconstructing electrocardiogram (ECG) from partial measurements for accurate cardiac diagnosis.” ECG reconstruction and cardiac diagnosis are healthcare AI tasks involving biomedical signal processing. Hence it belongs to the Healthcare AI / Biomedicine AI domain.",
    "prompt_tokens": 21004,
    "completion_tokens": 101,
    "total_tokens": 21105,
    "topic": "Time Series - ECG Reconstruction",
    "method": "Latent Diffusion Model (LDM); Structured State Space Diffusion",
    "application": "ECG imputation and reconstruction",
    "code_link": "https://github.com/yazidjanati/mgps",
    "dataset_name": [
      "PTB-XL"
    ]
  },
  {
    "id": "TUKt7ag0qq",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Metalic: Meta-Learning In-Context with Protein Language Models",
    "authors": [
      "Jacob Beck",
      "Shikha Surana",
      "Manus McAuliffe",
      "Oliver Bent",
      "Thomas D Barrett",
      "Juan Jose Garau-Luis",
      "Paul Duckworth"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Predicting the biophysical and functional properties of proteins is essential for in silico protein design. Machine learning has emerged as a promising technique for such prediction tasks. However, the relative scarcity of in vitro annotations means that these models often have little, or no, specific data on the desired fitness prediction task. As a result of limited data, protein language models (PLMs) are typically trained on general protein sequence modeling tasks, and then fine-tuned, or applied zero-shot, to protein fitness prediction. When no task data is available, the models make strong assumptions about the correlation between the protein sequence likelihood and fitness scores. In contrast, we propose meta-learning over a distribution of standard fitness prediction tasks, and demonstrate positive transfer to unseen fitness prediction tasks. Our method, called Metalic (Meta-Learning In-Context), uses in-context learning and fine-tuning, when data is available, to adapt to new tasks. Crucially, fine-tuning enables considerable generalization, even though it is not accounted for during meta-training. Our fine-tuned models achieve strong results with 18 times fewer parameters than state-of-the-art models. Moreover, our method sets a new state-of-the-art in low-data settings on ProteinGym, an established fitness-prediction benchmark. Due to data scarcity, we believe meta-learning will play a pivotal role in advancing protein engineering.",
    "keywords": "Meta-Learning, In-context Learning, Tuning, Protein, Fitness Prediction, Property Prediction, Protein Language Model, PLM, Large Language Model",
    "pdf_url": "https://openreview.net/pdf?id=TUKt7ag0qq",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work focuses on meta-learning for protein language models to predict protein “fitness” and biophysical properties, which falls squarely under molecular modeling and protein design—key tasks in biomedical research and drug discovery. Terms like “protein engineering,” “fitness prediction,” and use of benchmarks such as ProteinGym indicate relevance to biomedicine AI, even though no direct clinical or patient data are used.",
    "prompt_tokens": 20905,
    "completion_tokens": 117,
    "total_tokens": 21022,
    "topic": "Bioinformatics - Protein Fitness",
    "method": "In-context meta-learning; fine-tuning; protein language models (PLMs)",
    "application": "Protein fitness prediction",
    "code_link": "https://github.com/instadeepai/metalic",
    "dataset_name": [
      "ProteinGym"
    ]
  },
  {
    "id": "PstM8YfhvI",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "MorphoDiff: Cellular Morphology Painting with Diffusion Models",
    "authors": [
      "Zeinab Navidi",
      "Jun Ma",
      "Esteban Miglietta",
      "Le Liu",
      "Anne E Carpenter",
      "Beth A Cimini",
      "Benjamin Haibe-Kains",
      "BO WANG"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Understanding cellular responses to external stimuli is critical for parsing biological mechanisms and advancing therapeutic development. High-content image-based assays provide a cost-effective approach to examine cellular phenotypes induced by diverse interventions, which offers valuable insights into biological processes and cellular states. We introduce MorphoDiff, a generative pipeline to predict high-resolution cell morphological responses under different conditions based on perturbation encoding. To the best of our knowledge, MorphoDiff is the first framework capable of producing guided, high-resolution predictions of cell morphology that generalize across both chemical and genetic interventions. The model integrates perturbation embeddings as guiding signals within a 2D latent diffusion model. The comprehensive computational, biological, and visual validations across three open-source Cell Painting datasets show that MorphoDiff can generate high-fidelity images and produce meaningful biology signals under various interventions. We envision the model will facilitate efficient in silico exploration of perturbational landscapes towards more effective drug discovery studies.",
    "keywords": "Generative Modelling, Latent Diffusion Model, Cell Painting, Morphology, Drug Response Prediction, Cellular Phenotype, Machine Learning",
    "pdf_url": "https://openreview.net/pdf?id=PstM8YfhvI",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: MorphoDiff focuses on predicting cellular morphological responses to chemical and genetic perturbations using high-content Cell Painting assays. The abstract explicitly mentions “drug response prediction,” “perturbational landscapes,” and “drug discovery studies,” indicating direct application in biomedical research and therapeutic development.",
    "prompt_tokens": 20617,
    "completion_tokens": 115,
    "total_tokens": 20732,
    "topic": "Bioinformatics - Cellular Morphology",
    "method": "Diffusion model; Latent space projection; Conditional image generation",
    "application": "Cell morphology prediction – Genetic and chemical perturbations",
    "code_link": "https://github.com/bowang-lab/MorphoDiff",
    "dataset_name": [
      "RxRx1",
      "BBBC021",
      "Rohban"
    ]
  },
  {
    "id": "HNOo4UNPBF",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Scale-Aware Contrastive Reverse Distillation for Unsupervised Medical Anomaly Detection",
    "authors": [
      "Chunlei Li",
      "Yilei Shi",
      "Jingliang Hu",
      "Xiao Xiang Zhu",
      "Lichao Mou"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Unsupervised anomaly detection using deep learning has garnered significant research attention due to its broad applicability, particularly in medical imaging where labeled anomalous data are scarce. While earlier approaches leverage generative models like autoencoders and generative adversarial networks (GANs), they often fall short due to overgeneralization. Recent methods explore various strategies, including memory banks, normalizing flows, self-supervised learning, and knowledge distillation, to enhance discrimination. Among these, knowledge distillation, particularly reverse distillation, has shown promise. Following this paradigm, we propose a novel scale-aware contrastive reverse distillation model that addresses two key limitations of existing reverse distillation methods: insufficient feature discriminability and inability to handle anomaly scale variations. Specifically, we introduce a contrastive student-teacher learning approach to derive more discriminative representations by generating and exploring out-of-normal distributions. Further, we design a scale adaptation mechanism to softly weight contrastive distillation losses at different scales to account for the scale variation issue. Extensive experiments on benchmark datasets demonstrate state-of-the-art performance, validating the efficacy of the proposed method. The code will be made publicly available.",
    "keywords": "unsupervised anomaly detection, medical images, contrastive reverse distillation, student-teacher",
    "pdf_url": "https://openreview.net/pdf?id=HNOo4UNPBF",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly targets “unsupervised anomaly detection” in “medical imaging,” addressing challenges in detecting anomalies in medical images where labeled data are scarce. This clearly situates the work in the medical domain, making it a Healthcare AI contribution.",
    "prompt_tokens": 20863,
    "completion_tokens": 120,
    "total_tokens": 20983,
    "topic": "Medical Imaging - Anomaly Detection",
    "method": "Reverse distillation; contrastive learning; scale adaptation mechanism",
    "application": "Unsupervised anomaly detection – medical imaging",
    "code_link": "https://github.com/MedAITech/SCRD4AD",
    "dataset_name": [
      "RSNA Pneumonia Detection Challenge",
      "Brain Tumor MRI",
      "ISIC 2018"
    ]
  },
  {
    "id": "rFpZnn11gj",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "PathGen-1.6M: 1.6 Million Pathology Image-text Pairs Generation through Multi-agent Collaboration",
    "authors": [
      "Yuxuan Sun",
      "Yunlong Zhang",
      "Yixuan Si",
      "Chenglu Zhu",
      "Kai Zhang",
      "Zhongyi Shui",
      "Jingxiong Li",
      "Xuan Gong",
      "XINHENG LYU",
      "Tao Lin",
      "Lin Yang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Vision Language Models (VLMs) like CLIP have attracted substantial attention in pathology, serving as backbones for applications such as zero-shot image classification and Whole Slide Image (WSI) analysis. Additionally, they can function as vision encoders when combined with large language models (LLMs) to support broader capabilities. Current efforts to train pathology VLMs rely on pathology image-text pairs from platforms like PubMed, YouTube, and Twitter, which provide limited, unscalable data with generally suboptimal image quality. In this work, we leverage large-scale WSI datasets like TCGA to extract numerous high-quality image patches. We then train a large multimodal model (LMM) to generate captions for extracted images, creating PathGen-1.6M, a dataset containing 1.6 million high-quality image-caption pairs. Our approach involves multiple agent models collaborating to extract representative WSI patches, generating and refining captions to obtain high-quality image-text pairs. Extensive experiments show that integrating these generated pairs with existing datasets to train a pathology-specific CLIP model, PathGen-CLIP, significantly enhances its ability to analyze pathological images, with substantial improvements across nine pathology-related zero-shot image classification tasks and three whole-slide image tasks. Furthermore, we construct 200K instruction-tuning data based on PathGen-1.6M and integrate PathGen-CLIP with the Vicuna LLM to create more powerful multimodal models through instruction tuning. Overall, we provide a scalable pathway for high-quality data generation in pathology, paving the way for next-generation general pathology models. Our dataset, code, and model are open-access at https://github.com/PathFoundation/PathGen-1.6M.",
    "keywords": "Image-text pairs generation, Vision-language models, Multi-agent collaboration",
    "pdf_url": "https://openreview.net/pdf?id=rFpZnn11gj",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on pathology—extracting patches from whole‐slide images (WSI) and generating high‐quality image–text pairs for training pathology‐specific vision‐language models (e.g., PathGen-CLIP). Pathology image analysis is a core medical imaging task used for disease diagnosis and research, clearly placing this work in the Healthcare/Biomedicine AI domain.",
    "prompt_tokens": 20599,
    "completion_tokens": 146,
    "total_tokens": 20745,
    "topic": "Medical Imaging - Histopathology",
    "method": "Vision-language pretrained models; multi-agent collaboration",
    "application": "Pathology image classification",
    "code_link": "https://github.com/PathFoundation/PathGen-1.6M",
    "dataset_name": [
      "PathGen-1.6M",
      "Camelyon17",
      "SICAPv2",
      "CRC100K",
      "LC25000",
      "SkinCancer",
      "BACH",
      "Osteo",
      "WSSS4LUAD"
    ]
  },
  {
    "id": "cWEfRkYj46",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Towards Homogeneous Lexical Tone Decoding from Heterogeneous Intracranial Recordings",
    "authors": [
      "Di Wu",
      "Siyuan Li",
      "Chen Feng",
      "Lu Cao",
      "Yue Zhang",
      "Jie Yang",
      "Mohamad Sawan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Recent advancements in brain-computer interfaces (BCIs) and deep learning have made decoding lexical tones from intracranial recordings possible, providing the potential to restore the communication ability of speech-impaired tonal language speakers. However, data heterogeneity induced by both physiological and instrumental factors poses a significant challenge for unified invasive brain tone decoding. Particularly, the existing heterogeneous decoding paradigm (training subject-specific models with individual data) suffers from the intrinsic limitation that fails to learn generalized neural representations and leverages data across subjects. To this end, we introduce Homogeneity-Heterogeneity Disentangled Learning for Neural Representations (H2DiLR), a framework that disentangles and learns the homogeneity and heterogeneity from intracranial recordings of multiple subjects. To verify the effectiveness of H2DiLR, we collected stereoelectroencephalography (sEEG) from multiple participants reading Mandarin materials containing 407 syllables (covering nearly all Mandarin characters). Extensive experiments demonstrate that H2DiLR, as a unified decoding paradigm, outperforms the naive heterogeneous decoding paradigm by a large margin. We also empirically show that H2DiLR indeed captures homogeneity and heterogeneity during neural representation learning.",
    "keywords": "brain-computer interfaces; speech decoding; tonal language; Homogeneity-Heterogeneity Disentanglement",
    "pdf_url": "https://openreview.net/pdf?id=cWEfRkYj46",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work uses invasive neural recordings (sEEG) and brain–computer interface techniques to decode speech for potential restoration of communication in speech-impaired individuals. The use of intracranial EEG, neural representation learning, and a BCI framework for healthcare rehabilitation places it squarely within Healthcare AI.",
    "prompt_tokens": 20814,
    "completion_tokens": 101,
    "total_tokens": 20915,
    "topic": "Neural Decoding - Tone Identification",
    "method": "Homogeneity-Heterogeneity Disentangled Learning (H2DiLR)",
    "application": "Lexical tone decoding – sEEG",
    "code_link": "N/A",
    "dataset_name": [
      "CHB-MIT",
      "Mandarin Tone Decoding Dataset"
    ]
  },
  {
    "id": "uOb7rij7sR",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "CryoGEN: Generative Energy-based Models for Cryogenic Electron Tomography Reconstruction",
    "authors": [
      "Yunfei Teng",
      "Yuxuan Ren",
      "Kai Chen",
      "Xi Chen",
      "Zhaoming Chen",
      "Qiwei Ye"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Cryogenic electron tomography (Cryo-ET) is a powerful technique for visualizing subcellular structures in their native states. Nonetheless, its effectiveness is compromised by anisotropic resolution artifacts caused by the missing-wedge effect. To address this, IsoNet, a deep learning-based method, proposes iteratively reconstructing the missing-wedge information. While successful, IsoNet's dependence on recursive prediction updates often leads to training instability and model divergence. In this study, we introduce CryoGEN—an energy-based probabilistic model that not only mitigates resolution anisotropy but also removes the need for recursive subtomogram averaging, delivering an approximate *10*$\\times$ speedup for training. Evaluations across various biological datasets, including immature HIV-1 virions and ribosomes, demonstrate that CryoGEN significantly enhances structural completeness and interpretability of the reconstructed samples.",
    "keywords": "Cryo-ET, EBMs, Cryogenic Electron Tomography, Generative Energy-based Model",
    "pdf_url": "https://openreview.net/pdf?id=uOb7rij7sR",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work develops deep learning methods for cryogenic electron tomography (Cryo-ET) reconstruction of subcellular and viral structures (e.g., HIV-1 virions, ribosomes). Cryo-ET is a biomedical imaging technique used in structural biology and virology research, placing it squarely in the Biomedicine AI domain.",
    "prompt_tokens": 20951,
    "completion_tokens": 108,
    "total_tokens": 21059,
    "topic": "Medical Imaging - Electron Tomography",
    "method": "Generative Energy-Based Models",
    "application": "Tomogram reconstruction",
    "code_link": "N/A",
    "dataset_name": [
      "EMDB:18424",
      "PDB:6Z6U",
      "EMPIAR-10045",
      "EMPIAR-10164"
    ]
  },
  {
    "id": "BpfsxFqhGa",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Animate Your Thoughts: Reconstruction of Dynamic Natural Vision from Human Brain Activity",
    "authors": [
      "Yizhuo Lu",
      "Changde Du",
      "Chong Wang",
      "Xuanliu Zhu",
      "Liuyun Jiang",
      "Xujin Li",
      "Huiguang He"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Reconstructing human dynamic vision from brain activity is a challenging task with great scientific significance.  Although prior video reconstruction methods have made substantial progress, they still suffer from several limitations, including: (1) difficulty in simultaneously reconciling semantic (e.g. categorical descriptions), structure (e.g. size and color), and consistent motion information (e.g. order of frames); (2) low temporal resolution of fMRI, which poses a challenge in decoding multiple frames of video dynamics from a single fMRI frame; (3) reliance on video generation models, which introduces ambiguity regarding whether the dynamics observed in the reconstructed videos are genuinely derived from fMRI data or are hallucinations from generative model. To overcome these limitations,  we propose a two-stage model named Mind-Animator. During the fMRI-to-feature stage, we decouple semantic, structure, and motion features from fMRI. Specifically, we employ fMRI-vision-language tri-modal contrastive learning to decode semantic feature from fMRI and design a sparse causal attention mechanism for decoding multi-frame video motion features through a next-frame-prediction task. In the feature-to-video stage, these features are integrated into videos using an inflated Stable Diffusion, effectively eliminating external video data interference.  Extensive experiments on multiple video-fMRI datasets demonstrate that our model achieves state-of-the-art performance. Comprehensive visualization analyses further elucidate the interpretability of our model from a neurobiological perspective.  Project page: https://mind-animator-design.github.io/.",
    "keywords": "Video reconstruction, Brain-computer Interface (BCI).",
    "pdf_url": "https://openreview.net/pdf?id=BpfsxFqhGa",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper centers on decoding and reconstructing dynamic visual experiences from human brain activity using fMRI data—a medical imaging modality. This work falls squarely under neurobiological modeling and brain decoding, which are listed as strong indicators of Healthcare/Biomedicine AI.",
    "prompt_tokens": 20900,
    "completion_tokens": 104,
    "total_tokens": 21004,
    "topic": "Neuroimaging - Video Reconstruction",
    "method": "Contrastive Learning; Transformer-based decoders; Stable Diffusion; VQ-VAE",
    "application": "Video reconstruction from fMRI signals",
    "code_link": "N/A",
    "dataset_name": [
      "CC2017",
      "HCP",
      "Algonauts2021"
    ]
  },
  {
    "id": "hjROBHstZ3",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Causal Representation Learning from Multimodal Biomedical Observations",
    "authors": [
      "Yuewen Sun",
      "Lingjing Kong",
      "Guangyi Chen",
      "Loka Li",
      "Gongxu Luo",
      "Zijian Li",
      "Yixuan Zhang",
      "Yujia Zheng",
      "Mengyue Yang",
      "Petar Stojanov",
      "Eran Segal",
      "Eric P. Xing",
      "Kun Zhang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Prevalent in biomedical applications (e.g., human phenotype research), multimodal datasets can provide valuable insights into the underlying physiological mechanisms. However, current machine learning (ML) models designed to analyze these datasets often lack interpretability and identifiability guarantees, which are essential for biomedical research. Recent advances in causal representation learning have shown promise in identifying interpretable latent causal variables with formal theoretical guarantees. Unfortunately, most current work on multimodal distributions either relies on restrictive parametric assumptions or yields only coarse identification results, limiting their applicability to biomedical research that favors a detailed understanding of the mechanisms.\n\nIn this work, we aim to develop flexible identification conditions for multimodal data and principled methods to facilitate the understanding of biomedical datasets. Theoretically, we consider a nonparametric latent distribution (c.f., parametric assumptions in previous work) that allows for causal relationships across potentially different modalities. We establish identifiability guarantees for each latent component, extending the subspace identification results from previous work. Our key theoretical contribution is the structural sparsity of causal connections between modalities, which, as we will discuss, is natural for a large collection of biomedical systems.\nEmpirically, we present a practical framework to instantiate our theoretical insights. We demonstrate the effectiveness of our approach through extensive experiments on both numerical and synthetic datasets. Results on a real-world human phenotype dataset are consistent with established biomedical research, validating our theoretical and methodological framework.",
    "keywords": "multimodal observations, identifiability, causal representation learning",
    "pdf_url": "https://openreview.net/pdf?id=hjROBHstZ3",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly focuses on “multimodal biomedical observations” and “human phenotype research,” aiming to uncover physiological mechanisms in biomedical datasets. It addresses interpretability and identifiability in causal representation learning specifically for biomedical applications, and validates results on a real-world human phenotype dataset—strongly indicating relevance to the Biomedicine AI domain.",
    "prompt_tokens": 20458,
    "completion_tokens": 111,
    "total_tokens": 20569,
    "topic": "Causal Inference - Multimodal Biomedical Observations",
    "method": "Causal representation learning; flow-based transformation; MLP; learnable adjacency matrix",
    "application": "Causal discovery and latent variable learning – human phenotype analysis",
    "code_link": "N/A",
    "dataset_name": [
      "Human phenotype dataset",
      "Synthetic Variant MNIST"
    ]
  },
  {
    "id": "FtjLUHyZAO",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Diffusion Generative Modeling for Spatially Resolved Gene Expression Inference from Histology Images",
    "authors": [
      "Sichen Zhu",
      "Yuchen Zhu",
      "Molei Tao",
      "Peng Qiu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Spatial Transcriptomics (ST) allows a high-resolution measurement of RNA sequence abundance by systematically connecting cell morphology depicted in Hematoxylin and eosin (H\\&E) stained histology images to spatially resolved gene expressions. ST is a time-consuming, expensive yet powerful experimental technique that provides new opportunities to understand cancer mechanisms at a fine-grained molecular level, which is critical for uncovering new approaches for disease diagnosis and treatments. Here, we present $\\textbf{Stem}$ ($\\underline{\\textbf{S}}$pa$\\underline{\\textbf{T}}$ially resolved gene $\\underline{\\textbf{E}}$xpression inference with diffusion $\\underline{\\textbf{M}}$odel), a novel computational tool that leverages a conditional diffusion generative model to enable in silico gene expression inference from H&E stained images. Through better capturing the inherent stochasticity and heterogeneity in ST data, $\\textbf{Stem}$ achieves state-of-the-art performance on spatial gene expression prediction and generates biologically meaningful gene profiles for new H&E stained images at test time. We evaluate the proposed algorithm on datasets with various tissue sources and sequencing platforms, where it demonstrates clear improvement over existing approaches. $\\textbf{Stem}$ generates high-fidelity gene expression predictions that share similar gene variation levels as ground truth data, suggesting that our method preserves the underlying biological heterogeneity. Our proposed pipeline opens up the possibility of analyzing existing, easily accessible H&E stained histology images from a genomics point of view without physically performing gene expression profiling and empowers potential biological discovery from H&E stained histology images. Code is available at: https://github.com/SichenZhu/Stem.",
    "keywords": "Gene Expression Prediction, Diffusion Model, Spatial Transcriptomics, H&E",
    "pdf_url": "https://openreview.net/pdf?id=FtjLUHyZAO",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work focuses on predicting spatially resolved gene expression from H&E‐stained histology images—a clear genomics and spatial transcriptomics application. It mentions “Spatial Transcriptomics,” “RNA sequence abundance,” “cancer mechanisms,” and “disease diagnosis and treatments,” all of which are central to biomedical research and AI for molecular profiling. Therefore, it falls squarely within Biomedicine AI.",
    "prompt_tokens": 20770,
    "completion_tokens": 113,
    "total_tokens": 20883,
    "topic": "Spatial Transcriptomics - Gene Expression Prediction",
    "method": "Diffusion generative modeling",
    "application": "Spatially resolved gene expression inference",
    "code_link": "https://github.com/SichenZhu/Stem",
    "dataset_name": [
      "Kidney Visium",
      "HER2ST",
      "Human Prostate Cancer (PRAD)",
      "Healthy Mouse Brain"
    ]
  },
  {
    "id": "FBhKUXK7od",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Fast unsupervised ground metric learning with tree-Wasserstein distance",
    "authors": [
      "Kira Michaela Düsterwald",
      "Samo Hromadka",
      "Makoto Yamada"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The performance of unsupervised methods such as clustering depends on the choice of distance metric between features, or ground metric. Commonly, ground metrics are decided with heuristics or learned via supervised algorithms. However, since many interesting datasets are unlabelled, unsupervised ground metric learning approaches have been introduced. One promising option employs Wasserstein singular vectors (WSVs), which emerge when computing optimal transport distances between features and samples simultaneously. WSVs are effective, but can be prohibitively computationally expensive in some applications: $\\mathcal{O}(n^2m^2(n \\log(n) + m \\log(m))$ for $n$ samples and $m$ features. In this work, we propose to augment the WSV method by embedding samples and features on trees, on which we compute the tree-Wasserstein distance (TWD). We demonstrate theoretically and empirically that the algorithm converges to a better approximation of the standard WSV approach than the best known alternatives, and does so with $\\mathcal{O}(n^3+m^3+mn)$ complexity. In addition, we prove that the initial tree structure can be chosen flexibly, since tree geometry does not constrain the richness of the approximation up to the number of edge weights. This proof suggests a fast and recursive algorithm for computing the tree parameter basis set, which we find crucial to realising the efficiency gains at scale. Finally, we employ the tree-WSV algorithm to several single-cell RNA sequencing genomics datasets, demonstrating its scalability and utility for unsupervised cell-type clustering problems. These results poise unsupervised ground metric learning with TWD as a low-rank approximation of WSV with the potential for widespread application.",
    "keywords": "unsupervised learning, optimal transport, distance-based learning, clustering, trees, wasserstein distance",
    "pdf_url": "https://openreview.net/pdf?id=FBhKUXK7od",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper specifically applies its unsupervised ground metric learning method to “single-cell RNA sequencing genomics datasets” for “unsupervised cell-type clustering.” Single-cell RNA-seq is a core biomedical data modality used to study gene expression at the cellular level, placing this work squarely in the realm of Biomedicine AI.",
    "prompt_tokens": 20876,
    "completion_tokens": 115,
    "total_tokens": 20991,
    "topic": "Bioinformatics - Ground Metric Learning",
    "method": "Tree-Wasserstein distance; Unsupervised ground metric learning",
    "application": "Single-cell RNA clustering",
    "code_link": "https://github.com/kiradust/tree-wsv/",
    "dataset_name": [
      "PBMC3k",
      "Neurons V1",
      "Human Lung Cell Atlas (HLCA)"
    ]
  },
  {
    "id": "i1NNCrRxdM",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "SymDiff: Equivariant Diffusion via Stochastic Symmetrisation",
    "authors": [
      "Leo Zhang",
      "Kianoosh Ashouritaklimi",
      "Yee Whye Teh",
      "Rob Cornish"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We propose SymDiff, a method for constructing equivariant diffusion models using the framework of stochastic symmetrisation. SymDiff resembles a learned data augmentation that is deployed at sampling time, and is lightweight, computationally efficient, and easy to implement on top of arbitrary off-the-shelf models. In contrast to previous work, SymDiff typically does not require any neural network components that are intrinsically equivariant, avoiding the need for complex parameterisations or the use of higher-order geometric features. Instead, our method can leverage highly scalable modern architectures as drop-in replacements for these more constrained alternatives. We show that this additional flexibility yields significant empirical benefit for E(3)-equivariant molecular generation. To the best of our knowledge, this is the first application of symmetrisation to generative modelling, suggesting its potential in this domain more generally.",
    "keywords": "Equivariance, Diffusion Models, Symmetrisation, Molecular Generation, Markov Categories",
    "pdf_url": "https://openreview.net/pdf?id=i1NNCrRxdM",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “E(3)-equivariant molecular generation,” which directly pertains to generative modeling of molecules—a core component of drug discovery and molecular modeling in biomedicine. Although it does not explicitly mention “drug discovery,” the routine task of generating novel chemical structures falls squarely under the “drug discovery” and “molecular modeling” contexts listed in Biomedicine AI.",
    "prompt_tokens": 20635,
    "completion_tokens": 102,
    "total_tokens": 20737,
    "topic": "Drug Discovery - Molecular Generation",
    "method": "Equivariant diffusion; Stochastic symmetrisation",
    "application": "3D molecular structure generation",
    "code_link": "https://github.com/leozhangML/SymDiff",
    "dataset_name": [
      "QM9",
      "GEOM-Drugs"
    ]
  },
  {
    "id": "trj2Jq8riA",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Interpretable Vision-Language Survival Analysis with Ordinal Inductive Bias for Computational Pathology",
    "authors": [
      "Pei Liu",
      "Luping Ji",
      "Jiaxiang Gou",
      "Bo Fu",
      "Mao Ye"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Histopathology Whole-Slide Images (WSIs) provide an important tool to assess cancer prognosis in computational pathology (CPATH). While existing survival analysis (SA) approaches have made exciting progress, they are generally limited to adopting highly-expressive network architectures and only coarse-grained patient-level labels to learn visual prognostic representations from gigapixel WSIs. Such learning paradigm suffers from critical performance bottlenecks, when facing present scarce training data and standard multi-instance learning (MIL) framework in CPATH. To overcome it, this paper, for the first time, proposes a new Vision-Language-based SA (**VLSA**) paradigm. Concretely, (1) VLSA is driven by pathology VL foundation models. It no longer relies on high-capability networks and shows the advantage of *data efficiency*. (2) In vision-end, VLSA encodes textual prognostic prior and then employs it as *auxiliary signals* to guide the aggregating of visual prognostic features at instance level, thereby compensating for the weak supervision in MIL. Moreover, given the characteristics of SA, we propose i) *ordinal survival prompt learning* to transform continuous survival labels into textual prompts; and ii) *ordinal incidence function* as prediction target to make SA compatible with VL-based prediction. Notably, VLSA's predictions can be interpreted intuitively by our Shapley values-based method. The extensive experiments on five datasets confirm the effectiveness of our scheme. Our VLSA could pave a new way for SA in CPATH by offering weakly-supervised MIL an effective means to learn valuable prognostic clues from gigapixel WSIs. Our source code is available at https://github.com/liupei101/VLSA.",
    "keywords": "Computation Pathology, Survival Analysis, Multi-Instance Learning, Whole-Slide Images, Vision-Language Modes",
    "pdf_url": "https://openreview.net/pdf?id=trj2Jq8riA",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on survival analysis of cancer prognosis using histopathology Whole-Slide Images (WSIs) in computational pathology. It directly addresses a clinical task—assessing patient outcomes (survival) from medical images—and proposes a Vision-Language-based method to extract prognostic information from gigapixel pathology slides. These elements place it squarely in the Healthcare AI / Biomedicine AI domain.",
    "prompt_tokens": 20861,
    "completion_tokens": 134,
    "total_tokens": 20995,
    "topic": "Computational Pathology - Vision-Language Survival Analysis",
    "method": "Vision-Language Models; Ordinal survival prompt learning; Ordinal incidence function",
    "application": "Cancer prognosis assessment",
    "code_link": "https://github.com/liupei101/VLSA",
    "dataset_name": [
      "TCGA-BLCA",
      "TCGA-BRCA",
      "TCGA-GBMLGG",
      "TCGA-LUAD",
      "TCGA-UCEC"
    ]
  },
  {
    "id": "KSLkFYHlYg",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "ShEPhERD: Diffusing shape, electrostatics, and pharmacophores for bioisosteric drug design",
    "authors": [
      "Keir Adams",
      "Kento Abeywardane",
      "Jenna Fromer",
      "Connor W. Coley"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Engineering molecules to exhibit precise 3D intermolecular interactions with their environment forms the basis of chemical design. In ligand-based drug design, bioisosteric analogues of known bioactive hits are often identified by virtually screening chemical libraries with shape, electrostatic, and pharmacophore similarity scoring functions. We instead hypothesize that a generative model which learns the joint distribution over 3D molecular structures and their interaction profiles may facilitate 3D interaction-aware chemical design. We specifically design ShEPhERD, an SE(3)-equivariant diffusion model which jointly diffuses/denoises 3D molecular graphs and representations of their shapes, electrostatic potential surfaces, and (directional) pharmacophores to/from Gaussian noise. Inspired by traditional ligand discovery, we compose 3D similarity scoring functions to assess ShEPhERD’s ability to conditionally generate novel molecules with desired interaction profiles. We demonstrate ShEPhERD’s potential for impact via exemplary drug design tasks including natural product ligand hopping, protein-blind bioactive hit diversification, and bioisosteric fragment merging.",
    "keywords": "3D molecular generation, drug design, molecules",
    "pdf_url": "https://openreview.net/pdf?id=KSLkFYHlYg",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper targets ligand-based drug design and molecular generation for bioisosteric drug discovery. It introduces an SE(3)-equivariant diffusion model for 3D molecular structures, pharmacophores, and electrostatic surfaces explicitly to generate novel drug-like molecules. References to “ligand discovery,” “bioactive hit diversification,” and “drug design tasks” indicate direct relevance to biomedicine AI in the drug discovery domain.",
    "prompt_tokens": 20943,
    "completion_tokens": 113,
    "total_tokens": 21056,
    "topic": "Drug Discovery - Structure-based Generative Models",
    "method": "3D diffusion model; conditional generation; inpainting",
    "application": "Molecular structure generation",
    "code_link": "https://github.com/coleygroup/shepherd",
    "dataset_name": [
      "ShEPhERD-GDB17",
      "ShEPhERD-MOSES-aq"
    ]
  },
  {
    "id": "5yDS32hKJc",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Time After Time: Deep-Q Effect Estimation for Interventions on When and What to do",
    "authors": [
      "Yoav Wald",
      "Mark Goldstein",
      "Yonathan Efroni",
      "Wouter A.C. van Amsterdam",
      "Rajesh Ranganath"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Problems in fields such as healthcare, robotics, and finance requires reasoning about the value both of what decision or action to take and when to take it. The prevailing hope is that artificial intelligence will support such decisions by estimating the causal effect of policies such as how to treat patients or how to allocate resources over time. However, existing methods for estimating the effect of a policy struggle with \\emph{irregular time}.  They either discretize time, or disregard the effect of timing policies.\n\nWe present a new deep-Q algorithm that estimates the effect of both when and what to do called Earliest Disagreement Q-Evaluation (EDQ). EDQ makes use of recursion for the Q-function that is compatible with flexible sequence models, such as transformers. EDQ provides accurate estimates under standard assumptions. We validate the approach through experiments on survival time and tumor growth tasks.",
    "keywords": "effect estimation, treatment times, irregular times, sequential decision making",
    "pdf_url": "https://openreview.net/pdf?id=5yDS32hKJc",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract explicitly mentions applications in “healthcare” and “how to treat patients,” and the experiments focus on “survival time and tumor growth tasks,” both of which are clinical/biomedical settings. The paper’s goal of estimating treatment timing and effects directly addresses medical decision making, fitting squarely within Healthcare/Biomedicine AI.",
    "prompt_tokens": 21003,
    "completion_tokens": 95,
    "total_tokens": 21098,
    "topic": "Causal Inference - Treatment Timing",
    "method": "Dynamic programming; fitted Q-evaluation",
    "application": "Effect estimation of treatment timing policies",
    "code_link": "N/A",
    "dataset_name": [
      "Time-to-failure simulator",
      "Tumor-growth simulator"
    ]
  },
  {
    "id": "3usdM1AuI3",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "BRAID: Input-driven Nonlinear Dynamical Modeling of Neural-Behavioral Data",
    "authors": [
      "Parsa Vahidi",
      "Omid G. Sani",
      "Maryam Shanechi"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Neural populations exhibit complex recurrent structures that drive behavior, while continuously receiving and integrating external inputs from sensory stimuli, upstream regions, and neurostimulation. However, neural populations are often modeled as autonomous dynamical systems, with little consideration given to the influence of external inputs that shape the population activity and behavioral outcomes. Here, we introduce BRAID, a deep learning framework that models nonlinear neural dynamics underlying behavior while explicitly incorporating any measured external inputs. Our method disentangles intrinsic recurrent neural population dynamics from the effects of inputs by including a forecasting objective within input-driven recurrent neural networks. BRAID further prioritizes the learning of intrinsic dynamics that are related to a behavior of interest by using a multi-stage optimization scheme. We validate BRAID with nonlinear simulations, showing that it can accurately learn the intrinsic dynamics shared between neural and behavioral modalities. We then apply BRAID to motor cortical activity recorded during a motor task and demonstrate that our method more accurately fits the neural-behavioral data by incorporating measured sensory stimuli into the model and improves the forecasting of neural-behavioral data compared with various baseline methods, whether input-driven or not.",
    "keywords": "Deep learning, Dynamic modeling, Sensory stimuli, RNN, Intrinsic, Behavior",
    "pdf_url": "https://openreview.net/pdf?id=3usdM1AuI3",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on modeling neural population dynamics and motor cortical activity (“motor cortical activity recorded during a motor task”), which falls squarely under neurobiological modeling. Neurobiological and systems‐level studies of brain dynamics are considered part of the Biomedicine AI domain (e.g., “neuroscience or neurobiological modeling: … neural system dynamics”). Although it does not address a specific clinical application, it deals with biological neural data and behavior, justifying its classification as Biomedicine AI.",
    "prompt_tokens": 20998,
    "completion_tokens": 106,
    "total_tokens": 21104,
    "topic": "Neuroscience - Neural Behavior Dynamics",
    "method": "Nonlinear latent-space modeling; RNN; BRAID framework",
    "application": "Neural-behavior forecasting",
    "code_link": "https://github.com/ShanechiLab/BRAID",
    "dataset_name": [
      "Non-human primate motor cortical activity dataset"
    ]
  },
  {
    "id": "YeSxbRrDRl",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Dist Loss: Enhancing Regression in Few-Shot Region through Distribution Distance Constraint",
    "authors": [
      "Guangkun Nie",
      "Gongzheng Tang",
      "Shenda Hong"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Imbalanced data distributions are prevalent in real-world scenarios, presenting significant challenges in both classification and regression tasks. This imbalance often causes deep learning models to overfit in regions with abundant data (manyshot regions) while underperforming in regions with sparse data (few-shot regions). Such characteristics limit the applicability of deep learning models across various domains, notably in healthcare, where rare cases often carry greater clinical significance. While recent studies have highlighted the benefits of incorporating distributional information in imbalanced classification tasks, similar strategies have been largely unexplored in imbalanced regression. To address this gap, we propose Dist Loss, a novel loss function that integrates distributional information into model training by jointly optimizing the distribution distance between model predictions and target labels, alongside sample-wise prediction errors. This dual-objective approach encourages the model to balance its predictions across different label regions, leading to significant improvements in accuracy in fewshot regions. We conduct extensive experiments across three datasets spanning computer vision and healthcare: IMDB-WIKI-DIR, AgeDB-DIR, and ECG-KDIR. The results demonstrate that Dist Loss effectively mitigates the impact of imbalanced data distributions, achieving state-of-the-art performance in few-shot regions. Furthermore, Dist Loss is easy to integrate and complements existing methods. To facilitate further research, we provide our implementation at https://github.com/Ngk03/DIR-Dist-Loss.",
    "keywords": "Deep imbalanced regression, sparse data region optimization",
    "pdf_url": "https://openreview.net/pdf?id=YeSxbRrDRl",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although Dist Loss is a general imbalanced‐regression method, the paper explicitly evaluates on ECG-KDIR—a dataset of electrocardiogram signals—and even states it spans “computer vision and healthcare.” Applying and improving performance on ECG data situates this work squarely within Healthcare AI.",
    "prompt_tokens": 20436,
    "completion_tokens": 103,
    "total_tokens": 20539,
    "topic": "Imbalanced Data - Regression",
    "method": "Distribution Distance Optimization; Differentiable sorting",
    "application": "Few-shot analysis and regression accuracy improvement",
    "code_link": "N/A",
    "dataset_name": [
      "IMDB-WIKI-DIR",
      "AgeDB-DIR",
      "ECG-K-DIR"
    ]
  },
  {
    "id": "78tc3EiUrN",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "MADGEN: Mass-Spec attends to De Novo Molecular generation",
    "authors": [
      "Yinkai Wang",
      "Xiaohui Chen",
      "Liping Liu",
      "Soha Hassoun"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The annotation (assigning structural chemical identities) of MS/MS spectra remains a significant challenge due to the enormous molecular diversity in biological samples and the limited scope of reference databases.  Currently, the vast majority of spectral measurements remain in the \"dark chemical space\" without structural annotations.  To improve annotation, we propose MADGEN (Mass-spec Attends to De Novo Molecular GENeration), a scaffold-based method for de novo molecular structure generation guided by mass spectrometry data. MADGEN operates in two stages: scaffold retrieval and spectra-conditioned molecular generation starting with the scaffold. In the first stage, given an MS/MS spectrum, we formulate scaffold retrieval as a ranking problem and employ contrastive learning to align mass spectra with candidate molecular scaffolds. In the second stage, starting from the retrieved scaffold, we employ the MS/MS spectrum to guide an attention-based generative model to generate the final molecule. Our approach constrains the molecular generation search space, reducing its complexity and improving generation accuracy. We evaluate MADGEN on three datasets (NIST23, CANOPUS, and MassSpecGym) and  evaluate MADGEN's performance with a predictive scaffold retriever and with an oracle retriever. We demonstrate the effectiveness of using  attention to integrate spectral information throughout the generation process to achieve strong results with the oracle retriever.",
    "keywords": "AI4Science, Biology Discovery, Metabolomics, MS/MS spectra",
    "pdf_url": "https://openreview.net/pdf?id=78tc3EiUrN",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work focuses on de novo molecular structure generation guided by MS/MS spectra for metabolomics (“annotation of MS/MS spectra,” “dark chemical space,” “Metabolomics,” “MS/MS spectra”). Mass‐spectrometry‐based molecular identification is a key task in biomedical and drug‐discovery research, placing this squarely in the Biomedicine AI domain.",
    "prompt_tokens": 20974,
    "completion_tokens": 116,
    "total_tokens": 21090,
    "topic": "Drug Discovery - Metabolomics",
    "method": "Contrastive learning; graph neural networks (GNN); self-attention; classifier-free guidance (CFG)",
    "application": "Molecular structure generation",
    "code_link": "https://github.com/HassounLab/MADGEN",
    "dataset_name": [
      "NIST23",
      "CANOPUS",
      "MassSpecGym"
    ]
  },
  {
    "id": "WoPovNkM5h",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Small Models are LLM Knowledge Triggers for Medical Tabular Prediction",
    "authors": [
      "Jiahuan Yan",
      "Jintai Chen",
      "Chaowen Hu",
      "Bo Zheng",
      "Yaojun Hu",
      "Jimeng Sun",
      "Jian Wu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Recent development in large language models (LLMs) has demonstrated impressive domain proficiency on unstructured textual or multi-modal tasks. However, despite with intrinsic world knowledge, their application on structured tabular data prediction still lags behind, primarily due to the numerical insensitivity and modality discrepancy that brings a gap between LLM reasoning and statistical tabular learning. Unlike textual or vision data (e.g., electronic clinical notes or medical imaging data), tabular data is often presented in heterogeneous numerical values (e.g., CBC reports). This ubiquitous data format requires intensive expert annotation, and its numerical nature limits LLMs' capability to effectively transfer untapped domain expertise. In this paper, we propose SERSAL, a general self-prompting method by synergy learning with small models to enhance LLM tabular prediction in an unsupervised manner. Specifically, SERSAL utilizes the LLM's prior outcomes as original soft noisy annotations, which are dynamically leveraged to teach a better small student model. Reversely, the outcomes from the trained small model are used to teach the LLM to further refine its real capability. This process can be repeatedly applied to gradually distill refined knowledge for continuous progress. Comprehensive experiments on widely used medical domain tabular datasets show that, without access to gold labels, applying SERSAL to OpenAI GPT reasoning process attains substantial improvement compared to linguistic prompting methods, which serves as an orthogonal direction for tabular LLM, and increasing prompting bonus is observed as more powerful LLMs appear. Codes are available at https://github.com/jyansir/sersal.",
    "keywords": "tabular data, prompt learning, classification",
    "pdf_url": "https://openreview.net/pdf?id=WoPovNkM5h",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The work specifically targets “medical domain tabular datasets” (e.g., CBC reports) and presents a method to improve “LLM tabular prediction” for healthcare data without gold labels. Its experiments and use cases are grounded in clinical lab results, indicating clear relevance to Healthcare AI.",
    "prompt_tokens": 20807,
    "completion_tokens": 160,
    "total_tokens": 20967,
    "topic": "Medical Tabular Data - Prediction Enhancement",
    "method": "Synergy learning; Unsupervised self-prompting; DivideMix",
    "application": "Disease diagnosis prediction – Tabular Data",
    "code_link": "https://github.com/jyansir/sersal",
    "dataset_name": [
      "MIMIC-III",
      "Indian Liver Patient Records",
      "Pima Indians Diabetes Database",
      "Framingham Heart Study",
      "Stroke Prediction",
      "Hepatitis C Prediction",
      "COVID-19 Presence",
      "Lung Cancer Prediction",
      "Heart Failure Prediction",
      "Early Classification of Diabetes",
      "Anemia Disease"
    ]
  },
  {
    "id": "MMHqnUOnl0",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "HELM: Hierarchical Encoding for mRNA Language Modeling",
    "authors": [
      "Mehdi Yazdani-Jahromi",
      "Mangal Prakash",
      "Tommaso Mansi",
      "Artem Moskalev",
      "Rui Liao"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Messenger RNA (mRNA) plays a crucial role in protein synthesis, with its codon structure directly impacting biological properties. While Language Models (LMs) have shown promise in analyzing biological sequences, existing approaches fail to account for the hierarchical nature of mRNA's codon structure. We introduce Hierarchical Encoding for mRNA Language Modeling (HELM), a novel pre-training strategy that incorporates codon-level hierarchical structure into language model training. HELM modulates the loss function based on codon synonymity, aligning the model's learning process with the biological reality of mRNA sequences. We evaluate HELM on diverse mRNA datasets and tasks, demonstrating that HELM outperforms standard language model pre-training as well as existing foundation model baselines on six diverse downstream property prediction tasks and an antibody region annotation tasks on average by around 8%. Additionally, HELM enhances the generative capabilities of language model, producing diverse mRNA sequences that better align with the underlying true data distribution compared to  non-hierarchical baselines.",
    "keywords": "Messenger RNA (mRNA), Codon structure, Hierarchical modeling, Bio-language model, Property prediction, mRNA sequence generation",
    "pdf_url": "https://openreview.net/pdf?id=MMHqnUOnl0",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on modeling messenger RNA (mRNA) sequences and their codon structure—core topics in molecular biology and genomics. By proposing a hierarchical encoding scheme for mRNA language modeling and testing on downstream property prediction and sequence generation tasks, it clearly addresses a biomedicine AI problem (RNA sequence analysis and design), which is directly relevant to biomedical research and synthetic biology.",
    "prompt_tokens": 20477,
    "completion_tokens": 132,
    "total_tokens": 20609,
    "topic": "Bioinformatics - mRNA Language Modeling",
    "method": "Causal Language Modeling (CLM); Masked Language Modeling (MLM); Hierarchical Encoding Loss (HELM)",
    "application": "mRNA property prediction",
    "code_link": "N/A",
    "dataset_name": [
      "Ab1",
      "Ab2",
      "MLOS",
      "iCodon",
      "Tc-Riboswitches",
      "mRFP",
      "COVID-19 Vaccine"
    ]
  },
  {
    "id": "nYpPAT4L3D",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Large-scale and Fine-grained Vision-language Pre-training for Enhanced CT Image Understanding",
    "authors": [
      "Zhongyi Shui",
      "Jianpeng Zhang",
      "Weiwei Cao",
      "Sinuo Wang",
      "Ruizhe Guo",
      "Le Lu",
      "Lin Yang",
      "Xianghua Ye",
      "Tingbo Liang",
      "Qi Zhang",
      "Ling Zhang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Artificial intelligence (AI) shows great potential in assisting radiologists to improve the efficiency and accuracy of medical image interpretation and diagnosis. However, a versatile AI model requires large-scale data and comprehensive annotations, which are often impractical in medical settings. Recent studies leverage radiology reports as a naturally high-quality supervision for medical images, using contrastive language-image pre-training (CLIP) to develop language-informed models for radiological image interpretation. Nonetheless, these approaches typically contrast entire images with reports, neglecting the local associations between imaging regions and report sentences, which may undermine model performance and interoperability. In this paper, we propose a fine-grained vision-language model (fVLM) for anatomy-level CT image interpretation. Specifically, we explicitly match anatomical regions of CT images with corresponding descriptions in radiology reports and perform contrastive pre-training for each anatomy individually. Fine-grained alignment, however, faces considerable false-negative challenges, mainly from the abundance of anatomy-level healthy samples and similarly diseased abnormalities, leading to ambiguous patient-level pairings. To tackle this issue, we propose identifying false negatives of both normal and abnormal samples and calibrating contrastive learning from patient-level to disease-aware pairing. We curated the largest CT dataset to date, comprising imaging and report data from 69,086 patients, and conducted a comprehensive evaluation of 54 major and important disease (including several most deadly cancers) diagnosis tasks across 15 main anatomies. Experimental results demonstrate the substantial potential of fVLM in versatile medical image interpretation. In the zero-shot classification task, we achieved an average AUC of 81.3% on 54 diagnosis tasks, surpassing CLIP and supervised methods by 12.9% and 8.0%, respectively. Additionally, on the publicly available CT-RATE and Rad-ChestCT benchmarks, our fVLM outperformed the current state-of-the-art methods with absolute AUC gains of 7.4% and 4.8%, respectively.",
    "keywords": "Vision-language model, fine-grained alignment, large-scale pre-training, CT image",
    "pdf_url": "https://openreview.net/pdf?id=nYpPAT4L3D",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on CT image interpretation and disease diagnosis (“54 major and important disease diagnosis tasks across 15 anatomies,” “zero-shot classification,” “CT-RATE and Rad-ChestCT benchmarks”), uses radiology reports and contrastive vision-language pre-training for medical imaging. These are clear medical imaging and diagnostic applications, placing it squarely in the Healthcare AI domain.",
    "prompt_tokens": 20224,
    "completion_tokens": 117,
    "total_tokens": 20341,
    "topic": "Medical Imaging - CT",
    "method": "Fine-grained vision-language pretraining; Contrastive learning",
    "application": "Abnormality detection; Radiology report generation",
    "code_link": "https://github.com/alibaba-damo-academy/fvlm",
    "dataset_name": [
      "MedVL-CT69K",
      "CT-RATE",
      "Rad-ChestCT"
    ]
  },
  {
    "id": "a6U41REOa5",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Retrieval Augmented Diffusion Model for Structure-informed Antibody Design and Optimization",
    "authors": [
      "Zichen Wang",
      "Yaokun Ji",
      "Jianing Tian",
      "Shuangjia Zheng"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Antibodies are essential proteins responsible for immune responses in organisms, capable of specifically recognizing antigen molecules of pathogens. Recent advances in generative models have significantly enhanced rational antibody design. However, existing methods mainly create antibodies from scratch without template constraints, leading to model optimization challenges and unnatural sequences. To address these issues, we propose a retrieval-augmented diffusion framework, termed RADAb, for efficient antibody design. Our method leverages a set of structural homologous motifs that align with query structural constraints to guide the generative model in inversely optimizing antibodies according to desired design criteria. Specifically, we introduce a structure-informed retrieval mechanism that integrates these exemplar motifs with the input backbone through a novel dual-branch denoising module, utilizing both structural and evolutionary information. Additionally, we develop a conditional diffusion model that iteratively refines the optimization process by incorporating both global context and local evolutionary conditions. Our approach is agnostic to the choice of generative models. Empirical experiments demonstrate that our method achieves state-of-the-art performance in multiple antibody inverse folding and optimization tasks, offering a new perspective on biomolecular generative models.",
    "keywords": "Generative model, Retrieval augmented geneartion, Protein design",
    "pdf_url": "https://openreview.net/pdf?id=a6U41REOa5",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on antibody design and optimization—a core task in protein engineering and therapeutic biologics development. It introduces a “retrieval‐augmented diffusion framework” for “structure-informed antibody design,” clearly placing it within the domain of biomedicine AI, specifically in drug discovery and protein design.",
    "prompt_tokens": 20959,
    "completion_tokens": 108,
    "total_tokens": 21067,
    "topic": "Antibody Design - Retrieval-Augmented Models",
    "method": "Retrieval-augmented generative diffusion model",
    "application": "Antibody sequence design and optimization",
    "code_link": "https://github.com/GENTEL-lab/RADAb",
    "dataset_name": [
      "SAbDab",
      "CDR-like fragments dataset"
    ]
  },
  {
    "id": "owEQ0FTfVj",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "GlycanML: A Multi-Task and Multi-Structure Benchmark for Glycan Machine Learning",
    "authors": [
      "Minghao Xu",
      "Yunteng Geng",
      "Yihang Zhang",
      "Ling Yang",
      "Jian Tang",
      "Wentao Zhang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Glycans are basic biomolecules and perform essential functions within living organisms. The rapid increase of functional glycan data provides a good opportunity for machine learning solutions to glycan understanding. However, there still lacks a standard machine learning benchmark for glycan property and function prediction. In this work, we fill this blank by building a comprehensive benchmark for Glycan Machine Learning (GlycanML). The GlycanML benchmark consists of diverse types of tasks including glycan taxonomy prediction, glycan immunogenicity prediction, glycosylation type prediction, and protein-glycan interaction prediction. Glycans can be represented by both sequences and graphs in GlycanML, which enables us to extensively evaluate sequence-based models and graph neural networks (GNNs) on benchmark tasks. Furthermore, by concurrently performing eight glycan taxonomy prediction tasks, we introduce the GlycanML-MTL testbed for multi-task learning (MTL) algorithms. Also, we evaluate how taxonomy prediction can boost other three function prediction tasks by MTL. Experimental results show the superiority of modeling glycans with multi-relational GNNs, and suitable MTL methods can further boost model performance. We provide all datasets and source codes at https://github.com/GlycanML/GlycanML and maintain a leaderboard at https://GlycanML.github.io/project",
    "keywords": "Glycan Machine Learning, Representation Learning, Multi-Task Learning",
    "pdf_url": "https://openreview.net/pdf?id=owEQ0FTfVj",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on machine learning for glycans, which are fundamental biomolecules. Tasks include glycan immunogenicity prediction, glycosylation type prediction, and protein-glycan interaction prediction—clear biomedical applications at the molecular level (e.g., “protein-glycan interaction prediction,” “glycan immunogenicity prediction,” “glycosylation type prediction”). This falls squarely under Biomedicine AI (molecular modeling/biomolecular machine learning).",
    "prompt_tokens": 20883,
    "completion_tokens": 134,
    "total_tokens": 21017,
    "topic": "Bioinformatics - Glycan Analysis",
    "method": "Multi-relational GNNs; multi-task learning (MTL); shallow CNN",
    "application": "Glycan taxonomy prediction; glycan immunogenicity prediction; glycosylation type prediction; protein-glycan interaction prediction",
    "code_link": "https://github.com/GlycanML/GlycanML",
    "dataset_name": [
      "SugarBase",
      "LectinOracle",
      "GlyConnect"
    ]
  },
  {
    "id": "YH4M1Tbxfz",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "BoneMet: An Open Large-Scale Multi-Modal Murine Dataset for Breast Cancer Bone Metastasis Diagnosis and Prognosis",
    "authors": [
      "Tiankuo Chu",
      "Fudong Lin",
      "Shubo Wang",
      "Jason Jiang",
      "Wiley Jia-Wei Gong",
      "Xu Yuan",
      "Liyun Wang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Breast cancer bone metastasis (BCBM) affects women’s health globally, calling\n for the development of effective diagnosis and prognosis solutions. While deep\n learning has exhibited impressive capacities across various healthcare domains, its\n applicability in BCBM diseases is consistently hindered by the lack of an open,\n large-scale, deep learning-ready dataset. As such, we introduce the Bone Metastasis\n (BoneMet) dataset, the first large-scale, publicly available, high-resolution medical\n resource, which is derived from a well-accepted murine BCBM model. The unique\n advantage of BoneMet over existing human datasets is repeated sequential scans\n per subject over the entire disease development phases. The dataset consists of\n over 67 terabytes of multi-modal medical data, including 2D X-ray images, 3D\n CT scans, and detailed biological data (e.g., medical records and bone quantitative\n analysis), collected from more than five hundreds mice spanning from 2019 to\n 2024. Our BoneMet dataset is well-organized into six components, i.e., Rotation\nX-Ray, Recon-CT, Seg-CT, Regist-CT, RoI-CT, and MiceMediRec. We further\n show that BoneMet can be readily adopted to build versatile, large-scale AI models\n for managing BCBM diseases in terms of diagnosis using 2D or 3D images, prognosis of bone deterioration, and sparse-angle 3D reconstruction for safe long-term\n disease monitoring. Our preliminary results demonstrate that BoneMet has the\n potentials to jump-start the development and fine-tuning of AI-driven solutions\n prior to their applications to human patients. To facilitate its easy access and\n wide dissemination, we have created the BoneMet package, providing three APIs\n that enable researchers to (i) flexibly process and download the BoneMet data\n filtered by specific time frames; and (ii) develop and train large-scale AI models for\n precise BCBM diagnosis and prognosis. The BoneMet dataset is officially available on Hugging Face Datasets at https://huggingface.co/datasets/BoneMet/BoneMet. The BoneMet package is available on the Python Package Index (PyPI) at https://pypi.org/project/BoneMet. Code and tutorials are available at https://github.com/Tiankuo528/BoneMet.",
    "keywords": "Medical Dataset, Breast Cancer Bone Metastasis, Diagnosis, Prognosis, Sparse CT reconstruction, CT, X-ray, Large language model, AI for Science",
    "pdf_url": "https://openreview.net/pdf?id=YH4M1Tbxfz",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper presents BoneMet, a large-scale multi-modal medical imaging dataset derived from a murine breast cancer bone metastasis model. It explicitly targets “diagnosis using 2D or 3D images” and “prognosis of bone deterioration,” both core Healthcare AI tasks. The focus on CT/X-ray imaging, disease monitoring, and AI-driven diagnostic and prognostic tools for breast cancer bone metastasis firmly places this work in the Healthcare/​Biomedicine AI domain.",
    "prompt_tokens": 20618,
    "completion_tokens": 131,
    "total_tokens": 20749,
    "topic": "Medical Imaging - Cancer Metastasis",
    "method": "NeRF-based reconstruction; supervised learning; nnU-Net segmentation",
    "application": "Multimodal metastatic bone analysis",
    "code_link": "https://github.com/Tiankuo528/BoneMet",
    "dataset_name": [
      "Rotation-X-Ray",
      "Recon-CT",
      "Seg-CT",
      "Regist-CT",
      "RoI-CT",
      "MiceMediRec"
    ]
  },
  {
    "id": "zDC3iCBxJb",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Group Ligands Docking to Protein Pockets",
    "authors": [
      "Jiaqi Guan",
      "Jiahan Li",
      "Xiangxin Zhou",
      "Xingang Peng",
      "Sheng Wang",
      "Yunan Luo",
      "Jian Peng",
      "Jianzhu Ma"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Molecular docking is a key task in computational biology that has attracted increasing interest from the machine learning community. While existing methods have achieved success, they generally treat each protein-ligand pair in isolation. Inspired by the biochemical observation that ligands binding to the same target protein tend to adopt similar poses, we propose \\textsc{GroupBind}, a novel molecular docking framework that simultaneously considers multiple ligands docking to a protein. This is achieved by introducing an interaction layer for the group of ligands and a triangle attention module for embedding protein-ligand and group-ligand pairs. By integrating our approach with diffusion based docking model, we set a new state-of-the-art performance on the PDBBind blind docking benchmark, demonstrating the effectiveness of our paradigm in enhancing molecular docking accuracy.",
    "keywords": "molecular docking, ai4science",
    "pdf_url": "https://openreview.net/pdf?id=zDC3iCBxJb",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on molecular docking of ligands to protein pockets, a core task in drug discovery and molecular modeling. It references PDBBind, protein–ligand interactions, and diffusion-based docking models, all of which are central to Biomedicine AI applications in drug design and computational biology.",
    "prompt_tokens": 20364,
    "completion_tokens": 92,
    "total_tokens": 20456,
    "topic": "Drug Discovery - Molecular Docking",
    "method": "Group docking with diffusion models; triangle attention; ligand grouping",
    "application": "Protein-ligand docking",
    "code_link": "N/A",
    "dataset_name": [
      "PDBBind v2020"
    ]
  },
  {
    "id": "NPNUHgHF2w",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "CBraMod: A Criss-Cross Brain Foundation Model for EEG Decoding",
    "authors": [
      "Jiquan Wang",
      "Sha Zhao",
      "Zhiling Luo",
      "Yangxuan Zhou",
      "Haiteng Jiang",
      "Shijian Li",
      "Tao Li",
      "Gang Pan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Electroencephalography (EEG) is a non-invasive technique to measure and record brain electrical activity, widely used in various BCI and healthcare applications. Early EEG decoding methods rely on supervised learning, limited by specific tasks and datasets, hindering model performance and generalizability. With the success of large language models, there is a growing body of studies focusing on EEG foundation models. However, these studies still leave challenges: Firstly, most of existing EEG foundation models employ full EEG modeling strategy. It models the spatial and temporal dependencies between all EEG patches together, but ignores that the spatial and temporal dependencies are heterogeneous due to the unique structural characteristics of EEG signals. Secondly, existing EEG foundation models have limited generalizability on a wide range of downstream BCI tasks due to varying formats of EEG data, making it challenging to adapt to. To address these challenges, we propose a novel foundation model called CBraMod. Specifically, we devise a criss-cross transformer as the backbone to thoroughly leverage the structural characteristics of EEG signals, which can model spatial and temporal dependencies separately through two parallel attention mechanisms. And we utilize an asymmetric conditional positional encoding scheme which can encode positional information of EEG patches and be easily adapted to the EEG with diverse formats. CBraMod is pre-trained on a very large corpus of EEG through patch-based masked EEG reconstruction. We evaluate CBraMod on up to 10 downstream BCI tasks (12 public datasets). CBraMod achieves the state-of-the-art performance across the wide range of tasks, proving its strong capability and generalizability. The source code is publicly available at https://github.com/wjq-learning/CBraMod.",
    "keywords": "Foundation Model; EEG; Criss-Cross Transformer; Downstream BCI tasks",
    "pdf_url": "https://openreview.net/pdf?id=NPNUHgHF2w",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on modeling electroencephalography (EEG) signals—an established biomedical imaging modality—“widely used in various BCI and healthcare applications.” It introduces a foundation model for “patch-based masked EEG reconstruction” and evaluates on “downstream BCI tasks,” which clearly situates it in the realm of medical AI for physiological signal decoding and neurotechnology.",
    "prompt_tokens": 20153,
    "completion_tokens": 163,
    "total_tokens": 20316,
    "topic": "BCI - EEG Foundation Models",
    "method": "Criss-cross transformer; patch-based masked EEG reconstruction",
    "application": "EEG signal classification – emotion recognition and motor imagery",
    "code_link": "https://github.com/wjq-learning/CBraMod",
    "dataset_name": [
      "FACED",
      "SEED-V",
      "PhysioNet-MI",
      "SHU-MI",
      "ISRUC",
      "CHB-MIT",
      "BCIC2020-3",
      "Mumtaz2016",
      "SEED-VIG",
      "MentalArithmetic",
      "TUEV",
      "TUAB"
    ]
  },
  {
    "id": "5WEpbilssv",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Contextualizing biological perturbation experiments through language",
    "authors": [
      "Menghua Wu",
      "Russell Littman",
      "Jacob Levine",
      "Lin Qiu",
      "Tommaso Biancalani",
      "David Richmond",
      "Jan-Christian Huetter"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "High-content perturbation experiments allow scientists to probe biomolecular systems at unprecedented resolution, but experimental and analysis costs pose significant barriers to widespread adoption. Machine learning has the potential to guide efficient exploration of the perturbation space and extract novel insights from these data. However, current approaches neglect the semantic richness of the relevant biology, and their objectives are misaligned with downstream biological analyses. In this paper, we hypothesize that large language models (LLMs) present a natural medium for representing complex biological relationships and rationalizing experimental outcomes. We propose PerturbQA, a benchmark for structured reasoning over perturbation experiments. Unlike current benchmarks that primarily interrogate existing knowledge, PerturbQA is inspired by open problems in perturbation modeling: prediction of differential expression and change of direction for unseen perturbations, and gene set enrichment. We evaluate state-of-the-art machine learning and statistical approaches for modeling perturbations, as well as standard LLM reasoning strategies, and we find that current methods perform poorly on PerturbQA. As a proof of feasibility, we introduce Summer (SUMMarize, retrievE, and answeR, a simple, domain-informed LLM framework that matches or exceeds the current state-of-the-art. Our code and data are publicly available at https://github.com/genentech/PerturbQA.",
    "keywords": "large language models, Perturb-seq, perturbation experiments, knowledge graphs, retrieval-augmented generation, chain of thought prompting",
    "pdf_url": "https://openreview.net/pdf?id=5WEpbilssv",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on modeling high-content biological perturbation experiments (e.g. differential gene expression, gene set enrichment, Perturb-seq) using machine learning and large language models. These tasks—probing biomolecular systems at single-cell resolution and predicting transcriptional responses—fall squarely within biomedical research rather than general ML, making it a Biomedicine AI contribution.",
    "prompt_tokens": 20861,
    "completion_tokens": 120,
    "total_tokens": 20981,
    "topic": "Bioinformatics - Gene Expression Analysis",
    "method": "LLM-based reasoning; graph-based knowledge retrieval; chain-of-thought prompting",
    "application": "Differential expression prediction",
    "code_link": "https://github.com/genentech/PerturbQA",
    "dataset_name": [
      "K562",
      "RPE1",
      "HepG2",
      "Jurkat",
      "K562-Set"
    ]
  },
  {
    "id": "iZl0VqEdxa",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Uncertainty modeling for fine-tuned implicit functions",
    "authors": [
      "Anna Susmelj",
      "Mael Macuglia",
      "Natasa Tagasovska",
      "Reto Sutter",
      "Sebastiano Caprara",
      "Jean-Philippe Thiran",
      "Ender Konukoglu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Implicit functions such as Neural Radiance Fields (NeRFs), occupancy networks, and signed distance functions (SDFs) have become pivotal in computer vision for reconstructing detailed object shapes from sparse views. Achieving optimal performance with these models can be challenging due to the extreme sparsity of inputs and distribution shifts induced by data corruptions. To this end, large, noise-free synthetic datasets can serve as shape priors to help models fill in gaps, but the resulting reconstructions must be approached with caution. Uncertainty estimation is crucial for assessing the quality of these reconstructions, particularly in identifying areas where the model is uncertain about the parts it has inferred from the prior. In this paper, we introduce Dropsembles, a novel method for uncertainty estimation in tuned implicit functions. We demonstrate the efficacy of our approach through a series of experiments, starting with toy examples and progressing to a real-world scenario. Specifically, we train a Convolutional Occupancy Network on synthetic anatomical data and test it on low-resolution MRI segmentations of the lumbar spine. Our results show that Dropsembles achieve the accuracy and calibration levels of deep ensembles but with significantly less computational cost.",
    "keywords": "uncertainty, implicit functions, 3D reconstruction, occupancy networks",
    "pdf_url": "https://openreview.net/pdf?id=iZl0VqEdxa",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper applies implicit 3D reconstruction methods to low-resolution MRI segmentations of the lumbar spine—a clear medical imaging task. It uses “synthetic anatomical data” and tests on “MRI segmentations,” which directly falls under Healthcare AI for medical image analysis.",
    "prompt_tokens": 21099,
    "completion_tokens": 105,
    "total_tokens": 21204,
    "topic": "3D Reconstruction - Uncertainty Modeling",
    "method": "Elastic Weight Consolidation; Dropsembles",
    "application": "3D shape reconstruction from sparse input",
    "code_link": "https://github.com/klanita/Dropsembles",
    "dataset_name": [
      "ShapeNet",
      "MNIST",
      "Lumbar spine MRI"
    ]
  },
  {
    "id": "VGURexnlUL",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Accelerating 3D Molecule Generation via Jointly Geometric Optimal Transport",
    "authors": [
      "Haokai Hong",
      "Wanyu Lin",
      "KC Tan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "This paper proposes a new 3D molecule generation framework, called GOAT, for fast and effective 3D molecule generation based on the flow-matching optimal transport objective. Specifically, we formulate a geometric transport formula for measuring the cost of mapping multi-modal features (e.g., continuous atom coordinates and categorical atom types) between a base distribution and a target data distribution. Our formula is solved within a joint, equivariant, and smooth representation space. This is achieved by transforming the multi-modal features into a continuous latent space with equivariant networks. In addition, we find that identifying optimal distributional coupling is necessary for fast and effective transport between any two distributions. We further propose a mechanism for estimating and purifying optimal coupling to train the flow model with optimal transport. By doing so, GOAT can turn arbitrary distribution couplings into new deterministic couplings, leading to an estimated optimal transport plan for fast 3D molecule generation. The purification filters out the subpar molecules to ensure the ultimate generation quality. We theoretically and empirically prove that the proposed optimal coupling estimation and purification yield transport plan with non-increasing cost. Finally, extensive experiments show that GOAT enjoys the efficiency of solving geometric optimal transport, leading to a double speedup compared to the sub-optimal method while achieving the best generation quality regarding validity, uniqueness, and novelty.",
    "keywords": "Molecule Generation, Flow Matching, Fast Generation",
    "pdf_url": "https://openreview.net/pdf?id=VGURexnlUL",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper proposes a novel 3D molecule generation framework (GOAT) for generating atomic coordinates and atom types, which falls squarely under “molecular generation” and “molecular modeling” — a core task in drug discovery and biomedicine. Even though it does not explicitly mention a therapeutic application, the focus on 3D molecule generation is a standard biomedical AI task used in drug design and screening.",
    "prompt_tokens": 20550,
    "completion_tokens": 101,
    "total_tokens": 20651,
    "topic": "Drug Discovery - Structural Modeling",
    "method": "Flow matching; geometric optimal transport",
    "application": "3D molecule generation",
    "code_link": "https://github.com/WanyuGroup/ICLR2025-GOAT",
    "dataset_name": [
      "QM9",
      "GEOM-DRUG"
    ]
  },
  {
    "id": "GK5ni7tIHp",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "TFG-Flow: Training-free Guidance in Multimodal Generative Flow",
    "authors": [
      "Haowei Lin",
      "Shanda Li",
      "Haotian Ye",
      "Yiming Yang",
      "Stefano Ermon",
      "Yitao Liang",
      "Jianzhu Ma"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Given an unconditional generative model and a predictor for a target property (e.g., a classifier), the goal of training-free guidance is to generate samples with desirable target properties without additional training. As a highly efficient technique for steering generative models toward flexible outcomes, training-free guidance has gained increasing attention in diffusion models. However, existing methods only handle data in continuous spaces, while many scientific applications involve both continuous and discrete data (referred to as multimodality). Another emerging trend is the growing use of the simple and general flow matching framework in building generative foundation models, where guided generation remains under-explored. To address this, we introduce TFG-Flow, a novel training-free guidance method for multimodal generative flow. TFG-Flow addresses the curse-of-dimensionality while maintaining the property of unbiased sampling in guiding discrete variables. We validate TFG-Flow on four molecular design tasks and show that TFG-Flow has great potential in drug design by generating molecules with desired properties.",
    "keywords": "flow matching, molecular design, training-free guidance",
    "pdf_url": "https://openreview.net/pdf?id=GK5ni7tIHp",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract explicitly mentions “molecular design tasks” and “drug design,” indicating that the method is applied to generate molecules with desired properties for therapeutic purposes. Generative flow methods for drug discovery clearly fall under Biomedicine AI.",
    "prompt_tokens": 20688,
    "completion_tokens": 110,
    "total_tokens": 20798,
    "topic": "Drug Discovery - Target-based",
    "method": "Guided multimodal flow; training-free guidance",
    "application": "Molecular design and generation",
    "code_link": "https://github.com/linhaowei1/TFG-Flow",
    "dataset_name": [
      "QM9",
      "GEOM-Drug",
      "CrossDocked2020"
    ]
  },
  {
    "id": "XQlccqJpCC",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Going Beyond Static: Understanding Shifts with Time-Series Attribution",
    "authors": [
      "Jiashuo Liu",
      "Nabeel Seedat",
      "Peng Cui",
      "Mihaela van der Schaar"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Distribution shifts in time-series data are complex due to temporal dependencies, multivariable interactions, and trend changes. \nHowever, robust methods often rely on structural assumptions that lack thorough empirical validation, limiting their practical applicability. \nIn order to support an empirically grounded inductive approach to research, we introduce  our **T**ime-**S**eries **S**hift **A**ttribution (TSSA) framework, which analyzes *problem-specific* patterns of distribution shifts. Our framework attributes performance degradation from various types of shifts to each *temporal data property* in a detailed manner, supported by theoretical analysis of unbiasedness and asymptotic properties. Empirical studies in real-world healthcare applications highlight how the TSSA framework enhances the understanding of time-series shifts, facilitating reliable model deployment and driving targeted improvements from both algorithmic and data-centric perspectives.",
    "keywords": "distribution shifts, performance drop, attribution, time-series data",
    "pdf_url": "https://openreview.net/pdf?id=XQlccqJpCC",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract explicitly states that “Empirical studies in real-world healthcare applications” demonstrate the utility of the TSSA framework. Although the core contribution is a general time-series shift attribution method, its evaluation and motivation clearly center on healthcare data, indicating relevance to Healthcare AI.",
    "prompt_tokens": 21047,
    "completion_tokens": 86,
    "total_tokens": 21133,
    "topic": "Time Series - Distribution Shift Analysis",
    "method": "Time-Series Shift Attribution; Transformer-based models",
    "application": "Mortality prediction – ICU",
    "code_link": "N/A",
    "dataset_name": [
      "MIMIC"
    ]
  },
  {
    "id": "uNd289HjLi",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Score-based Self-supervised MRI Denoising",
    "authors": [
      "Jiachen Tu",
      "Yaokun Shi",
      "Fan Lam"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Magnetic resonance imaging (MRI) is a powerful noninvasive diagnostic imaging tool that provides unparalleled soft tissue contrast and anatomical detail. Noise contamination, especially in accelerated and/or low-field acquisitions, can significantly degrade image quality and diagnostic accuracy. Supervised learning based denoising approaches have achieved impressive performance but require high signal-to-noise ratio (SNR) labels, which are often unavailable. Self-supervised learning holds promise to address the label scarcity issue, but existing self-supervised denoising methods tend to oversmooth fine spatial features and often yield inferior performance than supervised methods. We introduce Corruption2Self (C2S), a novel score-based self-supervised framework for MRI denoising. At the core of C2S is a generalized denoising score matching (GDSM) loss, which extends denoising score matching to work directly with noisy observations by modeling the conditional expectation of higher-SNR images given further corrupted observations. This allows the model to effectively learn denoising across multiple noise levels directly from noisy data. Additionally, we incorporate a reparameterization of noise levels to stabilize training and enhance convergence, and introduce a detail refinement extension to balance noise reduction with the preservation of fine spatial features. Moreover, C2S can be extended to multi-contrast denoising by leveraging complementary information across different MRI contrasts. We demonstrate that our method achieves state-of-the-art performance among self-supervised methods and competitive results compared to supervised counterparts across varying noise conditions and MRI contrasts on the M4Raw and fastMRI dataset. The project website is available at: https://jiachentu.github.io/Corruption2Self-Self-Supervised-Denoising/.",
    "keywords": "Generalized Denoising Score Matching; Self-supervised Learning; Self-supervised Denoising; Score-based denoising; Medical Image Denoising;",
    "pdf_url": "https://openreview.net/pdf?id=uNd289HjLi",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper develops a self-supervised denoising method specifically for MRI, a core medical imaging modality. It references MRI acquisitions, noise reduction for diagnostic accuracy, multi-contrast MRI, and evaluates on clinical datasets (M4Raw, fastMRI), all of which are central to Healthcare AI’s medical imaging domain.",
    "prompt_tokens": 21051,
    "completion_tokens": 120,
    "total_tokens": 21171,
    "topic": "Medical Imaging - Denoising",
    "method": "Score-matching; self-supervised learning; Noise Variance Conditioned Multi-Head Self-Attention (NVC-MSA)",
    "application": "MRI denoising",
    "code_link": "https://openreview.net/forum?id=wxPnuFp8fZ",
    "dataset_name": [
      "M4Raw",
      "fastMRI"
    ]
  },
  {
    "id": "0mtz0pet1z",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Incremental Causal Effect for Time to Treatment Initialization",
    "authors": [
      "Andrew Ying",
      "Zhichen Zhao",
      "Ronghui Xu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We consider time to treatment initialization. This can commonly occur in preventive medicine, such as disease screening and vaccination; it can also occur with non-fatal health conditions such as HIV infection without the onset of AIDS. While traditional causal inference focused on ‘when to treat’ and its effects, including their possible dependence on subject characteristics, we consider the incremental causal effect when the intensity of time to treatment initialization is intervened upon. We provide identification of the incremental causal effect without the commonly required positivity assumption, as well as an estimation framework using inverse probability weighting. We illustrate our approach via simulation, and apply it to a rheumatoid arthritis study to evaluate the incremental effect of time to start methotrexate on joint pain.",
    "keywords": "Causal Inference, Positivity, Incremental intervention, Incremental Causal Effect, Inverse probability weighting",
    "pdf_url": "https://openreview.net/pdf?id=0mtz0pet1z",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper develops causal‐inference methods for “time to treatment initialization” in preventive medicine (e.g., disease screening, vaccination) and non-fatal health conditions (HIV, rheumatoid arthritis). It specifically applies the framework to evaluate the effect of starting methotrexate on joint pain—clearly a clinical treatment setting. These are strong indicators of a healthcare/biomedicine application.",
    "prompt_tokens": 20792,
    "completion_tokens": 96,
    "total_tokens": 20888,
    "topic": "Causal Inference - Treatment Timing",
    "method": "Incremental causal effect modeling; inverse probability weighting (IPW)",
    "application": "Evaluating treatment timing effect – rheumatoid arthritis",
    "code_link": "N/A",
    "dataset_name": [
      "Methotrexate Data"
    ]
  },
  {
    "id": "xOmC5LiVuN",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Learning General-purpose Biomedical Volume Representations using Randomized Synthesis",
    "authors": [
      "Neel Dey",
      "Benjamin Billot",
      "Hallee E. Wong",
      "Clinton Wang",
      "Mengwei Ren",
      "Ellen Grant",
      "Adrian V Dalca",
      "Polina Golland"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Current volumetric biomedical foundation models struggle to generalize as public 3D datasets are small and do not cover the broad diversity of medical procedures, conditions, anatomical regions, and imaging protocols. We address this by creating a representation learning method that instead anticipates strong domain shifts at training time itself. We first propose a data engine that synthesizes highly variable training samples that would enable generalization to new biomedical contexts. To then train a single 3D network for any voxel-level task, we develop a contrastive learning method that pretrains the network to be stable against nuisance imaging variation simulated by the data engine, a key inductive bias for generalization. This network's features can be used as robust representations of input images for downstream tasks and its weights provide a strong, _dataset-agnostic_ initialization for finetuning on new datasets. As a result, we set new standards across _both_ multimodality registration and few-shot segmentation, a first for any 3D biomedical vision model, all without (pre-)training on any existing dataset of real images.",
    "keywords": "synthetic data, representation learning, medical image analysis, image registration, image segmentation",
    "pdf_url": "https://openreview.net/pdf?id=xOmC5LiVuN",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on volumetric biomedical data and medical image analysis, specifically addressing “medical image analysis,” “image registration,” and “image segmentation” on 3D biomedical scans. It proposes a foundation model for downstream clinical imaging tasks (CT/MRI-like volumes), a core topic in Healthcare AI/Biomedicine AI.",
    "prompt_tokens": 20844,
    "completion_tokens": 121,
    "total_tokens": 20965,
    "topic": "Biomedical Imaging - Representation Learning",
    "method": "Contrastive learning; Volumetric pretraining",
    "application": "Multimodality registration and segmentation",
    "code_link": "https://www.neeldey.com/anatomix/",
    "dataset_name": [
      "MM-WHS",
      "FeTA",
      "AMOS-CT",
      "PROMISE12",
      "WUFetal",
      "MSD-Heart"
    ]
  },
  {
    "id": "BksqWM8737",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "ProteinBench: A Holistic Evaluation of Protein Foundation Models",
    "authors": [
      "Fei YE",
      "Zaixiang Zheng",
      "Dongyu Xue",
      "Yuning Shen",
      "Lihao Wang",
      "Yiming Ma",
      "Yan Wang",
      "Xinyou Wang",
      "Xiangxin Zhou",
      "Quanquan Gu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Recent years have witnessed a surge in the development of protein foundation models, significantly improving performance in protein prediction and generative tasks ranging from 3D structure prediction and protein design to conformational dynamics. However, the capabilities and limitations associated with these models remain poorly understood due to the absence of a unified evaluation framework. To fill this gap, we introduce ProteinBench, a holistic evaluation framework designed to enhance the transparency of protein foundation models. Our approach consists of three key components: (i) A taxonomic classification of tasks that broadly encompass the main challenges in the protein domain, based on the relationships between different protein modalities; (ii) A multi-metric evaluation approach that assesses performance across four key dimensions: quality, novelty, diversity, and robustness; and (iii) In-depth analyses from various user objectives, providing a holistic view of model performance. Our comprehensive evaluation of protein foundation models reveals several key findings that shed light on their current capabilities and limitations. To promote transparency and facilitate further research, we release the evaluation dataset, code, and a public leaderboard publicly for further analysis and a general modular toolkit. We intend for ProteinBench to be a living benchmark for establishing a standardized, in-depth evaluation framework for protein foundation models, driving their development and application while fostering collaboration within the field.",
    "keywords": "Protein foundation model, benchmark, protein design, protein conformation prediction",
    "pdf_url": "https://openreview.net/pdf?id=BksqWM8737",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper centers on “protein foundation models” with tasks such as “protein design” and “protein conformation prediction,” which are core topics in molecular modeling and biomedicine. Protein structure prediction and generative protein design directly impact drug discovery and therapeutic development, placing this work squarely in the Biomedicine AI domain.",
    "prompt_tokens": 20961,
    "completion_tokens": 103,
    "total_tokens": 21064,
    "topic": "Bioinformatics - Protein Design and Conformation",
    "method": "Protein foundation models; Diffusion models",
    "application": "Evaluating protein sequences and predictive modeling",
    "code_link": "https://github.com/proteinbench",
    "dataset_name": [
      "ATLAS",
      "SAbDab",
      "Protein Data Bank"
    ]
  },
  {
    "id": "7zwIEbSTDy",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "PPT: Patch Order Do Matters In Time Series Pretext Task",
    "authors": [
      "Jaeho Kim",
      "Kwangryeol Park",
      "Sukmin Yun",
      "Seulki Lee"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Recently, patch-based models have been widely discussed in time series analysis. However, existing pretext tasks for patch-based learning, such as masking, may not capture essential time and channel-wise patch interdependencies in time series data, presumed to result in subpar model performance. In this work, we introduce *Patch order-aware Pretext Task (PPT)*, a new self-supervised patch order learning pretext task for time series classification. PPT exploits the intrinsic sequential order information among patches across time and channel dimensions of time series data, where model training is aided by channel-wise patch permutations. The permutation disrupts patch order consistency across time and channel dimensions with controlled intensity to provide supervisory signals for learning time series order characteristics. To this end, we propose two patch order-aware learning methods: patch order consistency learning, which quantifies patch order correctness, and contrastive learning, which distinguishes weakly permuted patch sequences from strongly permuted ones. With patch order learning, we observe enhanced model performance, e.g., improving up to 7% accuracy for the supervised cardiogram task and outperforming mask-based learning by 5% in the self-supervised human activity recognition task. We also propose ACF-CoS, an evaluation metric that measures the *importance of orderness* for time series datasets, which enables pre-examination of the efficacy of PPT in model training.",
    "keywords": "Time Series Classification, Self-Supervised Learning, Pretext Task",
    "pdf_url": "https://openreview.net/pdf?id=7zwIEbSTDy",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the paper focuses on a general self-supervised learning method for time series, it explicitly reports up to a 7% accuracy improvement on a “supervised cardiogram task,” i.e., ECG signal classification, which is a core healthcare/biomedical application. This use of medical time-series data (cardiogram) qualifies it as relevant to Healthcare AI.",
    "prompt_tokens": 20942,
    "completion_tokens": 105,
    "total_tokens": 21047,
    "topic": "Time Series - Representation Learning",
    "method": "Patch-based time series modeling; contrastive learning; consistency loss",
    "application": "Time series classification",
    "code_link": "N/A",
    "dataset_name": [
      "MS HAR",
      "Gilon HAR",
      "EMOPain",
      "PTB ECG",
      "Sleep EEG"
    ]
  },
  {
    "id": "Tqdsruwyac",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Estimation of single-cell and tissue perturbation effect in spatial transcriptomics via Spatial Causal Disentanglement",
    "authors": [
      "Stathis Megas",
      "Daniel G. Chen",
      "Krzysztof Polanski",
      "Moshe Eliasof",
      "Carola-Bibiane Schönlieb",
      "Sarah A Teichmann"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Models of Virtual Cells and Virtual Tissues at single-cell resolution would allow us to test perturbations in silico and accelerate progress in tissue and cell engineering. \nHowever, most such models are not rooted in causal inference and as a result, could mistake correlation for causation.\nWe introduce Celcomen, a novel generative graph neural network grounded in mathematical causality to disentangle intra- and inter-cellular gene regulation in spatial transcriptomics and single-cell data. \nCelcomen can also be prompted by perturbations to generate spatial counterfactuals, thus offering insights into experimentally inaccessible states, with potential applications in human health. \nWe validate the model's disentanglement and identifiability through simulations, and demonstrate its counterfactual predictions in clinically relevant settings, including human glioblastoma and fetal spleen, recovering inflammation-related gene programs post immune system perturbation. \nMoreover, it supports mechanistic interpretability, as its parameters can be reverse-engineered from observed behavior, making it an accessible model for understanding both neural networks and complex biological systems.",
    "keywords": "spatial causal inference, spatially disentangled representations, spatial transcriptomics, mechanistic interpretability",
    "pdf_url": "https://openreview.net/pdf?id=Tqdsruwyac",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on spatial transcriptomics and single-cell gene regulation (“intra- and inter-cellular gene regulation in spatial transcriptomics”), applies the model to clinically relevant settings such as human glioblastoma and fetal spleen, and recovers inflammation-related gene programs after immune perturbation. These are clear indicators of biomedical research using AI on molecular and tissue-level data.",
    "prompt_tokens": 20798,
    "completion_tokens": 113,
    "total_tokens": 20911,
    "topic": "Bioinformatics - Spatial Transcriptomics",
    "method": "Causal inference; k-hop Graph Neural Networks (GNNs)",
    "application": "Spatial counterfactual prediction – tissue-level perturbation modeling",
    "code_link": "https://shorturl.at/cNQt0",
    "dataset_name": [
      "Xenium",
      "Visium",
      "Perturb-map"
    ]
  },
  {
    "id": "p66a00KLWN",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "NExT-Mol: 3D Diffusion Meets 1D Language Modeling for 3D Molecule Generation",
    "authors": [
      "Zhiyuan Liu",
      "Yanchen Luo",
      "Han Huang",
      "Enzhi Zhang",
      "Sihang Li",
      "Junfeng Fang",
      "Yaorui Shi",
      "Xiang Wang",
      "Kenji Kawaguchi",
      "Tat-Seng Chua"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "3D molecule generation is crucial for drug discovery and material design. While prior efforts focus on 3D diffusion models for their benefits in modeling continuous 3D conformers, they overlook the advantages of 1D SELFIES-based Language Models (LMs), which can generate 100\\% valid molecules and leverage the billion-scale 1D molecule datasets. To combine these advantages for 3D molecule generation, we propose a foundation model -- NExT-Mol: 3D Diffusion Meets 1D Language Modeling for 3D Molecule Generation. NExT-Mol uses an extensively pretrained molecule LM for 1D molecule generation, and subsequently predicts the generated molecule's 3D conformers with a 3D diffusion model. We enhance NExT-Mol's performance by scaling up the LM's model size, refining the diffusion neural architecture, and applying 1D to 3D transfer learning. Notably, our 1D molecule LM significantly outperforms baselines in distributional similarity while ensuring validity, and our 3D diffusion model achieves leading performances in conformer prediction. Given these improvements in 1D and 3D modeling, NExT-Mol achieves a 26\\% relative improvement in 3D FCD for de novo 3D generation on GEOM-DRUGS, and a 13\\% average relative gain for conditional 3D generation on QM9-2014. Our codes and pretrained checkpoints are available at https://github.com/acharkq/NExT-Mol.",
    "keywords": "3D molecule generation, molecular conformer generation, large language models, diffusion models, geometric deep learning",
    "pdf_url": "https://openreview.net/pdf?id=p66a00KLWN",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on 3D molecule generation “crucial for drug discovery,” and evaluates on benchmarks like GEOM-DRUGS and QM9, which are directly tied to molecular design for therapeutic applications. This places it squarely in the Biomedicine AI domain, as it addresses molecular modeling and generative chemistry for drug discovery.",
    "prompt_tokens": 20675,
    "completion_tokens": 127,
    "total_tokens": 20802,
    "topic": "Drug Discovery - Molecule Generation",
    "method": "Diffusion model; Transformer-based model (MoLlama); 1D-to-3D transfer learning",
    "application": "3D conformer prediction",
    "code_link": "https://github.com/acharkq/NExT-Mol",
    "dataset_name": [
      "GEOM-DRUGS",
      "GEOM-QM9",
      "QM9-2014"
    ]
  },
  {
    "id": "hLwcNSFhC2",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "SAGEPhos: Sage Bio-Coupled and Augmented Fusion for Phosphorylation Site Detection",
    "authors": [
      "Jingjie Zhang",
      "Hanqun CAO",
      "Zijun Gao",
      "Xiaorui Wang",
      "Chunbin Gu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Phosphorylation site prediction based on kinase-substrate interaction plays a vital role in understanding cellular signaling pathways and disease mechanisms. Computational methods for this task can be categorized into kinase-family-focused and individual kinase-targeted approaches. Individual kinase-targeted methods have gained prominence for their ability to explore a broader protein space and provide more precise target information for kinase inhibitors. However, most existing individual kinase-based approaches focus solely on sequence inputs, neglecting crucial structural information. To address this limitation, we introduce SAGEPhos (Structure-aware kinAse-substrate bio-coupled and bio-auGmented nEtwork for Phosphorylation site prediction), a novel framework that modifies the semantic space of main protein inputs using auxiliary inputs at two distinct modality levels. At the inter-modality level, SAGEPhos introduces a Bio-Coupled Modal Fusion method, distilling essential kinase sequence information to refine task-oriented local substrate feature space, creating a shared semantic space that captures crucial kinase-substrate interaction patterns. Within the substrate's intra-modality domain, it focuses on Bio-Augmented Fusion, emphasizing 2D local sequence information while selectively incorporating 3D spatial information from predicted structures to complement the sequence space. Moreover, to address the lack of structural information in current datasets, we contribute a new, refined phosphorylation site prediction dataset, which incorporates crucial structural elements and will serve as a new benchmark for the field. Experimental results demonstrate that SAGEPhos significantly outperforms baseline methods, notably achieving almost 10\\% and 12\\% improvements in prediction accuracy and AUC-ROC, respectively. We further demonstrate our algorithm's robustness and generalization through stable results across varied data partitions and significant improvements in zero-shot scenarios. These results underscore the effectiveness of constructing a larger and more precise protein space in advancing the state-of-the-art in phosphorylation site prediction. We release the SAGEPhos models and code at https://github.com/ZhangJJ26/SAGEPhos.",
    "keywords": "Deep Learning, Bioinformatics, Phosphorylation prediction",
    "pdf_url": "https://openreview.net/pdf?id=hLwcNSFhC2",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper presents SAGEPhos, a deep learning framework for predicting protein phosphorylation sites—a core task in molecular signaling and drug‐target interaction studies. It focuses on kinase–substrate interactions, 3D protein structure information, and contributes a bioinformatics dataset for phosphorylation site prediction. These elements place it squarely in the Biomedicine AI domain, where AI is applied to protein modeling, post-translational modification prediction, and understanding disease mechanisms.",
    "prompt_tokens": 20649,
    "completion_tokens": 132,
    "total_tokens": 20781,
    "topic": "Bioinformatics - Post-translational Modifications",
    "method": "Relational Graph Convolutional Network (R-GCN); Multimodal gated-residual integration",
    "application": "Phosphorylation site prediction",
    "code_link": "https://github.com/ZhangJJ26/SAGEPhos",
    "dataset_name": [
      "Phospho.ELM",
      "PhosphoNetworks",
      "PhosphoSitePlus",
      "AlphaFoldDB"
    ]
  },
  {
    "id": "QaTBHSqmH9",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Size-Generalizable RNA Structure Evaluation by Exploring Hierarchical Geometries",
    "authors": [
      "Zongzhao Li",
      "Jiacheng Cen",
      "Wenbing Huang",
      "Taifeng Wang",
      "Le Song"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Understanding the 3D structure of RNA is essential for deciphering its function and developing RNA-based therapeutics. Geometric Graph Neural Networks (GeoGNNs) that conform to the $\\mathrm{E}(3)$-symmetry have advanced RNA structure evaluation, a crucial step toward RNA structure prediction. However, existing GeoGNNs are still defective in two aspects: 1. inefficient or incapable of capturing the full geometries of RNA; 2. limited generalization ability when the size of RNA significantly differs between training and test datasets. In this paper, we propose EquiRNA, a novel equivariant GNN model by exploring the three-level hierarchical geometries of RNA. At its core, EquiRNA effectively addresses the size generalization challenge by reusing the representation of nucleotide, the common building block shared across RNAs of varying sizes. Moreover, by adopting a scalarization-based equivariant GNN as the backbone, our model maintains directional information while offering higher computational efficiency compared to existing GeoGNNs. Additionally, we propose a size-insensitive $K$-nearest neighbor sampling strategy to enhance the model's robustness to RNA size shifts. We test our approach on our created benchmark as well as an existing dataset. The results show that our method significantly outperforms other state-of-the-art methods, providing a robust baseline for RNA 3D structure modeling and evaluation.",
    "keywords": "RNA Structure, RNA Evaluation, Geometric Deep Learning, Graph Neural Networks",
    "pdf_url": "https://openreview.net/pdf?id=QaTBHSqmH9",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on 3D RNA structure evaluation and modeling—key tasks in molecular modeling and drug discovery (“developing RNA-based therapeutics,” “RNA 3D structure modeling and evaluation”). It addresses hierarchical geometries of RNA and proposes an equivariant GNN for RNA structure, which is directly relevant to biomedicine AI for biomolecular research and therapeutic design.",
    "prompt_tokens": 20786,
    "completion_tokens": 103,
    "total_tokens": 20889,
    "topic": "Bioinformatics - RNA Structure Evaluation",
    "method": "Equivariant Graph Neural Networks (EquiRNA); size-insensitive K-nearest neighbor sampling",
    "application": "RNA 3D structure modeling and evaluation",
    "code_link": "N/A",
    "dataset_name": [
      "rRNAsolo",
      "ARES"
    ]
  },
  {
    "id": "MBBRHDuiwM",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "URLOST: Unsupervised Representation Learning without Stationarity or Topology",
    "authors": [
      "Zeyu Yun",
      "Juexiao Zhang",
      "Yann LeCun",
      "Yubei Chen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Unsupervised representation learning has seen tremendous progress. However, it is constrained by its reliance on domain specific stationarity and topology, a limitation not found in biological intelligence systems. For instance, unlike computer vision, human vision can process visual signals sampled from highly irregular and non-stationary sensors. We introduce a novel framework that learns from high-dimensional data without prior knowledge of stationarity and topology. Our model, abbreviated as URLOST, combines a learnable self-organizing layer, spectral clustering, and a masked autoencoder (MAE). We evaluate its effectiveness on three diverse data modalities including simulated biological vision data, neural recordings from the primary visual cortex, and gene expressions. Compared to state-of-the-art unsupervised learning methods like SimCLR and MAE, our model excels at learning meaningful representations across diverse modalities without knowing their stationarity or topology. It also outperforms other methods that are not dependent on these factors, setting a new benchmark in the field. We position this work as a step toward unsupervised learning methods capable of generalizing across diverse high-dimensional data modalities.",
    "keywords": "Unsupervised learning, Self-Supervised Learning, NeuroAI, Multi-Modality, Human Vision, Biologically-inspired Models",
    "pdf_url": "https://openreview.net/pdf?id=MBBRHDuiwM",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although URLOST is fundamentally a general unsupervised representation‐learning framework, the authors explicitly demonstrate its applicability to “gene expressions,” a core genomics task. Genomics and gene‐expression analysis are central to biomedicine AI (e.g., in biomarker discovery, single‐cell analysis, and molecular profiling). The inclusion of “gene expressions” alongside neural recordings from cortex indicates the method is applied to biomedical data, qualifying it as Biomedicine AI.",
    "prompt_tokens": 20831,
    "completion_tokens": 141,
    "total_tokens": 20972,
    "topic": "Unsupervised Learning - Multi-Domain Representation",
    "method": "Density adjusted spectral clustering; self-organizing layer; masked autoencoder (MAE)",
    "application": "Representation learning for data without stationarity or topology",
    "code_link": "https://github.com/zeyuyun1/URLOST",
    "dataset_name": [
      "CIFAR-10",
      "Permuted CIFAR-10",
      "Foveated CIFAR-10",
      "TCGA",
      "V1 neural response"
    ]
  },
  {
    "id": "JSB171dSUU",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Efficiently Democratizing Medical LLMs for 50 Languages via a Mixture of Language Family Experts",
    "authors": [
      "Guorui Zheng",
      "Xidong Wang",
      "Juhao Liang",
      "Nuo Chen",
      "Yuping Zheng",
      "Benyou Wang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Adapting medical Large  Language Models to local languages can reduce barriers to accessing healthcare services, but data scarcity remains a significant challenge, particularly for low-resource languages. To address this, we first construct a high-quality medical dataset and conduct analysis to ensure its quality. In order to leverage the generalization capability of multilingual LLMs to efficiently scale to more resource-constrained languages, we explore the internal information flow of LLMs from a multilingual perspective using Mixture of Experts (MoE) modularity. Technically, we propose a novel MoE routing method that employs language-specific experts and cross-lingual routing. Inspired by circuit theory, our routing analysis revealed a \\textit{``Spread Out in the End``} information flow mechanism: while earlier layers concentrate cross-lingual information flow, the later layers exhibit language-specific divergence. This insight directly led to the development of the Post-MoE architecture, which applies sparse routing only in the later layers while maintaining dense others. Experimental results demonstrate that this approach enhances the generalization of multilingual models to other languages while preserving interpretability. Finally, to efficiently scale the model to 50 languages, we introduce the concept of \\textit{language family} experts, drawing on linguistic priors, which enables scaling the number of languages without adding additional parameters.",
    "keywords": "Multilingual LLM, Medical LLM",
    "pdf_url": "https://openreview.net/pdf?id=JSB171dSUU",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly focuses on “medical Large Language Models,” the construction of a “high-quality medical dataset,” and democratizing access to “healthcare services” in 50 languages. The work is centered on adapting and scaling LLMs for medical/healthcare applications, which clearly places it in the Healthcare AI domain.",
    "prompt_tokens": 20542,
    "completion_tokens": 118,
    "total_tokens": 20660,
    "topic": "Multilingual Medical Models - Routing Architectures",
    "method": "Mixture of Experts (MoE); Hybrid Routing",
    "application": "Multilingual expansion in medical LLMs",
    "code_link": "https://github.com/FreedomIntelligence/ApolloMoE",
    "dataset_name": [
      "MMLU",
      "PMC-Patients",
      "ShareGPT",
      "Alpaca"
    ]
  },
  {
    "id": "3xqqYOKILp",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "BrainOOD: Out-of-distribution Generalizable Brain Network Analysis",
    "authors": [
      "Jiaxing Xu",
      "Yongqiang Chen",
      "Xia Dong",
      "Mengcheng Lan",
      "Tiancheng HUANG",
      "Qingtian Bian",
      "James Cheng",
      "Yiping Ke"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In neuroscience, identifying distinct patterns linked to neurological disorders, such as Alzheimer's and Autism, is critical for early diagnosis and effective intervention. Graph Neural Networks (GNNs) have shown promising in analyzing brain networks, but there are two major challenges in using GNNs: (1) distribution shifts in multi-site brain network data, leading to poor Out-of-Distribution (OOD) generalization, and (2) limited interpretability in identifying key brain regions critical to neurological disorders. Existing graph OOD methods, while effective in other domains, struggle with the unique characteristics of brain networks. To bridge these gaps, we introduce BrainOOD,  a novel framework tailored for brain networks that enhances GNNs' OOD generalization and interpretability. BrainOOD framework consists of a feature selector and a structure extractor, which incorporates various auxiliary losses including an improved Graph Information Bottleneck (GIB) objective to recover causal subgraphs. By aligning structure selection across brain networks and filtering noisy features, BrainOOD offers reliable interpretations of critical brain regions. Our approach outperforms 16 existing methods and improves generalization to OOD subjects by up to 8.5%. Case studies highlight the scientific validity of the patterns extracted, which aligns with the findings in known neuroscience literature. We also propose the first OOD brain network benchmark, which provides a foundation for future research in this field. Our code is available at https://github.com/AngusMonroe/BrainOOD.",
    "keywords": "Out-of-distribution Generalization, Brain Network Analysis, Graph Representation Learning",
    "pdf_url": "https://openreview.net/pdf?id=3xqqYOKILp",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on analyzing brain networks to identify patterns linked to neurological disorders such as Alzheimer’s and Autism for early diagnosis and intervention, directly targeting medical/clinical applications. It leverages fMRI‐style brain network data and aims to interpret critical brain regions related to disease, which clearly places it within Healthcare/Biomedicine AI.",
    "prompt_tokens": 20608,
    "completion_tokens": 116,
    "total_tokens": 20724,
    "topic": "Brain Networks - Out-of-Distribution Generalization",
    "method": "Graph Neural Networks (GNNs); Graph Information Bottleneck (GIB); High-pass GNN",
    "application": "Brain network classification – Autism and Alzheimer’s diagnosis",
    "code_link": "https://github.com/AngusMonroe/BrainOOD",
    "dataset_name": [
      "ABIDE",
      "ADNI"
    ]
  },
  {
    "id": "nYPuSzGE3X",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "InversionGNN: A Dual Path Network for Multi-Property Molecular Optimization",
    "authors": [
      "Yifan Niu",
      "Ziqi Gao",
      "Tingyang Xu",
      "Yang Liu",
      "Yatao Bian",
      "Yu Rong",
      "Junzhou Huang",
      "Jia Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Exploring chemical space to find novel molecules that simultaneously satisfy multiple properties is crucial in drug discovery. However, existing methods often struggle with trading off multiple properties due to the conflicting or correlated nature of chemical properties.  To tackle this issue, we introduce InversionGNN framework, an effective yet sample-efficient dual-path graph neural network (GNN) for multi-objective drug discovery.  In the direct prediction path of InversionGNN, we train the model for multi-property prediction to acquire knowledge of the optimal combination of functional groups.\nThen the learned chemical knowledge helps the inversion generation path to generate molecules with required properties. \nIn order to decode the complex knowledge of multiple properties in the inversion path, we propose a gradient-based Pareto search method to balance conflicting properties and generate Pareto optimal molecules. \nAdditionally, InversionGNN is able to search the full Pareto front approximately in discrete chemical space. Comprehensive experimental evaluations show that InversionGNN is both effective and sample-efficient in various discrete multi-objective settings including drug discovery.",
    "keywords": "multi-objective drug discovery",
    "pdf_url": "https://openreview.net/pdf?id=nYPuSzGE3X",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly targets “multi-objective drug discovery,” using graph neural networks to explore chemical space and generate novel molecules with desired pharmacological properties. Drug discovery is a core task in Biomedicine AI, involving molecular modeling and optimization for therapeutic applications.",
    "prompt_tokens": 20488,
    "completion_tokens": 101,
    "total_tokens": 20589,
    "topic": "Drug Discovery - Multi-objective Optimization",
    "method": "Graph Neural Networks (GNN); Gradient-Based Pareto Optimization",
    "application": "Drug property optimization",
    "code_link": "https://github.com/ivanniu/InversionGNN",
    "dataset_name": [
      "ZINC 250K"
    ]
  },
  {
    "id": "B07dLVWLyD",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Revisiting Convolution Architecture in the Realm of DNA Foundation Models",
    "authors": [
      "Yu Bo",
      "Weian Mao",
      "Yanjun Shao",
      "Weiqiang Bai",
      "Peng Ye",
      "Xinzhu Ma",
      "Junbo Zhao",
      "Hao Chen",
      "Chunhua Shen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In recent years, A variety of methods based on Transformer and state space model (SSM) architectures have been proposed, advancing foundational DNA language models. \nHowever, there is a lack of comparison between these recent approaches and the classical architecture—convolutional networks (CNNs)—on foundation model benchmarks.\nThis raises the question: are CNNs truly being surpassed by these recent approaches based on transformer and SSM architectures? In this paper, we develop a simple but well-designed CNN-based method, termed ConvNova. ConvNova identifies and proposes three effective designs: 1) dilated convolutions, 2) gated convolutions, and 3) a dual-branch framework for gating mechanisms. \nThrough extensive empirical experiments, we demonstrate that ConvNova significantly outperforms recent methods on more than half of the tasks across several foundation model benchmarks. For example, in histone-related tasks, ConvNova exceeds the second-best method by an average of 5.8\\%, while generally utilizing fewer parameters and enabling faster computation.  In addition, the experiments observed findings that may be related to biological characteristics. This indicates that CNNs are still a strong competitor compared to Transformers and SSMs. We anticipate that this work will spark renewed interest in CNN-based methods for DNA foundation models.",
    "keywords": "DNA modeling, foundation model, Genomic Language Model, Representation Learning",
    "pdf_url": "https://openreview.net/pdf?id=B07dLVWLyD",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper develops a foundation model for DNA sequence data (“Genomic Language Model,” “DNA modeling”) and evaluates on tasks like histone-related prediction. These are core problems in genomics and molecular biology, placing the work squarely in the domain of Biomedicine AI rather than general ML.",
    "prompt_tokens": 20314,
    "completion_tokens": 106,
    "total_tokens": 20420,
    "topic": "Bioinformatics - DNA Foundation Models",
    "method": "Convolutional Neural Networks (CNN); dilated convolution; gated convolution",
    "application": "Gene annotation and chromatin profile prediction",
    "code_link": "https://github.com/aim-uofa/ConvNova",
    "dataset_name": [
      "HG38",
      "GENCODE"
    ]
  },
  {
    "id": "pH543jrbe8",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Multimodal Lego: Model Merging and Fine-Tuning Across Topologies and Modalities in Biomedicine",
    "authors": [
      "Konstantin Hemker",
      "Nikola Simidjievski",
      "Mateja Jamnik"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Learning holistic computational representations in physical, chemical or biological systems requires the ability to process information from different distributions and modalities within the same model. Thus, the demand for multimodal machine learning models has sharply risen for modalities that go beyond vision and language, such as sequences, graphs, time series, or tabular data. While there are many available multimodal fusion and alignment approaches, most of them require end-to-end training, scale quadratically with the number of modalities, cannot handle cases of high modality imbalance in the training set, or are highly topology-specific, making them too restrictive for many biomedical learning tasks. This paper presents Multimodal Lego (MM-Lego), a general-purpose fusion framework to turn any set of encoders into a competitive multimodal model with no or minimal fine-tuning. We achieve this by introducing a wrapper for any unimodal encoder that enforces shape consistency between modality representations. It harmonises these representations by learning features in the frequency domain to enable model merging with little signal interference. We show that MM-Lego 1) can be used as a model merging method which achieves competitive performance with end-to-end fusion models without any fine-tuning, 2) can operate on any unimodal encoder, and 3) is a model fusion method that, with minimal fine-tuning, surpasses all benchmarks in five out of seven datasets.",
    "keywords": "multimodal, deep learning, fusion, biomedicine, model merging",
    "pdf_url": "https://openreview.net/pdf?id=pH543jrbe8",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper title and keywords explicitly reference “Biomedicine,” and the abstract discusses fusing modalities common in biomedical research (e.g., sequences, molecular graphs, time-series biosignals, tabular biological data). MM-Lego is presented as a general multmodal fusion framework “in Biomedicine,” implying direct application to biomedical systems and datasets.",
    "prompt_tokens": 20625,
    "completion_tokens": 114,
    "total_tokens": 20739,
    "topic": "Multimodal Biomedical Models - Fusion and Merging",
    "method": "Model merging; frequency-domain representation; cross-modal fusion",
    "application": "Survival analysis and disease classification",
    "code_link": "https://github.com/konst-int-i/mm-lego",
    "dataset_name": [
      "TCGA",
      "MIMIC",
      "SIIM-ISIC"
    ]
  },
  {
    "id": "Lb91pXwZMR",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "UniGEM: A Unified Approach to Generation and Property Prediction for Molecules",
    "authors": [
      "Shikun Feng",
      "Yuyan Ni",
      "Lu yan",
      "Zhi-Ming Ma",
      "Wei-Ying Ma",
      "Yanyan Lan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Molecular generation and molecular property prediction are both crucial for drug discovery, but they are often developed independently. Inspired by recent studies, which demonstrate that diffusion model, a prominent generative approach, can learn meaningful data representations that enhance predictive tasks, we explore the potential for developing a unified generative model in the molecular domain that effectively addresses both molecular generation and property prediction tasks. However, the integration of these tasks is challenging due to inherent inconsistencies, making simple multi-task learning ineffective. To address this, we propose UniGEM, the first unified model to successfully integrate molecular generation and property prediction, delivering superior performance in both tasks. Our key innovation lies in a novel two-phase generative process, where predictive tasks are activated in the later stages, after the molecular scaffold is formed. We further enhance task balance through innovative training strategies. Rigorous theoretical analysis and comprehensive experiments demonstrate our significant improvements in both tasks. The principles behind UniGEM hold promise for broader applications, including natural language processing and computer vision.",
    "keywords": "Molecular generation, representation learning",
    "pdf_url": "https://openreview.net/pdf?id=Lb91pXwZMR",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper centers on “molecular generation” and “molecular property prediction” explicitly for “drug discovery,” which is a core biomedical AI application. Developing models to generate molecules and predict their properties is directly relevant to biomedicine and therapeutic development.",
    "prompt_tokens": 20960,
    "completion_tokens": 99,
    "total_tokens": 21059,
    "topic": "Drug Discovery - Molecular Generation",
    "method": "Diffusion model; two-phase generative modeling",
    "application": "Molecule generation and property prediction",
    "code_link": "https://github.com/fengshikun/UniGEM",
    "dataset_name": [
      "QM9",
      "GEOM-Drugs"
    ]
  },
  {
    "id": "3b9SKkRAKw",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "LeFusion: Controllable Pathology Synthesis via Lesion-Focused Diffusion Models",
    "authors": [
      "Hantao Zhang",
      "Yuhe Liu",
      "Jiancheng Yang",
      "Shouhong Wan",
      "Xinyuan Wang",
      "Wei Peng",
      "Pascal Fua"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Patient data from real-world clinical practice often suffers from data scarcity and long-tail imbalances, leading to biased outcomes or algorithmic unfairness. This study addresses these challenges by generating lesion-containing image-segmentation pairs from lesion-free images. Previous efforts in medical imaging synthesis have struggled with separating lesion information from background, resulting in low-quality backgrounds and limited control over the synthetic output. Inspired by diffusion-based image inpainting, we propose LeFusion, a lesion-focused diffusion model. By redesigning the diffusion learning objectives to focus on lesion areas, we simplify the learning process and improve control over the output while preserving high-fidelity backgrounds by integrating forward-diffused background contexts into the reverse diffusion process. Additionally, we tackle two major challenges in lesion texture synthesis: 1) multi-peak and 2) multi-class lesions. We introduce two effective strategies: histogram-based texture control and multi-channel decomposition, enabling the controlled generation of high-quality lesions in difficult scenarios. Furthermore, we incorporate lesion mask diffusion, allowing control over lesion size, location, and boundary, thus increasing lesion diversity. Validated on 3D cardiac lesion MRI and lung nodule CT datasets, LeFusion-generated data significantly improves the performance of state-of-the-art segmentation models, including nnUNet and SwinUNETR.",
    "keywords": "data synthesis, diffusion models, cardiac MRI, lung nodule CT, segmentation",
    "pdf_url": "https://openreview.net/pdf?id=3b9SKkRAKw",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on generating and segmenting lesion-containing images in 3D cardiac MRI and lung nodule CT, which are clinical imaging modalities. It explicitly addresses “cardiac lesion MRI” and “lung nodule CT” and aims to improve segmentation models (nnUNet, SwinUNETR) for medical diagnosis. These are strong indicators of a healthcare AI application in medical imaging.",
    "prompt_tokens": 20545,
    "completion_tokens": 107,
    "total_tokens": 20652,
    "topic": "Medical Imaging - Pathology Synthesis",
    "method": "Lesion-focused diffusion model; histogram-based texture control; multi-channel decomposition",
    "application": "Synthetic lesion generation – CT and MRI",
    "code_link": "https://github.com/M3DV/LeFusion",
    "dataset_name": [
      "LIDC",
      "Emidec"
    ]
  },
  {
    "id": "kYwTmlq6Vn",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "PaPaGei: Open Foundation Models for Optical Physiological Signals",
    "authors": [
      "Arvind Pillai",
      "Dimitris Spathis",
      "Fahim Kawsar",
      "Mohammad Malekzadeh"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Photoplethysmography (PPG) is the leading non-invasive technique for monitoring biosignals and cardiovascular health, with widespread adoption in both clinical settings and consumer wearable devices. While machine learning models trained on PPG signals have shown promise, they tend to be task-specific and struggle with generalization. Current research is limited by the use of single-device datasets, insufficient exploration of out-of-domain generalization, and a lack of publicly available models, which hampers reproducibility. To address these limitations, we present PaPaGei, the first open foundation model for PPG signals. The model is pre-trained on over 57,000 hours of data, comprising 20 million unlabeled PPG segments from publicly available datasets. We introduce a novel representation learning approach that leverages domain knowledge of PPG signal morphology across individuals, enabling the capture of richer representations compared to traditional contrastive learning methods. We evaluate PaPaGei against state-of-the-art time-series foundation models and self-supervised learning benchmarks across 20 tasks from 10 diverse datasets, spanning cardiovascular health, sleep disorders, pregnancy monitoring, and wellbeing assessment. Our model demonstrates superior performance, improving classification and regression metrics by 6.3% and 2.9% respectively in at least 14 tasks. Notably, PaPaGei achieves these results while being more data- and parameter-efficient, outperforming models that are 70x larger. Beyond accuracy, we examine model robustness across different skin tones, establishing a benchmark for bias evaluation in future models. PaPaGei can serve as both a feature extractor and an encoder for multimodal models, opening up new opportunities for multimodal health monitoring. Models, data, and code are available at: https://github.com/nokia-bell-labs/papagei-foundation-model",
    "keywords": "self-supervised learning, foundation models, time series, Photoplethysmography (PPG), health, physiology",
    "pdf_url": "https://openreview.net/pdf?id=kYwTmlq6Vn",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on Photoplethysmography (PPG), a non-invasive biosignal widely used for cardiovascular health monitoring and consumer wearable devices. It develops a foundation model for physiological signal analysis across tasks including cardiovascular health, sleep disorders, pregnancy monitoring, and well-being assessment. These applications—patient monitoring, health assessment from wearable sensors, and robustness across skin tones—are clearly within the scope of Healthcare AI.",
    "prompt_tokens": 20327,
    "completion_tokens": 184,
    "total_tokens": 20511,
    "topic": "Time Series - Physiological Modeling",
    "method": "Self-supervised learning; Morphology-aware contrastive learning",
    "application": "Cardiovascular health monitoring; Sleep disorder prediction; Pregnancy monitoring",
    "code_link": "https://github.com/nokia-bell-labs/papagei-foundation-model",
    "dataset_name": [
      "VitalDB",
      "MIMIC-III",
      "MESA",
      "nuMoM2B",
      "VV",
      "PPG-BP",
      "SDB",
      "ECSMP",
      "WESAD",
      "PPG-DaLiA"
    ]
  },
  {
    "id": "eGqQyTAbXC",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "3D-MolT5: Leveraging Discrete Structural Information for Molecule-Text Modeling",
    "authors": [
      "Qizhi Pei",
      "Rui Yan",
      "Kaiyuan Gao",
      "Jinhua Zhu",
      "Lijun Wu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The integration of molecular and natural language representations has emerged as a focal point in molecular science, with recent advancements in Language Models (LMs) demonstrating significant potential for comprehensive modeling of both domains. However, existing approaches face notable limitations, particularly in their neglect of three-dimensional (3D) information, which is crucial for understanding molecular structures and functions. While some efforts have been made to incorporate 3D molecular information into LMs using external structure encoding modules, significant difficulties remain, such as insufficient interaction across modalities in pre-training and challenges in modality alignment. To address the limitations, we propose \\textbf{3D-MolT5}, a unified framework designed to model molecule in both sequence and 3D structure spaces. The key innovation of our approach lies in mapping fine-grained 3D substructure representations into a specialized 3D token vocabulary. This methodology facilitates the seamless integration of sequence and structure representations in a tokenized format, enabling 3D-MolT5 to encode molecular sequences, molecular structures, and text sequences within a unified architecture. Leveraging this tokenized input strategy, we build a foundation model that unifies the sequence and structure data formats. We then conduct joint pre-training with multi-task objectives to enhance the model's comprehension of these diverse modalities within a shared representation space. Thus, our approach significantly improves cross-modal interaction and alignment, addressing key challenges in previous work. Further instruction tuning demonstrated that our 3D-MolT5 has strong generalization ability and surpasses existing methods with superior performance in multiple downstream tasks, such as nearly 70\\% improvement on the molecular property prediction task compared to state-of-the-art methods. Our code is available at \\url{https://github.com/QizhiPei/3D-MolT5}.",
    "keywords": "molecule-text modeling, 3D molecular tokenization, language model",
    "pdf_url": "https://openreview.net/pdf?id=eGqQyTAbXC",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on 3D molecular modeling and “molecular property prediction,” which falls squarely under “molecular modeling” in the biomedical research domain. Its contributions—tokenizing 3D substructures and integrating sequence/structure data for downstream tasks—are directly relevant to biomedicine AI tasks such as drug discovery and molecular design.",
    "prompt_tokens": 20662,
    "completion_tokens": 125,
    "total_tokens": 20787,
    "topic": "Drug Discovery - Molecular Modeling",
    "method": "3D molecular tokenization; Transformer-based models",
    "application": "Molecular property prediction; 3D molecule captioning; text-based molecule generation",
    "code_link": "https://github.com/QizhiPei/3D-MolT5",
    "dataset_name": [
      "QM9",
      "PubChemQC",
      "PubChem",
      "CheBI-20"
    ]
  },
  {
    "id": "dsHpulHpOK",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Reinforcement Learning for Control of Non-Markovian Cellular Population Dynamics",
    "authors": [
      "Josiah C Kratz",
      "Jacob Adamczyk"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Many organisms and cell types, from bacteria to cancer cells, exhibit a remarkable ability to adapt to fluctuating environments. Additionally, cells can leverage memory of past environments to better survive previously-encountered stressors. From a control perspective, this adaptability poses significant challenges in driving cell populations toward extinction, and is thus an open question with great clinical significance. In this work, we focus on drug dosing in cell populations exhibiting phenotypic plasticity. For specific dynamical models switching between resistant and susceptible states, exact solutions are known. However, when the underlying system parameters are unknown, and for complex memory-based systems, obtaining the optimal solution is currently intractable. To address this challenge, we apply reinforcement learning (RL) to identify informed dosing strategies to control cell populations evolving under novel non-Markovian dynamics. We find that model-free deep RL is able to recover exact solutions and control cell populations even in the presence of long-range temporal dynamics.  To further test our approach in more realistic settings, we demonstrate performant RL-based control strategies in environments with dynamic memory strength.",
    "keywords": "optimal drug dosing, fractional differential equations, reinforcement learning, control theory",
    "pdf_url": "https://openreview.net/pdf?id=dsHpulHpOK",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “drug dosing in cell populations exhibiting phenotypic plasticity” and aims to “drive cell populations toward extinction,” which is directly relevant to therapeutic treatment planning in a biomedical context. References to controlling resistant versus susceptible cell states and optimal drug dosing strategies clearly place this work within Biomedicine AI.",
    "prompt_tokens": 21193,
    "completion_tokens": 97,
    "total_tokens": 21290,
    "topic": "Bioinformatics - Drug Resistance",
    "method": "Reinforcement Learning; Bang-bang control; Fractional differential equations",
    "application": "Drug resistance management",
    "code_link": "https://github.com/JacobHA/RL4Dosing",
    "dataset_name": [
      "N/A"
    ]
  },
  {
    "id": "3MnMGLctKb",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Multi-Modal and Multi-Attribute Generation of Single Cells with CFGen",
    "authors": [
      "Alessandro Palma",
      "Till Richter",
      "Hanyi Zhang",
      "Manuel Lubetzki",
      "Alexander Tong",
      "Andrea Dittadi",
      "Fabian J Theis"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Generative modeling of single-cell RNA-seq data is crucial for tasks like trajectory inference, batch effect removal, and simulation of realistic cellular data. However, recent deep generative models simulating synthetic single cells from noise operate on pre-processed continuous gene expression approximations, overlooking the discrete nature of single-cell data, which limits their effectiveness and hinders the incorporation of robust noise models. Additionally, aspects like controllable multi-modal and multi-label generation of cellular data remain underexplored. This work introduces CellFlow for Generation (CFGen), a flow-based conditional generative model that preserves the inherent discreteness of single-cell data. CFGen reliably generates whole-genome, multi-modal, single-cell data, improving the recovery of crucial biological data characteristics while tackling relevant generative tasks such as rare cell type augmentation and batch correction. We also introduce a novel framework for compositional data generation using Flow Matching. By showcasing CFGen on a diverse set of biological datasets and settings, we provide evidence of its value to the fields of computational biology and deep generative models.",
    "keywords": "scRNA-seq, Flow Matching, Generative modeling, Multiomics",
    "pdf_url": "https://openreview.net/pdf?id=3MnMGLctKb",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on generative modeling of single-cell RNA-seq data (“scRNA-seq”) and multi-omics data, which are key tasks in biomedical research and genomics. It explicitly addresses preserving the discreteness of single-cell data and generating realistic cellular profiles—strong indicators of biomedicine AI in the context of molecular and cellular biology.",
    "prompt_tokens": 21045,
    "completion_tokens": 135,
    "total_tokens": 21180,
    "topic": "Bioinformatics - Single-cell Data",
    "method": "Flow Matching; Conditional Generative Model; Classifier-free guidance",
    "application": "Data augmentation to improve classification of rare cell types; batch correction",
    "code_link": "https://github.com/theislab/CFGen",
    "dataset_name": [
      "NeurIPS 2021",
      "Tabula Muris",
      "PBMC COVID",
      "HLCA",
      "PBMC10K",
      "C. Elegans"
    ]
  },
  {
    "id": "peX9zpWgg4",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Adaptive Shrinkage Estimation for Personalized Deep Kernel Regression in Modeling Brain Trajectories",
    "authors": [
      "Vasiliki Tassopoulou",
      "Haochang Shou",
      "Christos Davatzikos"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Longitudinal biomedical studies monitor individuals over time to capture dynamics in brain development, disease progression, and treatment effects. However, estimating trajectories of brain biomarkers is challenging due to biological variability, inconsistencies in measurement protocols (e.g., differences in MRI scanners) as well as scarcity and irregularity in longitudinal measurements. Herein,\nwe introduce a novel personalized deep kernel regression framework for forecasting brain biomarkers, with application to regional volumetric measurements. Our approach integrates two key components: a population model that captures brain trajectories from a large and diverse cohort, and a subject-specific model that captures individual trajectories. To optimally combine these, we propose Adaptive Shrinkage Estimation, which effectively balances population and subject-specific models. We assess our model’s performance through predictive accuracy metrics, uncertainty quantification, and validation against external clinical studies. Benchmarking against state-of-the-art statistical and machine learning models—including linear mixed effects models, generalized additive models, and deep learning methods—demonstrates the superior predictive performance of our approach. Additionally, we apply our method to predict trajectories of composite neuroimaging biomarkers, which highlights the versatility of our approach in modeling the progression of longitudinal neuroimaging biomarkers. Furthermore, validation on three external neuroimaging studies confirms the robustness of our method across different clinical contexts. We make the code available at https://github.com/vatass/AdaptiveShrinkageDKGP.",
    "keywords": "Deep Kernel Regression, Personalization, Posterior Correction, Longitudinal Biomarker Prediction",
    "pdf_url": "https://openreview.net/pdf?id=peX9zpWgg4",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on predicting longitudinal “brain biomarkers” using MRI volumetric measurements, modeling “brain development” and “disease progression” in clinical cohorts, and validating on “external neuroimaging studies.” These are clearly medical imaging and biomedical research contexts.",
    "prompt_tokens": 20814,
    "completion_tokens": 122,
    "total_tokens": 20936,
    "topic": "Neuroimaging - Longitudinal Biomarker Modeling",
    "method": "Deep Kernel Regression; Adaptive Shrinkage Estimation",
    "application": "Predicting biomarker trajectories",
    "code_link": "https://github.com/vatass/AdaptiveShrinkageDKGP",
    "dataset_name": [
      "ADNI",
      "BLSA",
      "OASIS",
      "AIBL",
      "PreventAD"
    ]
  },
  {
    "id": "6jjAYmppGQ",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "BrainUICL: An Unsupervised Individual Continual Learning Framework for EEG Applications",
    "authors": [
      "Yangxuan Zhou",
      "Sha Zhao",
      "Jiquan Wang",
      "Haiteng Jiang",
      "Shijian Li",
      "Tao Li",
      "Gang Pan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Electroencephalography (EEG) is a non-invasive brain-computer interface technology used for recording brain electrical activity. It plays an important role in human life and has been widely uesd in real life, including sleep staging, emotion recognition, and motor imagery. However, existing EEG-related models cannot be well applied in practice, especially in clinical settings, where new patients with individual discrepancies appear every day. Such EEG-based model trained on fixed datasets cannot generalize well to the continual flow of numerous unseen subjects in real-world scenarios. This limitation can be addressed through continual learning (CL), wherein the CL model can continuously learn and advance over time. Inspired by CL, we introduce a novel Unsupervised Individual Continual Learning paradigm for handling this issue in practice. We propose the BrainUICL framework, which enables the EEG-based model to continuously adapt to the incoming new subjects. Simultaneously, BrainUICL helps the model absorb new knowledge during each adaptation, thereby advancing its generalization ability for all unseen subjects. The effectiveness of the proposed BrainUICL has been evaluated on three different mainstream EEG tasks. The BrainUICL can effectively balance both the plasticity and stability during CL, achieving better plasticity on new individuals and better stability across all the unseen individuals, which holds significance in a practical  setting.",
    "keywords": "Continual Learning; EEG Applications",
    "pdf_url": "https://openreview.net/pdf?id=6jjAYmppGQ",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on continual learning for EEG applications—a key biomedical signal modality used in clinical settings (e.g., “sleep staging,” “emotion recognition,” and “motor imagery”). It explicitly addresses adapting models to “new patients with individual discrepancies” and improving performance in “practical clinical settings,” which places it squarely within Healthcare AI / Biomedicine AI.",
    "prompt_tokens": 20739,
    "completion_tokens": 108,
    "total_tokens": 20847,
    "topic": "EEG Analysis - Continual Learning",
    "method": "Unsupervised continual domain adaptation; Contrastive predictive coding",
    "application": "EEG tasks – Sleep staging, emotion recognition, and motor imagery",
    "code_link": "N/A",
    "dataset_name": [
      "ISRUC",
      "FACED",
      "Physionet-MI"
    ]
  },
  {
    "id": "aN57tSd5Us",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Stabilized Neural Prediction of Potential Outcomes in Continuous Time",
    "authors": [
      "Konstantin Hess",
      "Stefan Feuerriegel"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Patient trajectories from electronic health records are widely used to estimate conditional average potential outcomes (CAPOs) of treatments over time, which then allows to personalize care. Yet, existing neural methods for this purpose have a key limitation: while some adjust for time-varying confounding, these methods assume that the time series are recorded in discrete time. In other words, they are constrained to settings where measurements and treatments are conducted at fixed time steps, even though this is unrealistic in medical practice. In this work, we aim to estimate CAPOs in continuous time. The latter is of direct practical relevance because it allows for modeling patient trajectories where measurements and treatments take place at arbitrary, irregular timestamps. We thus propose a new method called stabilized continuous time inverse propensity network (SCIP-Net). For this, we further derive stabilized inverse propensity weights for robust estimation of the CAPOs. To the best of our knowledge, our SCIP-Net is the first neural method that performs proper adjustments for time-varying confounding in continuous time.",
    "keywords": "causal inference, potential outcomes, continuous time, treatment effects, inverse propensity weighting, confounding, medicine",
    "pdf_url": "https://openreview.net/pdf?id=aN57tSd5Us",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses explicitly on patient trajectories from electronic health records (EHRs) to estimate treatment effects over time, mentions “personalize care,” “time-varying confounding,” and introduces a method for “robust estimation of CAPOs” in a medical context. The keywords include “causal inference,” “treatment effects,” and “medicine,” indicating direct relevance to clinical decision support and personalized medicine.",
    "prompt_tokens": 39149,
    "completion_tokens": 124,
    "total_tokens": 39273,
    "topic": "Causal Inference - Treatment effect estimation",
    "method": "Neural controlled differential equations (CDE); stabilized inverse propensity weighting",
    "application": "Time-varying treatment outcome prediction",
    "code_link": "https://github.com/konstantinhess/SCIP-Net",
    "dataset_name": [
      "MIMIC-III",
      "Tumor growth model"
    ]
  },
  {
    "id": "gVkX9QMBO3",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Efficient Biological Data Acquisition through Inference Set Design",
    "authors": [
      "Ihor Neporozhnii",
      "Julien Roy",
      "Emmanuel Bengio",
      "Jason Hartford"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In drug discovery, highly automated high-throughput laboratories are used to screen a large number of compounds in search of effective drugs. These experiments are expensive, so one might hope to reduce their cost by only experimenting on a subset of the compounds, and predicting the outcomes of the remaining experiments. In this work, we model this scenario as a sequential subset selection problem: we aim to select the smallest set of candidates in order to achieve some desired level of accuracy for the system as a whole. Our key observation is that, if there is heterogeneity in the difficulty of the prediction problem across the input space, selectively obtaining the labels for the hardest examples in the acquisition pool will leave only the relatively easy examples to remain in the inference set, leading to better overall system performance. We call this mechanism inference set design, and propose the use of a confidence-based active learning solution to prune out these challenging examples. Our algorithm includes an explicit stopping criterion that interrupts the acquisition loop when it is sufficiently confident that the system has reached the target performance. Our empirical studies on image and molecular datasets, as well as a real-world large-scale biological assay, show that active learning for inference set design leads to significant reduction in experimental cost while retaining high system performance.",
    "keywords": "Active Learning, Data Acquisition, ML for Drug Discovery",
    "pdf_url": "https://openreview.net/pdf?id=gVkX9QMBO3",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on drug discovery workflows—“high-throughput laboratories … to screen a large number of compounds,” “molecular datasets,” and “real-world large-scale biological assay.” This clearly situates the work in biomedical research, using machine learning to optimize experimental design in a pharmaceutical/biological context.",
    "prompt_tokens": 21317,
    "completion_tokens": 109,
    "total_tokens": 21426,
    "topic": "Active Learning - Drug Discovery",
    "method": "Inference set design; active learning",
    "application": "Hybrid screening – drug discovery",
    "code_link": "https://github.com/ineporozhnii/inference_set_design",
    "dataset_name": [
      "MNIST",
      "QM9",
      "Molecules3D",
      "RxRx3"
    ]
  },
  {
    "id": "T4sMzjy7fO",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "CryoFM: A Flow-based Foundation Model for Cryo-EM Densities",
    "authors": [
      "Yi Zhou",
      "Yilai Li",
      "Jing Yuan",
      "Quanquan Gu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Cryo-electron microscopy (cryo-EM) is a powerful technique in structural biology and drug discovery, enabling the study of biomolecules at high resolution. Significant advancements by structural biologists using cryo-EM have led to the production of around 40k protein density maps at various resolutions. However, cryo-EM data processing algorithms have yet to fully benefit from our knowledge of biomolecular density maps, with only a few recent models being data-driven but limited to specific tasks. In this study, we present CryoFM, a foundation model designed as a generative model, learning the distribution of high-quality density maps and generalizing effectively to downstream tasks. Built on flow matching, CryoFM is trained to accurately capture the prior distribution of biomolecular density maps. Furthermore, we introduce a flow posterior sampling method that leverages CryoFM as a flexible prior for several downstream tasks in cryo-EM and cryo-electron tomography (cryo-ET) without the need for fine-tuning, achieving state-of-the-art performance on most tasks and demonstrating its potential as a foundational model for broader applications in these fields.",
    "keywords": "cryoEM; foundation model; flow matching",
    "pdf_url": "https://openreview.net/pdf?id=T4sMzjy7fO",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on modeling cryo-electron microscopy (cryo-EM) density maps of biomolecules and mentions applications in structural biology and drug discovery—hallmarks of biomedical research (e.g., “study of biomolecules at high resolution,” “drug discovery,” “biomolecular density maps,” “protein density maps”). This clearly aligns with Biomedicine AI.",
    "prompt_tokens": 20939,
    "completion_tokens": 112,
    "total_tokens": 21051,
    "topic": "Bioinformatics - CryoEM",
    "method": "Flow matching; Diffusion posterior sampling",
    "application": "3D protein density reconstruction",
    "code_link": "https://github.com/cryofm-research/flow-matching",
    "dataset_name": [
      "EMDB",
      "EMPIAR-10028",
      "EMPIAR-10827"
    ]
  },
  {
    "id": "uQnvYP7yX9",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "ReNovo: Retrieval-Based \\emph{De Novo} Mass Spectrometry Peptide Sequencing",
    "authors": [
      "Shaorong Chen",
      "Jun Xia",
      "Jingbo Zhou",
      "Lecheng Zhang",
      "Zhangyang Gao",
      "Bozhen Hu",
      "Cheng Tan",
      "Wenjie Du",
      "Stan Z. Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Proteomics is the large-scale study of proteins. Tandem mass spectrometry, as the only high-throughput technique for protein sequence identification, plays a pivotal role in proteomics research. One of the long-standing challenges in this field is peptide identification, which entails determining the specific peptide (sequence of amino acids) that corresponds to each observed mass spectrum. The conventional approach involves database searching, wherein the observed mass spectrum is scored against a pre-constructed peptide database. However, the reliance on pre-existing databases limits applicability in scenarios where the peptide is absent from existing databases. Such circumstances necessitate \\emph{de novo} peptide sequencing, which derives peptide sequence solely from input mass spectrum, independent of any peptide database. Despite ongoing advancements in \\emph{de novo} peptide sequencing, its performance still has considerable room for improvement, which limits its application in large-scale experiments. In this study, we introduce a novel \\textbf{Re}trieval-based \\emph{De \\textbf{Novo}} peptide sequencing methodology, termed \\textbf{ReNovo}, which draws inspiration from database search methods. Specifically, by constructing a datastore from training data, ReNovo can retrieve information from the datastore during the inference stage to conduct retrieval-based inference, thereby achieving improved performance. This innovative approach enables ReNovo to effectively combine the strengths of both methods: utilizing the assistance of the datastore while also being capable of predicting novel peptides that are not present in pre-existing databases. A series of experiments have confirmed that ReNovo outperforms state-of-the-art models across multiple widely-used datasets, incurring only minor storage and time consumption, representing a significant advancement in proteomics. Supplementary materials include the code.",
    "keywords": "Peptide Sequencing",
    "pdf_url": "https://openreview.net/pdf?id=uQnvYP7yX9",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work focuses on peptide sequencing from tandem mass spectrometry data, a core task in proteomics (“Proteomics is the large-scale study of proteins,” “tandem mass spectrometry … protein sequence identification”). Proteomics and peptide identification are fundamental topics in biomedical research, placing this squarely in the Biomedicine AI domain.",
    "prompt_tokens": 20614,
    "completion_tokens": 98,
    "total_tokens": 20712,
    "topic": "Bioinformatics - Proteomics",
    "method": "Retrieval-augmented generation (RAG)",
    "application": "De novo peptide sequencing",
    "code_link": "N/A",
    "dataset_name": [
      "Seven-species Dataset",
      "Nine-species Dataset",
      "HC-PT Dataset"
    ]
  },
  {
    "id": "7B9FCDoUzB",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Regretful Decisions under Label Noise",
    "authors": [
      "Sujay Nagaraj",
      "Yang Liu",
      "Flavio Calmon",
      "Berk Ustun"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Machine learning models are routinely used to support decisions that affect individuals -- be it to screen a patient for a serious illness or to gauge their response to treatment. In these tasks, we are limited to learning models from datasets with noisy labels. In this paper, we study the instance-level impact of learning under label noise. We introduce a notion of regret for this regime, which measures the number of unforeseen mistakes due to noisy labels. We show that standard approaches to learning under label noise can return models that perform well at a population-level while subjecting individuals to a lottery of mistakes. We present a versatile approach to estimate the likelihood of mistakes at the individual-level from a noisy dataset by training models over plausible realizations of datasets without label noise. This is supported by a comprehensive empirical study of label noise in clinical prediction tasks. Our results reveal how failure to anticipate mistakes can compromise model reliability and adoption -- we demonstrate how we can address these challenges by anticipating and avoiding regretful decisions.",
    "keywords": "Uncertainty Quantification, Fairness, Model Multiplicity, Clinical Decision Support, Classification, Label Noise",
    "pdf_url": "https://openreview.net/pdf?id=7B9FCDoUzB",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper studies decision‐support models in medical contexts, explicitly mentioning “screen a patient for a serious illness,” “gauge their response to treatment,” and a “comprehensive empirical study of label noise in clinical prediction tasks.” It also lists “Clinical Decision Support” as a keyword, indicating direct relevance to Healthcare AI.",
    "prompt_tokens": 20498,
    "completion_tokens": 113,
    "total_tokens": 20611,
    "topic": "Clinical Prediction - Label Noise",
    "method": "Noise-tolerant techniques; ambiguity-based data cleaning",
    "application": "Mortality prediction – ICU",
    "code_link": "https://github.com/sujaynagaraj/regretful_decisions",
    "dataset_name": [
      "shock_eicu",
      "shock_mimic",
      "lungcancer",
      "mortality",
      "support"
    ]
  },
  {
    "id": "Nq7yKYL0Bp",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "ProtPainter: Draw or Drag Protein via Topology-guided Diffusion",
    "authors": [
      "Zhengxi Lu",
      "Shizhuo Cheng",
      "Tintin Jiang",
      "Yan Zhang",
      "Min Zhang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Recent advances in protein backbone generation have achieved promising results under structural, functional, or physical constraints. However, existing methods lack the flexibility for precise topology control, limiting navigation of the backbone space. We present $\\textbf{ProtPainter}$, a diffusion-based approach for generating protein backbones conditioned on 3D curves. ProtPainter follows a two-stage process: curve-based sketching and sketch-guided backbone generation. For the first stage, we propose $\\textbf{CurveEncoder}$, which predicts secondary structure annotations from a curve to parametrize sketch generation. For the second stage, the sketch guides the generative process in Denoising Diffusion Probabilistic Modeling (DDPM) to generate backbones. During the process, we further introduce a fusion scheduling scheme, Helix-Gating, to control the scaling factors. To evaluate, we propose the first benchmark for topology-conditioned protein generation, introducing Protein Restoration Task and a new metric, self-consistency Topology Fitness (scTF). Experiments demonstrate ProtPainter's ability to generate topology-fit (scTF $>$ 0.8) and designable (scTM $>$ 0.5) backbones, with drawing and dragging tasks showcasing its flexibility and versatility.",
    "keywords": "Protein Backbone Generation, Conditional Diffusion, Topology, Protein Editing",
    "pdf_url": "https://openreview.net/pdf?id=Nq7yKYL0Bp",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on protein backbone generation via diffusion (“ProtPainter” for “protein backbone generation,” “secondary structure annotations,” “de novo protein design”). Protein design and molecular modeling are core tasks in biomedicine AI (“drug discovery,” “protein design,” “molecular modeling”), even if not framed around a specific therapeutic application. Therefore, this work belongs to the Biomedicine AI domain.",
    "prompt_tokens": 20734,
    "completion_tokens": 128,
    "total_tokens": 20862,
    "topic": "Bioinformatics - Protein Topology",
    "method": "Diffusion model; Conditional generation; Equivariant Graph Neural Networks (EGNN)",
    "application": "Topology-conditioned protein backbone generation",
    "code_link": "https://github.com/lll6gg/ChimeraX_plugin_binder",
    "dataset_name": [
      "HHH_ems",
      "med",
      "GPCR"
    ]
  },
  {
    "id": "lBB3eSn6fY",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Gaussian Mixture Counterfactual Generator",
    "authors": [
      "Jong-Hoon Ahn",
      "Akshay Vashist"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We address the individualized treatment effect (ITE) estimation problem, focusing on continuous, multidimensional, and time-dependent treatments for precision medicine. The central challenge lies in modeling these complex treatment scenarios while capturing dynamic patient responses and minimizing reliance on control data. We propose the Gaussian Mixture Counterfactual Generator (GMCG), a generative model that transforms the Gaussian mixture model—traditionally a tool for clustering and density estimation—into a new tool explicitly geared toward causal inference. This approach generates robust counterfactuals by effectively handling continuous and multidimensional treatment spaces. We evaluate GMCG on synthetic crossover trial data and simulated datasets, demonstrating its superior performance over existing methods, particularly in scenarios with limited control data. GMCG derives its effectiveness from modeling the joint distribution of covariates, treatments, and outcomes using a latent state vector while employing a conditional distribution of the state vector to suppress confounding and isolate treatment-outcome relationships.",
    "keywords": "Gaussian mixture model, synthetic data generation, clinical trial, individual treatment effect, counterfactual generation",
    "pdf_url": "https://openreview.net/pdf?id=lBB3eSn6fY",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly focuses on individualized treatment effect (ITE) estimation in a “precision medicine” context, modeling continuous, multidimensional, time-dependent treatments and generating counterfactuals for clinical trial data. It evaluates on “synthetic crossover trial data” and aims to capture “dynamic patient responses,” all clear indicators of a healthcare/biomedicine application.",
    "prompt_tokens": 20780,
    "completion_tokens": 109,
    "total_tokens": 20889,
    "topic": "Causal Inference - Counterfactual Estimation",
    "method": "Gaussian Mixture Models (GMM); Expectation-Maximization Algorithm",
    "application": "Counterfactual data generation - clinical trials",
    "code_link": "N/A",
    "dataset_name": [
      "Simulated LDL Cholesterol Data",
      "Synthetic Crossover Trial Data"
    ]
  },
  {
    "id": "3Fgylj4uqL",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Interpretable Causal Representation Learning for Biological Data in the Pathway Space",
    "authors": [
      "Jesus de la Fuente Cedeño",
      "Robert Lehmann",
      "Carlos Ruiz-Arenas",
      "Jan Voges",
      "Irene Marín-Goñi",
      "Xabier Martinez de Morentin",
      "David Gomez-Cabrero",
      "Idoia Ochoa",
      "Jesper Tegnér",
      "Vincenzo Lagani",
      "Mikel Hernaez"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Predicting the impact of genomic and drug perturbations in cellular function is crucial for understanding gene functions and drug effects, ultimately leading to improved therapies. To this end, Causal Representation Learning (CRL) constitutes one of the most promising approaches, as it aims to identify the latent factors that causally govern biological systems, thus facilitating the prediction of the effect of unseen perturbations. Yet, current CRL methods fail in reconciling their principled latent representations with known biological processes, leading to models that are not interpretable. To address this major issue, in this work we present SENA-discrepancy-VAE, a model based on the recently proposed CRL method discrepancy-VAE, that produces representations where each latent factor can be interpreted as the (linear) combination of the activity of a (learned) set of biological processes. To this extent, we present an encoder, SENA-$\\delta$, that efficiently compute and map biological processes' activity levels to the latent causal factors. We show that SENA-discrepancy-VAE achieves predictive performances on unseen combinations of interventions that are comparable with its original, non-interpretable counterpart, while inferring causal latent factors that are biologically meaningful.",
    "keywords": "Causal Representation Learning, Intepretability, VAE, Genomic Perturbations, Health",
    "pdf_url": "https://openreview.net/pdf?id=3Fgylj4uqL",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on predicting the impact of genomic and drug perturbations on cellular function, learning causal representations tied to biological pathways. References to “genomic perturbations,” “drug effects,” and “biological processes” place it squarely in the realm of biomedicine AI, as it targets biomedical research tasks such as understanding gene function and drug action.",
    "prompt_tokens": 21124,
    "completion_tokens": 113,
    "total_tokens": 21237,
    "topic": "Causal Inference - Biological Systems",
    "method": "Causal Representation Learning; Variational Autoencoder (VAE)",
    "application": "Prediction of effects of perturbations on biological processes",
    "code_link": "https://github.com/ML4BM-Lab/SENA",
    "dataset_name": [
      "Norman2019",
      "Wessels2023"
    ]
  },
  {
    "id": "noUF58SMra",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "MeToken: Uniform Micro-environment Token Boosts Post-Translational Modification Prediction",
    "authors": [
      "Cheng Tan",
      "Zhenxiao Cao",
      "Zhangyang Gao",
      "Lirong Wu",
      "Siyuan Li",
      "Yufei Huang",
      "Jun Xia",
      "Bozhen Hu",
      "Stan Z. Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Post-translational modifications (PTMs) profoundly expand the complexity and functionality of the proteome, regulating protein attributes and interactions that are crucial for biological processes. Accurately predicting PTM sites and their specific types is therefore essential for elucidating protein function and understanding disease mechanisms. Existing computational approaches predominantly focus on protein sequences to predict PTM sites, driven by the recognition of sequence-dependent motifs. However, these approaches often overlook protein structural contexts. In this work, we first compile a large-scale sequence-structure PTM dataset, which serves as the foundation for fair comparison. We introduce the MeToken model, which tokenizes the micro-environment of each amino acid, integrating both sequence and structural information into unified discrete tokens. This model not only captures the typical sequence motifs associated with PTMs but also leverages the spatial arrangements dictated by protein tertiary structures, thus providing a holistic view of the factors influencing PTM sites. Designed to address the long-tail distribution of PTM types, MeToken employs uniform sub-codebooks that ensure even the rarest PTMs are adequately represented and distinguished. We validate the effectiveness and generalizability of MeToken across multiple datasets, demonstrating its superior performance in accurately identifying PTM types. The results underscore the importance of incorporating structural data and highlight MeToken's potential in facilitating accurate and comprehensive PTM predictions, which could significantly impact proteomics research.",
    "keywords": "Biomolecular learning, Protein sequence",
    "pdf_url": "https://openreview.net/pdf?id=noUF58SMra",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The work focuses on predicting post-translational modification (PTM) sites in proteins—a core task in proteomics and molecular biology. By integrating sequence and structural data to improve PTM site identification, it directly supports biomedical research into protein function and disease mechanisms. The emphasis on “proteome,” “post-translational modifications,” and “proteomics research” marks it as Biomedicine AI.",
    "prompt_tokens": 21168,
    "completion_tokens": 105,
    "total_tokens": 21273,
    "topic": "Bioinformatics - Protein Modifications",
    "method": "Graph Neural Networks (GNN); temperature-scaled vector quantization",
    "application": "Post-translational modification (PTM) prediction",
    "code_link": "N/A",
    "dataset_name": [
      "PTMint",
      "qPTM",
      "dbPTM"
    ]
  },
  {
    "id": "ozZG5FXuTV",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Learning Causal Alignment for Reliable Disease Diagnosis",
    "authors": [
      "Mingzhou Liu",
      "Ching-Wen Lee",
      "Xinwei Sun",
      "Xueqing Yu",
      "Yu QIAO",
      "Yizhou Wang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Aligning the decision-making process of machine learning algorithms with that of experienced radiologists is crucial for reliable diagnosis. While existing methods have attempted to align their prediction behaviors to those of radiologists reflected in the training data, this alignment is primarily associational rather than causal, resulting in pseudo-correlations that may not transfer well. In this paper, we propose a causality-based alignment framework towards aligning the model's decision process with that of experts. Specifically, we first employ counterfactual generation to identify the causal chain of model decisions. To align this causal chain with that of experts, we propose a causal alignment loss that enforces the model to focus on causal factors underlying each decision step in the whole causal chain. To optimize this loss that involves the counterfactual generator as an implicit function of the model's parameters, we employ the implicit function theorem equipped with the conjugate gradient method for efficient estimation. We demonstrate the effectiveness of our method on two medical diagnosis applications, showcasing faithful alignment to radiologists.",
    "keywords": "alignment, causal learning, counterfactual, disease diagnosis",
    "pdf_url": "https://openreview.net/pdf?id=ozZG5FXuTV",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on aligning machine learning decision processes with those of radiologists for “reliable disease diagnosis,” explicitly referencing medical imaging and clinical decision‐making. It targets a healthcare application—improving radiologist‐model alignment in disease diagnosis—which places it squarely in the Healthcare AI domain.",
    "prompt_tokens": 21078,
    "completion_tokens": 126,
    "total_tokens": 21204,
    "topic": "Medical Imaging - Lung and Breast Cancer Diagnosis",
    "method": "Causal alignment; counterfactual generation",
    "application": "Benign/malignant classification of lung nodules and breast masses",
    "code_link": "https://github.com/lmz123321/Causal_alignment",
    "dataset_name": [
      "LIDC-IDRI",
      "CBIS-DDSM"
    ]
  },
  {
    "id": "NJxCpMt0sf",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Dynamic Modeling of Patients, Modalities and Tasks via Multi-modal Multi-task Mixture of Experts",
    "authors": [
      "Chenwei Wu",
      "Zitao Shuai",
      "Zhengxu Tang",
      "Luning Wang",
      "Liyue Shen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Multi-modal multi-task learning holds significant promise in tackling complex diagnostic tasks and many significant medical imaging problems. It fulfills the needs in real-world diagnosis protocol to leverage information from different data sources and simultaneously perform mutually informative tasks. However, medical imaging domains introduce two key challenges: dynamic modality fusion and modality-task dependence. The quality and amount of task-related information from different modalities could vary significantly across patient samples, due to biological and demographic factors. Traditional fusion methods apply fixed combination strategies that fail to capture this dynamic relationship, potentially underutilizing modalities that carry stronger diagnostic signals for specific patients. Additionally, different clinical tasks may require dynamic feature selection and combination from various modalities, a phenomenon we term “modality-task dependence.” To address these issues, we propose M4oE, a novel Multi-modal Multi-task Mixture of Experts framework for precise Medical diagnosis. M4oE comprises Modality-Specific (MSoE) modules and a Modality-shared Modality-Task MoE (MToE) module. With collaboration from both modules, our model dynamically decomposes and learns distinct and shared information from different modalities and achieves dynamic fusion. MToE provides a joint probability model of modalities and tasks by using experts as a link and encourages experts to learn modality-task dependence via conditional mutual information loss. By doing so, M4oE offers sample and population-level interpretability of modality contributions. We evaluate M4oE on four public multi-modal medical benchmark datasets for solving two important medical diagnostic problems including breast cancer screening and retinal disease diagnosis. Results demonstrate our method's superiority over state-of-the-art methods under different metrics of classification and segmentation tasks like Accuracy, AUROC, AUPRC, and DICE.",
    "keywords": "Multimodal Learning, Medical Imaging",
    "pdf_url": "https://openreview.net/pdf?id=NJxCpMt0sf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses squarely on medical imaging for diagnosis, referencing “breast cancer screening” and “retinal disease diagnosis,” as well as evaluations on “public multi-modal medical benchmark datasets.” It addresses clinical tasks such as disease classification and segmentation (Accuracy, AUROC, AUPRC, DICE), and builds a model for “precise Medical diagnosis,” making it a clear fit for Healthcare AI.",
    "prompt_tokens": 20819,
    "completion_tokens": 139,
    "total_tokens": 20958,
    "topic": "Medical Imaging - Multi-modal Multi-task Learning",
    "method": "Multi-modal Multi-task Mixture of Experts (M4oE); Modality-specific MoE (MSoE); Modality-shared Modality-Task MoE (MToE)",
    "application": "Breast cancer screening and retinal disease diagnosis",
    "code_link": "https://github.com/tangzhengxu2001/m4oe",
    "dataset_name": [
      "EMBED",
      "RSNA",
      "VinDR",
      "GAMMA"
    ]
  },
  {
    "id": "RgE1qiO2ek",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "3DMolFormer: A Dual-channel Framework for Structure-based Drug Discovery",
    "authors": [
      "Xiuyuan Hu",
      "Guoqing Liu",
      "Can Chen",
      "Yang Zhao",
      "Hao Zhang",
      "Xue Liu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Structure-based drug discovery, encompassing the tasks of protein-ligand docking and pocket-aware 3D drug design, represents a core challenge in drug discovery. However, no existing work can deal with both tasks to effectively leverage the duality between them, and current methods for each task are hindered by challenges in modeling 3D information and the limitations of available data. To address these issues, we propose 3DMolFormer, a unified dual-channel transformer-based framework applicable to both docking and 3D drug design tasks, which exploits their duality by utilizing docking functionalities within the drug design process. Specifically, we represent 3D pocket-ligand complexes using parallel sequences of discrete tokens and continuous numbers, and we design a corresponding dual-channel transformer model to handle this format, thereby overcoming the challenges of 3D information modeling. Additionally, we alleviate data limitations through large-scale pre-training on a mixed dataset, followed by supervised and reinforcement learning fine-tuning techniques respectively tailored for the two tasks. Experimental results demonstrate that 3DMolFormer outperforms previous approaches in both protein-ligand docking and pocket-aware 3D drug design, highlighting its promising application in structure-based drug discovery. The code is available at: https://github.com/HXYfighter/3DMolFormer.",
    "keywords": "Structure-based Drug Discovery, Protein-ligand Docking, 3D Molecule Generation, Transformer",
    "pdf_url": "https://openreview.net/pdf?id=RgE1qiO2ek",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “Structure-based drug discovery” through “protein-ligand docking” and “3D drug design,” which are core tasks in biomedical research aimed at therapeutic development. The keywords “drug discovery,” “protein-ligand docking,” and “3D molecule generation” directly indicate its relevance to Biomedicine AI.",
    "prompt_tokens": 20915,
    "completion_tokens": 119,
    "total_tokens": 21034,
    "topic": "Drug Discovery - Target-based",
    "method": "Dual-channel transformer; reinforcement learning",
    "application": "Protein-ligand binding pose prediction and pocket-aware 3D drug design",
    "code_link": "https://github.com/HXYfighter/3DMolFormer",
    "dataset_name": [
      "PDBbind v2020",
      "CASF-2016",
      "CrossDocked2020"
    ]
  },
  {
    "id": "0dELcFHig2",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Multi-modal brain encoding models for multi-modal stimuli",
    "authors": [
      "SUBBA REDDY OOTA",
      "Khushbu Pahwa",
      "mounika marreddy",
      "Maneesh Kumar Singh",
      "Manish Gupta",
      "Bapi Raju Surampudi"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Despite participants engaging in unimodal stimuli, such as watching images or silent videos, recent work has demonstrated that multi-modal Transformer models can predict visual brain activity impressively well, even with incongruent modality representations. This raises the question of how accurately these multi-modal models can predict brain activity when participants are engaged in multi-modal stimuli. As these models grow increasingly popular, their use in studying neural activity provides insights into how our brains respond to such multi-modal naturalistic stimuli, i.e., where it separates and integrates information across modalities through a hierarchy of early sensory regions to higher cognition (language regions). We investigate this question by using multiple unimodal and two types of multi-modal models—cross-modal and jointly pretrained—to determine which type of models is more relevant to fMRI brain activity when participants are engaged in watching movies (videos with audio). We observe that both types of multi-modal models show improved alignment in several language and visual regions. This study also helps in identifying which brain regions process unimodal versus multi-modal information. We further investigate the contribution of each modality to multi-modal alignment by carefully removing unimodal features one by one from multi-modal representations, and find that there is additional information beyond the unimodal embeddings that is processed in the visual and language regions. Based on this investigation, we find that while for cross-modal models, their brain alignment is partially attributed to the video modality; for jointly pretrained models, it is partially attributed to both the video and audio modalities. These findings serve as strong motivation for the neuro-science community to investigate the interpretability of these models for deepening our understanding of multi-modal information processing in brain.",
    "keywords": "brain encoding, fMRI, multi-modal models, multi-modal stimuli, Transformers, videos, speech, language",
    "pdf_url": "https://openreview.net/pdf?id=0dELcFHig2",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on building brain encoding models using fMRI data to predict neural activity in response to multimodal (audio-visual) stimuli. This falls squarely within neuroscience and neurobiological modeling (“brain decoding,” “fMRI,” “brain regions”), which is part of the Biomedicine AI domain.",
    "prompt_tokens": 21077,
    "completion_tokens": 125,
    "total_tokens": 21202,
    "topic": "Brain Encoding - Multi-modal Models",
    "method": "Transformer-based models; cross-modal embedding; joint multi-modal representation",
    "application": "Brain activity prediction",
    "code_link": "https://github.com/subbareddy248/multi-modal-brain-stimuli",
    "dataset_name": [
      "Movie10",
      "Audioset",
      "Ego4D",
      "SUN RGB-D",
      "HowTo100M",
      "YTTemporal180M"
    ]
  },
  {
    "id": "4S2L519nIX",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Pushing the Limits of All-Atom Geometric Graph Neural Networks: Pre-Training, Scaling, and Zero-Shot Transfer",
    "authors": [
      "Zihan Pengmei",
      "Zhengyuan Shen",
      "Zichen Wang",
      "Marcus D. Collins",
      "Huzefa Rangwala"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The ability to construct transferable descriptors for molecular and biological systems has broad applications in drug discovery, molecular dynamics, and protein analysis. Geometric graph neural networks (Geom-GNNs) utilizing all-atom information have revolutionized atomistic simulations by enabling the prediction of interatomic potentials and molecular properties. Despite these advances, the application of all-atom Geom-GNNs in protein modeling remains limited due to computational constraints. In this work, we first demonstrate the potential of pre-trained Geom-GNNs as zero-shot transfer learners, effectively modeling protein systems with all-atom granularity. Through extensive experimentation to evaluate their expressive power, we characterize the scaling behaviors of Geom-GNNs across self-supervised, supervised, and unsupervised setups. Interestingly, we find that Geom-GNNs deviate from conventional power-law scaling observed in other domains, with no predictable scaling principles for molecular representation learning. Furthermore, we show how pre-trained graph embeddings can be directly used for analysis and synergize with other architectures to enhance expressive power for protein modeling.",
    "keywords": "Geometric Graph Neural Networks, Self-supervised Pre-training, Scaling, Zero-shot Transfer, Molecular Representation",
    "pdf_url": "https://openreview.net/pdf?id=4S2L519nIX",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on all-atom geometric GNNs for “molecular and biological systems” with explicit applications in “drug discovery,” “molecular dynamics,” and “protein analysis.” It develops methods for protein modeling at atomic resolution and presents transferable molecular representations, which squarely places it in the Biomedicine AI domain.",
    "prompt_tokens": 20846,
    "completion_tokens": 118,
    "total_tokens": 20964,
    "topic": "Bioinformatics - Protein Representation",
    "method": "Geom-GNN; denoising pretraining",
    "application": "Protein folding and kinetic modeling",
    "code_link": "N/A",
    "dataset_name": [
      "PCQM4Mv2",
      "OrbNet-Denali",
      "QM9",
      "xxMD",
      "ALA2",
      "Pentapeptide",
      "λ6-85"
    ]
  },
  {
    "id": "9yJKTosUex",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Boltzmann Semantic Score: A Semantic Metric for Evaluating Large Vision Models Using Large Language Models",
    "authors": [
      "Ali Khajegili Mirabadi",
      "Katherine Rich",
      "Hossein Farahani",
      "Ali Bashashati"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Do Large Vision Models (LVMs) extract medically and semantically relevant features similar to those identified by human experts? Currently, only biased, qualitative approaches with limited, small-scale expert evaluations are available to answer this question. In this study, we propose the Boltzmann Semantic Score (BSS), a novel method inspired by state space modeling, to evaluate the encoding space of LVMs from medical images using the encoding space of Large Language Models (LLMs) from medical reports. Through extensive experimentation on 32 datasets from The Cancer Genome Atlas collection using five state-of-the-art LLMs, we first establish a baseline of LLMs' performance in digital pathology and show that LLMs' encoding can be linked to patient outcomes. Then, we compared seven LVMs with BSS and showed that LVMs suffer from poor semantic capability when compared with encoded expert knowledge from pathology reports.\nWe also found statistically significant correlations between BSS (as a measure of structural similarity) and performance in two downstream tasks: information retrieval and survival prediction tasks. Our study also investigates the consensus among LLMs in evaluating LVMs using BSS, indicating that LLMs generally reach substantial consensus in rating LVMs, with some variation dependant on the cancer type. We believe the BSS metric proposed here holds significant potential for application in other domains with similar contexts. Data and code can be found in \\footnotesize \\url{ https://github.com/AIMLab-UBC/Boltzmann}",
    "keywords": "Large Language Models, Large Vision Models, Semantic Evaluation, Computational Pathology, Medical Imaging",
    "pdf_url": "https://openreview.net/pdf?id=9yJKTosUex",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper applies AI to digital pathology and medical imaging, using The Cancer Genome Atlas collection of pathology images and reports. It evaluates semantic features against expert-annotated pathology reports and links model encodings to patient outcomes (e.g., survival prediction). These are clear indicators of a healthcare/biomedicine AI application.",
    "prompt_tokens": 21416,
    "completion_tokens": 306,
    "total_tokens": 21722,
    "topic": "Pathology AI - Cancer Report Analysis",
    "method": "Boltzmann Semantic Score (BSS); Large Language Models (LLMs)",
    "application": "Information retrieval and survival prediction – pathology",
    "code_link": "https://github.com/AIMLab-UBC/Boltzmann",
    "dataset_name": [
      "TCGA-ACC",
      "TCGA-BLCA",
      "TCGA-BRCA",
      "TCGA-CESC",
      "TCGA-CHOL",
      "TCGA-CRC",
      "TCGA-DLBC",
      "TCGA-ESCA",
      "TCGA-GBM",
      "TCGA-HNSC",
      "TCGA-KICH",
      "TCGA-KIRC",
      "TCGA-KIRP",
      "TCGA-LGG",
      "TCGA-LIHC",
      "TCGA-LUAD",
      "TCGA-LUSC",
      "TCGA-MESO",
      "TCGA-OV",
      "TCGA-PAAD",
      "TCGA-PCPG",
      "TCGA-PRAD",
      "TCGA-SARC",
      "TCGA-SKCM",
      "TCGA-STAD",
      "TCGA-TGCT",
      "TCGA-THCA",
      "TCGA-THYM",
      "TCGA-UCEC",
      "TCGA-UCS",
      "TCGA-UVM"
    ]
  },
  {
    "id": "Y0QqruhqIa",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Efficient Neuron Segmentation in Electron Microscopy by Affinity-Guided Queries",
    "authors": [
      "Hang Chen",
      "Chufeng Tang",
      "Xiao Li",
      "Xiaolin Hu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Accurate segmentation of neurons in electron microscopy (EM) images plays a crucial role in understanding the intricate wiring patterns of the brain. Existing automatic neuron segmentation methods rely on traditional clustering algorithms, where affinities are predicted first, and then watershed and post-processing algorithms are applied to yield segmentation results. Due to the nature of watershed algorithm, this paradigm has deficiency in both prediction quality and speed. Inspired by recent advances in natural image segmentation, we propose to use query-based methods to address the problem because they do not necessitate watershed algorithms. However, we find that directly applying existing query-based methods faces great challenges due to the large memory requirement of the 3D data and considerably different morphology of neurons. To tackle these challenges, we introduce affinity-guided queries and integrate them into a lightweight query-based framework. Specifically, we first predict affinities with a lightweight branch, which provides coarse neuron structure information. The affinities are then used to construct affinity-guided queries, facilitating segmentation with bottom-up cues. These queries, along with additional learnable queries, interact with the image features to directly predict the final segmentation results. Experiments on benchmark datasets demonstrated that our method achieved better results over state-of-the-art methods with a 2$\\sim$3$\\times$ speedup in inference. Code is available at https://github.com/chenhang98/AGQ.",
    "keywords": "Neuron Segmentation; Biomedical Image Segmentation; Electron Microscopy Image",
    "pdf_url": "https://openreview.net/pdf?id=Y0QqruhqIa",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on segmenting neurons in electron microscopy (EM) images to reveal brain wiring patterns, which falls squarely into biomedical image analysis and connectomics. It addresses a core biomedical research task—neuron segmentation from high‐resolution EM data—commonly used in neuroscience and biomedicine to understand neural circuitry.",
    "prompt_tokens": 20391,
    "completion_tokens": 105,
    "total_tokens": 20496,
    "topic": "Neuron Processing - EM Segmentation",
    "method": "Affinity-guided queries; query-based model",
    "application": "Neuron segmentation in EM images",
    "code_link": "https://github.com/chenhang98/AGQ",
    "dataset_name": [
      "AC3",
      "AC4",
      "ZEBRAFINCH"
    ]
  },
  {
    "id": "xiyzCfXTS6",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Optimistic Games for Combinatorial Bayesian Optimization with Application to Protein Design",
    "authors": [
      "Melis Ilayda Bal",
      "Pier Giuseppe Sessa",
      "Mojmir Mutny",
      "Andreas Krause"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Bayesian optimization (BO) is a powerful framework to optimize black-box expensive-to-evaluate functions via sequential interactions. In several important problems (e.g. drug discovery, circuit design, neural architecture search, etc.), though, such functions are defined over large $\\textit{combinatorial and unstructured}$ spaces. This makes existing BO algorithms not feasible due to the intractable maximization of the acquisition function over these domains. To address this issue, we propose $\\textbf{GameOpt}$, a novel game-theoretical approach to combinatorial BO. $\\textbf{GameOpt}$ establishes a cooperative game between the different optimization variables, and selects points that are game $\\textit{equilibria}$ of an upper confidence bound acquisition function. These are stable configurations from which no variable has an incentive to deviate$-$ analog to local optima in continuous domains. Crucially, this allows us to efficiently break down the complexity of the combinatorial domain into individual decision sets, making $\\textbf{GameOpt}$ scalable to large combinatorial spaces. We demonstrate the application of $\\textbf{GameOpt}$ to the challenging $\\textit{protein design}$ problem and validate its performance on four real-world protein datasets. Each protein can take up to $20^{X}$ possible configurations, where $X$ is the length of a protein, making standard BO methods infeasible. Instead, our approach iteratively selects informative protein configurations and very quickly discovers highly active protein variants compared to other baselines.",
    "keywords": "Combinatorial Bayesian Optimization, Game Theory, Gaussian Processes, Protein Design",
    "pdf_url": "https://openreview.net/pdf?id=xiyzCfXTS6",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper specifically targets “protein design,” a core task in biomedicine and drug discovery. It applies Bayesian optimization to generate “highly active protein variants,” which directly relates to molecular-level biomedical research and therapeutic design.",
    "prompt_tokens": 20479,
    "completion_tokens": 108,
    "total_tokens": 20587,
    "topic": "Protein Design - Combinatorial Optimization",
    "method": "Game Theory Framework; Bayesian Optimization",
    "application": "Protein fitness optimization",
    "code_link": "https://github.com/melisilaydabal/gameopt",
    "dataset_name": [
      "Halogenase",
      "GB1(4)",
      "GB1(55)",
      "GFP"
    ]
  },
  {
    "id": "BdmVgLMvaf",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Adaptive teachers for amortized samplers",
    "authors": [
      "Minsu Kim",
      "Sanghyeok Choi",
      "Taeyoung Yun",
      "Emmanuel Bengio",
      "Leo Feng",
      "Jarrid Rector-Brooks",
      "Sungsoo Ahn",
      "Jinkyoo Park",
      "Nikolay Malkin",
      "Yoshua Bengio"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Amortized inference is the task of training a parametric model, such as a neural network, to approximate a distribution with a given unnormalized density where exact sampling is intractable. When sampling is modeled as a sequential decision-making process, reinforcement learning (RL) methods, such as generative flow networks, can be used to train the sampling policy. Off-policy RL training facilitates the discovery of diverse, high-reward candidates, but existing methods still face challenges in efficient exploration. We propose to use an adaptive training distribution (the Teacher) to guide the training of the primary amortized sampler (the Student). The  Teacher, an auxiliary behavior model, is trained to sample high-loss regions of the Student and can generalize across unexplored modes, thereby enhancing mode coverage by providing an efficient training curriculum. We validate the effectiveness of this approach in a synthetic environment designed to present an exploration challenge, two diffusion-based sampling tasks, and four biochemical discovery tasks demonstrating its ability to improve sample efficiency and mode coverage. Source code is available at https://github.com/alstn12088/adaptive-teacher.",
    "keywords": "amortized inference, generative models, reinforcement learning, GFlowNets",
    "pdf_url": "https://openreview.net/pdf?id=BdmVgLMvaf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the core contribution is a general sampling method (amortized inference, GFlowNets), the paper’s experiments explicitly include “four biochemical discovery tasks,” which implies applications in molecular or drug discovery. Drug and molecular discovery are central domains of Biomedicine AI. Thus, the work is relevant to Biomedicine AI.",
    "prompt_tokens": 20740,
    "completion_tokens": 127,
    "total_tokens": 20867,
    "topic": "Reinforcement Learning - Off-policy Training",
    "method": "GFlowNets; Trajectory Balance Objective; Local Search",
    "application": "Mode discovery for sampling tasks",
    "code_link": "https://github.com/alstn12088/adaptive-teacher",
    "dataset_name": [
      "QM9",
      "TFbind8",
      "sEH",
      "L14-RNA1",
      "25GMM",
      "Manywell"
    ]
  },
  {
    "id": "A1HhtITVEi",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "CheapNet: Cross-attention on Hierarchical representations for Efficient protein-ligand binding Affinity Prediction",
    "authors": [
      "Hyukjun Lim",
      "Sun Kim",
      "Sangseon Lee"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Accurately predicting protein-ligand binding affinity is a critical challenge in drug discovery, crucial for understanding drug efficacy. While existing models typically rely on atom-level interactions, they often fail to capture the complex, higher-order interactions, resulting in noise and computational inefficiency. Transitioning to modeling these interactions at the cluster level is challenging because it is difficult to determine which atoms form meaningful clusters that drive the protein-ligand interactions. To address this, we propose CheapNet, a novel interaction-based model that integrates atom-level representations with hierarchical cluster-level interactions through a cross-attention mechanism. By employing differentiable pooling of atom-level embeddings, CheapNet efficiently captures essential higher-order molecular representations crucial for accurate binding predictions. Extensive evaluations demonstrate that CheapNet not only achieves state-of-the-art performance across multiple binding affinity prediction tasks but also maintains prediction accuracy with reasonable computational efficiency. The code of CheapNet is available at https://github.com/hyukjunlim/CheapNet.",
    "keywords": "Protein-Ligand Binding Affinity, Hierarchical Representation Learning, Cross-Attention Mechanism, Drug Discovery",
    "pdf_url": "https://openreview.net/pdf?id=A1HhtITVEi",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on predicting protein–ligand binding affinity, a core problem in drug discovery and molecular modeling—both key areas in biomedicine. It explicitly mentions “drug discovery,” “protein-ligand interactions,” and “molecular representations,” all of which are strong indicators of Biomedicine AI.",
    "prompt_tokens": 20581,
    "completion_tokens": 155,
    "total_tokens": 20736,
    "topic": "Drug Discovery - Protein-Ligand Binding",
    "method": "Geometric Interaction Graph Neural Networks (GIGN); differentiable pooling; cluster-attention mechanism",
    "application": "Binding affinity prediction",
    "code_link": "https://github.com/hyukjunlim/CheapNet",
    "dataset_name": [
      "PDBbind v2016 general set",
      "PDB v2013 core set",
      "PDB v2016 core set",
      "PDB v2019 holdout set",
      "LBA 30%",
      "LBA 60%",
      "LEP"
    ]
  },
  {
    "id": "w8LMtFY97b",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Hierarchical Uncertainty Estimation for Learning-based Registration in Neuroimaging",
    "authors": [
      "Xiaoling Hu",
      "Karthik Gopinath",
      "Peirong Liu",
      "Malte Hoffmann",
      "Koen Van Leemput",
      "Oula Puonti",
      "Juan Eugenio Iglesias"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Over recent years, deep learning based image registration has achieved impressive accuracy in many domains, including medical imaging and, specifically, human neuroimaging with magnetic resonance imaging (MRI). However, the uncertainty estimation associated with these methods has been largely limited to the application of generic techniques (e.g., Monte Carlo dropout) that do not exploit the peculiarities of the problem domain, particularly spatial modeling. Here, we propose a principled way to propagate uncertainties (epistemic or aleatoric) estimated at the level of spatial location by these methods, to the level of global transformation models, and further to downstream tasks.  Specifically, we justify the choice of a Gaussian distribution for the local uncertainty modeling, and then propose a framework where uncertainties spread across hierarchical levels, depending on the choice of transformation model. Experiments on publicly available data sets show that Monte Carlo dropout correlates very poorly with the reference registration error, whereas our uncertainty estimates correlate much better. Crucially, the results also show that uncertainty-aware fitting of transformations improves the registration accuracy of brain MRI scans. Finally, we illustrate how sampling from the posterior distribution of the transformations can be used to propagate uncertainties to downstream neuroimaging tasks. Code is available at: https://github.com/HuXiaoling/Regre4Regis.",
    "keywords": "Image registration, uncertainty estimation, medical image analysis",
    "pdf_url": "https://openreview.net/pdf?id=w8LMtFY97b",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on deep learning–based image registration for human neuroimaging with MRI, explicitly addressing “registration accuracy of brain MRI scans” and uncertainty propagation in “medical image analysis.” This application to brain MRI and downstream neuroimaging tasks clearly places it within the Healthcare AI domain.",
    "prompt_tokens": 20765,
    "completion_tokens": 116,
    "total_tokens": 20881,
    "topic": "Medical Imaging - Registration",
    "method": "Uncertainty estimation; deep learning-based registration",
    "application": "Image registration – neuroimaging",
    "code_link": "https://github.com/HuXiaoling/Regre4Regis",
    "dataset_name": [
      "HCP",
      "ADNI",
      "ABIDE",
      "OASIS3"
    ]
  },
  {
    "id": "yu1vqQqKkx",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "LICO: Large Language Models for In-Context Molecular Optimization",
    "authors": [
      "Tung Nguyen",
      "Aditya Grover"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Optimizing black-box functions is a fundamental problem in science and engineering. To solve this problem, many approaches learn a surrogate function that estimates the underlying objective from limited historical evaluations. Large Language Models (LLMs), with their strong pattern-matching capabilities via pretraining on vast amounts of data, stand out as a potential candidate for surrogate modeling. However, directly prompting a pretrained language model to produce predictions is not feasible in many scientific domains due to the scarcity of domain-specific data in the pretraining corpora and the challenges of articulating complex problems in natural language. In this work, we introduce LICO, a general-purpose model that extends arbitrary base LLMs for black-box optimization, with a particular application to the molecular domain. To achieve this, we equip the language model with a separate embedding layer and prediction layer, and train the model to perform in-context predictions on a diverse set of functions defined over the domain. Once trained, LICO can generalize to unseen molecule properties simply via in-context prompting. LICO performs competitively on PMO, a challenging molecular optimization benchmark comprising 23 objective functions, and achieves state-of-the-art performance on its low-budget version PMO-1K.",
    "keywords": "large language models, molecular optimization, black-box optimization, foundation models, in-context learning",
    "pdf_url": "https://openreview.net/pdf?id=yu1vqQqKkx",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “molecular optimization” and evaluates on PMO, a “molecular optimization benchmark” of 23 objective functions. Molecular optimization is a core component of drug discovery and therapeutic design in biomedicine. By leveraging large language models to predict and optimize molecular properties, this work directly addresses a biomedical problem (drug‐like molecule design), fitting squarely within the Biomedicine AI domain.",
    "prompt_tokens": 20877,
    "completion_tokens": 98,
    "total_tokens": 20975,
    "topic": "Drug Discovery - Molecular Optimization",
    "method": "In-context optimization; Embedding layers; Semi-synthetic training",
    "application": "Molecular property optimization",
    "code_link": "N/A",
    "dataset_name": [
      "ZINC250K",
      "PMO",
      "Guacamol"
    ]
  },
  {
    "id": "AD5yx2xq8R",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "XAIguiFormer: explainable artificial intelligence guided transformer for brain disorder identification",
    "authors": [
      "Hanning Guo",
      "Farah Abdellatif",
      "Yu Fu",
      "N. Jon Shah",
      "Abigail Morrison",
      "Jürgen Dammers"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "EEG-based connectomes offer a low-cost and portable method to identify brain disorders using deep learning. With the growing interest in model interpretability and transparency, explainable artificial intelligence (XAI) is widely applied to understand the decision of deep learning models. However, most research focuses solely on interpretability analysis based on the insights from XAI, overlooking XAI’s potential to improve model performance. To bridge this gap, we propose a dynamical-system-inspired architecture, XAI guided transformer (XAIguiFormer), where XAI not only provides explanations but also contributes to enhancing the transformer by refining the originally coarse information in self-attention mechanism to capture more relevant dependency relationships. In order not to damage the connectome’s topological structure, the connectome tokenizer treats the single-band graphs as atomic tokens to generate a sequence in the frequency domain. To address the limitations of conventional positional encoding in understanding the frequency and mitigating the individual differences, we integrate frequency and demographic information into tokens via a rotation matrix, resulting in a richly informative representation. Our experiment demonstrates that XAIguiFormer achieves superior performance over all baseline models. In addition, XAIguiFormer provides valuable interpretability through visualization of the frequency band importance. Our code is available at https://github.com/HanningGuo/XAIguiFormer.",
    "keywords": "EEG, Explainable Artificial Intelligence (XAI), Explanation-Guided Learning, Transformer",
    "pdf_url": "https://openreview.net/pdf?id=AD5yx2xq8R",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “EEG-based connectomes” for “brain disorder identification,” which is a clinical diagnostic task using biomedical signals. It applies explainable AI to EEG data—a biomedical time-series—to improve detection of neurological disorders, clearly situating it within Healthcare/​Biomedicine AI.",
    "prompt_tokens": 21178,
    "completion_tokens": 103,
    "total_tokens": 21281,
    "topic": "EEG Analysis - Brain Disorders",
    "method": "Explainable AI; Transformer-based models; Graph Neural Networks",
    "application": "Brain disorder classification",
    "code_link": "https://github.com/HanningGuo/XAIguiFormer",
    "dataset_name": [
      "TUAB",
      "TDBRAIN"
    ]
  },
  {
    "id": "OdnqG1fYpo",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Moner: Motion Correction in Undersampled Radial MRI with Unsupervised Neural Representation",
    "authors": [
      "Qing Wu",
      "Chenhe Du",
      "Xuanyu Tian",
      "Jingyi Yu",
      "Yuyao Zhang",
      "Hongjiang Wei"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Motion correction (MoCo) in radial MRI is a particularly challenging problem due to the unpredictability of subject movement. Current state-of-the-art (SOTA) MoCo algorithms often rely on extensive high-quality MR images to pre-train neural networks, which constrains the solution space and leads to outstanding image reconstruction results. However, the need for large-scale datasets significantly increases costs and limits model generalization. In this work, we propose Moner, an unsupervised MoCo method that jointly reconstructs artifact-free MR images and estimates accurate motion from undersampled, rigid motion-corrupted k-space data, without requiring any training data. Our core idea is to leverage the continuous prior of implicit neural representation (INR) to constrain this ill-posed inverse problem, facilitating optimal solutions. Specifically, we integrate a quasi-static motion model into the INR, granting its ability to correct subject's motion. To stabilize model optimization, we reformulate radial MRI reconstruction as a back-projection problem using the Fourier-slice theorem. Additionally, we propose a novel coarse-to-fine hash encoding strategy, significantly enhancing MoCo accuracy. Experiments on multiple MRI datasets show our Moner achieves performance comparable to SOTA MoCo techniques on in-domain data, while demonstrating significant improvements on out-of-domain data. The code is available at: https://github.com/iwuqing/Moner",
    "keywords": "MRI Reconstruction, Motion Correction, Neural Representation, NeRF, Unsupervised Learning",
    "pdf_url": "https://openreview.net/pdf?id=OdnqG1fYpo",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on motion correction in radial MRI reconstruction (“Motion correction (MoCo) in radial MRI,” “artifact-free MR images”), which is a core medical imaging task. MRI is a clinical imaging modality used extensively in healthcare, so advances in reconstructing and correcting MRI data directly impact medical diagnosis and treatment planning.",
    "prompt_tokens": 20287,
    "completion_tokens": 103,
    "total_tokens": 20390,
    "topic": "Medical Imaging - Motion Correction",
    "method": "Implicit neural representation (INR); hash encoding; back-projection optimization",
    "application": "MRI motion correction and image reconstruction",
    "code_link": "https://github.com/iwuqing/Moner",
    "dataset_name": [
      "fastMRI",
      "MoDL"
    ]
  },
  {
    "id": "0ctvBgKFgc",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "ProtComposer: Compositional Protein Structure Generation with 3D Ellipsoids",
    "authors": [
      "Hannes Stark",
      "Bowen Jing",
      "Tomas Geffner",
      "Jason Yim",
      "Tommi Jaakkola",
      "Arash Vahdat",
      "Karsten Kreis"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We develop ProtComposer to generate protein structures conditioned on spatial protein layouts that are specified via a set of 3D ellipsoids capturing substructure shapes and semantics. At inference time, we condition on ellipsoids that are hand-constructed, extracted from existing proteins, or from a statistical model, with each option unlocking new capabilities. Hand-specifying ellipsoids enables users to control the location, size, orientation, secondary structure, and approximate shape of protein substructures. Conditioning on ellipsoids of existing proteins enables redesigning their substructure's connectivity or editing substructure properties. By conditioning on novel and diverse ellipsoid layouts from a simple statistical model, we improve protein generation with expanded Pareto frontiers between designability, novelty, and diversity. Further, this enables sampling designable proteins with a helix-fraction that matches PDB proteins, unlike existing generative models that commonly oversample conceptually simple helix bundles. Code is available at https://github.com/NVlabs/protcomposer.",
    "keywords": "protein design, diffusion model, controllable generation, drug discovery, proteins, biology",
    "pdf_url": "https://openreview.net/pdf?id=0ctvBgKFgc",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work focuses on generative modelling of protein structures (“ProtComposer to generate protein structures conditioned on spatial protein layouts”), with explicit mention of “protein design” and “drug discovery” in the keywords. Protein design and molecular modelling are core tasks in biomedicine and drug development, making this paper relevant to the Biomedicine AI domain.",
    "prompt_tokens": 21058,
    "completion_tokens": 97,
    "total_tokens": 21155,
    "topic": "Bioinformatics - Protein Structure Generation",
    "method": "Flow matching; Invariant Cross Attention",
    "application": "Controllable protein structure generation",
    "code_link": "https://github.com/NVlabs/protcomposer",
    "dataset_name": [
      "PDB (Protein Data Bank)"
    ]
  },
  {
    "id": "lzdFImKK8w",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Boltzmann-Aligned Inverse Folding Model as a Predictor of Mutational Effects on Protein-Protein Interactions",
    "authors": [
      "Xiaoran Jiao",
      "Weian Mao",
      "Wengong Jin",
      "Peiyuan Yang",
      "Hao Chen",
      "Chunhua Shen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Predicting the change in binding free energy ($\\Delta \\Delta G$) is crucial for understanding and modulating protein-protein interactions, which are critical in drug design.\nDue to the scarcity of experimental $\\Delta\\Delta G$ data, \nexisting methods focus on pre-training, \nwhile neglecting the importance of alignment.\nIn this work, we propose Boltzmann Alignment technique to transfer knowledge from pre-trained inverse folding models to prediction of $\\Delta\\Delta G$.\nWe begin by analyzing the thermodynamic definition of $\\Delta\\Delta G$ and introducing the Boltzmann distribution to connect energy to the protein conformational distribution. \nHowever, the protein conformational distribution is intractable. Therefore, we employ Bayes’ theorem to circumvent direct estimation and instead utilize the log-likelihood provided by protein inverse folding models for the estimation of $\\Delta\\Delta G$. \n\nCompared to previous methods based on inverse folding, our method explicitly accounts for the unbound state of the protein complex in the $\\Delta \\Delta G$ thermodynamic cycle, introducing a physical inductive bias and achieving supervised and unsupervised state-of-the-art (SoTA) performance.\nExperimental results on SKEMPI v2 indicate that our method achieves Spearman coefficients of 0.3201 (unsupervised) and 0.5134 (supervised) on SKEMPI v2, significantly surpassing the previously reported \n%SoTA values\nSoTA results \nof 0.2632 and 0.4324, respectively.\nFurthermore, we demonstrate the capability of our method in binding\nenergy prediction, protein-protein docking, and antibody optimization tasks.\n\nCode is available at [https://github.com/aim-uofa/BA-DDG](https://github.com/aim-uofa/BA-DDG)",
    "keywords": "Mutational Effects; Protein-Protein Interactions",
    "pdf_url": "https://openreview.net/pdf?id=lzdFImKK8w",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on predicting changes in binding free energy (ΔΔG) for protein–protein interactions—a core task in molecular modeling and drug discovery. It explicitly mentions applications such as “drug design,” “binding energy prediction,” and “antibody optimization,” which are central to biomedical research and therapeutic development. These traits align with the Biomedicine AI domain.",
    "prompt_tokens": 20088,
    "completion_tokens": 104,
    "total_tokens": 20192,
    "topic": "Bioinformatics - Protein Binding Energy Modeling",
    "method": "Boltzmann Alignment; ProteinMPNN",
    "application": "Binding energy prediction",
    "code_link": "https://github.com/aim-uofa/BA-DDG",
    "dataset_name": [
      "SKEMPI v2",
      "SAbDab"
    ]
  },
  {
    "id": "mXHTifc1Fn",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "E(3)-equivariant models cannot learn chirality: Field-based molecular generation",
    "authors": [
      "Alexandru Dumitrescu",
      "Dani Korpela",
      "Markus Heinonen",
      "Yogesh Verma",
      "Valerii Iakovlev",
      "Vikas Garg",
      "Harri Lähdesmäki"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Obtaining the desired effect of drugs is highly dependent on their molecular geometries. Thus, the current prevailing paradigm focuses on 3D point-cloud atom representations, utilizing graph neural network (GNN) parametrizations, with rotational symmetries baked in via E(3) invariant layers. We prove that such models must necessarily disregard chirality, a geometric property of the molecules that cannot be superimposed on their mirror image by rotation and translation. Chirality plays a key role in determining drug safety and potency. To address this glaring issue, we introduce a novel field-based representation, proposing reference rotations that replace rotational symmetry constraints. The proposed model captures all molecular geometries including chirality, while still achieving highly competitive performance with E(3)-based methods across standard benchmarking metrics.",
    "keywords": "deep generative models, molecule generation",
    "pdf_url": "https://openreview.net/pdf?id=mXHTifc1Fn",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on 3D molecular generation with direct implications for drug design (“Obtaining the desired effect of drugs is highly dependent on their molecular geometries”), discusses chirality’s role in drug safety and potency, and introduces models for generating chemically valid molecules. These elements place it squarely in the drug discovery/biomedicine AI domain.",
    "prompt_tokens": 75766,
    "completion_tokens": 160,
    "total_tokens": 75926,
    "topic": "Drug Discovery - 3D Molecule Generation",
    "method": "Diffusion model; classifier guidance",
    "application": "3D molecular conformer generation",
    "code_link": "N/A",
    "dataset_name": [
      "QM9",
      "GEOM-Drugs"
    ]
  },
  {
    "id": "P4XmKjXTrM",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "ACES: Automatic Cohort Extraction System for Event-Stream Datasets",
    "authors": [
      "Justin Xu",
      "Jack Gallifant",
      "ALISTAIR JOHNSON",
      "Matthew B.A. McDermott"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Reproducibility remains a significant challenge in machine learning (ML) for healthcare. Datasets, model pipelines, and even task or cohort definitions are often private in this field, leading to a significant barrier in sharing, iterating, and understanding ML results on electronic health record (EHR) datasets. We address a significant part of this problem by introducing the Automatic Cohort Extraction System (ACES) for event-stream data. This library is designed to simultaneously simplify the development of tasks and cohorts for ML in healthcare and also enable their reproduction, both at an exact level for single datasets and at a conceptual level across datasets. To accomplish this, ACES provides: (1) a highly intuitive and expressive domain-specific configuration language for defining both dataset-specific concepts and dataset-agnostic inclusion or exclusion criteria, and (2) a pipeline to automatically extract patient records that meet these defined criteria from real-world data. ACES can be automatically applied to any dataset in either the Medical Event Data Standard (MEDS) or Event Stream GPT (ESGPT) formats, or to *any* dataset in which the necessary task-specific predicates can be extracted in an event-stream form. ACES has the potential to significantly lower the barrier to entry for defining ML tasks in representation learning, redefine the way researchers interact with EHR datasets, and significantly improve the state of reproducibility for ML studies using this modality. ACES is available at: https://github.com/justin13601/aces.",
    "keywords": "Automatic Task Specification, Cohort Extraction, Electronic Health Records, Open Source Software, Benchmarks, Datasets",
    "pdf_url": "https://openreview.net/pdf?id=P4XmKjXTrM",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper addresses reproducible cohort extraction from electronic health record (EHR) data, defining patient inclusion/exclusion criteria and applying these to real-world medical event streams. It explicitly references “ML in healthcare,” “EHR datasets,” and “patient records,” making it directly relevant to Healthcare AI.",
    "prompt_tokens": 21008,
    "completion_tokens": 127,
    "total_tokens": 21135,
    "topic": "EHR - Predictive Models",
    "method": "Task configuration language; event-stream data processing",
    "application": "Cohort definition and prediction task extraction",
    "code_link": "https://github.com/justin13601/aces",
    "dataset_name": [
      "MIMIC-IV",
      "eICU",
      "Synthea"
    ]
  },
  {
    "id": "aX7X9z3vQS",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Recovering Manifold Structure Using Ollivier Ricci Curvature",
    "authors": [
      "Tristan Luca Saidi",
      "Abigail Hickok",
      "Andrew J. Blumberg"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We introduce ORC-ManL, a new algorithm to prune spurious edges from nearest neighbor graphs using a criterion based on Ollivier-Ricci curvature and estimated metric distortion. Our motivation comes from manifold learning: we show that when the data generating the nearest-neighbor graph consists of noisy samples from a low-dimensional manifold, edges that shortcut through the ambient space have more negative Ollivier-Ricci curvature than edges that lie along the data manifold. We demonstrate that our method outperforms alternative pruning methods and that it significantly improves performance on many downstream geometric data analysis tasks that use nearest neighbor graphs as input. Specifically, we evaluate on manifold learning, persistent homology, dimension estimation, and others. We also show that ORC-ManL can be used to improve clustering and manifold learning of single-cell RNA sequencing data. Finally, we provide empirical convergence experiments that support our theoretical findings.",
    "keywords": "Manifold Learning, Persistent Homology, Ollivier-Ricci Curvature, Pruning, Nearest-Neighbor Graphs",
    "pdf_url": "https://openreview.net/pdf?id=aX7X9z3vQS",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the core contribution is a general graph-pruning algorithm for manifold learning, the abstract specifically highlights its use “to improve clustering and manifold learning of single-cell RNA sequencing data,” which is a canonical biomedical data analysis task. This single-cell application places the work squarely in the Biomedicine AI domain.",
    "prompt_tokens": 20879,
    "completion_tokens": 120,
    "total_tokens": 20999,
    "topic": "Dimensionality Reduction - Graph-based Learning",
    "method": "Ollivier-Ricci Curvature; nearest-neighbor graph pruning",
    "application": "Manifold learning; clustering; scalar curvature estimation",
    "code_link": "https://github.com/TristanSaidi/orcml",
    "dataset_name": [
      "MNIST",
      "KMNIST",
      "PBMC",
      "ALM"
    ]
  },
  {
    "id": "S8gbnkCgxZ",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Redefining the task of Bioactivity Prediction",
    "authors": [
      "Yanwen Huang",
      "Bowen Gao",
      "Yinjun Jia",
      "Hongbo Ma",
      "Wei-Ying Ma",
      "Ya-Qin Zhang",
      "Yanyan Lan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Small molecules are vital to modern medicine, and accurately predicting their bioactivity against protein targets is crucial for therapeutic discovery and development. However, current machine learning models often rely on spurious features, leading to biased outcomes. Notably, a simple pocket-only baseline can achieve results comparable to, and sometimes better than, more complex models that incorporate both the protein pockets and the small molecules. Our analysis reveals that this phenomenon arises from insufficient training data and an improper evaluation process, which is typically conducted at the pocket level rather than the small molecule level. To address these issues, we redefine the bioactivity prediction task by introducing the SIU dataset-a million-scale Structural small molecule-protein Interaction dataset for Unbiased bioactivity prediction task, which is 50 times larger than the widely used PDBbind. The bioactivity labels in SIU are derived from wet experiments and organized by label types, ensuring greater accuracy and comparability. The complexes in SIU are constructed using a majority vote from three commonly used docking software programs, enhancing their reliability. Additionally, the structure of SIU allows for multiple small molecules to be associated with each protein pocket, enabling the redefinition of evaluation metrics like Pearson and Spearman correlations across different small molecules targeting the same protein pocket. Experimental results demonstrate that this new task provides a more challenging and meaningful benchmark for training and evaluating bioactivity prediction models, ultimately offering a more robust assessment of model performance.",
    "keywords": "Bioactivity Prediction, New Dataset",
    "pdf_url": "https://openreview.net/pdf?id=S8gbnkCgxZ",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on predicting small molecule bioactivity against protein targets, introducing a large structural small molecule–protein interaction dataset (SIU) for drug discovery. Terms like “bioactivity prediction,” “protein pockets,” “small molecules,” and “wet experiments” clearly place it in the realm of biomedical research and therapeutic discovery, characteristic of Biomedicine AI.",
    "prompt_tokens": 20760,
    "completion_tokens": 115,
    "total_tokens": 20875,
    "topic": "Drug Discovery - Bioactivity Prediction",
    "method": "GNN; 3D-CNN; structural docking; multi-software consensus filtering",
    "application": "Bioactivity prediction",
    "code_link": "https://github.com/bowen-gao/SIU",
    "dataset_name": [
      "SIU",
      "PDBbind",
      "BindingDB",
      "ChEMBL"
    ]
  },
  {
    "id": "bcTjW5kS4W",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "NetFormer: An interpretable model for recovering dynamical connectivity in neuronal population dynamics",
    "authors": [
      "Ziyu Lu",
      "Wuwei Zhang",
      "Trung Le",
      "Hao Wang",
      "Uygar Sümbül",
      "Eric Todd SheaBrown",
      "Lu Mi"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Neuronal dynamics are highly nonlinear and nonstationary. Traditional methods for extracting the underlying network structure from neuronal activity recordings mainly concentrate on modeling static connectivity, without accounting for key nonstationary aspects of biological neural systems, such as ongoing synaptic plasticity and neuronal modulation. To bridge this gap, we introduce the NetFormer model, an interpretable approach applicable to such systems. In NetFormer, the activity of each neuron across a series of historical time steps is defined as a token. These tokens are then linearly mapped through a query and key mechanism to generate a state- (and hence time-) dependent attention matrix that directly encodes nonstationary connectivity structures. We analyze our formulation from the perspective of nonstationary and nonlinear networked dynamical systems, and show both via an analytical expansion and targeted simulations how it can approximate the underlying  ground truth.  Next, we demonstrate NetFormer's ability to model a key feature of biological networks, spike-timing-dependent plasticity, whereby connection strengths continually change in response to local activity patterns. We further demonstrate that NetFormer can capture task-induced connectivity patterns on activity generated by task-trained recurrent neural networks. Thus informed, we apply NetFormer to a multi-modal dataset of real neural recordings, which contains neural activity, cell type, and behavioral state information.  We show that the NetFormer effectively predicts neural dynamics and identifies cell-type specific, state-dependent dynamic connectivity that matches patterns measured in separate ground-truth physiology experiments, demonstrating its ability to help decode complex neural interactions based on population activity observations alone.",
    "keywords": "neuronal dynamics, dynamical connectivity, interpretability, attention mechanism, transformer",
    "pdf_url": "https://openreview.net/pdf?id=bcTjW5kS4W",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work develops an attention‐based model for recovering time-varying “dynamical connectivity” in neuronal population recordings, demonstrating applications to spike-timing-dependent plasticity and real neural physiology data with cell-type and behavioral-state annotations. By focusing on neural system dynamics (“neuronal dynamics,” “spike-timing-dependent plasticity,” “multi-modal dataset of real neural recordings”) and interpreting population connectivity, it squarely falls under neurobiological modeling, a key component of Biomedicine AI.",
    "prompt_tokens": 20861,
    "completion_tokens": 108,
    "total_tokens": 20969,
    "topic": "Neural Networks - Brain Connectivity",
    "method": "Linearized attention mechanism; dynamical methods inference",
    "application": "Neuronal activity prediction; connectivity inference",
    "code_link": "https://github.com/NeuroAIHub/NetFormer",
    "dataset_name": [
      "Patch-clamp dataset",
      "Multimodal neural recording"
    ]
  },
  {
    "id": "BAelAyADqn",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "MuHBoost: Multi-Label Boosting For Practical Longitudinal Human Behavior Modeling",
    "authors": [
      "Nguyen T Thach",
      "Patrick Habecker",
      "Anika R. Eisenbraun",
      "W. Alex Mason",
      "Kimberly A. Tyler",
      "Bilal Khan",
      "Hau Chan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Longitudinal human behavior modeling has received increasing attention over the years due to its widespread applications to patient monitoring, dietary and lifestyle recommendations, and just-in-time intervention for at-risk individuals (e.g., problematic drug users and struggling students), to name a few. Using in-the-moment health data collected via ubiquitous devices (e.g., smartphones and smartwatches), this multidisciplinary field focuses on developing predictive models for certain health or well-being outcomes (e.g., depression and stress) in the short future given the time series of individual behaviors (e.g., resting heart rate, sleep quality, and current feelings). Yet, most existing models on these data, which we refer to as ubiquitous health data, do not achieve adequate accuracy. The latest works that yielded promising results have yet to consider realistic aspects of ubiquitous health data (e.g., containing features of different types and high rate of missing values) and the consumption of various resources (e.g., computing power, time, and cost). Given these two shortcomings, it is dubious whether these studies could translate to realistic settings. In this paper, we propose MuHBoost, a multi-label boosting method for addressing these shortcomings, by leveraging advanced methods in large language model (LLM) prompting and multi-label classification (MLC) to jointly predict multiple health or well-being outcomes. Because LLMs can hallucinate when tasked with answering multiple questions simultaneously, we also develop two variants of MuHBoost that alleviate this issue and thereby enhance its predictive performance. We conduct extensive experiments to evaluate MuHBoost and its variants on 13 health and well-being prediction tasks defined from four realistic ubiquitous health datasets. Our results show that our three developed methods outperform all considered baselines across three standard MLC metrics, demonstrating their effectiveness while ensuring resource efficiency.",
    "keywords": "AI for Public Health, large language models, heterogeneous time-series classification, multi-label classification",
    "pdf_url": "https://openreview.net/pdf?id=BAelAyADqn",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on modeling and predicting health and well-being outcomes (e.g., depression, stress) from wearable and smartphone sensor data (“in-the-moment health data collected via ubiquitous devices,” “patient monitoring,” “just-in-time intervention for at-risk individuals”). These are clear applications of AI to healthcare and patient monitoring, fitting squarely within the Healthcare AI domain.",
    "prompt_tokens": 21084,
    "completion_tokens": 125,
    "total_tokens": 21209,
    "topic": "Longitudinal Health Prediction - Multi-Label Classification",
    "method": "LLM prompting; boosting; multi-label classification",
    "application": "Health and well-being prediction tasks across multiple datasets",
    "code_link": "https://github.com/jindongwang/transferlearning/tree/master/code/deep/adarnn",
    "dataset_name": [
      "LifeSnaps",
      "GLOBEM",
      "CoSt",
      "PWUD"
    ]
  },
  {
    "id": "xkgfLXZ4e0",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Correlating instruction-tuning (in multimodal models) with vision-language processing (in the brain)",
    "authors": [
      "SUBBA REDDY OOTA",
      "Akshett Rai Jindal",
      "Ishani Mondal",
      "Khushbu Pahwa",
      "Satya Sai Srinath Namburi GNVV",
      "Manish Shrivastava",
      "Maneesh Kumar Singh",
      "Bapi Raju Surampudi",
      "Manish Gupta"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Transformer-based language models, though not explicitly trained to mimic brain recordings, have demonstrated surprising alignment with brain activity. Progress in these models—through increased size, instruction-tuning, and multimodality—has led to better representational alignment with neural data. Recently, a new class of instruction-tuned multimodal LLMs (MLLMs) have emerged, showing remarkable zero-shot capabilities in open-ended multimodal vision tasks. However, it is unknown whether MLLMs, when prompted with natural instructions, lead to better brain alignment and effectively capture instruction-specific representations. To address this, we first investigate the brain alignment, i.e., measuring the degree of predictivity of neural visual activity using text output response embeddings from MLLMs as participants engage in watching natural scenes. Experiments with 10 different instructions (like image captioning, visual question answering, etc.) show that  MLLMs exhibit significantly better brain alignment than vision-only models and perform comparably to non-instruction-tuned multimodal models like CLIP. We also find that while these MLLMs are effective at generating high-quality responses suitable to the task-specific instructions, not all instructions are relevant for brain alignment. Further, by varying instructions, we make the MLLMs encode instruction-specific visual concepts related to the input image. This analysis shows that MLLMs effectively capture count-related and recognition-related concepts, demonstrating strong alignment with brain activity. Notably, the majority of the explained variance of the brain encoding models is shared between MLLM embeddings of image captioning and other instructions. These results indicate that enhancing MLLMs' ability to capture more task-specific information could allow for better differentiation between various types of instructions, and hence improve their precision in predicting brain responses.",
    "keywords": "brain encoding, fMRI, visual processing, multimodal instruction-tuned models, language decoder, LLMs, MLLMs",
    "pdf_url": "https://openreview.net/pdf?id=xkgfLXZ4e0",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on modeling and predicting human brain activity (fMRI) in response to visual stimuli using multimodal LLM embeddings. It involves “brain encoding,” “fMRI,” and “visual processing,” which fall under neuroscience and neurobiological modeling—key subfields of Biomedicine AI.",
    "prompt_tokens": 21010,
    "completion_tokens": 109,
    "total_tokens": 21119,
    "topic": "Brain Encoding - Multimodal Integration",
    "method": "Instruction-tuned multimodal models; Ridge regression",
    "application": "Brain activity prediction during visual stimuli processing",
    "code_link": "https://github.com/subbareddy248/mllm_instruction_brain",
    "dataset_name": [
      "Natural Scenes Dataset (NSD)",
      "COCO"
    ]
  },
  {
    "id": "l0t2rumAvR",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Prompt as Knowledge Bank: Boost Vision-language model via Structural Representation for  zero-shot medical detection",
    "authors": [
      "Yuguang Yang",
      "Tongfei Chen",
      "Haoyu Huang",
      "Linlin Yang",
      "Chunyu Xie",
      "Dawei Leng",
      "Xianbin Cao",
      "Baochang Zhang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Zero-shot medical detection can further improve detection performance without relying on annotated medical images even upon the fine-tuned model, showing great clinical value. Recent studies leverage grounded vision-language models (GLIP) to achieve this by using detailed disease descriptions as prompts for the target disease name during the inference phase.  \nHowever, these methods typically treat prompts as equivalent context to the target name, making it difficult to assign specific disease knowledge based on visual information, leading to a coarse alignment between images and target descriptions. In this paper, we propose StructuralGLIP, which introduces an auxiliary branch to encode prompts into a latent knowledge bank layer-by-layer, enabling more context-aware and fine-grained alignment. Specifically, in each layer, we select highly similar features from both the image representation and the knowledge bank, forming structural representations that capture nuanced relationships between image patches and target descriptions. These features are then fused across modalities to further enhance detection performance.\nExtensive experiments demonstrate that StructuralGLIP achieves a +4.1\\% AP improvement over prior state-of-the-art methods across seven zero-shot medical detection benchmarks, and consistently improves fine-tuned models by +3.2\\% AP on endoscopy image datasets.",
    "keywords": "Vision-language model;  zero-shot enhancement; Structural Representation",
    "pdf_url": "https://openreview.net/pdf?id=l0t2rumAvR",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on zero‐shot medical detection and explicitly refers to “detailed disease descriptions,” “medical detection benchmarks,” and improvements on “endoscopy image datasets.” These are all medical imaging tasks with clear clinical value, placing the work squarely in the Healthcare AI domain.",
    "prompt_tokens": 20602,
    "completion_tokens": 141,
    "total_tokens": 20743,
    "topic": "Medical Imaging - Zero-shot Detection",
    "method": "Vision-language pretraining; prompt engineering; grounded language-image pre-training",
    "application": "Lesion detection – Radiology and Dermatology",
    "code_link": "https://github.com/CapricornGuang/StructuralGLIP",
    "dataset_name": [
      "CVC-300",
      "ClinicDB",
      "ColonDB",
      "Kvasir",
      "ETIS",
      "ISIC-2016",
      "BCCD",
      "TBX11K"
    ]
  },
  {
    "id": "E1m5yGMOiV",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "KinPFN: Bayesian Approximation of RNA Folding Kinetics using Prior-Data Fitted Networks",
    "authors": [
      "Dominik Scheuer",
      "Frederic Runge",
      "Jörg K.H. Franke",
      "Michael T. Wolfinger",
      "Christoph Flamm",
      "Frank Hutter"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "RNA is a dynamic biomolecule crucial for cellular regulation, with its function largely determined by its folding into complex structures, while misfolding can lead to multifaceted biological sequelae. During the folding process, RNA traverses through a series of intermediate structural states, with each transition occurring at variable rates that collectively influence the time required to reach the functional form. Understanding these folding kinetics is vital for predicting RNA behavior and optimizing applications in synthetic biology and drug discovery. While in silico kinetic RNA folding simulators are often computationally intensive and time-consuming, accurate approximations of the folding times can already be very informative to assess the efficiency of the folding process. In this work, we present KinPFN, a novel approach that leverages prior-data fitted networks to directly model the posterior predictive distribution of RNA folding times. By training on synthetic data representing arbitrary prior folding times, KinPFN efficiently approximates the cumulative distribution function of RNA folding times in a single forward pass, given only a few initial folding time examples. Our method offers a modular extension to existing RNA kinetics algorithms, promising significant computational speed-ups orders of magnitude faster, while achieving comparable results. We showcase the effectiveness of KinPFN through extensive evaluations and real-world case studies, demonstrating its potential for RNA folding kinetics analysis, its practical relevance, and generalization to other biological data.",
    "keywords": "RNA Folding Kinetics, Prior-Data Fitted Networks, Deep Learning, Synthetic Data, Transformer, Bayesian Inference",
    "pdf_url": "https://openreview.net/pdf?id=E1m5yGMOiV",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on modeling RNA folding kinetics, a core problem in molecular biology and synthetic biology with direct implications for drug discovery and understanding biomolecular function (\"RNA is a dynamic biomolecule crucial for cellular regulation… misfolding can lead to multifaceted biological sequelae\" and “synthetic biology and drug discovery”). Predicting RNA behavior and folding times is central to biomedicine, placing this work squarely in the Biomedicine AI domain.",
    "prompt_tokens": 20941,
    "completion_tokens": 108,
    "total_tokens": 21049,
    "topic": "Bioinformatics - RNA Kinetics",
    "method": "Transformer-based models (PFN); synthetic prior",
    "application": "RNA folding time distribution approximation",
    "code_link": "https://github.com/automl/KinPFN",
    "dataset_name": [
      "Synthetic RNA Folding Time Distributions",
      "KinFold",
      "KFold"
    ]
  },
  {
    "id": "Q95MaWfF4e",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Navigating Neural Space: Revisiting Concept Activation Vectors to Overcome Directional Divergence",
    "authors": [
      "Frederik Pahde",
      "Maximilian Dreyer",
      "Moritz Weckbecker",
      "Leander Weber",
      "Christopher J. Anders",
      "Thomas Wiegand",
      "Wojciech Samek",
      "Sebastian Lapuschkin"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "With a growing interest in understanding neural network prediction strategies, Concept Activation Vectors (CAVs) have emerged as a popular tool for modeling human-understandable concepts in the latent space.\nCommonly, CAVs are computed by leveraging linear classifiers optimizing the *separability* of latent representations of samples with and without a given concept. However, in this paper we show that such a separability-oriented computation leads to solutions, which may diverge from the actual goal of precisely modeling the concept direction.\nThis discrepancy can be attributed to the significant influence of distractor directions, i.e., signals unrelated to the concept, which are picked up by filters (i.e., weights) of linear models to optimize class-separability.\nTo address this, we introduce *pattern-based CAVs*, solely focussing on concept signals, thereby providing more accurate concept directions.\nWe evaluate various CAV methods in terms of their alignment with the true concept direction and their impact on CAV applications, including concept sensitivity testing and model correction for shortcut behavior caused by data artifacts. \nWe demonstrate the benefits of pattern-based CAVs using the Pediatric Bone Age, ISIC2019, and FunnyBirds datasets with VGG, ResNet, ReXNet, EfficientNet, and Vision Transformer as model architectures.",
    "keywords": "Explainable AI, Concept-based Explanations, Concept Activation Vectors",
    "pdf_url": "https://openreview.net/pdf?id=Q95MaWfF4e",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although this work proposes a general concept‐explanation method (pattern‐based CAVs), it is explicitly evaluated on medical imaging tasks—“Pediatric Bone Age” estimation and the ISIC2019 skin‐lesion dataset—both core Healthcare AI benchmarks. These applications indicate a clear focus on biomedical image analysis.",
    "prompt_tokens": 20273,
    "completion_tokens": 104,
    "total_tokens": 20377,
    "topic": "Explainable AI - Concept Activation Vectors",
    "method": "Concept Activation Vectors (CAVs); Pattern-CAV",
    "application": "Bias mitigation; Artifact correction",
    "code_link": "N/A",
    "dataset_name": [
      "ISIC2019",
      "Pediatric Bone Age",
      "FunnyBirds"
    ]
  },
  {
    "id": "IjbXZdugdj",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Bio-xLSTM: Generative modeling, representation and in-context learning of biological and chemical sequences",
    "authors": [
      "Niklas Schmidinger",
      "Lisa Schneckenreiter",
      "Philipp Seidl",
      "Johannes Schimunek",
      "Pieter-Jan Hoedt",
      "Johannes Brandstetter",
      "Andreas Mayr",
      "Sohvi Luukkonen",
      "Sepp Hochreiter",
      "Günter Klambauer"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Language models for biological and chemical sequences enable crucial applications such as drug discovery, protein engineering, and precision medicine. Currently, these language models are predominantly based on Transformer architectures. While Transformers have yielded impressive results, their quadratic runtime dependency on sequence length complicates their use for long genomic sequences and in-context learning on proteins and chemical sequences. Recently, the recurrent xLSTM architecture has been shown to perform favorably compared to Transformers and modern state-space models (SSMs) in the natural language domain. Similar to SSMs, xLSTMs have linear runtime dependency and allow for constant-memory decoding at inference time, which makes them prime candidates for modeling long-range dependencies in biological and chemical sequences. In this work, we tailor xLSTM towards these domains and we propose a suite of language models called Bio-xLSTM. Extensive experiments in three large domains, genomics, proteins, and chemistry, were performed to assess xLSTM’s ability to model biological and chemical sequences. The results show that Bio-xLSTM is a highly proficient generative model for DNA, protein, and chemical sequences, learns rich representations, and can perform in-context learning for proteins and small molecules.",
    "keywords": "xLSTM, large language model, foundation model, DNA, protein, small molecule, SMILES, in-context learning, masked language modeling, causal language modeling, fill-in the middle, equivariance, reverse complementary sequence",
    "pdf_url": "https://openreview.net/pdf?id=IjbXZdugdj",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper develops language models for DNA, protein, and small-molecule sequences with direct applications in “drug discovery,” “protein engineering,” and “precision medicine,” all of which are core to biomedical research. The focus on generative modeling of biological and chemical sequences (e.g., SMILES) further underscores its relevance to Biomedicine AI.",
    "prompt_tokens": 21015,
    "completion_tokens": 161,
    "total_tokens": 21176,
    "topic": "Bioinformatics - Molecular Language Models",
    "method": "Causal language modeling; Masked language modeling; In-context learning",
    "application": "Conditional molecule generation",
    "code_link": "https://github.com/ml-jku/DNA-xLSTM, https://github.com/ml-jku/Prot-xLSTM, https://github.com/ml-jku/Chem-xLSTM",
    "dataset_name": [
      "Coconut",
      "Probes & Drugs",
      "USPTO-50k",
      "ZINClick",
      "MoleculeNet",
      "FS-Mol",
      "PubChem",
      "BELKA challenge"
    ]
  },
  {
    "id": "zcTLpIfj9u",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Time-to-Event Pretraining for 3D Medical Imaging",
    "authors": [
      "Zepeng Frazier Huo",
      "Jason Alan Fries",
      "Alejandro Lozano",
      "Jeya Maria Jose Valanarasu",
      "Ethan Steinberg",
      "Louis Blankemeier",
      "Akshay S Chaudhari",
      "Curtis Langlotz",
      "Nigam Shah"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "With the rise of medical foundation models and the growing availability of imaging data, scalable pretraining techniques offer a promising way to identify imaging biomarkers predictive of future disease risk. While current self-supervised methods for 3D medical imaging models capture local structural features like organ morphology, they fail to link pixel biomarkers with long-term health outcomes due to a missing context problem. Current approaches lack the temporal context necessary to identify biomarkers correlated with disease progression, as they rely on supervision derived only from images and concurrent text descriptions. To address this, we introduce time-to-event pretraining, a pretraining framework for 3D medical imaging models that leverages large-scale temporal supervision from paired, longitudinal electronic health records (EHRs). Using a dataset of 18,945 CT scans (4.2 million 2D images) and time-to-event distributions across thousands of EHR-derived tasks, our method improves outcome prediction, achieving an average AUROC increase of 23.7% and a 29.4% gain in Harrell’s C-index across 8 benchmark tasks. Importantly, these gains are achieved without sacrificing diagnostic classification performance. This study lays the foundation for integrating longitudinal EHR and 3D imaging data to advance clinical risk prediction.",
    "keywords": "Multimodal learning, medical imaging, Electronic Health Records",
    "pdf_url": "https://openreview.net/pdf?id=zcTLpIfj9u",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on 3D medical imaging (CT scans) combined with longitudinal EHR data to predict clinical outcomes (\"time-to-event distributions,\" “disease risk,” “outcome prediction,” Harrell’s C-index). It explicitly targets identifying imaging biomarkers and improving clinical risk prediction, making it clearly part of Healthcare AI.",
    "prompt_tokens": 20680,
    "completion_tokens": 110,
    "total_tokens": 20790,
    "topic": "Medical Imaging - Prognostic Models",
    "method": "Time-to-event pretraining; Deep learning",
    "application": "Prognostic risk prediction – Pulmonary diseases",
    "code_link": "https://anonymous.4open.science/r/future_guided_pretraining-DA6C",
    "dataset_name": [
      "INSPECT",
      "RSPECT"
    ]
  },
  {
    "id": "pB1XSj2y4X",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Generative Flows on Synthetic Pathway for Drug Design",
    "authors": [
      "Seonghwan Seo",
      "Minsu Kim",
      "Tony Shen",
      "Martin Ester",
      "Jinkyoo Park",
      "Sungsoo Ahn",
      "Woo Youn Kim"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Generative models in drug discovery have recently gained attention as efficient alternatives to brute-force virtual screening. However, most existing models do not account for synthesizability, limiting their practical use in real-world scenarios. In this paper, we propose RxnFlow, which sequentially assembles molecules using predefined molecular building blocks and chemical reaction templates to constrain the synthetic chemical pathway. We then train on this sequential generating process with the objective of generative flow networks (GFlowNets) to generate both highly rewarded and diverse molecules. To mitigate the large action space of synthetic pathways in GFlowNets, we implement a novel action space subsampling method. This enables RxnFlow to learn generative flows over extensive action spaces comprising combinations of 1.2 million building blocks and 71 reaction templates without significant computational overhead. Additionally, RxnFlow can employ modified or expanded action spaces for generation without retraining, allowing for the introduction of additional objectives or the incorporation of newly discovered building blocks. We experimentally demonstrate that RxnFlow outperforms existing reaction-based and fragment-based models in pocket-specific optimization across various target pockets. Furthermore, RxnFlow achieves state-of-the-art performance on CrossDocked2020 for pocket-conditional generation, with an average Vina score of –8.85 kcal/mol and 34.8% synthesizability. Code is available at https://github.com/SeonghwanSeo/RxnFlow.",
    "keywords": "GFlowNet, synthesizability, structure-based drug design, molecule optimization",
    "pdf_url": "https://openreview.net/pdf?id=pB1XSj2y4X",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on generative models for drug discovery, explicitly mentioning “drug design,” “synthesizability,” “structure-based drug design,” and optimization against target protein pockets. Such work on molecular generation and synthesis pathways directly supports biomedical research and therapeutic development, placing it firmly in the Biomedicine AI domain.",
    "prompt_tokens": 21135,
    "completion_tokens": 104,
    "total_tokens": 21239,
    "topic": "Drug Discovery - Target-based",
    "method": "GFlowNet; synthesis-oriented generative model",
    "application": "Pocket-specific optimization; pocket-conditional generation",
    "code_link": "https://github.com/SeonghwanSeo/RxnFlow",
    "dataset_name": [
      "CrossDocked2020",
      "LIT-PCBA"
    ]
  },
  {
    "id": "FEZOLWexPb",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "MAESTRO: Masked Encoding Set Transformer with Self-Distillation",
    "authors": [
      "Matthew Eric Lee",
      "Jaesik Kim",
      "Matei Ionita",
      "Jonghyun Lee",
      "Michelle L. McKeague",
      "YONGHYUN NAM",
      "Irene Khavin",
      "Yidi Huang",
      "Victoria Fang",
      "Sokratis Apostolidis",
      "Divij Mathew",
      "Shwetank",
      "Ajinkya Pattekar",
      "Zahabia Rangwala",
      "Amit Bar-Or",
      "Benjamin A Fensterheim",
      "Benjamin A. Abramoff",
      "Rennie L. Rhee",
      "Damian Maseda",
      "Allison R Greenplate",
      "John Wherry",
      "Dokyoon Kim"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The interrogation of cellular states and interactions in immunology research is an ever-evolving task, requiring adaptation to the current levels of high dimensionality. Cytometry enables high-dimensional profiling of immune cells, but its analysis is hindered by the complexity and variability of the data. We present MAESTRO, a self-supervised set representation learning model that generates vector representations of set-structured data, which we apply to learn immune profiles from cytometry data. Unlike previous studies only learn cell-level representations, whereas MAESTRO uses all of a sample's cells to learn a set representation. MAESTRO leverages specialized attention mechanisms to handle sets of variable number of cells and ensure permutation invariance, coupled with an online tokenizer by self-distillation framework. We benchmarked our model against existing cytometry approaches and other existing machine learning methods that have never been applied in cytometry. Our model outperforms existing approaches in retrieving cell-type proportions and capturing clinically relevant features for downstream tasks such as disease diagnosis and immune cell profiling.",
    "keywords": "self-supervision, representation learning, immunology, biology, single-cell, cytometry, set, set representations",
    "pdf_url": "https://openreview.net/pdf?id=FEZOLWexPb",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on cytometry data for high-dimensional profiling of immune cells and explicitly targets downstream tasks such as “disease diagnosis and immune cell profiling.” It describes learning representations of single-cell/immune profiles—key biomedical applications in immunology and clinical diagnostics.",
    "prompt_tokens": 21183,
    "completion_tokens": 107,
    "total_tokens": 21290,
    "topic": "Single-cell Analysis - Immune Profiling",
    "method": "Self-supervised learning; Transformer-based models",
    "application": "Immune profile reconstruction – Cytometry",
    "code_link": "https://github.com/matthew-lee1/MAESTRO",
    "dataset_name": [
      "BatchControlHD2"
    ]
  },
  {
    "id": "vgt2rSf6al",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "MindSimulator: Exploring Brain Concept Localization via Synthetic fMRI",
    "authors": [
      "Guangyin Bao",
      "Qi Zhang",
      "Zixuan Gong",
      "Zhuojia Wu",
      "Duoqian Miao"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Concept-selective regions within the human cerebral cortex exhibit significant activation in response to specific visual stimuli associated with particular concepts. Precisely localizing these regions stands as a crucial long-term goal in neuroscience to grasp essential brain functions and mechanisms. Conventional experiment-driven approaches hinge on manually constructed visual stimulus collections and corresponding brain activity recordings, constraining the support and coverage of concept localization. Additionally, these stimuli often consist of concept objects in unnatural contexts and are potentially biased by subjective preferences, thus prompting concerns about the validity and generalizability of the identified regions. To address these limitations, we propose a data-driven exploration approach. By synthesizing extensive brain activity recordings, we statistically localize various concept-selective regions. Our proposed MindSimulator leverages advanced generative technologies to learn the probability distribution of brain activity conditioned on concept-oriented visual stimuli. This enables the creation of simulated brain recordings that reflect real neural response patterns. Using the synthetic recordings, we successfully localize several well-studied concept-selective regions and validate them against empirical findings, achieving promising prediction accuracy. The feasibility opens avenues for exploring novel concept-selective regions and provides prior hypotheses for future neuroscience research.",
    "keywords": "Neuroscience, fMRI encoding, Generative model, fMRI generation, fMRI functional localizer, Concept-selective voxel",
    "pdf_url": "https://openreview.net/pdf?id=vgt2rSf6al",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on modeling and synthesizing fMRI recordings to localize concept-selective regions in the human cortex. It centers on neuroimaging (“fMRI encoding,” “fMRI generation,” “fMRI functional localizer”) and cognitive neuroscience, which falls under biomedical AI applications in brain decoding and neurobiological modeling.",
    "prompt_tokens": 56765,
    "completion_tokens": 148,
    "total_tokens": 56913,
    "topic": "Neuroscience - FMRI Synthesis",
    "method": "Generative modeling; fMRI autoencoder; Diffusion model",
    "application": "fMRI synthesis for concept localization",
    "code_link": "N/A",
    "dataset_name": [
      "Natural Scenes Dataset (NSD)",
      "MSCOCO"
    ]
  },
  {
    "id": "U834XHJuqk",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Nonlinear Sequence Embedding by Monotone Variational Inequality",
    "authors": [
      "Jonathan Yuyang Zhou",
      "Yao Xie"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In the wild, we often encounter collections of sequential data such as electrocardiograms, motion capture, genomes, and natural language, and sequences may be multichannel or symbolic with nonlinear dynamics. We introduce a method to learn low-dimensional representations of nonlinear sequence and time-series data without supervision which has provable recovery guarantees. The learned representation can be used for downstream machine-learning tasks such as clustering and classification. The method assumes that the observed sequences arise from a common domain, with each sequence following its own autoregressive model, and these models are related through low-rank regularization. We cast the problem as a convex matrix parameter recovery problem using monotone variational inequalities (VIs) and encode the common domain assumption via low-rank constraint across the learned representations, which can learn a subspace approximately spanning the entire domain as well as faithful representations for the dynamics of each individual sequence incorporating the domain information in totality. We show the competitive performance of our method on real-world time-series data with baselines and demonstrate its effectiveness for symbolic text modeling and RNA sequence clustering.",
    "keywords": "Monotone Variational Inequality, Convex Optimization, Sequence Data, Time Series, Representation Learning",
    "pdf_url": "https://openreview.net/pdf?id=U834XHJuqk",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the core contribution is a general sequence-embedding method, the abstract explicitly mentions working with “genomes” and demonstrates “RNA sequence clustering,” which are central tasks in genomics and bioinformatics. This application to RNA and genomic data places the work squarely in the Biomedicine AI domain.",
    "prompt_tokens": 20708,
    "completion_tokens": 82,
    "total_tokens": 20790,
    "topic": "Time Series - Representation Learning",
    "method": "Low-rank embedding; nuclear norm constraints",
    "application": "Time series classification",
    "code_link": "N/A",
    "dataset_name": [
      "UCR"
    ]
  },
  {
    "id": "1iuaxjssVp",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Fast Uncovering of Protein Sequence Diversity from Structure",
    "authors": [
      "luca alessandro silva",
      "Barthelemy Meynard-Piganeau",
      "Carlo Lucibello",
      "Christoph Feinauer"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We present InvMSAFold, an inverse folding method for generating protein sequences optimized for diversity and speed. For a given structure, InvMSAFold generates the parameters of a pairwise probability distribution over the space of sequences, capturing the amino acid covariances observed in Multiple Sequence Alignments (MSA) of homologous proteins. This allows for the efficient generation of highly diverse protein sequences while preserving structural and functional integrity.\nWe demonstrate that this increased diversity in sampled sequences translates into greater variability in biochemical properties, highlighting the exciting potential of our method for applications such as protein design. The orders of magnitude improvement in sampling speed compared to existing methods unlocks new possibilities for high-throughput in virtual screening.",
    "keywords": "Protein design, inverse folding, generative modelling, transfer learning",
    "pdf_url": "https://openreview.net/pdf?id=1iuaxjssVp",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “inverse folding,” “protein design,” and generative modeling of protein sequences—core topics in molecular modeling and drug discovery. By capturing amino acid covariances from MSAs and enabling high‐throughput sampling of diverse protein variants, this work directly addresses biomedicine AI applications (e.g., protein engineering for therapeutics).",
    "prompt_tokens": 21456,
    "completion_tokens": 100,
    "total_tokens": 21556,
    "topic": "Drug Discovery - Protein Design",
    "method": "Inverse folding; pairwise model; low-rank approximations",
    "application": "Protein sequence generation",
    "code_link": "https://github.com/luchinoprince/Potts_Inverse_Folding",
    "dataset_name": [
      "MSA"
    ]
  },
  {
    "id": "27Qk18IZum",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "PharmacoMatch: Efficient 3D Pharmacophore Screening via Neural Subgraph Matching",
    "authors": [
      "Daniel Rose",
      "Oliver Wieder",
      "Thomas Seidel",
      "Thierry Langer"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The increasing size of screening libraries poses a significant challenge for the development of virtual screening methods for drug discovery, necessitating a re-evaluation of traditional approaches in the era of big data. Although 3D pharmacophore screening remains a prevalent technique, its application to very large datasets is limited by the computational cost associated with matching query pharmacophores to database molecules. In this study, we introduce PharmacoMatch, a novel contrastive learning approach based on neural subgraph matching. Our method reinterprets pharmacophore screening as an approximate subgraph matching problem and enables efficient querying of conformational databases by encoding query-target relationships in the embedding space. We conduct comprehensive investigations of the learned representations and evaluate PharmacoMatch as pre-screening tool in a zero-shot setting. We demonstrate significantly shorter runtimes and comparable performance metrics to existing solutions, providing a promising speed-up for screening very large datasets.",
    "keywords": "Contrastive Representation Learning, Neural Subgraph Matching, Virtual Screening, Pharmacophore Modeling",
    "pdf_url": "https://openreview.net/pdf?id=27Qk18IZum",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “3D pharmacophore screening” and “virtual screening methods for drug discovery,” clearly situating it in the biomedical context of in silico drug design. It presents a machine-learning approach (“contrastive learning,” “neural subgraph matching”) to accelerate pharmacophore matching, a core task in computational drug discovery, which is a hallmark of Biomedicine AI.",
    "prompt_tokens": 20800,
    "completion_tokens": 120,
    "total_tokens": 20920,
    "topic": "Drug Discovery - Virtual Screening",
    "method": "Graph Neural Networks (GNN); contrastive learning",
    "application": "Pharmacophore matching for virtual screening",
    "code_link": "https://github.com/molinfo-vienna/PharmacoMatch",
    "dataset_name": [
      "ChEMBL",
      "DUD-E",
      "DEKOIS2.0",
      "LIT-PCBA"
    ]
  },
  {
    "id": "1z3SOCwst9",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Differentially private learners for heterogeneous treatment effects",
    "authors": [
      "Maresa Schröder",
      "Valentyn Melnychuk",
      "Stefan Feuerriegel"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Patient data is widely used to estimate heterogeneous treatment effects and understand the effectiveness and safety of drugs. Yet, patient data includes highly\nsensitive information that must be kept private. In this work, we aim to estimate\nthe conditional average treatment effect (CATE) from observational data under\ndifferential privacy. Specifically, we present DP-CATE, a novel framework for\nCATE estimation that is *Neyman-orthogonal* and ensures *differential privacy* of the estimates.\n Our framework is highly general: it applies to any two-stage\nCATE meta-learner with a Neyman-orthogonal loss function and any machine\nlearning model can be used for nuisance estimation. We further provide an extension of our DP-CATE, where we employ RKHS regression to release the complete\nCATE function while ensuring differential privacy. We demonstrate the effectiveness of DP-CATE across various experiments using synthetic and real-world\ndatasets. To the best of our knowledge, we are the first to provide a framework for\nCATE estimation that is doubly robust and differentially private.",
    "keywords": "Causality, differential privacy, treatment effect estimation",
    "pdf_url": "https://openreview.net/pdf?id=1z3SOCwst9",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly addresses “patient data” and aims to estimate “heterogeneous treatment effects” to understand “effectiveness and safety of drugs,” which are core tasks in personalized medicine and clinical research. The focus on CATE from observational data in a healthcare context strongly aligns with Healthcare AI and Biomedicine AI.",
    "prompt_tokens": 20791,
    "completion_tokens": 106,
    "total_tokens": 20897,
    "topic": "Causal Inference - Differential Privacy",
    "method": "Output perturbation; Neyman-orthogonal meta-learners",
    "application": "Conditional average treatment effect (CATE) estimation",
    "code_link": "https://github.com/m-schroder/DP-CATE",
    "dataset_name": [
      "MIMIC-III",
      "TCGA"
    ]
  },
  {
    "id": "b57IG6N20B",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "The Case for Cleaner Biosignals: High-fidelity Neural Compressor Enables Transfer from Cleaner iEEG to Noisier EEG",
    "authors": [
      "Francesco S. Carzaniga",
      "Gary Tom Hoppeler",
      "Michael Hersche",
      "Kaspar Schindler",
      "Abbas Rahimi"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "All data modalities are not created equal, even when the signal they measure comes from the same source. In the case of the brain, two of the most important data modalities are the scalp electroencephalogram (EEG), and the intracranial electroencephalogram (iEEG). iEEG benefits from a higher signal-to-noise ratio (SNR), as it measures the electrical activity directly in the brain, while EEG is noisier and has lower spatial and temporal resolutions. Nonetheless, both EEG and iEEG are important sources of data for human neurology, from healthcare to brain–machine interfaces. They are used by human experts, supported by deep learning (DL) models, to accomplish a variety of tasks, such as seizure detection and motor imagery classification. Although the differences between EEG and iEEG are well understood by human experts, the performance of DL models across these two modalities remains under-explored. To help characterize the importance of clean data on the performance of DL models, we propose BrainCodec, a high-fidelity EEG and iEEG neural compressor. We find that training BrainCodec on iEEG and then transferring to EEG yields higher reconstruction quality than training on EEG directly. In addition, we also find that training BrainCodec on both EEG and iEEG improves fidelity when reconstructing EEG. Our work indicates that data sources with higher SNR, such as iEEG, provide better performance across the board also in the medical time-series domain. This finding is consistent with reports coming from natural language processing, where clean data sources appear to have an outsized effect on the performance of the DL model overall. BrainCodec also achieves up to a 64x compression on iEEG and EEG without a notable decrease in quality. BrainCodec markedly surpasses current state-of-the-art compression models both in final compression ratio and in reconstruction fidelity. We also evaluate the fidelity of the compressed signals objectively on a seizure detection and a motor imagery task performed by standard DL models. Here, we find that BrainCodec achieves a reconstruction fidelity high enough to ensure no performance degradation on the downstream tasks. Finally, we collect the subjective assessment of an expert neurologist, that confirms the high reconstruction quality of BrainCodec in a realistic scenario. The code is available at https://github.com/IBM/eeg-ieeg-brain-compressor.",
    "keywords": "eeg, ieeg, intracranial eeg, electroencephalography, compression, transfer, seizure, seizure detection, motor imagery",
    "pdf_url": "https://openreview.net/pdf?id=b57IG6N20B",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on neural compression of EEG and iEEG, both clinical brain‐signal modalities used in neurology. They evaluate reconstruction fidelity on downstream medical tasks (“seizure detection” and “motor imagery classification”) and include expert neurologist assessment. EEG and iEEG are biomedical time‐series signals for patient monitoring and neurological diagnosis, fitting squarely within Healthcare/Biomedicine AI.",
    "prompt_tokens": 21081,
    "completion_tokens": 147,
    "total_tokens": 21228,
    "topic": "EEG Compression - Neural Model",
    "method": "Quantized autoencoder; GAN-based multi-scale feature learning",
    "application": "Seizure detection and motor imagery classification",
    "code_link": "https://github.com/IBM/eeg-ieeg-brain-compressor",
    "dataset_name": [
      "SWEC iEEG",
      "Multi-center iEEG",
      "Brain Treebank iEEG",
      "CHB-MIT",
      "BONN",
      "BCI Competition IV-2a"
    ]
  },
  {
    "id": "ARQIJXFcTH",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "AtomSurf: Surface Representation for Learning on Protein Structures",
    "authors": [
      "Vincent Mallet",
      "Yangyang Miao",
      "Souhaib Attaiki",
      "Bruno Correia",
      "Maks Ovsjanikov"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "While there has been significant progress in evaluating and comparing different representations for learning on protein data, the role of surface-based learning approaches remains not well-understood. In particular, there is a lack of direct and fair benchmark comparison between the best available surface-based learning methods against alternative representations such as graphs. Moreover, the few existing surface-based approaches either use surface information in isolation or, at best, perform global pooling between surface and graph-based architectures. \n    \nIn this work, we fill this gap by first adapting a state-of-the-art surface encoder for protein learning tasks. We then perform a direct and fair comparison of the resulting method against alternative approaches within the Atom3D benchmark, highlighting the limitations of pure surface-based learning. Finally, we propose an integrated approach, which allows learned feature sharing between graphs and surface representations on the level of nodes and vertices \\textit{across all layers}.\n    \nWe demonstrate that the resulting architecture achieves state-of-the-art results on all tasks in the Atom3D benchmark, while adhering to the strict benchmark protocol, as well as more broadly on binding site identification and binding pocket classification. Furthermore, we use coarsened surfaces and optimize our approach for efficiency, making our tool competitive in training and inference time with existing techniques.\n\nCode can be found online: https://github.com/Vincentx15/atomsurf",
    "keywords": "deep learning, protein representation learning; surface methods; geometric deep learning",
    "pdf_url": "https://openreview.net/pdf?id=ARQIJXFcTH",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on learning representations of protein structures and demonstrates state-of-the-art performance on tasks such as binding site identification and binding pocket classification—core problems in molecular modeling and drug discovery. These applications fall squarely within Biomedicine AI, as they relate to understanding and engineering proteins for therapeutic purposes.",
    "prompt_tokens": 20773,
    "completion_tokens": 121,
    "total_tokens": 20894,
    "topic": "Bioinformatics - Protein Interactions",
    "method": "Surface-based learning; hybrid graph-surface representation; DiffusionNet",
    "application": "Protein-protein interaction prediction; Protein binding site prediction",
    "code_link": "https://github.com/Vincentx15/atomsurf",
    "dataset_name": [
      "PINDER",
      "AbAg",
      "Masif-ligand",
      "Atom3D",
      "CASP"
    ]
  },
  {
    "id": "Ombm8S40zN",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Steering Masked Discrete Diffusion Models via Discrete Denoising Posterior Prediction",
    "authors": [
      "Jarrid Rector-Brooks",
      "Mohsin Hasan",
      "Zhangzhi Peng",
      "Cheng-Hao Liu",
      "Sarthak Mittal",
      "Nouha Dziri",
      "Michael M. Bronstein",
      "Pranam Chatterjee",
      "Alexander Tong",
      "Joey Bose"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Generative modeling of discrete data underlies important applications spanning text-based agents like ChatGPT to the design of the very building blocks of life in protein sequences. However, application domains need to exert control over the generated data by steering the generative process—typically via RLHF—to satisfy a specified property, reward, or affinity metric. In this paper, we study the problem of steering Masked Diffusion Models (MDMs), a recent class of discrete diffusion models that offer a compelling alternative to traditional autoregressive models. We introduce Discrete Denoising Posterior Prediction (DDPP), a novel framework that casts the task of steering pretrained MDMs as a problem of probabilistic inference by learning to sample from a target Bayesian posterior. Our DDPP framework leads to a family of three novel objectives that are all simulation-free, and thus scalable while applying to general non-differentiable reward functions. Empirically, we instantiate DDPP by steering MDMs to perform class-conditional pixel-level image modeling, RLHF-based alignment of MDMs using text based rewards, and finetuning protein language models to generate more diverse secondary structures and shorter proteins. We substantiate our designs via wet-lab validation, where we observe transient expression of reward-optimized protein sequences.",
    "keywords": "Discrete diffusion models, language modeling, probabilistic inference",
    "pdf_url": "https://openreview.net/pdf?id=Ombm8S40zN",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the core contribution is a new discrete diffusion framework, the paper explicitly applies it to protein language models (“finetuning protein language models to generate more diverse secondary structures and shorter proteins”) and even provides wet-lab validation of “reward-optimized protein sequences.” Designing and validating novel protein sequences is a molecular-level, biomedicine AI task (protein design/synthetic biology).",
    "prompt_tokens": 20947,
    "completion_tokens": 131,
    "total_tokens": 21078,
    "topic": "Protein Modeling - Beta-sheet Structures",
    "method": "Discrete diffusion; Reward finetuning using DDPP (Discrete Denoising Posterior Prediction)",
    "application": "High beta-sheet content protein design",
    "code_link": "https://huggingface.co/airkingbd/dplm_150m",
    "dataset_name": [
      "Tinystories",
      "MNIST",
      "Amazon reviews",
      "CelebA"
    ]
  },
  {
    "id": "9SYczU3Qgm",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Meta Flow Matching: Integrating Vector Fields on the Wasserstein Manifold",
    "authors": [
      "Lazar Atanackovic",
      "Xi Zhang",
      "Brandon Amos",
      "Mathieu Blanchette",
      "Leo J Lee",
      "Yoshua Bengio",
      "Alexander Tong",
      "Kirill Neklyudov"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Numerous biological and physical processes can be modeled as systems of interacting entities evolving continuously over time, e.g. the dynamics of communicating cells or physical particles. Learning the dynamics of such systems is essential for predicting the temporal evolution of populations across novel samples and unseen environments. Flow-based models allow for learning these dynamics at the population level - they model the evolution of the entire distribution of samples. However, current flow-based models are limited to a single initial population and a set of predefined conditions which describe different dynamics. We argue that multiple processes in natural sciences have to be represented as vector fields on the Wasserstein manifold of probability densities. That is, the change of the population at any moment in time depends on the population itself due to the interactions between samples. In particular, this is crucial for personalized medicine where the development of diseases and their respective treatment response depend on the microenvironment of cells specific to each patient. We propose *Meta Flow Matching* (MFM), a practical approach to integrate along these vector fields on the Wasserstein manifold by amortizing the flow model over the initial populations. Namely, we embed the population of samples using a Graph Neural Network (GNN) and use these embeddings to train a Flow Matching model. This gives MFM the ability to generalize over the initial distributions, unlike previously proposed methods. We demonstrate the ability of MFM to improve the prediction of individual treatment responses on a large-scale multi-patient single-cell drug screen dataset.",
    "keywords": "Flow matching, Dynamics, Cell dynamics",
    "pdf_url": "https://openreview.net/pdf?id=9SYczU3Qgm",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly focuses on modeling cell dynamics for “personalized medicine” and demonstrates improved prediction of “individual treatment responses on a large-scale multi-patient single-cell drug screen dataset.” These are clear indicators of a biomedicine AI application in drug response modeling and therapeutic outcome prediction.",
    "prompt_tokens": 20573,
    "completion_tokens": 98,
    "total_tokens": 20671,
    "topic": "Drug Discovery - Single Cell Perturbation",
    "method": "Meta flow matching; Graph neural networks (GNN)",
    "application": "Treatment response prediction",
    "code_link": "https://github.com/lazaratan/meta-flow-matching",
    "dataset_name": [
      "Organoid drug-screen"
    ]
  },
  {
    "id": "vFanHFE4Qv",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Neuron Platonic Intrinsic Representation From Dynamics Using Contrastive Learning",
    "authors": [
      "Wei Wu",
      "Can Liao",
      "zizhen Deng",
      "Zhengrui Guo",
      "Jinzhuo Wang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The Platonic Representation Hypothesis posits that behind different modalities of data (what we sense or detect), there exists a universal, modality-independent representation of reality. Inspired by this, we treat each neuron as a system, where we can detect the neuron’s multi-segment activity data under different peripheral conditions. We believe that, similar to the Platonic idea, there exists a time-invariant representation behind the different segments of the same neuron, which reflects the intrinsic properties of the neuron’s system. Intrinsic properties include the molecular profiles, brain regions and morphological structure, etc. The optimization objective for obtaining the intrinsic representation of neurons should satisfy two criteria: (I) segments from the same neuron should have a higher similarity than segments from different neurons; (II) the representations should generalize well to out-of-domain data. To achieve this, we employ contrastive learning, treating different segments from the same neuron as positive pairs and segments from different neurons as negative pairs. During the implementation, we chose the VICReg, which uses only positive pairs for optimization but indirectly separates dissimilar samples via regularization terms. To validate the efficacy of our method, we first applied it to simulated neuron population dynamics data generated using the Izhikevich model. We successfully confirmed that our approach captures the type of each neuron as defined by preset hyperparameters. We then applied our method to two real-world neuron dynamics datasets, including spatial transcriptomics-derived neuron type annotations and the brain regions where each neuron is located. The learned representations from our model not only predict neuron type and location but also show robustness when tested on out-of-domain data (unseen animals). This demonstrates the potential of our approach in advancing the understanding of neuronal systems and offers valuable insights for future neuroscience research.",
    "keywords": "representation learning, biology, neuroscience, contrastive learning",
    "pdf_url": "https://openreview.net/pdf?id=vFanHFE4Qv",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work centers on learning representations of neuronal systems using real-world “spatial transcriptomics-derived neuron type annotations” and the “brain regions where each neuron is located.” It focuses on neuron type classification and brain-region prediction—clearly falling under neuroscience/neurobiological modeling, which is a subdomain of Biomedicine AI.",
    "prompt_tokens": 21089,
    "completion_tokens": 104,
    "total_tokens": 21193,
    "topic": "Neuroscience - Representation Learning",
    "method": "Contrastive learning; VICReg; CEBRA",
    "application": "Neuron type classification and brain region classification",
    "code_link": "https://github.com/ww20hust/NeurPIR",
    "dataset_name": [
      "Bugeon",
      "Steinmetz"
    ]
  },
  {
    "id": "OzUNDnpQyd",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Structure Language Models for Protein Conformation Generation",
    "authors": [
      "Jiarui Lu",
      "Xiaoyin Chen",
      "Stephen Zhewen Lu",
      "Chence Shi",
      "Hongyu Guo",
      "Yoshua Bengio",
      "Jian Tang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Proteins adopt multiple structural conformations to perform their diverse biological functions, and understanding these conformations is crucial for advancing drug discovery. Traditional physics-based simulation methods often struggle with sampling equilibrium conformations and are computationally expensive. Recently, deep generative models have shown promise in generating protein conformations as a more efficient alternative. However, these methods predominantly rely on the diffusion process within a 3D geometric space, which typically centers around the vicinity of metastable states and is often inefficient in terms of runtime. In this paper, we introduce Structure Language Modeling (SLM) as a novel framework for efficient protein conformation generation. Specifically, the protein structures are first encoded into a compact latent space using a discrete variational auto-encoder, followed by conditional language modeling that effectively captures sequence-specific conformation distributions.  This enables a more efficient and interpretable exploration of diverse ensemble modes compared to existing methods. Based on this general framework, we instantiate SLM with various popular LM architectures as well as proposing the ESMDiff, a novel BERT-like structure language model fine-tuned from ESM3 with masked diffusion. We verify our approach in various scenarios, including the equilibrium dynamics of BPTI, conformational change pairs, and intrinsically disordered proteins. SLM provides a highly efficient solution, offering a 20-100x speedup than existing methods in generating diverse conformations, shedding light on promising avenues for future research.",
    "keywords": "protein, conformation generation, conformation sampling, generative models, language models, diffusion models",
    "pdf_url": "https://openreview.net/pdf?id=OzUNDnpQyd",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on generating protein structures—a core task in molecular modeling and drug discovery (“understanding these conformations is crucial for advancing drug discovery”). It develops new generative models for protein conformation sampling, directly aligning with biomedicine AI themes such as “protein design,” “molecular modeling,” and “drug discovery.”",
    "prompt_tokens": 20616,
    "completion_tokens": 103,
    "total_tokens": 20719,
    "topic": "Bioinformatics - Protein Conformations",
    "method": "Structure language modeling (SLM); masked diffusion model",
    "application": "Protein conformation generation",
    "code_link": "https://github.com/lujiarui/esmdiff",
    "dataset_name": [
      "Protein Ensemble Database (PED)",
      "PDB"
    ]
  },
  {
    "id": "At9JmGF3xy",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Toward Generalizing Visual Brain Decoding to Unseen Subjects",
    "authors": [
      "Xiangtao Kong",
      "Kexin Huang",
      "Ping Li",
      "Lei Zhang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Visual brain decoding aims to decode visual information from human brain activities. Despite the great progress, one critical limitation of current brain decoding research lies in the lack of generalization capability to unseen subjects. Prior work typically focuses on decoding brain activity of individuals based on the observation that different subjects exhibit different brain activities, while it remains unclear whether brain decoding can be generalized to unseen subjects. This study aims to answer this question. We first consolidate an image-fMRI dataset consisting of stimulus-image and fMRI-response pairs, involving 177 subjects in the movie-viewing task of the Human Connectome Project (HCP). This dataset allows us to investigate the brain decoding performance with the increase of participants. We then present a learning paradigm that applies uniform processing across all subjects, instead of employing different network heads or tokenizers for individuals as in previous methods, so that we can accommodate a large number of subjects to explore the generalization capability across different subjects. A series of experiments are conducted and we have the following findings. First, the network exhibits clear generalization capabilities with the increase of training subjects. Second, the generalization capability is common to popular network architectures (MLP, CNN and Transformer). Third, the generalization performance is affected by the similarity between subjects. Our findings reveal the inherent similarities in brain activities across individuals. With the emergence of larger and more comprehensive datasets, it is possible to train a brain decoding foundation model in the future. Codes and models can be found at https://github.com/Xiangtaokong/TGBD}{https://github.com/Xiangtaokong/TGBD.",
    "keywords": "Visual brain decoding, fMRI - image retrieval, Generalizing to unseen subjects",
    "pdf_url": "https://openreview.net/pdf?id=At9JmGF3xy",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on decoding visual information from human brain activity using fMRI data from the Human Connectome Project. This falls under neuroscience and neurobiological modeling—key components of Biomedicine AI as per the definitions (e.g., “fMRI,” “brain decoding,” “neuroscience modeling”).",
    "prompt_tokens": 21002,
    "completion_tokens": 104,
    "total_tokens": 21106,
    "topic": "Visual Brain Decoding - Generalization",
    "method": "Contrastive learning; ViT-based encoding",
    "application": "Generalizable brain decoding from unseen subjects",
    "code_link": "https://github.com/Xiangtaokong/TGBD",
    "dataset_name": [
      "NSD",
      "BOLD5000",
      "HCP"
    ]
  },
  {
    "id": "oYemKnlIrO",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Do Mice Grok? Glimpses of Hidden Progress in Sensory Cortex",
    "authors": [
      "Tanishq Kumar",
      "Blake Bordelon",
      "Cengiz Pehlevan",
      "Venkatesh N Murthy",
      "Samuel J. Gershman"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Does learning of task-relevant representations stop when behavior stops changing? Motivated by recent work in machine learning and the intuitive observation that human experts continue to learn after mastery, we hypothesize that task-specific representation learning in cortex can continue, even when behavior saturates. In a novel reanalysis of recently published neural data, we find evidence for such learning in posterior piriform cortex of mice following continued training on a task, long after behavior saturates at near-ceiling performance (\"overtraining\"). We demonstrate that class representations in cortex continue to separate during overtraining, so that examples that were incorrectly classified at the beginning of overtraining can abruptly be correctly classified later on, despite no changes in behavior during that time. We hypothesize this hidden learning takes the form of approximate margin maximization; we validate this and other predictions in the neural data, as well as build and interpret a simple synthetic model that recapitulates these phenomena. We conclude by demonstrating how this model of late-time feature learning implies an explanation for the empirical puzzle of overtraining reversal in animal learning, where task-specific representations are more robust to particular task changes because the learned features can be reused.",
    "keywords": "neuroscience; representation learning; grokking; overtraining; cortex",
    "pdf_url": "https://openreview.net/pdf?id=oYemKnlIrO",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although this work is not about clinical diagnosis or treatment, it applies machine learning to neural system dynamics in the posterior piriform cortex of mice (“sensory cortex,” “neural data,” “representation learning in cortex”), which falls under neuroscience or neurobiological modeling—a recognized subfield of Biomedicine AI.",
    "prompt_tokens": 21108,
    "completion_tokens": 95,
    "total_tokens": 21203,
    "topic": "Neuroscience - Sensory Learning",
    "method": "Margin maximization; biologically plausible model; synthetic modeling",
    "application": "Discrimination task – olfactory cortex",
    "code_link": "N/A",
    "dataset_name": [
      "Mouse piriform cortex dataset"
    ]
  },
  {
    "id": "SjMtxqdQ73",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Bridging the Gap between Database Search and \\emph{De Novo} Peptide Sequencing with SearchNovo",
    "authors": [
      "Jun Xia",
      "Sizhe Liu",
      "Jingbo Zhou",
      "Shaorong Chen",
      "hongxin xiang",
      "Zicheng Liu",
      "Yue Liu",
      "Stan Z. Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Accurate protein identification from mass spectrometry (MS) data is fundamental to unraveling the complex roles of proteins in biological systems, with peptide sequencing being a pivotal step in this process. The two main paradigms for peptide sequencing are database search, which matches experimental spectra with peptide sequences from databases, and \\emph{de novo} sequencing, which infers peptide sequences directly from MS without relying on pre-constructed database. Although database search methods are highly accurate, they are limited by their inability to identify novel, modified, or mutated peptides absent from the database. In contrast, \\emph{de novo} sequencing is adept at discovering novel peptides but often struggles with missing peaks issue, further leading to lower precision. We introduce SearchNovo, a novel framework that synergistically integrates the strengths of database search and \\emph{de novo} sequencing to enhance peptide sequencing. SearchNovo employs an efficient search mechanism to retrieve the most similar peptide spectrum match (PSM) from a database for each query spectrum, followed by a fusion module that utilizes the reference peptide sequence to guide the generation of the target sequence. Furthermore, we observed that dissimilar (noisy) reference peptides negatively affect model performance. To mitigate this, we constructed pseudo reference PSMs to minimize their impact. Comprehensive evaluations on multiple datasets reveal that SearchNovo significantly outperforms state-of-the-art models. Also, analysis indicates that many retrieved spectra contain missing peaks absent in the query spectra, and the retrieved reference peptides often share common fragments with the target peptides. These are key elements in the recipe for SearchNovo’s success. The code is available at: \\textcolor{magenta}{\\url{https://github.com/junxia97/SearchNovo}}.",
    "keywords": "Protein Identification, Mass Spectrum, Proteomics",
    "pdf_url": "https://openreview.net/pdf?id=SjMtxqdQ73",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on peptide sequencing from mass spectrometry data for protein identification—central tasks in proteomics and bioinformatics. It directly addresses “protein identification,” “peptide sequencing,” and “mass spectrum,” all of which are core to biomedical research and molecular-level analysis. The development of SearchNovo to improve de novo peptide sequencing and database search clearly situates this work in the Biomedicine AI domain.",
    "prompt_tokens": 20944,
    "completion_tokens": 101,
    "total_tokens": 21045,
    "topic": "Proteomics - Peptide Sequencing",
    "method": "Transformer-based models; retrieval-augmented generation",
    "application": "Peptide sequence prediction",
    "code_link": "https://github.com/junxia97/SearchNovo",
    "dataset_name": [
      "Seven-species",
      "Nine-species",
      "HC-PT"
    ]
  },
  {
    "id": "G328D1xt4W",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Fine-Tuning Discrete Diffusion Models via Reward Optimization with Applications to DNA and Protein Design",
    "authors": [
      "Chenyu Wang",
      "Masatoshi Uehara",
      "Yichun He",
      "Amy Wang",
      "Avantika Lal",
      "Tommi Jaakkola",
      "Sergey Levine",
      "Aviv Regev",
      "Hanchen",
      "Tommaso Biancalani"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Recent studies have demonstrated the strong empirical performance of diffusion models on discrete sequences (i.e., discrete diffusion models) across domains such as natural language and biological sequence generation. For example, in the protein inverse folding task, where the goal is to generate a protein sequence from a given backbone structure, conditional diffusion models have achieved impressive results in generating \"natural\" sequences that fold back into the original structure. However, practical design tasks often require not only modeling a conditional distribution but also optimizing specific task objectives. For instance, in the inverse folding task, we may prefer proteins with high stability. To address this, we consider the scenario where we have pre-trained discrete diffusion models that can generate \"natural\" sequences, as well as reward models that map sequences to task objectives. We then formulate the reward maximization problem within discrete diffusion models, analogous to reinforcement learning (RL), while minimizing the KL divergence against pre-trained diffusion models to preserve naturalness. To solve this RL problem, we propose a novel algorithm that enables direct backpropagation of rewards through entire trajectories generated by diffusion models, by making the originally non-differentiable trajectories differentiable using the Gumbel-Softmax trick. Our theoretical analysis indicates that our approach can generate sequences that are both \"natural\" (i.e., have a high probability under a pre-trained model) and yield high rewards. While similar tasks have been recently explored in diffusion models for continuous domains, our work addresses unique algorithmic and theoretical challenges specific to discrete diffusion models, which arise from their foundation in continuous-time Markov chains rather than Brownian motion. Finally, we demonstrate the effectiveness of our algorithm in generating DNA and protein sequences that optimize enhancer activity and protein stability, respectively, important tasks for gene therapies and protein-based therapeutics. The code is available at https://github.com/ChenyuWang-Monica/DRAKES.",
    "keywords": "Discrete Diffusion Models, Reward Optimization, Fine-Tuning, AI for science, Reinforcement learning",
    "pdf_url": "https://openreview.net/pdf?id=G328D1xt4W",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper develops methods for optimizing DNA enhancer activity and protein stability—key tasks in gene therapy and protein‐based therapeutics. It specifically targets “DNA and protein sequences that optimize enhancer activity and protein stability,” which are central problems in biomedical research and drug/therapeutic design.",
    "prompt_tokens": 20517,
    "completion_tokens": 115,
    "total_tokens": 20632,
    "topic": "Bioinformatics - Protein and DNA Sequence Design",
    "method": "Discrete diffusion model; reinforcement learning; Gumbel-Softmax trick",
    "application": "Protein sequence stability optimization; DNA enhancer activity optimization",
    "code_link": "https://github.com/ChenyuWang-Monica/DRAKES",
    "dataset_name": [
      "Megascale",
      "Gosai"
    ]
  },
  {
    "id": "qFZnAC4GHR",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "A new framework for evaluating model out-of-distribution generalisation for the biochemical domain",
    "authors": [
      "Raul Fernandez-Diaz",
      "Hoang Thanh Lam",
      "Vanessa López",
      "Denis C. Shields"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Quantifying model generalization to out-of-distribution data has been a longstanding challenge in machine learning. Addressing this issue is crucial for leveraging machine learning in scientific discovery, where models must generalize to new molecules or materials. Current methods typically split data into train and test sets using various criteria — temporal, sequence identity, scaffold, or random cross-validation — before evaluating model performance. However, with so many splitting criteria available, existing approaches offer limited guidance on selecting the most appropriate one, and they do not provide mechanisms for incorporating prior knowledge about the target deployment distribution(s).\n\nTo tackle this problem, we have developed a novel metric, AU-GOOD, which quantifies expected model performance under conditions of increasing dissimilarity between train and test sets, while also accounting for prior knowledge about the target deployment distribution(s), when available. This metric is broadly applicable to biochemical entities, including proteins, small molecules, nucleic acids, or cells; as long as a relevant similarity function is defined for them. Recognizing the wide range of similarity functions used in biochemistry, we propose criteria to guide the selection of the most appropriate metric for partitioning. We also introduce a new partitioning algorithm that generates more challenging test sets, and we propose statistical methods for comparing models based on AU-GOOD.\n\nFinally, we demonstrate the insights that can be gained from this framework by applying it to two different use cases: developing predictors for pharmaceutical properties of small molecules, and using protein language models as embeddings to build biophysical property predictors.",
    "keywords": "Machine learning evaluation, AI4Science, Biochemistry, Proteins, Small molecules, Protein Language Models",
    "pdf_url": "https://openreview.net/pdf?id=qFZnAC4GHR",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper develops evaluation methods for models predicting properties of biochemical entities—“small molecules,” “proteins,” “nucleic acids, or cells”—and demonstrates use cases in “pharmaceutical properties of small molecules” and building “biophysical property predictors” from protein language models. These tasks are central to drug discovery and molecular modeling, which fall squarely under Biomedicine AI.",
    "prompt_tokens": 20828,
    "completion_tokens": 125,
    "total_tokens": 20953,
    "topic": "Biochemical Methods - Model Generalisation",
    "method": "OOD generalisation evaluation; AU-GOOD metric; similarity-based partitioning algorithm",
    "application": "Prediction of pharmaceutical properties of small molecules; protein sequence property prediction",
    "code_link": "https://github.com/IBM/Hestia-GOOD",
    "dataset_name": [
      "Therapeutics Data Commons",
      "SwissProt"
    ]
  },
  {
    "id": "BHFs80Jf5V",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Constructing Confidence Intervals for Average Treatment Effects from Multiple Datasets",
    "authors": [
      "Yuxin Wang",
      "Maresa Schröder",
      "Dennis Frauen",
      "Jonas Schweisthal",
      "Konstantin Hess",
      "Stefan Feuerriegel"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Constructing confidence intervals (CIs) for the average treatment effect (ATE) from patient records is crucial to assess the effectiveness and safety of drugs. However, patient records typically come from different hospitals, thus raising the question of how multiple observational/experimental datasets can be effectively combined for this purpose. In our paper, we propose a new method that estimates the ATE from multiple observational/experimental datasets and provides valid CIs. Our method makes little assumptions about the observational datasets and is thus widely applicable in medical practice. The key idea of our method is that we leverage prediction-powered inferences and thereby essentially `shrink' the CIs so that we offer more precise uncertainty quantification as compared to na{\\\"i}ve approaches. We further prove the unbiasedness of our method and the validity of our CIs. We confirm our theoretical results through various numerical experiments.",
    "keywords": "Causality machine learning, Average treatment effects, Confidence intervals, Prediction-powered inference",
    "pdf_url": "https://openreview.net/pdf?id=BHFs80Jf5V",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly addresses estimating and constructing confidence intervals for average treatment effects (ATE) from patient records across multiple hospitals to assess “effectiveness and safety of drugs.” It involves combining observational and experimental medical datasets (EHRs) and focuses on causal inference in a clinical context, which falls squarely under Healthcare AI.",
    "prompt_tokens": 20951,
    "completion_tokens": 109,
    "total_tokens": 21060,
    "topic": "Causal Inference - ATE estimation",
    "method": "Prediction-powered inference; doubly robust estimator",
    "application": "Confidence interval construction for ATE",
    "code_link": "https://github.com/Yuxin217/causalppi",
    "dataset_name": [
      "MIMIC-III",
      "Brazilian COVID-19 dataset"
    ]
  },
  {
    "id": "Yt9CFhOOFe",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Concept Bottleneck Language Models For Protein Design",
    "authors": [
      "Aya Abdelsalam Ismail",
      "Tuomas Oikarinen",
      "Amy Wang",
      "Julius Adebayo",
      "Samuel Don Stanton",
      "Hector Corrada Bravo",
      "Kyunghyun Cho",
      "Nathan C. Frey"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We introduce Concept Bottleneck Protein Language Models (CB-pLM), a generative masked language model with a layer where each neuron corresponds to an interpretable concept. Our architecture offers three key benefits: i) Control: We can intervene on concept values to precisely control the properties of generated proteins, achieving a 3$\\times$ larger change in desired concept values compared to baselines. ii) Interpretability: A linear mapping between concept values and predicted tokens allows transparent analysis of the model's decision-making process. iii) Debugging: This transparency facilitates easy debugging of trained models. Our models achieve pre-training perplexity and downstream task performance comparable to traditional masked protein language models, demonstrating that interpretability does not compromise performance. While adaptable to any language model, we focus on masked protein language models due to their importance in drug discovery and the ability to validate our model's capabilities through real-world experiments and expert knowledge. We scale our CB-pLM from 24 million to 3 billion parameters, making them the largest Concept Bottleneck Models trained and the first capable of generative language modeling.",
    "keywords": "LLMs, protein design, concept bottleneck",
    "pdf_url": "https://openreview.net/pdf?id=Yt9CFhOOFe",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on generative masked protein language models for protein design—a core task in molecular modeling and drug discovery. It explicitly cites “drug discovery” and centers on protein engineering, which squarely falls under Biomedicine AI.",
    "prompt_tokens": 20598,
    "completion_tokens": 93,
    "total_tokens": 20691,
    "topic": "Bioinformatics - Protein Engineering",
    "method": "Concept Bottleneck Models; Masked language modeling",
    "application": "Protein design and optimization",
    "code_link": "N/A",
    "dataset_name": [
      "SWISS-PROT",
      "Siltuximab"
    ]
  },
  {
    "id": "mOpNrrV2zH",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "CBGBench: Fill in the Blank of Protein-Molecule Complex Binding Graph",
    "authors": [
      "Haitao Lin",
      "Guojiang Zhao",
      "Odin Zhang",
      "Yufei Huang",
      "Lirong Wu",
      "Cheng Tan",
      "Zicheng Liu",
      "Zhifeng Gao",
      "Stan Z. Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Structure-based drug design (SBDD) aims to generate potential drugs that can bind to a target protein and is greatly expedited by the aid of AI techniques in generative models. However, a lack of systematic understanding persists due to the diverse settings, complex implementation, difficult reproducibility, and task singularity. Firstly, the absence of standardization can lead to unfair comparisons and inconclusive insights. To address this dilemma, we propose CBGBench, a comprehensive benchmark for SBDD, that unifies the task as a generative graph completion, analogous to fill-in-the-blank of the 3D complex binding graph. By categorizing existing methods based on their attributes, CBGBench facilitates a modular and extensible framework that implements cutting-edge methods. Secondly, a single de novo molecule generation task can hardly reflect their capabilities. To broaden the scope, we adapt these models to a range of tasks essential in drug design, considered sub-tasks within the graph fill-in-the-blank tasks. These tasks include the generative designation of de novo molecules, linkers, fragments, scaffolds, and sidechains, all conditioned on the structures of protein pockets. Our evaluations are conducted with fairness, encompassing comprehensive perspectives on interaction, chemical properties, geometry authenticity, and substructure validity. We further provide insights with analysis from empirical studies. Our results indicate that there is potential for further improvements on many tasks, with optimization in network architectures, and effective incorporation of chemical prior knowledge. Finally, to lower the barrier to entry and facilitate further developments in the field, we also provide a single [codebase](https://github.com/EDAPINENUT/CBGBench) that unifies the discussed models, data pre-processing, training, sampling, and evaluation.",
    "keywords": "Molecule Generation Benchmark, Target-Aware Drug Design, Generative Model",
    "pdf_url": "https://openreview.net/pdf?id=mOpNrrV2zH",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on structure-based drug design and generative models for molecule–protein binding (“de novo molecule generation,” “linkers, fragments, scaffolds, and sidechains, all conditioned on the structures of protein pockets”). Drug discovery and molecular modeling clearly fall under Biomedicine AI.",
    "prompt_tokens": 20763,
    "completion_tokens": 111,
    "total_tokens": 20874,
    "topic": "Drug Discovery - Structure-based Design",
    "method": "Diffusion models; Auto-regressive generation",
    "application": "De novo molecular generation; Lead optimization",
    "code_link": "https://github.com/EDAPINENUT/CBGBench",
    "dataset_name": [
      "CrossDocked2020",
      "LiGAN",
      "3DSBDD"
    ]
  },
  {
    "id": "tnB94WQGrn",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "KGARevion: An AI Agent for Knowledge-Intensive Biomedical QA",
    "authors": [
      "Xiaorui Su",
      "Yibo Wang",
      "Shanghua Gao",
      "Xiaolong Liu",
      "Valentina Giunchiglia",
      "Djork-Arné Clevert",
      "Marinka Zitnik"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Biomedical reasoning integrates structured, codified knowledge with tacit, experience-driven insights. Depending on the context, quantity, and nature of available evidence, researchers and clinicians use diverse strategies, including rule-based, prototype-based, and case-based reasoning. Effective medical AI models must handle this complexity while ensuring reliability and adaptability. We introduce KGARevion, a knowledge graph-based agent that answers knowledge-intensive questions. Upon receiving a query, KGARevion generates relevant triplets by leveraging the latent knowledge embedded in a large language model. It then verifies these triplets against a grounded knowledge graph, filtering out errors and retaining only accurate, contextually relevant information for the final answer. This multi-step process strengthens reasoning, adapts to different models of medical inference, and outperforms retrieval-augmented generation-based approaches that lack effective verification mechanisms. Evaluations on medical QA benchmarks show that KGARevion improves accuracy by over 5.2% over 15 models in handling complex medical queries. To further assess its effectiveness, we curated three new medical QA datasets with varying levels of semantic complexity, where KGARevion improved accuracy by 10.4%. The agent integrates with different LLMs and biomedical knowledge graphs for broad applicability across knowledge-intensive tasks. We evaluated KGARevion on AfriMed-QA, a newly introduced dataset focused on African healthcare, demonstrating its strong zero-shot generalization to underrepresented medical contexts.",
    "keywords": "Medical Reasoning, Medical QA, Agent, Knowledge Graph, LLM",
    "pdf_url": "https://openreview.net/pdf?id=tnB94WQGrn",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “biomedical reasoning” and develops an AI agent for “knowledge-intensive biomedical QA,” leveraging a “grounded knowledge graph” of medical facts. It is evaluated on medical QA benchmarks and a dataset centered on African healthcare (AfriMed-QA), clearly situating it within the Biomedicine AI domain.",
    "prompt_tokens": 20956,
    "completion_tokens": 137,
    "total_tokens": 21093,
    "topic": "Bioinformatics - Medical QA",
    "method": "Knowledge graphs (KG); Retrieval-augmented generation (RAG)",
    "application": "Complex biomedical question answering",
    "code_link": "https://github.com/mims-harvard/KGARevion",
    "dataset_name": [
      "MMLU-Med",
      "MedQA-US",
      "PubMedQA",
      "BioASQ-Y/N",
      "MedDDx",
      "AfriMed-QA"
    ]
  },
  {
    "id": "rQ7fz9NO7f",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Multimodal Large Language Models for Inverse Molecular Design with Retrosynthetic Planning",
    "authors": [
      "Gang Liu",
      "Michael Sun",
      "Wojciech Matusik",
      "Meng Jiang",
      "Jie Chen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "While large language models (LLMs) have integrated images, adapting them to graphs remains challenging, limiting their applications in materials and drug design. This difficulty stems from the need for coherent autoregressive generation across texts and graphs. To address this, we introduce Llamole, the first multimodal LLM capable of interleaved text and graph generation, enabling molecular inverse design with retrosynthetic planning. Llamole integrates a base LLM with the Graph Diffusion Transformer and Graph Neural Networks for multi-conditional molecular generation and reaction inference within texts, while the LLM, with enhanced molecular understanding, flexibly controls activation among the different graph modules. Additionally, Llamole integrates A* search with LLM-based cost functions for efficient retrosynthetic planning. We create benchmarking datasets and conduct extensive experiments to evaluate Llamole against in-context learning and supervised fine-tuning. Llamole significantly outperforms 14 adapted LLMs across 12 metrics for controllable molecular design and retrosynthetic planning. Code and model at https://github.com/liugangcode/Llamole.",
    "keywords": "Multimodal Large Languge Models, Large Languge Models, Graph Diffusion Models, Inverse Molecular Design, Retrosynthesis",
    "pdf_url": "https://openreview.net/pdf?id=rQ7fz9NO7f",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work focuses on inverse molecular design with retrosynthetic planning—core tasks in drug discovery and pharmaceutical chemistry. It leverages graph diffusion models and retrosynthesis search for molecular generation (“multi-conditional molecular generation and reaction inference”) which is directly relevant to Biomedicine AI’s “drug discovery” category.",
    "prompt_tokens": 21080,
    "completion_tokens": 134,
    "total_tokens": 21214,
    "topic": "Drug Discovery - Multimodal Molecular Design",
    "method": "Multimodal autoregressive modeling; GNN; Graph Diffusion Transformer; A* search",
    "application": "Molecular inverse design and retrosynthetic planning",
    "code_link": "https://github.com/liugangcode/Llamole",
    "dataset_name": [
      "USPTO",
      "MoleculeNet",
      "PubChem",
      "ChEMBL",
      "ZINC",
      "PI1M"
    ]
  },
  {
    "id": "Mfnh1Sqdwf",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Learning to Discover Regulatory Elements for Gene Expression Prediction",
    "authors": [
      "Xingyu Su",
      "Haiyang Yu",
      "Degui Zhi",
      "Shuiwang Ji"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We consider the problem of predicting gene expressions from DNA sequences. A key challenge of this task is to find the regulatory elements that control gene expressions. Here, we introduce Seq2Exp, a Sequence to Expression network explicitly designed to discover and extract regulatory elements that drive target gene expression, enhancing the accuracy of the gene expression prediction. Our approach captures the causal relationship between epigenomic signals, DNA sequences and their associated regulatory elements. Specifically, we propose to decompose the epigenomic signals and the DNA sequence conditioned on the causal active regulatory elements, and apply an information bottleneck with the Beta distribution to combine their effects while filtering out non-causal components. Our experiments demonstrate that Seq2Exp outperforms existing baselines in gene expression prediction tasks and discovers influential regions compared to commonly used statistical methods for peak detection such as MACS3. The source code is released as part of the AIRS library (https://github.com/divelab/AIRS/).",
    "keywords": "Gene Expression, Deep Learning, Sequence Modeling",
    "pdf_url": "https://openreview.net/pdf?id=Mfnh1Sqdwf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on predicting gene expression from DNA sequences and discovering regulatory elements—core tasks in genomics and epigenomics. It explicitly deals with “epigenomic signals,” “DNA sequences,” and “regulatory elements,” all of which are fundamental to biomedical research in understanding gene regulation and function.",
    "prompt_tokens": 20891,
    "completion_tokens": 96,
    "total_tokens": 20987,
    "topic": "Bioinformatics - Gene Expression Prediction",
    "method": "Learning to mask; Beta distribution; Information bottleneck",
    "application": "Gene Expression Prediction",
    "code_link": "https://github.com/divelab/AIRS/",
    "dataset_name": [
      "ENCODE",
      "FANTOM5"
    ]
  },
  {
    "id": "v9EjwMM55Y",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "UniMatch: Universal Matching from Atom to Task for Few-Shot Drug Discovery",
    "authors": [
      "Ruifeng Li",
      "Mingqian Li",
      "Wei Liu",
      "Yuhua Zhou",
      "Xiangxin Zhou",
      "Yuan Yao",
      "Qiang Zhang",
      "Hongyang Chen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Drug discovery is crucial for identifying candidate drugs for various diseases. However, its low success rate often results in a scarcity of annotations, posing a few-shot learning problem. Existing methods primarily focus on single-scale features, overlooking the hierarchical molecular structures that determine different molecular properties. To address these issues, we introduce Universal Matching Networks (UniMatch), a dual matching framework that integrates explicit hierarchical molecular matching with implicit task-level matching via meta-\nlearning, bridging multi-level molecular representations and task-level generalization. Specifically, our approach explicitly captures structural features across multiple levels—atoms, substructures, and molecules—via hierarchical pooling and matching, facilitating precise molecular representation and comparison. Additionally, we employ a meta-learning strategy for implicit task-level matching, allowing the model to capture shared patterns across tasks and quickly adapt to new ones. This unified matching framework ensures effective molecular alignment while leveraging shared meta-knowledge for fast adaptation. Our experimental results demonstrate that UniMatch outperforms state-of-the-art methods on the MoleculeNet and FS-Mol benchmarks, achieving improvements of 2.87% in AUROC and 6.52% in ∆AUPRC. UniMatch also shows excellent generalization ability on the Meta-MolNet benchmark.",
    "keywords": "Few-shot molecular representation learning, maching learning",
    "pdf_url": "https://openreview.net/pdf?id=v9EjwMM55Y",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “few-shot drug discovery,” explicitly addressing molecular representation learning and matching for identifying candidate drugs. Terms like “hierarchical molecular structures,” “atom to task,” and evaluation on benchmarks such as MoleculeNet and FS-Mol confirm its direct relevance to biomedical research and drug development.",
    "prompt_tokens": 21101,
    "completion_tokens": 137,
    "total_tokens": 21238,
    "topic": "Drug Discovery - Few-shot Learning",
    "method": "Hierarchical molecular matching; meta-learning",
    "application": "Molecular property prediction",
    "code_link": "https://github.com/Lirain21/UniMatch.git",
    "dataset_name": [
      "FS-Mol",
      "Meta-MolNet",
      "MoleculeNet",
      "GSK3",
      "JNK3",
      "HIV",
      "Tox21",
      "ToxCast",
      "PCBA",
      "MUV"
    ]
  },
  {
    "id": "wxPnuFp8fZ",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Self-Supervised Diffusion MRI Denoising via Iterative and Stable Refinement",
    "authors": [
      "Chenxu Wu",
      "Qingpeng Kong",
      "Zihang Jiang",
      "S Kevin Zhou"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Magnetic Resonance Imaging (MRI), including diffusion MRI (dMRI), serves as a ``microscope'' for anatomical structures and routinely mitigates the influence of low signal-to-noise ratio scans by compromising temporal or spatial resolution. However, these compromises fail to meet clinical demands for both efficiency and precision. Consequently, denoising is a vital preprocessing step, particularly for dMRI, where clean data is unavailable. In this paper, we introduce Di-Fusion, a fully self-supervised denoising method that leverages the latter diffusion steps and an adaptive sampling process. Unlike previous approaches, our single-stage framework achieves efficient and stable training without extra noise model training and offers adaptive and controllable results in the sampling process. Our thorough experiments on real and simulated data demonstrate that Di-Fusion achieves state-of-the-art performance in microstructure modeling, tractography tracking, and other downstream tasks. Code is available at https://github.com/FouierL/Di-Fusion.",
    "keywords": "Diffusion based models, Self-supervised MRI denoising",
    "pdf_url": "https://openreview.net/pdf?id=wxPnuFp8fZ",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on denoising diffusion MRI (dMRI) data—a core medical imaging modality used in clinical and research settings (“Magnetic Resonance Imaging (MRI), including diffusion MRI (dMRI)…”). It targets improvements in microstructure modeling and tractography, both downstream tasks in neuroimaging and clinical diagnosis. These are clear applications within healthcare/biomedical AI.",
    "prompt_tokens": 20713,
    "completion_tokens": 133,
    "total_tokens": 20846,
    "topic": "Medical Imaging - Diffusion MRI",
    "method": "Denoising diffusion model; Self-supervised learning; Adaptive sampling",
    "application": "Noise removal in diffusion MRI",
    "code_link": "https://github.com/FouierL/Di-Fusion",
    "dataset_name": [
      "Stanford HARDI",
      "Sherbrooke 3-Shell",
      "PPMI",
      "fastMRI"
    ]
  },
  {
    "id": "2o58Mbqkd2",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "The Superposition of Diffusion Models Using the Itô Density Estimator",
    "authors": [
      "Marta Skreta",
      "Lazar Atanackovic",
      "Joey Bose",
      "Alexander Tong",
      "Kirill Neklyudov"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The Cambrian explosion of easily accessible pre-trained diffusion models suggests a demand for methods that combine multiple different pre-trained diffusion models without incurring the significant computational burden of re-training a larger combined model. In this paper, we cast the problem of combining multiple pre-trained diffusion models at the generation stage under a novel proposed framework termed superposition. Theoretically, we derive superposition from rigorous first principles stemming from the celebrated continuity equation and design two novel algorithms tailor-made for combining diffusion models in SuperDiff. SuperDiff leverages a new scalable Itô density estimator for the log likelihood of the diffusion SDE which incurs *no additional overhead* compared to the well-known Hutchinson's estimator needed for divergence calculations. We demonstrate that SuperDiff is scalable to large pre-trained diffusion models as superposition is performed *solely through composition during inference*, and also enjoys painless implementation as it combines different pre-trained vector fields through an automated re-weighting scheme. Notably, we show that SuperDiff is efficient during inference time, and mimics traditional composition operators such as the logical OR and the logical AND.  We empirically demonstrate the utility of using SuperDiff for generating more diverse images on CIFAR-10, more faithful prompt conditioned image editing using Stable Diffusion, as well as improved conditional molecule generation and unconditional *de novo* structure design of proteins. https://github.com/necludov/super-diffusion",
    "keywords": "generative modelling, protein generation, image generation, diffusion models",
    "pdf_url": "https://openreview.net/pdf?id=2o58Mbqkd2",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: While the core contribution is a general generative-modeling technique, the paper explicitly demonstrates its utility for “conditional molecule generation” and “unconditional de novo structure design of proteins,” both of which fall squarely under biomedical AI tasks (molecular modeling, drug discovery, and protein design).",
    "prompt_tokens": 20392,
    "completion_tokens": 121,
    "total_tokens": 20513,
    "topic": "Generative Modeling - Diffusion Models",
    "method": "Diffusion models; Itô density estimator; Logical operations for model composition",
    "application": "Image generation; Protein structure generation",
    "code_link": "https://github.com/necludov/super-diffusion",
    "dataset_name": [
      "CIFAR-10",
      "Protein Data Bank (PDB)"
    ]
  },
  {
    "id": "IxmWIkcKs5",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "A Simple yet Effective $\\Delta\\Delta G$ Predictor is An Unsupervised Antibody Optimizer and Explainer",
    "authors": [
      "Lirong Wu",
      "Yunfan Liu",
      "Haitao Lin",
      "Yufei Huang",
      "Guojiang Zhao",
      "Zhifeng Gao",
      "Stan Z. Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The proteins that exist today have been optimized over billions of years of natural evolution, during which nature creates random mutations and selects them. The discovery of functionally promising mutations is challenged by the limited evolutionary accessible regions, i.e., only a small region on the fitness landscape is beneficial. There have been numerous priors used to constrain protein evolution to regions of landscapes with high-fitness variants, among which the change in binding free energy ($\\Delta\\Delta G$) of protein complexes upon mutations is one of the most commonly used priors. However, the huge mutation space poses two challenges: (1) how to improve the efficiency of $\\Delta\\Delta G$ prediction for fast mutation screening; and (2) how to explain mutation preferences and efficiently explore accessible evolutionary regions. To address these challenges, we propose a lightweight $\\Delta\\Delta G$ predictor (Light-DDG), which adopts a structure-aware Transformer as the backbone and enhances it by knowledge distilled from existing powerful but computationally heavy $\\Delta\\Delta G$ predictors. Additionally, we augmented, annotated, and released a large-scale dataset containing millions of mutation data for pre-training Light-DDG. We find that such a simple yet effective Light-DDG can serve as a good unsupervised antibody optimizer and explainer. For the target antibody, we propose a novel Mutation Explainer to learn mutation preferences, which accounts for the marginal benefit of each mutation per residue. To further explore accessible evolutionary regions, we conduct preference-guided antibody optimization and evaluate antibody candidates quickly using Light-DDG to identify desirable mutations. Extensive experiments have demonstrated the effectiveness of Light-DDG in terms of test generalizability, noise robustness, and inference practicality, e.g., 89.7$\\times$ inference acceleration and 15.45\\% performance gains over previous state-of-the-art baselines. A case study of SARS-CoV-2 further demonstrates the crucial role of Light-DDG for mutation explanation and antibody optimization.",
    "keywords": "Mutation Effect Prediction, Mutation Preference Explanation, Unsupervised Protein Evolution",
    "pdf_url": "https://openreview.net/pdf?id=IxmWIkcKs5",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work focuses on predicting ΔΔG for protein–protein interactions upon mutation and uses that to guide antibody optimization (a key step in therapeutic design). It explicitly targets “antibody optimizers” and includes a case study on SARS-CoV-2, situating it firmly within the protein design/drug discovery domain of Biomedicine AI.",
    "prompt_tokens": 20703,
    "completion_tokens": 123,
    "total_tokens": 20826,
    "topic": "Bioinformatics - Protein Mutation Effects",
    "method": "Lightweight Transformer; Knowledge Distillation; Iterative Shapley Value Estimation",
    "application": "Antibody optimization",
    "code_link": "https://github.com/LirongWu/Uni-Anti",
    "dataset_name": [
      "SKEMPI v2.0",
      "PDB-REDO",
      "SKEMPI-Aug",
      "AFDB"
    ]
  },
  {
    "id": "wyF5vNIsO7",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Scalable Universal T-Cell Receptor Embeddings from Adaptive Immune Repertoires",
    "authors": [
      "Paidamoyo Chapfuwa",
      "Ilker Demirel",
      "Lorenzo Pisani",
      "Javier Zazo",
      "Elon Portugaly",
      "H. Jabran Zahid",
      "Julia Greissl"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "T cells are a key component of the adaptive immune system, targeting infections, cancers, and allergens with specificity encoded by their T cell receptors (TCRs), and retaining a memory of their targets. High-throughput TCR repertoire sequencing captures a cross-section of TCRs that encode the immune history of any subject, though the data are heterogeneous, high dimensional, sparse, and mostly unlabeled. \nSets of TCRs responding to the same antigen, *i.e.*, a protein fragment, co-occur in subjects sharing immune genetics and exposure history. Here, we leverage TCR co-occurrence across a large set of TCR repertoires and employ the GloVe (Pennington et al., 2014)  algorithm to derive low-dimensional, dense vector representations (embeddings) of TCRs. We then aggregate these TCR embeddings to generate subject-level embeddings based on observed *subject-specific* TCR subsets. Further, we leverage random projection theory to improve GloVe's computational efficiency in terms of memory usage and training time. Extensive experimental results show that TCR embeddings targeting the same pathogen have high cosine similarity, and subject-level embeddings encode both immune genetics and pathogenic exposure history.",
    "keywords": "Immunomics, T-cell Receptor Embeddings, GloVe, Random Projection Theory, Scaling, Unsupervised Representation Learning",
    "pdf_url": "https://openreview.net/pdf?id=wyF5vNIsO7",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “T-cell Receptor Embeddings” derived from “adaptive immune repertoires,” leveraging high-throughput TCR sequencing data to study immune genetics and pathogenic exposure history. It deals explicitly with immunomics, receptor sequence analysis, and pathogen-specific immune responses—core topics in biomedical research. Thus, it clearly falls under the Biomedicine AI domain.",
    "prompt_tokens": 20738,
    "completion_tokens": 112,
    "total_tokens": 20850,
    "topic": "Bioinformatics - T-cell Receptor Embedding",
    "method": "GloVe embedding; random projection theory",
    "application": "HLA classification and disease prediction",
    "code_link": "https://github.com/microsoft/jl-glove",
    "dataset_name": [
      "TDETECT",
      "PUBLIC",
      "MULTIID",
      "EMERSON"
    ]
  },
  {
    "id": "3kiZ5S5WkY",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Iterative Substructure Extraction for Molecular Relational Learning with Interactive Graph Information Bottleneck",
    "authors": [
      "Shuai Zhang",
      "Junfeng Fang",
      "Xuqiang Li",
      "hongxin xiang",
      "ALAN XIA",
      "Ye Wei",
      "Wenjie Du",
      "Yang Wang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Molecular relational learning (MRL) seeks to understand the interaction behaviors between molecules, a pivotal task in domains such as drug discovery and materials science. Recently, extracting core substructures and modeling their interactions have emerged as mainstream approaches within machine learning-assisted methods. However, these methods still exhibit some limitations, such as insufficient consideration of molecular interactions or capturing substructures that include excessive noise, which hampers precise core substructure extraction.\nTo address these challenges, we present an integrated dynamic framework called Iterative Substructure Extraction (ISE). ISE employs the Expectation-Maximization (EM) algorithm for MRL tasks, where the core substructures of interacting molecules are treated as latent variables and model parameters, respectively. Through iterative refinement, ISE gradually narrows the interactions from the entire molecular structures to just the core substructures.\nMoreover, to ensure the extracted substructures are concise and compact, we propose the Interactive Graph Information Bottleneck (IGIB) theory, which focuses on capturing the most influential yet minimal interactive substructures. In summary, our approach, guided by the IGIB theory, achieves precise substructure extraction within the ISE framework and is encapsulated in the IGIB-ISE}\nExtensive experiments validate the superiority of our model over state-of-the-art baselines across various tasks in terms of accuracy, generalizability, and interpretability.",
    "keywords": "Molecular Relational Learning, EM Algorithm, Substructure Extraction, Interactive Graph Information Bottleneck",
    "pdf_url": "https://openreview.net/pdf?id=3kiZ5S5WkY",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on molecular relational learning with explicit mention of “drug discovery” as a pivotal domain. Extracting and modeling molecular substructures to predict interactions is a core task in biomedicine and pharmaceutical research. By addressing substructure extraction for molecules and highlighting applications in drug discovery, this work clearly falls under the Biomedicine AI domain.",
    "prompt_tokens": 20998,
    "completion_tokens": 127,
    "total_tokens": 21125,
    "topic": "Molecular Relational Learning - Drug-Drug Interactions",
    "method": "Interactive Graph Information Bottleneck (IGIB); Iterative Substructure Extraction (ISE)",
    "application": "Drug-drug interaction prediction",
    "code_link": "https://github.com/congcijueqi/IGIB-ISE",
    "dataset_name": [
      "ZhangDDI",
      "ChChMiner",
      "DeepDDI",
      "MIRACLE"
    ]
  },
  {
    "id": "iOMnn1hSBO",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Utility-Directed Conformal Prediction: A Decision-Aware Framework for Actionable Uncertainty Quantification",
    "authors": [
      "Santiago Cortes-Gomez",
      "Carlos Miguel Patiño",
      "Yewon Byun",
      "Steven Wu",
      "Eric Horvitz",
      "Bryan Wilder"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "There is increasing interest in ``decision-focused\" machine learning methods which train models to account for how their predictions are used in downstream optimization problems. Doing so can often improve performance on subsequent decision problems. However, current methods for uncertainty quantification do not incorporate any information at all about downstream decisions. We develop a framework based on conformal prediction to produce prediction sets that account for a downstream decision loss function, making them more appropriate to inform high-stakes decision-making. Our approach harnesses the strengths of conformal methods—modularity, model-agnosticism, and statistical coverage guarantees—while incorporating downstream decisions and user-specified utility functions. We prove that our methods retain standard coverage guarantees.  Empirical evaluation across a range of datasets and utility metrics demonstrates that our methods achieve significantly lower decision loss compared to standard conformal methods. Additionally, we present a real-world use case in healthcare diagnosis, where our method effectively incorporates the hierarchical structure of dermatological diseases. It successfully generates sets with coherent diagnostic meaning, aiding the triage process during dermatology diagnosis and illustrating how our method can ground high-stakes decision-making on external domain knowledge.",
    "keywords": "Decision-focused learning, decision making, uncertainty quantification, healthcare",
    "pdf_url": "https://openreview.net/pdf?id=iOMnn1hSBO",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the paper develops a general-purpose conformal‐prediction framework, it explicitly demonstrates a real‐world use case in healthcare diagnosis (“triage process during dermatology diagnosis”) and incorporates the hierarchical structure of dermatological diseases. This direct application to medical decision‐making and disease diagnosis qualifies it as relevant to the Healthcare AI domain.",
    "prompt_tokens": 20795,
    "completion_tokens": 132,
    "total_tokens": 20927,
    "topic": "Medical Diagnosis - Uncertainty Quantification",
    "method": "Conformal Prediction; Decision-focused optimization; Penalized conformal methods",
    "application": "Dermatology disease triage and diagnosis",
    "code_link": "N/A",
    "dataset_name": [
      "Fitzpatrick",
      "Fitzpatrick Clean",
      "iNaturalist",
      "CIFAR-100",
      "ImageNet"
    ]
  },
  {
    "id": "g3VCIM94ke",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Multi-domain Distribution Learning for De Novo Drug Design",
    "authors": [
      "Arne Schneuing",
      "Ilia Igashov",
      "Adrian W. Dobbelstein",
      "Thomas Castiglione",
      "Michael M. Bronstein",
      "Bruno Correia"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We introduce DrugFlow, a generative model for structure-based drug design that integrates continuous flow matching with discrete Markov bridges, demonstrating state-of-the-art performance in learning chemical, geometric, and physical aspects of three-dimensional protein-ligand data. We endow DrugFlow with an uncertainty estimate that is able to detect out-of-distribution samples. To further enhance the sampling process towards distribution regions with desirable metric values, we propose a joint preference alignment scheme applicable to both flow matching and Markov bridge frameworks. Furthermore, we extend our model to also explore the conformational landscape of the protein by jointly sampling side chain angles and molecules.",
    "keywords": "Drug Discovery, Flow Matching, Markov Bridge, Equivariance",
    "pdf_url": "https://openreview.net/pdf?id=g3VCIM94ke",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on structure-based drug design (“de Novo Drug Design,” “protein-ligand data,” “drug discovery”) and molecular generation techniques, which are core tasks in biomedicine AI. It explicitly addresses “drug discovery,” “protein design,” and 3D “protein-ligand” modeling, all of which align with biomedical research applications.",
    "prompt_tokens": 21134,
    "completion_tokens": 97,
    "total_tokens": 21231,
    "topic": "Drug Discovery - Structure-based",
    "method": "Flow matching; Markov bridge model; Preference alignment",
    "application": "Molecular property optimization",
    "code_link": "https://github.com/LPDI-EPFL/DrugFlow",
    "dataset_name": [
      "CrossDocked"
    ]
  },
  {
    "id": "zg3ec1TdAP",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Context Clues: Evaluating Long Context Models for Clinical Prediction Tasks on EHR Data",
    "authors": [
      "Michael Wornow",
      "Suhana Bedi",
      "Miguel Angel Fuentes Hernandez",
      "Ethan Steinberg",
      "Jason Alan Fries",
      "Christopher Re",
      "Sanmi Koyejo",
      "Nigam Shah"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Foundation Models (FMs) trained on Electronic Health Records (EHRs) have achieved state-of-the-art results on numerous clinical prediction tasks. However, prior EHR FMs typically have context windows of $<$1k tokens, which prevents them from modeling full patient EHRs which can exceed 10k's of events. For making clinical predictions, both model performance and robustness to the unique properties of EHR data are crucial. Recent advancements in subquadratic long-context architectures (e.g. Mamba) offer a promising solution. However, their application to EHR data has not been well-studied. We address this gap by presenting the first systematic evaluation of the effect of context length on modeling EHR data. We find that longer context models improve predictive performance -- our Mamba-based model surpasses the prior state-of-the-art on 9/14 tasks on the EHRSHOT prediction benchmark. Additionally, we measure robustness to three unique, previously underexplored properties of EHR data: (1) the prevalence of ``copy-forwarded\" diagnoses which create artificial token repetition in EHR sequences; (2) the irregular time intervals between EHR events which can lead to a wide range of timespans within a context window; and (3) the natural increase in disease complexity over time which makes later tokens in the EHR harder to predict than earlier ones. Stratifying our EHRSHOT results, we find that higher levels of each property correlate negatively with model performance (e.g., a 14% higher Brier loss between the least and most irregular patients), but that longer context models are more robust to more extreme levels of these properties. Our work highlights the potential for using long-context architectures to model EHR data, and offers a case study on how to identify and quantify new challenges in modeling sequential data motivated by domains outside of natural language. We release all of our model checkpoints and code.",
    "keywords": "ehr, foundation model, long context, clinical prediction making, healthcare",
    "pdf_url": "https://openreview.net/pdf?id=zg3ec1TdAP",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on clinical prediction tasks using Electronic Health Records (EHRs), explicitly mentioning “clinical prediction tasks,” EHR data, and evaluating foundation models on the EHRSHOT benchmark. These are clear indicators of applying AI methods to healthcare data and patient outcomes.",
    "prompt_tokens": 20932,
    "completion_tokens": 114,
    "total_tokens": 21046,
    "topic": "EHR - Predictive Models",
    "method": "Subquadratic models (Mamba, Hyena); Transformer-based models (GPT, Llama)",
    "application": "Clinical prediction tasks",
    "code_link": "https://github.com/som-shahlab/long_context_clues",
    "dataset_name": [
      "EHRSHOT",
      "EHR-OMOP"
    ]
  },
  {
    "id": "n34taxF0TC",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Shedding Light on Time Series Classification using Interpretability Gated Networks",
    "authors": [
      "Yunshi Wen",
      "Tengfei Ma",
      "Ronny Luss",
      "Debarun Bhattacharjya",
      "Achille Fokoue",
      "Anak Agung Julius"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In time-series classification, interpretable models can bring additional insights but be outperformed by deep models since human-understandable features have limited expressivity and flexibility. In this work, we present InterpGN, a framework that integrates an interpretable model and a deep neural network. Within this framework, we introduce a novel gating function design based on the confidence of the interpretable expert, preserving interpretability for samples where interpretable features are significant while also identifying samples that require additional expertise. For the interpretable expert, we incorporate shapelets to effectively model shape-level features for time-series data. We introduce a variant of Shapelet Transforms to build logical predicates using shapelets. Our proposed model achieves comparable performance with state-of-the-art deep learning models while additionally providing interpretable classifiers for various benchmark datasets. We further show that our models improve on quantitative shapelet quality and interpretability metrics over existing shapelet-learning formulations. Finally, we show that our models can integrate additional advanced architectures and be applied to real-world tasks beyond standard benchmarks such as the MIMIC-III and time series extrinsic regression datasets.",
    "keywords": "Interpretability, Time-series, Shapelet",
    "pdf_url": "https://openreview.net/pdf?id=n34taxF0TC",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the core contribution is a general time-series classification framework, the paper explicitly demonstrates its applicability on MIMIC-III (“real-world tasks beyond standard benchmarks such as the MIMIC-III … datasets”), which is a large-scale clinical EHR dataset. This direct reference to a healthcare dataset indicates relevance to Healthcare AI.",
    "prompt_tokens": 20573,
    "completion_tokens": 113,
    "total_tokens": 20686,
    "topic": "Time Series - Classification",
    "method": "Shapelet bottleneck model; Fully Convolutional Network (FCN)",
    "application": "Multivariate time series classification",
    "code_link": "https://github.com/YunshiWen/InterpretGatedNetwork",
    "dataset_name": [
      "MIMIC-III",
      "UEA multivariate time-series classification archive"
    ]
  },
  {
    "id": "E48QvQppIN",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Bayesian Optimization of Antibodies Informed by a Generative Model of Evolving Sequences",
    "authors": [
      "Alan Nawzad Amin",
      "Nate Gruver",
      "Yilun Kuang",
      "Yucen Lily Li",
      "Hunter Elliott",
      "Calvin McCarter",
      "Aniruddh Raghu",
      "Peyton Greenside",
      "Andrew Gordon Wilson"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "To build effective therapeutics, biologists iteratively mutate antibody sequences to improve binding and stability. Proposed mutations can be informed by previous measurements or by learning from large antibody databases to predict only typical antibodies. Unfortunately, the space of typical antibodies is enormous to search, and experiments often fail to find suitable antibodies on a budget. We introduce Clone-informed Bayesian Optimization (CloneBO), a Bayesian optimization procedure that efficiently optimizes antibodies in the lab by teaching a generative model how our immune system optimizes antibodies. Our immune system makes antibodies by iteratively evolving specific portions of their sequences to bind their target strongly and stably, resulting in a set of related, evolving sequences known as a *clonal family*. We train a large language model, CloneLM, on hundreds of thousands of clonal families and use it to design sequences with mutations that are most likely to optimize an antibody within the human immune system. We propose to guide our designs to fit previous measurements with a twisted sequential Monte Carlo procedure. We show that CloneBO optimizes antibodies substantially more efficiently than previous methods in realistic *in silico* experiments and designs stronger and more stable binders in *in vitro* wet lab experiments.",
    "keywords": "Bayesian optimization, generative model, antibody, biological sequence",
    "pdf_url": "https://openreview.net/pdf?id=E48QvQppIN",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on designing and optimizing antibody sequences—a core task in drug discovery and protein engineering for therapeutic applications. It introduces a generative model trained on clonal families from the immune system and validates designs in *in vitro* wet-lab experiments, directly aligning with biomedicine AI’s scope of “protein design for therapeutics” and “drug discovery.”",
    "prompt_tokens": 20893,
    "completion_tokens": 115,
    "total_tokens": 21008,
    "topic": "Bioinformatics - Antibody Optimization",
    "method": "Bayesian Optimization; Language Modeling; Martingale Posterior Sampling",
    "application": "Antibody sequence optimization for binding and stability",
    "code_link": "https://github.com/AlanNawzadAmin/CloneBO",
    "dataset_name": [
      "Observed Antibody Space (OAS)",
      "CoVAbDab"
    ]
  },
  {
    "id": "ja4rpheN2n",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "GeSubNet: Gene Interaction Inference for Disease Subtype Network Generation",
    "authors": [
      "Ziwei Yang",
      "Zheng Chen",
      "Xin Liu",
      "Rikuto Kotoge",
      "Peng Chen",
      "Yasuko Matsubara",
      "Yasushi Sakurai",
      "Jimeng Sun"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Retrieving gene functional networks from knowledge databases presents a challenge due to the mismatch between disease networks and subtype-specific variations. Current solutions, including statistical and deep learning methods, often fail to effectively integrate gene interaction knowledge from databases or explicitly learn subtype-specific interactions. To address this mismatch, we propose GeSubNet, which learns a unified representation capable of predicting gene interactions while distinguishing between different disease subtypes. Graphs generated by such representations can be considered subtype-specific networks. GeSubNet is a multi-step representation learning framework with three modules: First, a deep generative model learns distinct disease subtypes from patient gene expression profiles. Second, a graph neural network captures representations of prior gene networks from knowledge databases, ensuring accurate physical gene interactions. Finally, we integrate these two representations using an inference loss that leverages graph generation capabilities, conditioned on the patient separation loss, to refine subtype-specific information in the learned representation. GeSubNet consistently outperforms traditional methods, with average improvements of 30.6%, 21.0%, 20.1%, and 56.6% across four graph evaluation metrics, averaged over four cancer datasets. Particularly, we conduct a biological simulation experiment to assess how the behavior of selected genes from over 11,000 candidates affects subtypes or patient distributions. The results show that the generated network has the potential to identify subtype-specific genes with an 83% likelihood of impacting patient distribution shifts.",
    "keywords": "Gene Functional Networks, Disease Subtypes, Bioinformatics",
    "pdf_url": "https://openreview.net/pdf?id=ja4rpheN2n",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on inferring gene functional networks for disease subtypes using patient gene expression profiles and cancer datasets. It explicitly addresses “disease subtypes,” “gene interaction,” and “patient distribution shifts,” which are core topics in biomedical research and genomics. The use of cancer data and gene expression further confirms its relevance to Biomedicine AI.",
    "prompt_tokens": 21164,
    "completion_tokens": 137,
    "total_tokens": 21301,
    "topic": "Bioinformatics - Gene Network Construction",
    "method": "Vector Quantized-Variational AutoEncoder (VQ-VAE); Graph Neural Networks (Neo-GNN); Link Prediction",
    "application": "Subtype-specific gene network inference",
    "code_link": "https://github.com/chenzRG/GeSubNet",
    "dataset_name": [
      "TCGA-BRCA",
      "TCGA-GBM",
      "TCGA-LGG",
      "TCGA-OV"
    ]
  },
  {
    "id": "L238BAx0wP",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Learning to engineer protein flexibility",
    "authors": [
      "Petr Kouba",
      "Joan Planas-Iglesias",
      "Jiri Damborsky",
      "Jiri Sedlar",
      "Stanislav Mazurenko",
      "Josef Sivic"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Generative machine learning models are increasingly being used to design novel proteins. However, their major limitation is the inability to account for protein flexibility, a property crucial for protein function. Learning to engineer flexibility is difficult because the relevant data is scarce, heterogeneous, and costly to obtain using computational and experimental methods. Our contributions are three-fold. First, we perform a comprehensive comparison of methods for evaluating protein flexibility and identify relevant data for learning. Second, we overcome the data scarcity issue by leveraging a pre-trained protein language model. We design and train flexibility predictors utilizing either only sequential or both sequential and structural information on the input. Third, we introduce a method for fine-tuning a protein inverse folding model to make it steerable toward desired flexibility at specified regions. We demonstrate that our method Flexpert enables guidance of inverse folding models toward increased flexibility. This opens up a transformative possibility of engineering protein flexibility.",
    "keywords": "protein flexibility, protein flexibility prediction, protein design, protein sequence design, inverse folding",
    "pdf_url": "https://openreview.net/pdf?id=L238BAx0wP",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “protein flexibility prediction” and “inverse folding” for “protein sequence design,” which falls squarely under molecular modeling and protein design—key areas of Biomedicine AI. It leverages generative ML to engineer novel proteins, a methodology highly relevant to drug discovery, synthetic biology, and other biomedical applications.",
    "prompt_tokens": 21038,
    "completion_tokens": 103,
    "total_tokens": 21141,
    "topic": "Bioinformatics - Protein Engineering",
    "method": "Protein language model; Inverse folding; LoRA fine-tuning",
    "application": "Protein flexibility prediction and engineering",
    "code_link": "https://github.com/KoubaPetr/Flexpert",
    "dataset_name": [
      "ATLAS",
      "mdCATH"
    ]
  },
  {
    "id": "6xrDPHhwD3",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "A Multiscale Frequency Domain Causal Framework for Enhanced Pathological Analysis",
    "authors": [
      "Xiaoyu Cui",
      "Weixing Chen",
      "Jiandong Su"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Multiple Instance Learning (MIL) in digital pathology Whole Slide Image (WSI) analysis has shown significant progress. However, due to data bias and unobservable confounders, this paradigm still faces challenges in terms of performance and interpretability. Existing MIL methods might identify patches that do not have true diagnostic significance, leading to false correlations, and experience difficulties in integrating multi-scale features and handling unobservable confounders. To address these issues, we propose a new Multi-Scale Frequency Domain Causal framework (MFC). This framework employs an adaptive memory module to estimate the overall data distribution through multi-scale frequency-domain information during training and simulates causal interventions based on this distribution to mitigate confounders in pathological diagnosis tasks. The framework integrates the Multi-scale Spatial Representation Module (MSRM), Frequency Domain Structure Representation Module (FSRM), and Causal Memory Intervention Module (CMIM) to enhance the model's performance and interpretability. Furthermore, the plug-and-play nature of this framework allows it to be broadly applied across various models. Experimental results on Camelyon16 and TCGA-NSCLC dataset show that, compared to previous work, our method has significantly improved accuracy and generalization ability, providing a new theoretical perspective for medical image analysis and potentially advancing the field further. The code will be released at https://github.com/WissingChen/MFC-MIL.",
    "keywords": "Causal Inference, Pathological Image Analysis",
    "pdf_url": "https://openreview.net/pdf?id=6xrDPHhwD3",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on whole slide image (WSI) analysis for digital pathology, explicitly addressing pathological diagnosis tasks. It evaluates on Camelyon16 and TCGA-NSCLC datasets, both standard benchmarks in cancer histopathology. The methods aim to improve diagnostic interpretability and accuracy in medical imaging, making it a clear Healthcare AI paper.",
    "prompt_tokens": 20386,
    "completion_tokens": 115,
    "total_tokens": 20501,
    "topic": "Medical Imaging - Pathological Image Classification",
    "method": "Multiple Instance Learning (MIL); Causal Inference; Multiscale Spatial Representation; Frequency-domain Representation",
    "application": "Pathological image classification",
    "code_link": "https://github.com/WissingChen/MFC-MIL",
    "dataset_name": [
      "Camelyon16",
      "TCGA-NSCLC"
    ]
  },
  {
    "id": "IuU0wcO0mo",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Multi-session, multi-task neural decoding from distinct cell-types and brain regions",
    "authors": [
      "Mehdi Azabou",
      "Krystal Xuejing Pan",
      "Vinam Arora",
      "Ian Jarratt Knight",
      "Eva L Dyer",
      "Blake Aaron Richards"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Recent work has shown that scale is important for improved brain decoding, with more data leading to greater decoding accuracy. However, large-scale decoding across many different datasets is challenging because neural circuits are heterogeneous---each brain region contains a unique mix of cellular sub-types, and the responses to different stimuli are diverse across regions and sub-types. It is unknown whether it is possible to pre-train and transfer brain decoding models between distinct tasks, cellular sub-types, and brain regions. To address these questions, we developed a multi-task transformer architecture and trained it on the entirety of the Allen Institute's Brain Observatory dataset. This dataset contains responses from over 100,000 neurons in 6 areas of the brains of mice, observed with two-photon calcium imaging, recorded while the mice observed different types of visual stimuli. Our results demonstrate that transfer is indeed possible -combining data from different sources is beneficial for a number of downstream decoding tasks. As well, we can transfer the model between regions and sub-types, demonstrating that there is in fact common information in diverse circuits that can be extracted by an appropriately designed model. Interestingly, we found that the model's latent representations showed clear distinctions between different brain regions and cellular sub-types, even though it was never given any information about these distinctions. Altogether, our work demonstrates that training a large-scale neural decoding model on diverse data is possible, and this provides a means of studying the differences and similarities between heterogeneous neural circuits.",
    "keywords": "neural population, multi-task, transformer, tokenization, two-photon calcium imaging, visual stimuli, cell types",
    "pdf_url": "https://openreview.net/pdf?id=IuU0wcO0mo",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on large-scale neural decoding from two-photon calcium imaging data of mouse brain circuits, addressing “distinct cell-types and brain regions.” This falls squarely under neuroscience or neurobiological modeling—a strong indicator of Biomedicine AI as per the criteria (“brain decoding, neuron type classification, neural system dynamics”).",
    "prompt_tokens": 20810,
    "completion_tokens": 103,
    "total_tokens": 20913,
    "topic": "Neural Decoding - Multi-Task Learning",
    "method": "Transformer-based models; multi-task decoder; latent embeddings",
    "application": "Neural activity decoding – Brain regions",
    "code_link": "https://poyo-plus.github.io",
    "dataset_name": [
      "Allen Brain Observatory Dataset"
    ]
  },
  {
    "id": "jE5ZbtMtcU",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "BLEND: Behavior-guided Neural Population Dynamics Modeling via Privileged Knowledge Distillation",
    "authors": [
      "Zhengrui Guo",
      "Fangxu Zhou",
      "Wei Wu",
      "Qichen Sun",
      "Lishuang Feng",
      "Jinzhuo Wang",
      "Hao Chen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Modeling the nonlinear dynamics of neuronal populations represents a key pursuit in computational neuroscience. Recent research has increasingly focused on jointly modeling neural activity and behavior to unravel their interconnections. Despite significant efforts, these approaches often necessitate either intricate model designs or oversimplified assumptions. Given the frequent absence of perfectly paired neural-behavioral datasets in real-world scenarios when deploying these models, a critical yet understudied research question emerges: how to develop a model that performs well using only neural activity as input at inference, while benefiting from the insights gained from behavioral signals during training?\n\nTo this end, we propose **BLEND**, the **B**ehavior-guided neura**L** population dynamics mod**E**lling framework via privileged k**N**owledge **D**istillation. By considering behavior as privileged information, we train a teacher model that takes both behavior observations (privileged features) and neural activities (regular features) as inputs. A student model is then distilled using only neural activity. Unlike existing methods, our framework is model-agnostic and avoids making strong assumptions about the relationship between behavior and neural activity. This allows BLEND to enhance existing neural dynamics modeling architectures without developing specialized models from scratch. Extensive experiments across neural population activity modeling and transcriptomic neuron identity prediction tasks demonstrate strong capabilities of BLEND, reporting over 50% improvement in behavioral decoding and over 15% improvement in transcriptomic neuron identity prediction after behavior-guided distillation. Furthermore, we empirically explore various behavior-guided distillation strategies within the BLEND framework and present a comprehensive analysis of effectiveness and implications for model performance. Code will be made available at https://github.com/dddavid4real/BLEND.",
    "keywords": "Computational Neuroscience, Neural Dynamics Modeling, Behavior as Guidance, Privileged Knowledge Distillation",
    "pdf_url": "https://openreview.net/pdf?id=jE5ZbtMtcU",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work focuses on modeling neural population dynamics and even includes a “transcriptomic neuron identity prediction” task—i.e., predicting neuron types from single-cell transcriptomic data—and “behavioral decoding,” both of which squarely fall under neuroscience and neurobiological modeling. According to the definitions provided, brain decoding, neuron type classification, and transcriptomics are strong indicators of Biomedicine AI.",
    "prompt_tokens": 20851,
    "completion_tokens": 126,
    "total_tokens": 20977,
    "topic": "Computational Neuroscience - Neural Dynamics",
    "method": "Privileged knowledge distillation; Behavior-guided modeling",
    "application": "Neural activity prediction; behavior decoding; transcriptomic neuron identity prediction",
    "code_link": "https://github.com/dddavid4real/BLEND",
    "dataset_name": [
      "MC-Maze",
      "MC-RTT",
      "Area2-Bump",
      "Multi-modal neural activity dataset"
    ]
  },
  {
    "id": "UvPdpa4LuV",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Protein Language Model Fitness is a Matter of Preference",
    "authors": [
      "Cade W Gordon",
      "Amy X. Lu",
      "Pieter Abbeel"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Leveraging billions of years of evolution, scientists have trained protein language models (pLMs) to understand the sequence and structure space of proteins aiding in the design of more functional proteins. Although they have shown ability to improve efficiency in engineering, it remains unclear under what conditions they will succeed or fail. We aim to predict the circumstances in which pLMs can successfully perform zero-shot fitness estimation. Our work demonstrates the trends observed over hundreds of deep mutational scans across multiple different fitness objectives. We find that the likelihood, or abstractly, implicit preference of a certain protein sequence imbued during pretraining is predictive fitness prediction capabilities. Both over-preferred and under-preferred wild type sequences harm performance. Generating a causal link between training data and likelihood, we show a power law tail over what data increases protein likelihood which is tied to training sequence homology. Lastly, proteins of low likelihood can be remedied by unsupervised finetuning. In sum, the zero-shot fitness estimation abilities of pLMs can be predicted by the likelihood of the engineered sequence, thus suggesting when pLMs should be deployed in protein maturation campaigns and a way to improve their performance under circumstances of low likelihood.",
    "keywords": "protein language models, zero-shot fitness prediction",
    "pdf_url": "https://openreview.net/pdf?id=UvPdpa4LuV",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on “protein language models” and zero‐shot fitness prediction across “deep mutational scans,” directly addressing protein design and molecular modeling. These topics—protein engineering, sequence–structure space exploration, and fitness estimation—are core to drug discovery and synthetic biology, placing this work squarely in the Biomedicine AI domain.",
    "prompt_tokens": 21073,
    "completion_tokens": 111,
    "total_tokens": 21184,
    "topic": "Bioinformatics - Protein Language Models",
    "method": "Masked language models; Influence functions; Pseudo log likelihood estimation",
    "application": "Protein fitness prediction",
    "code_link": "https://doi.org/10.5281/zenodo.13131049",
    "dataset_name": [
      "ProteinGym",
      "UniRef50",
      "UniRef100"
    ]
  },
  {
    "id": "9UGfOJBuL8",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Conditional Diffusion with Ordinal Regression: Longitudinal Data Generation for Neurodegenerative Disease Studies",
    "authors": [
      "Hyuna Cho",
      "Ziquan Wei",
      "Seungjoo Lee",
      "Tingting Dan",
      "Guorong Wu",
      "Won Hwa Kim"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Modeling the progression of neurodegenerative diseases such as Alzheimer’s disease (AD) is crucial for early detection and prevention given their irreversible nature. However, the scarcity of longitudinal data and complex disease dynamics make the analysis highly challenging. Moreover, longitudinal samples often contain irregular and large intervals between subject visits, which underscore the necessity for advanced data generation techniques that can accurately simulate disease progression over time. In this regime, we propose a novel conditional generative model for synthesizing longitudinal sequences and present its application to neurodegenerative disease data generation conditioned on multiple time-dependent ordinal factors, such as age and disease severity. Our method sequentially generates continuous data by bridging gaps between sparse data points with a diffusion model, ensuring a realistic representation of disease progression. The synthetic data are curated to integrate both cohort-level and individual-specific characteristics, where the cohort-level representations are modeled with an ordinal regression to capture longitudinally monotonic behavior. Extensive experiments on four AD biomarkers validate the superiority of our method over nine baseline approaches, highlighting its potential to be applied to a variety of longitudinal data generation.",
    "keywords": "neurodegenerative disease, conditional diffusion model, longitudinal data analysis",
    "pdf_url": "https://openreview.net/pdf?id=9UGfOJBuL8",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on modeling and generating longitudinal data for neurodegenerative disease progression—specifically Alzheimer’s disease biomarkers and disease severity—using conditional diffusion and ordinal regression. It directly addresses a biomedical problem (disease progression modeling, early detection, AD biomarkers), making it clearly relevant to Healthcare/​Biomedicine AI.",
    "prompt_tokens": 20564,
    "completion_tokens": 113,
    "total_tokens": 20677,
    "topic": "Neurodegenerative Disorders - Longitudinal Data Generation",
    "method": "Conditional Diffusion model; Ordinal Regression",
    "application": "Longitudinal data synthesis – Alzheimer’s Disease progression",
    "code_link": "https://github.com/Hannah37/ConDOR-ICLR25",
    "dataset_name": [
      "ADNI",
      "OASIS"
    ]
  },
  {
    "id": "61ss5RA1MM",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Training Free Guided Flow-Matching with Optimal Control",
    "authors": [
      "Luran Wang",
      "Chaoran Cheng",
      "Yizhen Liao",
      "Yanru Qu",
      "Ge Liu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Controlled generation with pre-trained Diffusion and Flow Matching models has vast applications. One strategy for guiding ODE-based generative models is through optimizing a target loss $R(x_1)$ while staying close to the prior distribution. Along this line, some recent work showed the effectiveness of guiding flow model by differentiating through its ODE sampling process. Despite the superior performance, the theoretical understanding of this line of methods is still preliminary, leaving space for algorithm improvement. Moreover, existing methods predominately focus on Euclidean data manifold, and there is a compelling need for guided flow methods on complex geometries such as SO(3), which prevails in high-stake scientific applications like protein design. We present OC-Flow, a general and theoretically grounded training-free framework for guided flow matching using optimal control. Building upon advances in optimal control theory, we develop effective and practical algorithms for solving optimal control in guided ODE-based generation and provide a systematic theoretical analysis of the convergence guarantee in both Euclidean and SO(3). We show that existing backprop-through-ODE methods can be interpreted as special cases of Euclidean OC-Flow. OC-Flow achieved superior performance in extensive experiments on text-guided image manipulation, conditional molecule generation, and all-atom peptide design.",
    "keywords": "flow matching, controlled generation, inverse problem",
    "pdf_url": "https://openreview.net/pdf?id=61ss5RA1MM",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: Although the paper focuses on a general optimal‐control framework for guided flow matching, its applications include “conditional molecule generation” and “all-atom peptide design,” which are clear instances of molecular and protein design—strongly aligned with biomedicine AI (e.g., drug discovery and protein engineering).",
    "prompt_tokens": 20780,
    "completion_tokens": 91,
    "total_tokens": 20871,
    "topic": "Generative Modeling - Optimal Control",
    "method": "Optimal control framework; guided flow matching; vector-Jacobian product",
    "application": "Peptide design; molecule generation",
    "code_link": "N/A",
    "dataset_name": [
      "QM9"
    ]
  },
  {
    "id": "kSISSDUYFh",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Beyond single neurons: population response geometry in digital twins of mouse visual cortex",
    "authors": [
      "Dario Liscai",
      "Emanuele Luconi",
      "Alessandro Marin Vargas",
      "Alessandro Sanzeni"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Hierarchical visual processing  is essential for cognitive functions like object recognition and spatial localization. Traditional studies of the neural basis of these computations have focused on single-neuron activity, but recent advances in large-scale neural recordings emphasize the growing need to understand computations at the population level. Digital twins-computational models trained on neural data-have successfully replicated single-neuron behavior, but their effectiveness in capturing the joint activity of neurons remains unclear. In this study, we investigate how well digital twins describe population responses in  mouse visual cortex. We show that these models fail to accurately represent the geometry of  population activity, particularly its differentiability and how this geometry evolves across the visual hierarchy. To address this, we explore how dataset, network architecture, loss function, and training method affect the ability of digital twins to recapitulate population properties. We demonstrate that improving model alignment with experiments requires training strategies that enhance robustness and generalization, reflecting principles observed in biological systems. These findings underscore the need to evaluate digital twins from multiple perspectives, identify key areas for refinement, and establish a foundation for using these models to explore neural computations at the population level.",
    "keywords": "neuroscience, representation learning, population responses, cortical hierarchy, computational biology, visual perception",
    "pdf_url": "https://openreview.net/pdf?id=kSISSDUYFh",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work focuses on digital‐twin models of mouse visual cortex population responses—a clear instance of neurobiological modeling. Although it does not address a clinical disease or patient data, it falls under the umbrella of biomedical research (“neuroscience or neurobiological modeling: … neural system dynamics”), aligning with Biomedicine AI.",
    "prompt_tokens": 20871,
    "completion_tokens": 100,
    "total_tokens": 20971,
    "topic": "Neuroscience - Population Dynamics",
    "method": "Digital Twin Modeling; 3D Convolutional Networks; Transformer-based models",
    "application": "Neural activity prediction – mouse visual cortex",
    "code_link": "N/A",
    "dataset_name": [
      "MICrONS",
      "SENSORIUM"
    ]
  },
  {
    "id": "k2uUeLCrQq",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "RelCon: Relative Contrastive Learning for a Motion Foundation Model for Wearable Data",
    "authors": [
      "Maxwell A Xu",
      "Jaya Narain",
      "Gregory Darnell",
      "Haraldur T Hallgrimsson",
      "Hyewon Jeong",
      "Darren Forde",
      "Richard Andres Fineman",
      "Karthik Jayaraman Raghuram",
      "James Matthew Rehg",
      "Shirley You Ren"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We present RelCon, a novel self-supervised Relative Contrastive learning approach for training a motion foundation model from wearable accelerometry sensors. First, a learnable distance measure is trained to capture motif similarity and domain-specific semantic information such as rotation invariance. Then, the learned distance provides a measurement of semantic similarity between a pair of accelerometry time-series, which we use to train our foundation model to model relative relationships across time and across subjects. The foundation model is trained on 1 billion segments from 87,376 participants, and achieves strong performance across multiple downstream tasks, including human activity recognition and gait metric regression. To our knowledge, we are the first to show the generalizability of a foundation model with motion data from wearables across distinct evaluation tasks.",
    "keywords": "imu, har, biosignals, activity classification, gait metrics, time-series, foundation model, contrastive learning, self-supervised learning",
    "pdf_url": "https://openreview.net/pdf?id=k2uUeLCrQq",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on learning representations from wearable accelerometry sensors and evaluates on gait metric regression—tasks commonly tied to health and mobility monitoring. It leverages wearable-based biosignals (IMU data) for human activity recognition and physiological metric estimation, which falls under Healthcare AI’s domain of wearable sensor–based health monitoring.",
    "prompt_tokens": 20430,
    "completion_tokens": 119,
    "total_tokens": 20549,
    "topic": "Wearables - Foundation Model",
    "method": "Relative contrastive loss; motif-based distance measure",
    "application": "Human activity recognition; gait metric regression",
    "code_link": "https://github.com/maxxu05/relcon",
    "dataset_name": [
      "Apple Heart and Movement Study (AHMS)",
      "Opportunity",
      "PAMAP2",
      "HHAR",
      "Motionsense"
    ]
  },
  {
    "id": "F4IMiNhim1",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Regulatory DNA Sequence Design with Reinforcement Learning",
    "authors": [
      "Zhao Yang",
      "Bing Su",
      "Chuan Cao",
      "Ji-Rong Wen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "$\\textit{Cis}$-regulatory elements (CREs), such as promoters and enhancers, are relatively short DNA sequences that directly regulate gene expression. The fitness of CREs, measured by their ability to modulate gene expression, highly depends on the nucleotide sequences, especially specific motifs known as transcription factor binding sites (TFBSs). Designing high-fitness CREs is crucial for therapeutic and bioengineering applications. Current CRE design methods are limited by two major drawbacks: (1) they typically rely on iterative optimization strategies that modify existing sequences and are prone to local optima, and (2) they lack the guidance of biological prior knowledge in sequence optimization. In this paper, we address these limitations by proposing a generative approach that leverages reinforcement learning (RL) to fine-tune a pre-trained autoregressive (AR) model. Our method incorporates data-driven biological priors by deriving computational inference-based rewards that simulate the addition of activator TFBSs and removal of repressor TFBSs, which are then integrated into the RL process. We evaluate our method on promoter design tasks in two yeast media conditions and enhancer design tasks for three human cell types, demonstrating its ability to generate high-fitness CREs while maintaining sequence diversity. The code is available at https://github.com/yangzhao1230/TACO.",
    "keywords": "sequence optimize, generative models, ai4science, dna, rl",
    "pdf_url": "https://openreview.net/pdf?id=F4IMiNhim1",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on designing cis-regulatory DNA elements (promoters and enhancers) and leverages transcription factor binding site inference for “therapeutic and bioengineering applications.” This falls squarely into biomedicine AI, as it addresses sequence optimization in genomics and synthetic biology with potential therapeutic aims.",
    "prompt_tokens": 20664,
    "completion_tokens": 151,
    "total_tokens": 20815,
    "topic": "Bioinformatics - CRE Design",
    "method": "Reinforcement Learning; Autoregressive DNA Models; TFBS-guided optimization",
    "application": "Synthetic CRE fitness optimization",
    "code_link": "https://github.com/yangzhao1230/TACO",
    "dataset_name": [
      "Yeast Promoter Dataset - Complex",
      "Yeast Promoter Dataset - Defined",
      "Human Enhancer Dataset - HepG2",
      "Human Enhancer Dataset - K562",
      "Human Enhancer Dataset - SK-N-SH"
    ]
  },
  {
    "id": "g3xuCtrG6H",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "A Computational Framework for Modeling Emergence of Color Vision in the Human Brain",
    "authors": [
      "Atsunobu Kotani",
      "Ren Ng"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "It is a mystery how the brain decodes color vision purely from the optic nerve signals it receives, with a core inferential challenge being how it disentangles internal perception with the correct color dimensionality from the unknown encoding properties of the eye. \nIn this paper, we introduce a computational framework for modeling this emergence of human color vision by simulating both the eye and the cortex. Existing research often overlooks how the cortex develops color vision or represents color space internally, assuming that the color dimensionality is known a priori; however, we argue that the visual cortex has the capability and the challenge of inferring the color dimensionality purely from fluctuations in the optic nerve signals. To validate our theory, we introduce a simulation engine for biological eyes based on established vision science and generate optic nerve signals resulting from looking at natural images. Further, we propose a bio-plausible model of cortical learning based on self-supervised prediction of optic nerve signal fluctuations under natural eye motions. We show that this model naturally learns to generate color vision by disentangling retinal invariants from the sensory signals. When the retina contains $N$ types of color photoreceptors, our simulation shows that $N$-dimensional color vision naturally emerges, verified through formal colorimetry. Using this framework, we also present the first simulation work that successfully boosts the color dimensionality, as observed in gene therapy on squirrel monkeys, and demonstrates the possibility of enhancing human color vision from 3D to 4D.",
    "keywords": "color vision, computational neuroscience, retina simulation, cortical learning, self-supervised learning, color blindness",
    "pdf_url": "https://openreview.net/pdf?id=g3xuCtrG6H",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: This work sits squarely in computational neuroscience and neurobiological modeling, as it simulates the biological retina and cortical learning of color vision. The abstract discusses “simulating both the eye and the cortex,” “optic nerve signals,” and even references “gene therapy on squirrel monkeys” and “color blindness,” all of which are strong indicators of a biomedicine/neuroscience application rather than a purely technical ML contribution.",
    "prompt_tokens": 39158,
    "completion_tokens": 112,
    "total_tokens": 39270,
    "topic": "Computational Neuroscience - Color Vision Models",
    "method": "Self-supervised learning; computational simulation",
    "application": "Color vision modeling in the human brain",
    "code_link": "https://matisse.eecs.berkeley.edu",
    "dataset_name": [
      "N/A"
    ]
  },
  {
    "id": "yb4QE6b22f",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Scaling Wearable Foundation Models",
    "authors": [
      "Girish Narayanswamy",
      "Xin Liu",
      "Kumar Ayush",
      "Yuzhe Yang",
      "Xuhai Xu",
      "shun liao",
      "Jake Garrison",
      "Shyam A. Tailor",
      "Jacob Sunshine",
      "Yun Liu",
      "Tim Althoff",
      "Shrikanth Narayanan",
      "Pushmeet Kohli",
      "Jiening Zhan",
      "Mark Malhotra",
      "Shwetak Patel",
      "Samy Abdel-Ghaffar",
      "Daniel McDuff"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Wearable sensors have become ubiquitous thanks to a variety of health tracking features. The resulting continuous and longitudinal measurements from everyday life generate large volumes of data. However, making sense of these observations for scientific and actionable insights is non-trivial. Inspired by the empirical success of generative modeling, where large neural networks learn powerful representations from vast amounts of text, image, video, or audio data, we investigate the scaling properties of wearable sensor foundation models across compute, data, and model size. Using a dataset of up to 40 million hours of in-situ heart rate, heart rate variability, accelerometer, electrodermal activity, skin temperature, and altimeter per-minute data from over 165,000 people, we create LSM, a multimodal foundation model built on the largest wearable-signals dataset with the most extensive range of sensor modalities to date. Our results establish the scaling laws of LSM for tasks such as imputation, interpolation and extrapolation across both time and sensor modalities. Moreover, we highlight how LSM enables sample-efficient downstream learning for tasks including exercise and activity recognition.",
    "keywords": "Health, Foundation Model, Scaling, Wearables, Sensors",
    "pdf_url": "https://openreview.net/pdf?id=yb4QE6b22f",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper centers on large-scale modeling of wearable sensor data—heart rate, heart rate variability, electrodermal activity, skin temperature, accelerometry—which are quintessential biomedical signals used in patient and wellness monitoring. It explicitly targets health-related tasks like exercise and activity recognition and imputation of missing physiological measurements. These aspects firmly place it in the Healthcare AI domain.",
    "prompt_tokens": 20592,
    "completion_tokens": 103,
    "total_tokens": 20695,
    "topic": "Wearables - Sensor Modeling",
    "method": "Masked autoencoder; SimCLR; Masked Siamese Network",
    "application": "Activity recognition; Exercise detection",
    "code_link": "https://github.com/google-research/scenic",
    "dataset_name": [
      "Fitbit Sense 2",
      "Google Pixel Watch 2"
    ]
  },
  {
    "id": "CsOIYMOZaV",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "CFD: Learning Generalized Molecular Representation via Concept-Enhanced  Feedback Disentanglement",
    "authors": [
      "Aming WU",
      "Cheng Deng"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "To accelerate biochemical research, e.g., drug and protein discovery, molecular representation learning (MRL) has attracted much attention. However, most existing methods follow the closed-set assumption that training and testing data share identical distribution, which limits their generalization abilities in out-of-distribution (OOD) cases. In this paper, we explore designing a new disentangled mechanism for learning generalized molecular representation that exhibits robustness against distribution shifts. And an approach of Concept-Enhanced Feedback Disentanglement (CFD) is proposed, whose goal is to exploit the feedback mechanism to learn distribution-agnostic representation. Specifically, we first propose two dedicated variational encoders to separately decompose distribution-agnostic and spurious features. Then, a set of molecule-aware concepts are tapped to focus on invariant substructure characteristics. By fusing these concepts into the disentangled distribution-agnostic features, the generalization ability of the learned molecular representation could be further enhanced. Next, we execute iteratively the disentangled operations based on a feedback received from the previous output. Finally, based on the outputs of multiple feedback iterations, we construct a self-supervised objective to promote the variational encoders to possess the disentangled capability. In the experiments, our method is verified on multiple real-world molecular datasets. The significant performance gains over state-of-the-art baselines demonstrate that our method can effectively disentangle generalized molecular representation in the presence of various distribution shifts. The source code will be released at https://github.com/AmingWu/MoleculeCFD.",
    "keywords": "Molecular Representation, Generalization, Feedback Disentanglement, Concepts",
    "pdf_url": "https://openreview.net/pdf?id=CsOIYMOZaV",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper targets molecular representation learning “to accelerate biochemical research, e.g., drug and protein discovery,” which falls squarely under Biomedicine AI. It addresses molecular‐level tasks (drug discovery, protein design) and develops specialized graph‐based encoders and disentanglement techniques for out‐of‐distribution generalization in molecular datasets, indicating a clear biomedical application.",
    "prompt_tokens": 20523,
    "completion_tokens": 124,
    "total_tokens": 20647,
    "topic": "Drug Discovery - Representation Learning",
    "method": "Concept-Enhanced Feedback Disentanglement",
    "application": "Molecular representation learning under distribution shifts",
    "code_link": "https://github.com/AmingWu/MoleculeCFD",
    "dataset_name": [
      "GOOD-HIV",
      "GOOD-ZINC",
      "GOOD-PCBA",
      "DrugOOD",
      "Molecule3D",
      "QM9"
    ]
  },
  {
    "id": "awWiNvQwf3",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Efficient Evolutionary Search Over Chemical Space with Large Language Models",
    "authors": [
      "Haorui Wang",
      "Marta Skreta",
      "Cher Tian Ser",
      "Wenhao Gao",
      "Lingkai Kong",
      "Felix Strieth-Kalthoff",
      "Chenru Duan",
      "Yuchen Zhuang",
      "Yue Yu",
      "Yanqiao Zhu",
      "Yuanqi Du",
      "Alan Aspuru-Guzik",
      "Kirill Neklyudov",
      "Chao Zhang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Molecular discovery, when formulated as an optimization problem, presents significant computational challenges because optimization objectives can be non-differentiable. Evolutionary Algorithms (EAs), often used to optimize black-box objectives in molecular discovery, traverse chemical space by performing random mutations and crossovers, leading to a large number of expensive objective evaluations. In this work, we ameliorate this shortcoming by incorporating chemistry-aware Large Language Models (LLMs) into EAs. Namely, we redesign crossover and mutation operations in EAs using LLMs trained on large corpora of chemical information. We perform extensive empirical studies on both commercial and open-source models on multiple tasks involving property optimization, molecular rediscovery, and structure-based drug design, demonstrating that the joint usage of LLMs with EAs yields superior performance over all baseline models across single- and multi-objective settings. We demonstrate that our algorithm improves both the quality of the final solution and convergence speed, thereby reducing the number of required objective evaluations.",
    "keywords": "Large Language Models, Evolutionary Search, Molecule Optimization, AI for Science, Molecular generation",
    "pdf_url": "https://openreview.net/pdf?id=awWiNvQwf3",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on molecular discovery and explicitly mentions “structure-based drug design,” a core task in drug discovery. Drug discovery is a recognized subfield of Biomedicine AI, as it directly supports the development of therapeutic compounds.",
    "prompt_tokens": 20646,
    "completion_tokens": 112,
    "total_tokens": 20758,
    "topic": "Drug Discovery - Molecular Optimization",
    "method": "Evolutionary Algorithms (EA) with LLM-based Genetic Operators",
    "application": "Molecular optimization and property prediction",
    "code_link": "https://github.com/zoom-wang112358/MOLLEO",
    "dataset_name": [
      "TDC",
      "PMO",
      "ZINC 250K"
    ]
  },
  {
    "id": "uvHmnahyp1",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "SynFlowNet: Design of Diverse and Novel Molecules with Synthesis Constraints",
    "authors": [
      "Miruna Cretu",
      "Charles Harris",
      "Ilia Igashov",
      "Arne Schneuing",
      "Marwin Segler",
      "Bruno Correia",
      "Julien Roy",
      "Emmanuel Bengio",
      "Pietro Lio"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Generative models see increasing use in computer-aided drug design. However, while performing well at capturing distributions of molecular motifs, they often produce synthetically inaccessible molecules. To address this, we introduce SynFlowNet, a GFlowNet model whose action space uses chemical reactions and buyable reactants to sequentially build new molecules. By incorporating forward synthesis as an explicit constraint of the generative mechanism, we aim at bridging the gap between in silico molecular generation and real world synthesis capabilities. We evaluate our approach using synthetic accessibility scores and an independent retrosynthesis tool to assess the synthesizability of our compounds, and motivate the choice of GFlowNets through considerable improvement in sample diversity compared to baselines. Additionally, we identify challenges with reaction encodings that can complicate traversal of the MDP in the backward direction. To address this, we introduce various strategies for learning the GFlowNet backward policy and thus demonstrate how additional constraints can be integrated into the GFlowNet MDP framework. This approach enables our model to successfully identify synthesis pathways for previously unseen molecules.",
    "keywords": "GFlowNets, de novo molecular generation, synthesizable molecular design",
    "pdf_url": "https://openreview.net/pdf?id=uvHmnahyp1",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on de novo molecular generation within \"computer-aided drug design,\" develops methods for generating synthesizable drug-like molecules, and evaluates compounds using synthetic accessibility and retrosynthesis tools. These are core tasks in drug discovery, situating the work squarely in the Biomedicine AI domain.",
    "prompt_tokens": 20697,
    "completion_tokens": 105,
    "total_tokens": 20802,
    "topic": "Drug Discovery - Synthesis Constraints",
    "method": "GFlowNets; message-passing neural networks",
    "application": "Synthesis-constrained molecule generation",
    "code_link": "https://github.com/mirunacrt/synflownet",
    "dataset_name": [
      "Enamine",
      "ChEMBL"
    ]
  },
  {
    "id": "hwnObmOTrV",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Modeling Complex System Dynamics with Flow Matching Across Time and Conditions",
    "authors": [
      "Martin Rohbeck",
      "Edward De Brouwer",
      "Charlotte Bunne",
      "Jan-Christian Huetter",
      "Anne Biton",
      "Kelvin Y. Chen",
      "Aviv Regev",
      "Romain Lopez"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Modeling the dynamics of complex real-world systems from temporal snapshot data is crucial for understanding phenomena such as gene regulation, climate change, and financial market fluctuations. Researchers have recently proposed a few methods based either on the Schroedinger Bridge or Flow Matching to tackle this problem, but these approaches remain limited in their ability to effectively combine data from multiple time points and different experimental settings. This integration is essential in real-world scenarios where observations from certain combinations of time points and experimental conditions are missing, either because of experimental costs or sensory failure. To address this challenge, we propose a novel method named Multi-Marginal Flow Matching (MMFM). MMFM first constructs a flow using smooth spline-based interpolation across time points and conditions and regresses it with a neural network using the classifier-free guided Flow Matching framework. This framework allows for the sharing of contextual information about the dynamics across multiple trajectories. We demonstrate the effectiveness of our method on both synthetic and real-world datasets, including a recent single-cell genomics data set with around a hundred chemical perturbations across time points. Our results show that MMFM significantly outperforms existing methods at imputing data at missing time points.",
    "keywords": "Flow Matching, dynamical systems",
    "pdf_url": "https://openreview.net/pdf?id=hwnObmOTrV",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The method is demonstrated on real-world single-cell genomics data with chemical perturbations to model gene regulation dynamics. References to “gene regulation,” “single-cell genomics,” and “chemical perturbations” indicate a clear biomedical application.",
    "prompt_tokens": 21123,
    "completion_tokens": 113,
    "total_tokens": 21236,
    "topic": "Bioinformatics - Gene regulation temporal modeling",
    "method": "Multi-marginal flow matching; Neural network regression; Spline-based interpolation",
    "application": "Cell state trajectory prediction – Single-cell genomics",
    "code_link": "https://github.com/Genentech/MMFM",
    "dataset_name": [
      "Synthetic dataset",
      "Single-cell perturbation screening dataset"
    ]
  },
  {
    "id": "zZ6TT254Np",
    "year": 2025,
    "conference": "ICLR (International Conference on Learning Representations)",
    "title": "Synthesizing Realistic fMRI: A Physiological Dynamics-Driven Hierarchical Diffusion Model for Efficient fMRI Acquisition",
    "authors": [
      "Yufan Hu",
      "Yujiang",
      "Wuyang Li",
      "Yixuan Yuan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Functional magnetic resonance imaging (fMRI) is essential for mapping brain activity but faces challenges like lengthy acquisition time and sensitivity to patient movement, limiting its clinical and machine learning applications. While generative models such as diffusion models can synthesize fMRI signals to alleviate these issues, they often underperform due to neglecting the brain's complex structural and dynamic properties.\nTo address these limitations, we propose the Physiological Dynamics-Driven Hierarchical Diffusion Model, a novel framework integrating two key brain physiological properties into the diffusion process: brain hierarchical regional interactions and multifractal dynamics. \nTo model complex interactions among brain regions, we construct hypergraphs based on the prior knowledge of brain functional parcellation reflected by resting-state functional connectivity (rsFC). This enables the aggregation of fMRI signals across multiple scales and generates hierarchical signals. \nAdditionally, by incorporating the prediction of two key dynamics properties of fMRI—the multifractal spectrum and generalized Hurst exponent—our framework effectively guides the diffusion process, ensuring the preservation of the scale-invariant characteristics inherent in real fMRI data.\nOur framework employs progressive diffusion generation, with signals representing broader brain region information conditioning those that capture localized details, and unifies multiple inputs during denoising for balanced integration.\nExperiments demonstrate that our model generates physiologically realistic fMRI signals, potentially reducing acquisition time and enhancing data quality, benefiting clinical diagnostics and machine learning in neuroscience.",
    "keywords": "Time Series, Diffusion",
    "pdf_url": "https://openreview.net/pdf?id=zZ6TT254Np",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on synthesizing and enhancing fMRI signals, which are a key medical imaging modality for brain activity mapping and clinical diagnostics. Terms like “fMRI acquisition,” “brain functional parcellation,” and potential benefits for “clinical diagnostics and machine learning in neuroscience” clearly situate it in the Healthcare/Biomedicine AI domain.",
    "prompt_tokens": 20722,
    "completion_tokens": 116,
    "total_tokens": 20838,
    "topic": "Medical Imaging - fMRI Signal Generation",
    "method": "Diffusion model; hypergraph-based hierarchical signal modeling; multifractal analysis",
    "application": "fMRI signal generation and imputation",
    "code_link": "https://github.com/CUHK-AIM-Group/PDH-Diffusion",
    "dataset_name": [
      "Human Connectome Project (HCP)"
    ]
  }
]
