[
  {
    "id": "rbr2mMSBua",
    "title": "SAM2Flow: Interactive Optical Flow Estimation with Dual Memory for in vivo Microcirculation Analysis",
    "authors": [
      "Luojie Huang",
      "Ryan Zhang",
      "Marisa M Morakis",
      "Michaela Taylor-Williams",
      "Gregory N. McKay",
      "Nicholas J. Durr"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Analysis of noninvasive microvascular blood flow can improve the diagnosis, prognosis, and management of many medical conditions, including cardiovascular, peripheral vascular, and sickle cell disease. This paper introduces SAM2Flow, an interactive optical flow estimation model to analyze long Oblique Back-illumination Microscopy (OBM) videos of *in vivo* microvascular flow. Inspired by the Segment Anything Model (SAM2), SAM2Flow enables users to specify regions of interest through user prompts for focused flow estimation. \nSAM2Flow also incorporates a dual memory attention mechanism, comprising both motion and context memory, to achieve efficient and stable flow estimations over extended video sequences. According to our experiments, SAM2Flow achieves SOTA accuracy in foreground optical flow estimation on both microvascular flow and public datasets, with a fast inference speed of over $20$ fps on $512\\times512$ inputs. Based on the temporally robust flow estimation, SAM2Flow demonstrated superior performance in downstream physiological applications compared to existing models. The code and dataset will be published with this paper.",
    "keywords": [
      "Optical Flow Estimation",
      "Microscopic Blood Cell Analysis",
      "Segment Anything Model"
    ],
    "pdf_url": "https://openreview.net/pdf?id=rbr2mMSBua",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper introduces a model, SAM2Flow, designed for analyzing microvascular blood flow using optical flow estimation. The abstract explicitly mentions applications in diagnosing and managing medical conditions related to microcirculation, such as cardiovascular diseases, peripheral vascular diseases, and sickle cell disease. Furthermore, the method is applied to *in vivo* microvascular flow analysis, which is directly relevant to healthcare and biomedicine. The involvement of medical conditions and physiological applications strongly indicates relevance to both Healthcare AI and Biomedicine AI domains. Keywords like \"Microscopic Blood Cell Analysis\" and the paper's focus on improving diagnosis and prognosis further reinforce its classification.",
    "prompt_tokens": 22293,
    "completion_tokens": 215,
    "total_tokens": 22508,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Other Imaging Modalities"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Optical Flow estimation; Dual memory mechanism",
    "application": "Microvascular flow estimation",
    "code_link": "https://github.com/DurrLab/SAM2Flow",
    "dataset_name": [
      "OBM Microvascular Videos Dataset",
      "Spring Dataset"
    ]
  },
  {
    "id": "nsv3ogqRIU",
    "title": "Adaptive Latent-Space Constraints in Personalized Federated Learning",
    "authors": [
      "Sana Ayromlou",
      "D. B. Emerson"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Federated learning (FL) is an effective and widely used approach to training deep learning models on decentralized datasets held by distinct clients. FL also strengthens both security and privacy protections for training data. Common challenges associated with statistical heterogeneity between distributed datasets have spurred significant interest in personalized FL (pFL) methods, where models combine aspects of global learning with local modeling specific to each client’s unique characteristics. This work investigates the efficacy of theoretically supported, adaptive MMD measures in pFL, primarily focusing on the Ditto framework, a state-of-the-art technique for distributed data heterogeneity. The use of such measures significantly improves model performance across a variety of tasks, especially those with pronounced feature heterogeneity. Additional experiments demonstrate that such measures are directly applicable to other pFL techniques and yield similar improvements across a number of datasets. Finally, the results motivate the use of constraints tailored to the various kinds of heterogeneity expected in FL systems.",
    "keywords": [
      "Federated Learning",
      "Maximum Mean Discrepancy",
      "Data Heterogeneity",
      "Deep Learning",
      "Medical Imaging"
    ],
    "pdf_url": "https://openreview.net/pdf?id=nsv3ogqRIU",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract explicitly mentions \"medical imaging\" as one of the application contexts, which is strong evidence of relevance to Healthcare or Biomedicine AI. Medical imaging pertains to the analysis of health-related datasets, aligning directly with the scope of Healthcare AI and Biomedicine AI. Furthermore, the study explores federated learning methods, which are particularly valuable in privacy-preserving contexts often required in healthcare and biomedical domains, further underscoring its applicability to these fields.",
    "prompt_tokens": 22510,
    "completion_tokens": 212,
    "total_tokens": 22722,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Digital Pathology"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Federated Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Multi-Kernel Maximum Mean Discrepancy (MK-MMD); Adaptive Regularization",
    "application": "Melanoma classification; Genetic treatment classification",
    "code_link": "N/A",
    "dataset_name": [
      "Fed-ISIC2019",
      "RxRx1",
      "Synthetic"
    ]
  },
  {
    "id": "FAiIRMvIwy",
    "title": "DesignX: Human-Competitive Algorithm Designer for Black-Box Optimization",
    "authors": [
      "Hongshu Guo",
      "Zeyuan Ma",
      "Yining Ma",
      "Xinglin Zhang",
      "Wei-Neng Chen",
      "Yue-Jiao Gong"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Designing effective black‑box optimizers is hampered by limited problem-specific knowledge and manual control that spans months for almost every detail. In this paper, we present DesignX, the first automated algorithm design framework that generates an effective optimizer specific to a given black-box optimization problem within seconds. Rooted in the first principles, we identify two key sub-tasks: 1) algorithm structure generation and 2) hyperparameter control. To enable systematic construction, a comprehensive modular algorithmic space is first built, embracing hundreds of algorithm components collected from decades of research. We then introduce a dual-agent reinforcement learning system that collaborates on structural and parametric design through a novel cooperative training objective, enabling large-scale meta-training across 10k diverse instances. Remarkably, through days of autonomous learning, the DesignX-generated optimizers continuously surpass human-crafted optimizers by orders of magnitude, either on synthetic testbed or on realistic optimization scenarios such as Protein-docking, AutoML and UAV path planning. Further in-depth analysis reveals DesignX's capability to discover non-trivial algorithm patterns beyond expert intuition, which, conversely, provides valuable design insights for the optimization community. We provide DesignX's Python project at~\\url{https://github.com/MetaEvo/DesignX}.",
    "keywords": [
      "Automated Algorithm Design",
      "Black-Box-Optimization",
      "Meta-Black-Box Optimization",
      "Learning to Optimize",
      "Deep Reinforcement Learning"
    ],
    "pdf_url": "https://openreview.net/pdf?id=FAiIRMvIwy",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses the application of its automated algorithm design framework, DesignX, in black-box optimization tasks such as protein-docking, a problem directly related to biomedicine AI. Protein-docking is integral to drug discovery and molecular modeling in biomedical research, as it helps predict how molecules, such as proteins, interact—a key step in understanding biological mechanisms and designing therapeutics. Additionally, its capacity to generate optimizers for AutoML and UAV path planning is mentioned, but the specific reference to protein-docking uniquely connects this work to biomedicine.",
    "prompt_tokens": 22249,
    "completion_tokens": 223,
    "total_tokens": 22472,
    "Topic Axis I": {
      "MainTopic": "Drug Discovery & Development",
      "SubTopic": "Target Identification & Validation"
    },
    "Topic Axis II": {
      "MainTopic": "Sequential Decision Making & Reinforcement Learning",
      "SubTopic": "Dynamic Treatment Regimes"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Transformer-based models (GPT-2); dual-agent reinforcement learning; Modular-EC system",
    "application": "Black-Box Optimization – automated algorithm design",
    "code_link": "https://anonymous.4open.science/r/DesignX-AF70/",
    "dataset_name": [
      "synthetic problem set",
      "realistic benchmarks",
      "Dtest"
    ]
  },
  {
    "id": "UAc6RL9Tt4",
    "title": "Neural-Driven Image Editing",
    "authors": [
      "Pengfei Zhou",
      "Jie Xia",
      "Xiaopeng Peng",
      "Wangbo Zhao",
      "Zilong Ye",
      "Zekai Li",
      "Suorong Yang",
      "Jiadong Pan",
      "Yuanxiang Chen",
      "Ziqiao Wang",
      "Kai Wang",
      "Qian Zheng",
      "Xiaojun Chang",
      "Gang Pan",
      "Shurong Dong",
      "Kaipeng Zhang",
      "Yang You"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Traditional image editing typically relies on manual prompting, making it labor-intensive and inaccessible to individuals with limited motor control or language abilities. Leveraging recent advances in brain-computer interfaces (BCIs) and generative models, we propose LoongX, a hands-free image editing approach driven by multimodal neurophysiological signals. \nLoongX utilizes state-of-the-art diffusion models trained on a comprehensive dataset of 23,928 image editing pairs, each paired with synchronized electroencephalography (EEG), functional near-infrared spectroscopy (fNIRS), photoplethysmography (PPG), and head motion signals that capture user intent.\nTo effectively address the heterogeneity of these signals, LoongX integrates two key modules. The cross-scale state space (CS3) module encodes informative modality-specific features. The dynamic gated fusion (DGF) module further aggregates these features into a unified latent space, which is then aligned with edit semantics via fine-tuning on a diffusion transformer (DiT).\nAdditionally, we pre-train the encoders using contrastive learning to align cognitive states with semantic intentions from embedded natural language.\nExtensive experiments demonstrate that LoongX achieves performance comparable to text-driven methods (CLIP-I: 0.6605 vs. 0.6558; DINO: 0.4812 vs. 0.4637) and outperforms them when neural signals are combined with speech (CLIP-T: 0.2588 vs. 0.2549). These results highlight the promise of neural-driven generative models in enabling accessible, intuitive image editing and open new directions for cognitive-driven creative technologies. The code and dataset are released on the project website: https://loongx1.github.io.",
    "keywords": [
      "Brain-Computer Interface",
      "Image Editing",
      "Visual Generation",
      "Generative Models",
      "Diffusion Models"
    ],
    "pdf_url": "https://openreview.net/pdf?id=UAc6RL9Tt4",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses the utilization of multimodal neurophysiological signals, including electroencephalography (EEG), functional near-infrared spectroscopy (fNIRS), and photoplethysmography (PPG). These signals are commonly associated with neuroscience and biomedical applications, as they are extensively used in brain-computer interfaces (BCIs) for tasks such as neural signal decoding, which often have significant relevance in healthcare and biomedicine contexts (e.g., rehabilitation technologies, assisting individuals with limited motor control). While the primary application described in the paper focuses on image editing, the development and use of BCIs inherently align with topics in neuroscience and therapeutic technologies. Additionally, the inclusion of signals like EEG and fNIRS suggests connections to cognitive health and neurobiology, which are relevant to Biomedicine AI.",
    "prompt_tokens": 22453,
    "completion_tokens": 194,
    "total_tokens": 22647,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Other Imaging Modalities"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Diffusion Models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-Neural Fusion Process Transparency"
    },
    "method": "Cross-Scale State Space encoder (CS3); Dynamic Gated Fusion; Diffusion transformer (DiT)",
    "application": "Image editing tasks",
    "code_link": "N/A",
    "dataset_name": [
      "L-Mind"
    ]
  },
  {
    "id": "L8pbQy0SsG",
    "title": "Are Pixel-Wise Metrics Reliable for Computerized Tomography Reconstruction?",
    "authors": [
      "Tianyu Lin",
      "Xinran Li",
      "Chuntung Zhuang",
      "Qi Chen",
      "Yuanhao Cai",
      "Kai Ding",
      "Alan Yuille",
      "Zongwei Zhou"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Widely adopted evaluation metrics for sparse-view CT reconstruction, such as Structural Similarity Index Measure and Peak Signal-to-Noise Ratio, prioritize pixel-wise fidelity but often fail to capture the completeness of critical anatomical structures, particularly small or thin regions that are easily missed. To address this limitation, we propose a suite of novel anatomy-aware evaluation metrics designed to assess structural completeness across anatomical structures, including large organs, small organs, intestines, and vessels. Building on these metrics, we introduce CARE, a Completeness-Aware Reconstruction Enhancement framework that incorporates structural penalties during training to encourage anatomical preservation of significant structures. CARE is model-agnostic and can be seamlessly integrated into analytical, implicit, and generative methods. \nWhen applied to these methods, CARE substantially improves structural completeness in CT reconstructions, achieving up to **32%** improvement for large organs, **22%** for small organs, **40%** for intestines, and **36%** for vessels.",
    "keywords": [
      "Reconstruction",
      "Diffusion Model"
    ],
    "pdf_url": "https://openreview.net/pdf?id=L8pbQy0SsG",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on computerized tomography (CT) reconstruction, a critical task in medical imaging primarily used in healthcare for diagnostic and treatment planning purposes. The abstract explicitly mentions the importance of preserving \"anatomical structures\" such as \"large organs,\" \"small organs,\" \"intestines,\" and \"vessels,\" which are all essential to clinical and biomedical applications. Additionally, the proposed method (CARE) addresses the structural integrity of these anatomical features during CT reconstruction. The emphasis on improving the quality of medical imaging directly aligns with the goals of Healthcare AI and Biomedicine AI. While the paper primarily focuses on developing and assessing novel metrics and reconstruction methods, these contributions are highly relevant within the context of healthcare and biomedicine.",
    "prompt_tokens": 22188,
    "completion_tokens": 218,
    "total_tokens": 22406,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Radiology"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Diffusion Models"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Diffusion model; Anatomy-guided reconstruction; Segmentation-driven metrics",
    "application": "CT reconstruction enhancement – sparse-view settings",
    "code_link": "https://github.com/MrGiovanni/CARE",
    "dataset_name": [
      "nnU-Net",
      "JHH Dataset for CARE Pretraining"
    ]
  },
  {
    "id": "JMq90N6lLe",
    "title": "Unified all-atom molecule generation with neural fields",
    "authors": [
      "Matthieu Kirchmeyer",
      "Pedro O. Pinheiro",
      "Emma Willett",
      "Karolis Martinkus",
      "Joseph Kleinhenz",
      "Emily K. Makowski",
      "Andrew Martin Watkins",
      "Vladimir Gligorijevic",
      "Richard Bonneau",
      "Saeed Saremi"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Generative models for structure-based drug design are often limited to a specific modality, restricting their broader applicability. To address this challenge, we introduce FuncBind, a framework based on computer vision to generate target-conditioned, all-atom molecules across atomic systems. FuncBind uses neural fields to represent molecules as continuous atomic densities and employs score-based generative models with modern architectures adapted from the computer vision literature. This modality-agnostic representation allows a single unified model to be trained on diverse atomic systems, from small to large molecules, and handle variable atom/residue counts, including non-canonical amino acids. FuncBind achieves competitive in silico performance in generating small molecules, macrocyclic peptides, and antibody complementarity-determining region loops, conditioned on target structures. FuncBind also generated in vitro novel antibody binders via de novo redesign of the complementarity-determining region H3 loop of two chosen co-crystal structures. As a final contribution, we introduce a new dataset and benchmark for structure-conditioned macrocyclic peptide generation.",
    "keywords": [
      "score-based generative model",
      "neural fields",
      "3D molecule"
    ],
    "pdf_url": "https://openreview.net/pdf?id=JMq90N6lLe",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses a generative model, FuncBind, designed for \"structure-based drug design,\" which strongly links to biomedical research, particularly in areas like \"drug discovery\" and \"therapeutics.\" FuncBind is applied to the generation of molecules, including small molecules, peptides, and antibody loops, conditioned on target structures. These applications are directly relevant to biomedicine, as they contribute to the development of new drugs and antibodies. The mention of \"in vitro novel antibody binders\" and the redesign of antibody complementarity-determining regions further emphasizes therapeutic and biomedical significance. Additionally, the introduction of a benchmark for \"macrocyclic peptide generation\" ties directly to molecular modeling tasks for biomedical applications. Keywords like “drug design,” “3D molecule,” and “score-based generative model” further solidify its connection to Biomedicine AI.",
    "prompt_tokens": 21780,
    "completion_tokens": 225,
    "total_tokens": 22005,
    "Topic Axis I": {
      "MainTopic": "Drug Discovery & Development",
      "SubTopic": "De Novo Molecule Design"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Diffusion Models"
    },
    "Topic Axis III": {
      "MainTopic": "Regulatory Science & Digital Biomarkers",
      "SubTopic": "Development & Validation of Digital Biomarkers"
    },
    "method": "Latent score-based generation; neural fields; denoising diffusion",
    "application": "Macrocyclic peptides generation conditioned on protein pockets",
    "code_link": "N/A",
    "dataset_name": [
      "CrossDocked2020",
      "MCP-protein complexes"
    ]
  },
  {
    "id": "NMvMYtRjkg",
    "title": "An Investigation of Memorization Risk in Healthcare Foundation Models",
    "authors": [
      "Sana Tonekaboni",
      "Lena Stempfle",
      "Adibvafa Fallahpour",
      "Walter Gerych",
      "Marzyeh Ghassemi"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Foundation models trained on large-scale de-identified electronic health records (EHRs) hold promise for clinical applications. However, their capacity to memorize patient information raises important privacy concerns. In this work, we introduce a suite of black-box evaluation tests to assess privacy-related memorization risks in foundation models trained on structured EHR data. Our framework includes methods for probing memorization at both the embedding and generative levels, and aims to distinguish between model generalization and harmful memorization in clinically relevant settings. We contextualize memorization in terms of its potential to compromise patient privacy, particularly for vulnerable subgroups. We validate our approach on a publicly available EHR foundation model and release an open-source toolkit to facilitate reproducible and collaborative privacy assessments in healthcare AI.",
    "keywords": [
      "Healthcare",
      "evaluation",
      "foundation model",
      "memorization"
    ],
    "pdf_url": "https://openreview.net/pdf?id=NMvMYtRjkg",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly addresses the training of foundation models on de-identified electronic health records (EHRs), which are structured healthcare datasets. It also highlights privacy concerns and the evaluation of memorization risks in these models, which aligns closely with Healthcare AI as it targets clinical applications and patient privacy implications. The abstract mentions methods relevant to assessing patient data security, and the keywords include \"Healthcare\" and \"foundation model,\" further confirming the focus on AI applications in clinical contexts.",
    "prompt_tokens": 22577,
    "completion_tokens": 244,
    "total_tokens": 22821,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "EHR/EMR Predictive Modeling"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Differential Privacy"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Privacy risk evaluation; Generative memorization detection; Embedding memorization detection; Differential privacy modeling",
    "application": "Privacy assessment – EHR models",
    "code_link": "https://github.com/sanatonek/EHR-FM_memorization",
    "dataset_name": [
      "MIMIC-IV"
    ]
  },
  {
    "id": "1BAiQmAFsx",
    "title": "Walking the Tightrope: Autonomous Disentangling Beneficial and Detrimental Drifts in Non-Stationary Custom-Tuning",
    "authors": [
      "Xiaoyu Yang",
      "Jie Lu",
      "En Yu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "This paper uncovers a critical yet overlooked phenomenon in multi-modal large language models (MLLMs), especially for chest diagnosis: detrimental concept drift within chain-of-thought (CoT) reasoning during non-stationary reinforcement fine-tuning (RFT), where reasoning token distributions evolve unpredictably, thereby introducing significant biases in final predictions. To address this, we are pioneers in establishing the theoretical bridge between concept drift theory and RFT processes by formalizing CoT's autoregressive token streams as non-stationary distributions undergoing arbitrary temporal shifts. Leveraging this framework, we propose a novel autonomous counterfact-aware RFT that systematically decouples beneficial distribution adaptation from harmful concept drift through concept graph-empowered LLM experts generating counterfactual reasoning trajectories. Our solution, Counterfactual Preference Optimization (CPO), enables autonomous and stable RFT in non-stationary environments, particularly within the medical domain, through custom-tuning of counterfactual-aware preference alignment. Extensive experiments demonstrate our superior performance of robustness, generalization and coordination within RFT. Besides, we also contribute a large-scale dataset CXR-CounterFact (CCF), comprising 320,416 meticulously curated counterfactual reasoning trajectories derived from MIMIC-CXR. Our code and data are public at: https://github.com/XiaoyuYoung/CPO.",
    "keywords": [
      "Concept Drift",
      "Reinforced Fine-tuning",
      "MLLMs"
    ],
    "pdf_url": "https://openreview.net/pdf?id=1BAiQmAFsx",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly addresses \"chest diagnosis,\" which is a healthcare-related application, as indicated in the abstract. Moreover, it references the use of \"MIMIC-CXR,\" a widely known medical imaging dataset containing chest X-rays, and proposes a method for handling non-stationary fine-tuning in medical contexts. The introduction of the large-scale dataset \"CXR-CounterFact (CCF)\" further emphasizes the focus on healthcare-specific data and applications. Additionally, the Counterfactual Preference Optimization (CPO) framework is tailored to improve reasoning stability \"particularly within the medical domain.\" These indications strongly tie the research to the Healthcare AI/Biomedicine AI domain.",
    "prompt_tokens": 22068,
    "completion_tokens": 194,
    "total_tokens": 22262,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Radiology"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Counterfactual Preference Optimization",
    "application": "disease classification – chest radiographs",
    "code_link": "https://github.com/XiaoyuYoung/CPO",
    "dataset_name": [
      "MIMIC-CXR",
      "CXR-CounterFact"
    ]
  },
  {
    "id": "H2m4chAfig",
    "title": "CRRL: Learning Channel-invariant Neural Representations for High-performance Cross-day Decoding",
    "authors": [
      "Xianhan Tan",
      "Binli Luo",
      "Yu Qi",
      "Yueming Wang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Brain-computer interfaces have shown great potential in motor and speech rehabilitation, but still suffer from low performance stability across days, mostly due to the instabilities in neural signals. These instabilities, partially caused by neuron deaths and electrode shifts, leading to channel-level variabilities among different recording days. Previous studies mostly focused on aligning multi-day neural signals of onto a low-dimensional latent manifold to reduce the variabilities, while faced with difficulties when neural signals exhibit significant drift. Here, we propose to learn a channel-level invariant neural representation to address the variabilities in channels across days. It contains a channel-rearrangement module to learn stable representations against electrode shifts, and a channel reconstruction module to handle the missing neurons. The proposed method achieved the state-of-the-art performance with cross-day decoding tasks over two months, on multiple benchmark BCI datasets. The proposed approach showed good generalization ability that can be incorporated to different neural networks.",
    "keywords": [
      "Neural Decoding"
    ],
    "pdf_url": "https://openreview.net/pdf?id=H2m4chAfig",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on developing methods for cross-day decoding of neural signals, which are crucial for brain-computer interfaces (BCIs). BCIs are commonly applied in motor and speech rehabilitation, directly tying the research to healthcare and biomedical applications. The abstract explicitly mentions the use of BCIs for rehabilitation purposes, which qualifies as a healthcare-related application, as these technologies are often critical for aiding individuals with neurological or motor impairments. Furthermore, the discussion of neural signals, neuron deaths, and electrode shifts implies a relevance to neuroscience and biomedical research. Thus, this paper falls under the domain of Biomedicine AI.",
    "prompt_tokens": 22218,
    "completion_tokens": 230,
    "total_tokens": 22448,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Physiological Time Series Analysis"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Channel Rearrangement; Reconstruction Learning; Vector Quantized Variational Autoencoder (VQ-VAE)",
    "application": "Neural decoding – Brain-computer interfaces (BCI)",
    "code_link": "N/A",
    "dataset_name": [
      "Center-out reach",
      "Isometric wrist task",
      "Key grasp task"
    ]
  },
  {
    "id": "kND7h1kD53",
    "title": "DualEqui: A Dual-Space Hierarchical Equivariant Network for Large Biomolecules",
    "authors": [
      "Junjie Xu",
      "Jiahao Zhang",
      "Mangal Prakash",
      "Xiang Zhang",
      "Suhang Wang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Geometric graph neural networks (GNNs) that respect E(3) symmetries have achieved strong performance on small molecule modeling, but they face scalability and expressiveness challenges when applied to large biomolecules such as RNA and proteins. These systems require models that can simultaneously capture fine-grained atomic interactions, long-range dependencies across spatially distant components, and biologically relevant hierarchical structure—such as atoms forming residues, which in turn form higher-order domains. Existing geometric GNNs, which typically operate exclusively in either Euclidean or Spherical Harmonics space, are limited in their ability to capture both the fine-scale atomic details and the long-range, symmetry-aware dependencies required for modeling the multi-scale structure of large biomolecules. We introduce DualEquiNet, a Dual-Space Hierarchical Equivariant Network that constructs complementary representations in both Euclidean and Spherical Harmonics spaces to capture local geometry and global symmetry-aware features. DualEquiNet employs bidirectional cross-space message passing and a novel Cross-Space Interaction Pooling mechanism to hierarchically aggregate atomic features into biologically meaningful units, such as residues, enabling efficient and expressive multi-scale modeling for large biomolecular systems. DualEquiNet achieves state-of-the-art performance on multiple existing benchmarks for RNA property prediction and protein modeling, and outperforms prior methods on two newly introduced 3D structural benchmarks demonstrating its broad effectiveness across a range of large biomolecule modeling tasks.",
    "keywords": [
      "Geometric deep learning",
      "Graph Neural Networks",
      "GNNs",
      "RNA property prediction"
    ],
    "pdf_url": "https://openreview.net/pdf?id=kND7h1kD53",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on modeling large biomolecules such as RNA and proteins, which are critical to biomedical research, particularly for understanding biological processes, drug discovery, and therapeutic interventions. The introduction of DualEquiNet specifically addresses RNA property prediction and protein modeling, tasks that are directly relevant to biomedicine. These applications support advancements in areas like genomics, molecular modeling, and other biomedically relevant domains, thereby classifying the paper under Biomedicine AI. Moreover, the benchmarks used in the study further confirm its relevance to large biomolecular systems often studied in biomedicine.",
    "prompt_tokens": 22360,
    "completion_tokens": 221,
    "total_tokens": 22581,
    "Topic Axis I": {
      "MainTopic": "Computational Genomics & Multi-Omics",
      "SubTopic": "Transcriptomics"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Dual-space message passing; Spherical Harmonics representations; Equivariant learning",
    "application": "RNA property prediction; RNA torsion angle prediction",
    "code_link": "N/A",
    "dataset_name": [
      "RNAGo",
      "RNAProt",
      "CovidVaccine",
      "Ribonanza",
      "Tc-ribo"
    ]
  },
  {
    "id": "swf3Hbc3Qe",
    "title": "Learning Crossmodal Interaction Patterns via Attributed Bipartite Graphs for Single-Cell Omics",
    "authors": [
      "Xiaotang Wang",
      "Xuanwei Lin",
      "Yun Zhu",
      "Hao Li",
      "Yongqi Zhang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Crossmodal matching in single-cell omics is essential for explaining biological regulatory mechanisms and enhancing downstream analyses. However, current single-cell crossmodal models often suffer from three limitations: sparse modality signals, underutilization of biological attributes, and insufficient modeling of regulatory interactions. These challenges hinder generalization in data-scarce settings and restrict the ability to uncover fine-grained biologically meaningful crossmodal relationships. \nHere, we present a novel framework which reformulates crossmodal matching as a graph classification task on Attributed Bipartite Graphs (ABGs).  It models single-cell ATAC-RNA data as an ABG, where each expressed ATAC and RNA is treated as a distinct node with unique IDs and biological features. To model crossmodal interaction patterns on the constructed ABG, we propose $\\text{Bi}^2\\text{Former}$, a **bi**ologically-driven **bi**partite graph trans**former** that learns interpretable attention over ATAC–RNA pairs. This design enables the model to effectively learn and explain biological regulatory relationships between ATAC and RNA modalities.\nExtensive experiments demonstrate that $\\text{Bi}^2\\text{Former}$ achieves state-of-the-art performance in crossmodal matching across diverse datasets, remains robust under sparse training data, generalizes to unseen cell types and datasets, and reveals biologically meaningful regulatory patterns. \nThis work pioneers an ABG-based approach for single-cell crossmodal matching, offering a powerful framework for uncovering regulatory interactions at the single-cell omics. Our code is available at: https://github.com/wangxiaotang0906/Bi2Former.",
    "keywords": [
      "Single-cell omics;  Crossmodal matching; Graph Transformer; Crossmodal Interaction Learning;"
    ],
    "pdf_url": "https://openreview.net/pdf?id=swf3Hbc3Qe",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses crossmodal matching models applied to single-cell omics data, including ATAC-RNA interactions, which are highly relevant to biomedical research. Single-cell omics is a key area in understanding biological regulatory mechanisms and has significant implications for fields like genomics, molecular biology, and disease understanding. The abstract emphasizes uncovering biologically meaningful regulatory patterns, which strongly aligns with Biomedicine AI. Keywords like \"single-cell omics,\" \"biological regulatory relationships,\" and \"biologically meaningful data\" further indicate relevance to biomedical applications rather than general machine learning methodologies.",
    "prompt_tokens": 22430,
    "completion_tokens": 237,
    "total_tokens": 22667,
    "Topic Axis I": {
      "MainTopic": "Computational Genomics & Multi-Omics",
      "SubTopic": "Transcriptomics"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Graph Representation Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Biologically-driven crossmodal graph transformer; Graph Message Passing",
    "application": "Crossmodal matching and regulation discovery – single-cell omics",
    "code_link": "https://github.com/wangxiaotang0906/Bi2Former",
    "dataset_name": [
      "ISSAAC-seq",
      "10×PBMC",
      "SHARE-seq",
      "SNARE-seq",
      "10×Multiome"
    ]
  },
  {
    "id": "D4hcJPkJ3y",
    "title": "NeurIPT: Foundation Model for Neural Interfaces",
    "authors": [
      "Zitao Fang",
      "CHENXUAN LI",
      "Zhou Hongting",
      "Shuyang Yu",
      "Guodong DU",
      "Ashwaq Qasem",
      "Yang Lu",
      "Jing Li",
      "Junsong Zhang",
      "Sim Kuan Goh"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Electroencephalography (EEG) has wide-ranging applications, from clinical diagnosis to brain-computer interfaces (BCIs). With the increasing volume and variety of EEG data, there has been growing interest in establishing foundation models (FMs) to scale up and generalize neural decoding. Despite showing early potential, applying FMs to EEG remains challenging due to substantial inter-subject, inter-task, and inter-condition variability, as well as diverse electrode configurations across recording setups. To tackle these open challenges, we propose **NeurIPT**, a foundation model tailored for diverse EEG-based **Neur**al **I**nterfaces with a **P**re-trained **T**ransformer by capturing both homogeneous and heterogeneous spatio-temporal characteristics inherent in EEG signals. Temporally, we introduce Amplitude-Aware Masked Pretraining (AAMP), masking based on signal amplitude rather than random intervals, to learn robust representations across varying signal intensities beyond local interpolation. Moreover, this temporal representation is enhanced by a progressive Mixture-of-Experts (MoE) architecture, where specialized expert subnetworks are progressively introduced at deeper layers, adapting effectively to the diverse temporal characteristics of EEG signals. Spatially, NeurIPT leverages the 3D physical coordinates of electrodes, enabling effective transfer across varying EEG settings, and develops Intra-Inter Lobe Pooling (IILP) during fine-tuning to efficiently exploit regional brain features. Empirical evaluations across nine downstream BCI datasets, via fine-tuning and training from scratch, demonstrated NeurIPT consistently achieved state-of-the-art performance, highlighting its broad applicability and robust generalization. Our work pushes forward the state of FMs in EEG and offers insights into scalable and generalizable neural information processing systems.",
    "keywords": [
      "BCI",
      "transformer",
      "EEG"
    ],
    "pdf_url": "https://openreview.net/pdf?id=D4hcJPkJ3y",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on a foundation model for EEG-based neural interfaces, specifically targeting applications such as Brain-Computer Interfaces (BCIs). EEG data is widely utilized in healthcare and biomedical domains for applications such as clinical diagnosis and monitoring neural activity. The abstract explicitly mentions its relevance to EEG, which is directly associated with neuroscience and neurobiological modeling. By improving generalization in neural decoding, the methods proposed in the paper have potential implications for medical research and healthcare-related tasks, such as diagnosis or brain function analysis, making this relevant to Healthcare AI / Biomedicine AI.",
    "prompt_tokens": 22602,
    "completion_tokens": 270,
    "total_tokens": 22872,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Physiological Time Series Analysis"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Progressive Mixture-of-Experts (PMoE); Intra-Inter Lobe Pooling (IILP); Amplitude-Aware Masked Pretraining (AAMP); Transformer-based models",
    "application": "EEG signal decoding",
    "code_link": "N/A",
    "dataset_name": [
      "MentalArithmetic",
      "Mumtaz2016",
      "PhysioNetP300",
      "Sleep-EDFx",
      "SEED-V",
      "BCIC-IV-2A",
      "TUAB",
      "TUEV"
    ]
  },
  {
    "id": "JML6Zi5J0s",
    "title": "Covering Multiple Objectives with a Small Set of Solutions Using Bayesian Optimization",
    "authors": [
      "Natalie Maus",
      "Kyurae Kim",
      "Yimeng Zeng",
      "Haydn Thomas Jones",
      "Fangping Wan",
      "Marcelo Der Torossian Torres",
      "Cesar de la Fuente-Nunez",
      "Jacob R. Gardner"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In multi-objective black-box optimization, the goal is typically to find solutions that optimize a set of $T$ black-box objective functions, $f_1, \\ldots f_T$, simultaneously. Traditional approaches often seek a single Pareto-optimal set that balances trade-offs among all objectives. \nIn contrast, we consider a problem setting that departs from this paradigm: finding a small set of $K < T$ solutions, that collectively \"cover\" the $T$ objectives. A set of solutions is defined as \"covering\" if, for each objective $f_1, \\ldots f_T$, there is at least one good solution. \nA motivating example for this problem setting occurs in drug design. \nFor example, we may have $T$ pathogens and aim to identify a set of $K < T$ antibiotics such that at least one antibiotic can be used to treat each pathogen. \nThis problem, known as coverage optimization, has yet to be tackled with the Bayesian optimization (BO) framework.\nTo fill this void, we develop Multi-Objective Coverage Bayesian Optimization (MOCOBO), a BO algorithm for solving coverage optimization. \nOur approach is based on a new acquisition function reminiscent of expected improvement in the vanilla BO setup.\nWe demonstrate the performance of our method on high-dimensional black-box optimization tasks, including applications in peptide and molecular design.\nResults show that the coverage of the $K < T$ solutions found by MOCOBO matches or nearly matches the coverage of $T$ solutions obtained by optimizing each objective individually.\nFurthermore, in *in vitro* experiments, the peptides found by MOCOBO exhibited high potency against drug-resistant pathogens, further demonstrating the potential of MOCOBO for drug discovery.\nAll of our code is publicly available at the following link: https://github.com/nataliemaus/mocobo.",
    "keywords": [
      "Bayesian optimization",
      "coverage optimization",
      "high-dimensional black-box optimization",
      "multi-objective Bayesian optimization",
      "drug design"
    ],
    "pdf_url": "https://openreview.net/pdf?id=JML6Zi5J0s",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on \"drug design,\" particularly in the context of identifying antibiotics to treat pathogens, which is directly relevant to biomedicine. The described application of the proposed MOCOBO algorithm aligns with therapeutic aims, specifically mentioning \"drug-resistant pathogens\" and *in vitro* experiments that demonstrate the potency of peptides found using the method. Keywords such as \"drug design,\" \"peptide,\" \"molecular design,\" and the abstract's discussion of antibiotic discovery further emphasize the paper's relevance to Biomedicine AI.",
    "prompt_tokens": 22541,
    "completion_tokens": 225,
    "total_tokens": 22766,
    "Topic Axis I": {
      "MainTopic": "Drug Discovery & Development",
      "SubTopic": "De Novo Molecule Design"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Diffusion Models"
    },
    "Topic Axis III": {
      "MainTopic": "Regulatory Science & Digital Biomarkers",
      "SubTopic": "Development & Validation of Digital Biomarkers"
    },
    "method": "Multi-objective Bayesian Optimization; Expected Coverage Improvement acquisition function; Submodular optimization",
    "application": "Peptide design for antimicrobial activity",
    "code_link": "https://github.com/nataliemaus/mocobo",
    "dataset_name": [
      "APEX 1.1",
      "Pre-trained VAE on 4.5 million amino acid sequences"
    ]
  },
  {
    "id": "dw9H08UxJb",
    "title": "Omni-Mol: Multitask Molecular Model for Any-to-any Modalities",
    "authors": [
      "Chengxin Hu",
      "Hao Li",
      "Yihe Yuan",
      "Zezheng Song",
      "Chenyang Zhao",
      "Haixin Wang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In the molecular domain, numerous studies have explored the use of multimodal large language models (LLMs) to construct a general-purpose, multi-task molecular model. However, these efforts are still far from achieving a truly universal molecular model. We identify three key challenges in this endeavor: (1) Existing molecular task datasets are typically small in scale and lack comprehensive domain coverage. (2) Tasks from different molecular subfields are difficult to effectively learn jointly through LLMs due to significant distributional shifts and competition among tasks, which introduces instability in the learning process. (3) Both inter-task and intra-task molecular representations demand different intrinsic dimensions in the language space, making it challenging to balance between redundancy and insufficiency in language model representations. To address these challenges, we innovatively categorize existing small-molecule tasks into four types: Mol2Mol, Mol2Text, Mol2Num, and Text2Mol. We then collect a dataset encompassing over 16 tasks with more than 1.4 million samples, making it the largest molecular instruction-tuning dataset to date. Leveraging the extensive pretraining of LLMs on existing chemical literature, we propose a novel multimodal LLM framework, named **Omni-Mol**, which unifies all small-molecule tasks and supports both molecular generation and understanding. The core of Omni-Mol is our proposed MoGE, which dynamically adapts to the intrinsic rank of different tasks. This mixture-of-experts architecture enhances the model's ability to handle diverse tasks and modalities effectively. Our model achieves unified instruction tuning across 16 tasks and attains state-of-the-art performance on 13 of them. Extensive experiments further demonstrate the scalability and versatility of Omni-Mol.",
    "keywords": [
      "Large Language Models",
      "Molecular Science",
      "Multi-modal Learning"
    ],
    "pdf_url": "https://openreview.net/pdf?id=dw9H08UxJb",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses a multitask molecular model, Omni-Mol, which performs tasks related to molecular generation and understanding. The classification of small-molecule tasks (e.g., Mol2Mol, Mol2Text, Mol2Num, and Text2Mol) and the focus on molecular science strongly indicate a connection to biomedical research. Additionally, the mention of leveraging chemical literature and supporting tasks like molecular generation suggests potential applications in drug discovery, compound understanding, or other areas relevant to biomedicine. These connections align with the Biomedicine AI domain because the work contributes to analyzing molecular-level data, which is a core aspect of biomedical research.",
    "prompt_tokens": 22599,
    "completion_tokens": 204,
    "total_tokens": 22803,
    "Topic Axis I": {
      "MainTopic": "Drug Discovery & Development",
      "SubTopic": "De Novo Molecule Design"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Other Generative Models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Gradient Adaptive LoRA (GAL); Graph Neural Networks (GNN)",
    "application": "Molecule property prediction and optimization",
    "code_link": "N/A",
    "dataset_name": [
      "Omni-Mol",
      "PubChem"
    ]
  },
  {
    "id": "P4KjfMrVNU",
    "title": "Hierarchical Information Aggregation for Incomplete Multimodal Alzheimer's Disease Diagnosis",
    "authors": [
      "Chengliang Liu",
      "Que Yuanxi",
      "Qihao Xu",
      "Yabo Liu",
      "Jie Wen",
      "Jinghua Wang",
      "Xiaoling Luo"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Alzheimer's Disease (AD) poses a significant health threat to the aging population, underscoring the critical need for early diagnosis to delay disease progression and improve patient quality of life. Recent advances in heterogeneous multimodal artificial intelligence (AI) have facilitated comprehensive joint diagnosis, yet practical clinical scenarios frequently encounter incomplete modalities due to factors like high acquisition costs or radiation risks. Moreover, traditional convolution-based architecture face inherent limitations in capturing long-range dependencies and handling heterogeneous medical data efficiently. To address these challenges, in our proposed heterogeneous multimodal diagnostic framework (HAD), we develop a multi-view Hilbert curve-based Mamba block and a hierarchical spatial feature extraction module to simultaneously capture local spatial features and global dependencies, effectively alleviating spatial discontinuities introduced by voxel serialization. Furthermore, to balance semantic consistency and modal specificity, we build a unified mutual information learning objective in the heterogeneous multimodal embedding space, which maintains effective learning of modality-specific information to avoid modality collapse caused by model preference. Extensive experiments demonstrate that our HAD significantly outperforms state-of-the-art methods in various modality-missing scenarios, providing an efficient and reliable solution for early-stage AD diagnosis.",
    "keywords": [
      "Incomplete Multimodal Learning",
      "State Space Model",
      "Alzheimer's Disease Diagnosis"
    ],
    "pdf_url": "https://openreview.net/pdf?id=P4KjfMrVNU",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly addresses the challenge of diagnosing Alzheimer's Disease (AD), which is a healthcare-related task, utilizing a heterogeneous multimodal AI framework. It aims to improve early-stage AD diagnosis—a medical application—with a focus on incomplete modalities encountered in clinical scenarios (e.g., due to radiation risks or acquisition costs). Additionally, the paper mentions the use of spatial feature extraction and mutual information learning tailored to heterogeneous medical data, which signifies its relevance to both Healthcare AI and Biomedicine AI domains. Terms like \"Alzheimer's Disease diagnosis,\" \"clinical scenarios,\" \"patient quality of life,\" and \"early diagnosis\" are strong indicators of relevance to these fields.",
    "prompt_tokens": 22196,
    "completion_tokens": 234,
    "total_tokens": 22430,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Physiological Time Series Analysis"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Multimodal semantic representation learning; multi-view Hilbert curve-based Mamba block; hierarchical spatial feature extraction",
    "application": "Early-stage Alzheimer's Disease (AD) diagnosis",
    "code_link": "N/A",
    "dataset_name": [
      "ADNI-1",
      "ADNI-2",
      "ADNI-3",
      "ADNI-GO"
    ]
  },
  {
    "id": "Iicv9iTPcU",
    "title": "RAD: Towards Trustworthy Retrieval-Augmented Multi-modal Clinical Diagnosis",
    "authors": [
      "Haolin Li",
      "Tianjie Dai",
      "Zhe Chen",
      "Siyuan Du",
      "Jiangchao Yao",
      "Ya Zhang",
      "Yanfeng Wang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Clinical diagnosis is a highly specialized discipline requiring both domain expertise and strict adherence to rigorous guidelines. \nWhile current AI-driven medical research predominantly focuses on knowledge graphs or natural text pretraining paradigms to incorporate medical knowledge, these approaches primarily rely on implicitly encoded knowledge within model parameters, neglecting task-specific knowledge required by diverse downstream tasks.\nTo address this limitation, we propose **R**etrieval-**A**ugmented **D**iagnosis (RAD), a novel framework that explicitly injects external knowledge into multimodal models directly on downstream tasks.\nSpecifically, RAD operates through three key mechanisms: retrieval and refinement of disease-centered knowledge from multiple medical sources, a guideline-enhanced contrastive loss that constrains the latent distance between multi-modal features and guideline knowledge, and the dual transformer decoder that employs guidelines as queries to steer cross-modal fusion, aligning the models with clinical diagnostic workflows from guideline acquisition to feature extraction and decision-making.\nMoreover, recognizing the lack of quantitative evaluation of interpretability for multimodal diagnostic models, we introduce a set of criteria to assess the interpretability from both image and text perspectives. Extensive evaluations across four datasets with different anatomies demonstrate RAD's generalizability, achieving state-of-the-art performance. Furthermore, RAD enables the model to concentrate more precisely on abnormal regions and critical indicators, ensuring evidence-based, trustworthy diagnosis. Our code is available at https://github.com/tdlhl/RAD.",
    "keywords": [
      "Multimodal Fusion",
      "Medical Imaging",
      "Interpretability",
      "Disease Diagnosis"
    ],
    "pdf_url": "https://openreview.net/pdf?id=Iicv9iTPcU",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly focuses on clinical diagnosis, a key domain within Healthcare AI, which involves disease-centered knowledge retrieval and decision-making workflows based on medical imaging and text data. The framework, RAD, is designed for multimodal clinical diagnosis and integrates external clinical knowledge to ensure trustworthy, evidence-based diagnosis. Mention of \"clinical diagnostic workflows,\" \"disease diagnosis,\" \"medical imaging,\" \"guideline-enhanced contrastive loss,\" and \"interpretability from image and text perspectives\" strongly ties the paper to the Healthcare AI domain. Additionally, its evaluation on datasets related to \"different anatomies\" emphasizes health-related applications of AI.",
    "prompt_tokens": 22342,
    "completion_tokens": 221,
    "total_tokens": 22563,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Radiology"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Other Generative Models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Guideline-enhanced contrastive feature constraint; Dual-decoder structure",
    "application": "Multi-modal diagnostic prediction",
    "code_link": "https://github.com/tdlhl/RAD",
    "dataset_name": [
      "MIMIC-ICD53",
      "Harvard-FairVLMed",
      "SkinCAP",
      "NACC"
    ]
  },
  {
    "id": "49EjZytlus",
    "title": "Reinforced Active Learning for Large-Scale Virtual Screening with Learnable Policy Model",
    "authors": [
      "Yicong Chen",
      "Jiahua Rao",
      "Jiancong Xie",
      "Dahao Xu",
      "Zhen WANG",
      "Yuedong Yang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Virtual Screening (VS) is vital for drug discovery but struggles with low hit rates and high computational costs. While Active Learning (AL) has shown promise in improving the efficiency of VS, traditional methods rely on inflexible and handcrafted heuristics, limiting adaptability in complex chemical spaces, particularly in balancing molecular diversity and selection accuracy. \nTo overcome these challenges, we propose GLARE, a reinforced active learning framework that reformulates VS as a Markov Decision Process (MDP). Using Group Relative Policy Optimization (GRPO), GLARE dynamically balances chemical diversity, biological relevance, and computational constraints, eliminating the need for inflexible heuristics.\nExperiments show GLARE outperforms state-of-the-art AL methods, with a 64.8% average improvement in Enrichment Factors (EF). Additionally, GLARE enhances the performance of VS foundation models like DrugCLIP, achieving up to an 8-fold improvement in  EF$_{0.5\\\\%}$ with as few as 15 active molecules. These results highlight the transformative potential of GLARE for adaptive and efficient drug discovery.",
    "keywords": [
      "Virtual Screening",
      "Active Learning",
      "Molecular Activity",
      "Drug Discovery"
    ],
    "pdf_url": "https://openreview.net/pdf?id=49EjZytlus",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on \"Virtual Screening\" (VS) and \"drug discovery,\" which are key aspects of biomedical research, making it highly relevant to the Biomedicine AI domain. The abstract discusses improving the efficiency and adaptability of VS using machine learning methods, specifically Active Learning reformulated as a Markov Decision Process (MDP). Additionally, the paper demonstrates the ability of the proposed framework to enhance VS foundation models like DrugCLIP, which directly applies to identifying active molecules for drug discovery. This aligns strongly with biomedical applications, particularly in molecular activity prediction and therapeutic agent identification. Keywords like \"molecular activity,\" \"Virtual Screening,\" and \"Drug Discovery\" further reinforce its relevance to Biomedicine AI.",
    "prompt_tokens": 22272,
    "completion_tokens": 207,
    "total_tokens": 22479,
    "Topic Axis I": {
      "MainTopic": "Drug Discovery & Development",
      "SubTopic": "Virtual Screening & Hit Generation"
    },
    "Topic Axis II": {
      "MainTopic": "Sequential Decision Making & Reinforcement Learning",
      "SubTopic": "Reinforcement Learning for Clinical Policy"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Reinforcement Learning; Group Relative Policy Optimization (GRPO)",
    "application": "Virtual screening – novel molecule selection",
    "code_link": "N/A",
    "dataset_name": [
      "LIT-PCBA",
      "Enamine"
    ]
  },
  {
    "id": "STsjfx2cee",
    "title": "Atomic Diffusion Models for Small Molecule Structure Elucidation from NMR Spectra",
    "authors": [
      "Ziyu Xiong",
      "Yichi Zhang",
      "Foyez Alauddin",
      "Chu Xin Cheng",
      "Joon Soo An",
      "Mohammad R. Seyedsayamdost",
      "Ellen D Zhong"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Nuclear Magnetic Resonance (NMR) spectroscopy is a cornerstone technique for determining the structures of small molecules and is especially critical in the discovery of novel natural products and clinical therapeutics. Yet, interpreting NMR spectra remains a time-consuming, manual process requiring extensive domain expertise. We introduce ChefNMR (CHemical Elucidation From NMR), an end-to-end framework that directly predicts an unknown molecule's structure solely from its 1D NMR spectra and chemical formula. We frame structure elucidation as conditional generation from an atomic diffusion model built on a non-equivariant transformer architecture. To model the complex chemical groups found in natural products, we generated a dataset of simulated 1D NMR spectra for over 111,000 natural products. ChefNMR predicts the structures of challenging natural product compounds with an unsurpassed accuracy of over 65%. This work takes a significant step toward solving the grand challenge of automating small-molecule structure elucidation and highlights the potential of deep learning in accelerating molecular discovery.",
    "keywords": [
      "Diffusion Models",
      "NMR Spectroscopy",
      "Natural Products",
      "Machine Learning for Chemistry"
    ],
    "pdf_url": "https://openreview.net/pdf?id=STsjfx2cee",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper is focused on using deep learning for the structure elucidation of small molecules from NMR spectra. NMR spectroscopy is a critical tool in biomedical research and drug discovery, as noted in the abstract (\"discovery of novel natural products and clinical therapeutics\"). Additionally, the application in elucidating chemical structures directly ties to molecular modeling and drug discovery—key aspects of Biomedicine AI. Terms such as \"natural products,\" \"clinical therapeutics,\" and \"molecular discovery\" strongly indicate relevance to biomedicine and healthcare research. Therefore, this paper belongs to the Biomedicine AI domain.",
    "prompt_tokens": 22169,
    "completion_tokens": 210,
    "total_tokens": 22379,
    "Topic Axis I": {
      "MainTopic": "Drug Discovery & Development",
      "SubTopic": "new-Molecular structure elucidation from NMR spectra"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Diffusion Models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-Model interpretability in molecular predictions"
    },
    "method": "Hybrid convolutional transformer; Diffusion Transformer",
    "application": "Molecular structure generation from 1D NMR spectra",
    "code_link": "N/A",
    "dataset_name": [
      "SpectraNP",
      "SpecTeach",
      "NMRShiftDB2",
      "SpectraBase",
      "USPTO"
    ]
  },
  {
    "id": "CrxR6CYeQn",
    "title": "Accurately Predicting Protein Mutational Effects via a Hierarchical Many-Body Attention Network",
    "authors": [
      "Dahao Xu",
      "Jiahua Rao",
      "Mingming Zhu",
      "Jixian Zhang",
      "Wei Lu",
      "Shuangjia Zheng",
      "Yuedong Yang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Predicting changes in binding free energy ($\\Delta\\Delta G$) is essential for understanding protein-protein interactions, which are critical in drug design and protein engineering. However, existing methods often rely on pre-trained knowledge and heuristic features, limiting their ability to accurately model complex mutation effects, particularly higher-order and many-body interactions.\nTo address these challenges, we propose H3-DDG, a Hypergraph-driven Hierarchical network to capture Higher-order many-body interactions across multiple scales. By introducing a hierarchical communication mechanism, H3-DDG effectively models both local and global mutational effects.\nExperimental results demonstrate state-of-the-art performance on multiple benchmarks. On the SKEMPI v2 dataset, H3-DDG achieves a Pearson correlation of 0.75, improving multi-point mutations prediction by 12.10%. On the challenging BindingGYM dataset, it outperforms Prompt-DDG and BA-DDG by 62.61% and 34.26%, respectively.\nAblation and efficiency analyses demonstrate its robustness and scalability, while a case study on SARS-CoV-2 antibodies highlights its practical value in improving binding affinity for therapeutic design.",
    "keywords": [
      "Protein Mutational Effects",
      "Protein-Protein Interactions",
      "Binding Free Energy",
      "Hierarchical Many-Body Attention"
    ],
    "pdf_url": "https://openreview.net/pdf?id=CrxR6CYeQn",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses the prediction of changes in binding free energy ($\\Delta\\Delta G$) for protein-protein interactions, a critical aspect of drug design and protein engineering. Key phrases like \"drug design,\" \"protein engineering,\" \"improving binding affinity for therapeutic design,\" and \"SARS-CoV-2 antibodies\" strongly align with the Biomedicine AI domain. Understanding protein mutational effects has direct implications for therapeutic applications, particularly in designing treatments for diseases. The use of AI methods (H3-DDG) to enable advancements in such tasks aligns closely with biomedical research.",
    "prompt_tokens": 22305,
    "completion_tokens": 217,
    "total_tokens": 22522,
    "Topic Axis I": {
      "MainTopic": "Drug Discovery & Development",
      "SubTopic": "Target Identification & Validation"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Graph Representation Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Hypergraph-driven hierarchical network; Many-body attention mechanism",
    "application": "Binding free energy prediction – protein-protein interaction mutations",
    "code_link": "https://github.com/biomed-AI/H3-DDG",
    "dataset_name": [
      "SKEMPI v2",
      "BindingGYM"
    ]
  },
  {
    "id": "TLlFnoPUdB",
    "title": "From Pixels to Views: Learning Angular-Aware and Physics-Consistent Representations for Light Field Microscopy",
    "authors": [
      "Feng He",
      "Guodong Tan",
      "Qiankun Li",
      "Jun Yu",
      "Quan Wen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Light field microscopy (LFM) has become an emerging tool in neuroscience for large-scale neural imaging in vivo, with XLFM (eXtended Light Field Microscopy) notable for its single-exposure volumetric imaging, broad field of view, and high temporal resolution.  However, learning-based 3D reconstruction in XLFM remains underdeveloped due to two core challenges: the absence of standardized datasets and the lack of methods that can efficiently model its angular–spatial structure while remaining physically grounded. We address these challenges by introducing three key contributions. First, we construct the XLFM-Zebrafish benchmark, a large-scale dataset and evaluation suite for XLFM reconstruction. Second, we propose Masked View Modeling for Light Fields (MVM-LF), a self-supervised task that learns angular priors by predicting occluded views, improving data efficiency. Third, we formulate the Optical Rendering Consistency Loss (ORC Loss), a differentiable rendering constraint that enforces alignment between predicted volumes and their PSF-based forward projections. On the XLFM-Zebrafish benchmark, our method improves PSNR by 7.7\\% over state-of-the-art baselines. Code and datasets are publicly available at: https://github.com/hefengcs/XLFM-Former.",
    "keywords": [
      "Physics-Guided Learning; Microscopy; Biomedical Imaging; Neural Imaging"
    ],
    "pdf_url": "https://openreview.net/pdf?id=TLlFnoPUdB",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses advancements in Light Field Microscopy (LFM) and XLFM for neural imaging in vivo, which is directly relevant to biomedical research. Neural imaging is a critical tool for understanding brain processes and can aid in neuroscience applications, which fall under the domain of Biomedicine AI. Additionally, the creation of the XLFM-Zebrafish benchmark, which focuses on biological tissue imaging (zebrafish as a biological model), further ties the work to biomedical research. The keywords like \"Microscopy,\" \"Biomedical Imaging,\" and \"Neural Imaging\" reinforce its classification in Biomedicine AI.",
    "prompt_tokens": 22030,
    "completion_tokens": 211,
    "total_tokens": 22241,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Other Imaging Modalities"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Vision Foundation Models (VFMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Transformer-based models; Masked view modeling; Optical reconstruction consistency loss",
    "application": "3D light field reconstruction – Zebrafish microscopy",
    "code_link": "N/A",
    "dataset_name": [
      "XLFM-Zebrafish Dataset",
      "H2B-Nemos"
    ]
  },
  {
    "id": "hw0hl4JmvA",
    "title": "FIGRDock: Fast Interaction-Guided Regression for Flexible Docking",
    "authors": [
      "Shikun Feng",
      "Bicheng Lin",
      "Yuanhuan Mo",
      "Yuyan Ni",
      "Wenyu Zhu",
      "Bowen Gao",
      "Wei-Ying Ma",
      "haitao li",
      "Yanyan Lan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Flexible docking, which predicts the binding conformations of both proteins and small molecules by modeling their structural flexibility, plays a vital role in structure-based drug design. Although recent generative approaches, particularly diffusion-based models, have shown promising results, they require iterative sampling to generate candidate structures and depend on separate scoring functions for pose selection. This leads to an inefficient pipeline that is difficult to scale in real-world drug discovery workflows. To overcome these challenges, we introduce FIGRDock, a fast and accurate flexible docking framework that understands complicated interactions between molecules and proteins with a regression-based approach. FIGRDock leverages initial docking poses from conventional tools to distill interaction-aware distance patterns, which serve as explicit structural conditions to directly guide the prediction of the final protein-ligand complex via a regression model. This one-shot inference paradigm enables rapid and precise pose prediction without reliance on multi-step sampling or external scoring stages. Experimental results show that FIGRDock achieves up to 100× faster inference than diffusion-based docking methods, while consistently surpassing them in accuracy across standard benchmarks. These results suggest that FIGRDock has the potential to offer a scalable and efficient solution for flexible docking, advancing the pace of structure-based drug discovery.",
    "keywords": [
      "Flexible Docking",
      "Protein-ligand interactions"
    ],
    "pdf_url": "https://openreview.net/pdf?id=hw0hl4JmvA",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on \"flexible docking,\" a crucial task in structure-based drug design, which involves predicting binding conformations of proteins and small molecules while accounting for structural flexibility. This falls under \"drug discovery,\" a key area of biomedical research. The abstract explicitly mentions advancing the pace of structure-based drug discovery, which has clear applications in therapeutic development and biomedicine. Therefore, this paper is directly relevant to the Biomedicine AI domain.",
    "prompt_tokens": 22552,
    "completion_tokens": 225,
    "total_tokens": 22777,
    "Topic Axis I": {
      "MainTopic": "Drug Discovery & Development",
      "SubTopic": "Flexible docking – Structure-based drug design"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Regression-based docking; Interaction-aware representation learning"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model generalization – Avoiding structural encoding bias"
    },
    "method": "Regression-based docking; Interaction-guided learning",
    "application": "Protein-ligand complex prediction – structure-based drug design",
    "code_link": "https://github.com/fengshikun/FIGRDock.git",
    "dataset_name": [
      "SIU",
      "PDBBind"
    ]
  },
  {
    "id": "0wV5HR7M4P",
    "title": "TEMPO: Temporal Multi-scale Autoregressive Generation of Protein Conformational Ensembles",
    "authors": [
      "Yaoyao Xu",
      "Di Wang",
      "Zihan Zhou",
      "Tianshu Yu",
      "Mingchen Chen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Understanding the dynamic behavior of proteins is critical to elucidating their functional mechanisms, yet generating realistic, temporally coherent trajectories of protein ensembles remains a significant challenge. In this work, we introduce a novel hierarchical autoregressive framework for modeling protein dynamics that leverages the intrinsic multi-scale organization of molecular motions. Unlike existing methods that focus on generating static conformational ensembles or treat dynamic sampling as an independent process, our approach characterizes protein dynamics as a Markovian process. The framework employs a two-scale architecture: a low-resolution model captures slow, collective motions driving major conformational transitions, while a high-resolution model generates detailed local fluctuations conditioned on these large-scale movements. This hierarchical design ensures that the causal dependencies inherent in protein dynamics are preserved, enabling the generation of temporally coherent and physically realistic trajectories. By bridging high-level biophysical principles with state-of-the-art generative modeling, our approach provides an efficient framework for simulating protein dynamics that balances computational efficiency with physical accuracy.",
    "keywords": [
      "Protein",
      "protein dynamic",
      "AI4Science"
    ],
    "pdf_url": "https://openreview.net/pdf?id=0wV5HR7M4P",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper is highly relevant to Biomedicine AI because it focuses on modeling the dynamic behavior of proteins, which is a critical aspect of biomedical research. Proteins play essential roles in biological processes, including disease mechanisms, drug interactions, and therapeutic design. The hierarchical autoregressive framework introduced in the paper aids in simulating protein dynamics, which could be directly applied to tasks such as drug discovery or understanding pathological conformational changes of proteins. Terms like \"protein dynamics,\" \"molecular motions,\" and \"conformational ensembles\" suggest relevance to biomedical applications rather than general machine learning methods.",
    "prompt_tokens": 22547,
    "completion_tokens": 215,
    "total_tokens": 22762,
    "Topic Axis I": {
      "MainTopic": "Computational Genomics & Multi-Omics",
      "SubTopic": "Proteomics & Protein Structure"
    },
    "Topic Axis II": {
      "MainTopic": "Sequential Decision Making & Reinforcement Learning",
      "SubTopic": "Dynamic Treatment Regimes"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Auto-regressive modeling; Stochastic differential equations; Equivariant Transformer models",
    "application": "Protein dynamics modeling; Trajectory generation; Structural flexibility prediction",
    "code_link": "N/A",
    "dataset_name": [
      "mdCATH",
      "ATLAS"
    ]
  },
  {
    "id": "IPxOoU8aqt",
    "title": "Doctor Approved: Generating Medically Accurate Skin Disease Images through AI-Expert Feedback",
    "authors": [
      "Janet Wang",
      "Yunbei Zhang",
      "Zhengming Ding",
      "Jihun Hamm"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Paucity of medical data severely limits the generalizability of diagnostic ML models, as the full spectrum of disease variability can not be represented by a small clinical dataset. To address this, diffusion models (DMs) have been considered as a promising avenue for synthetic image generation and augmentation. However, they frequently produce _medically inaccurate_ images, deteriorating the model performance. Expert domain knowledge is critical for synthesizing images that correctly encode clinical information, especially when data is scarce and quality outweighs quantity. Existing approaches for incorporating human feedback, such as reinforcement learning (RL) and Direct Preference Optimization (DPO), rely on robust reward functions or demand labor-intensive expert evaluations. Recent progress in Multimodal Large Language Models (MLLMs) reveals their strong visual reasoning capabilities, making them adept candidates as evaluators. In this work, we propose a novel framework, coined MAGIC (**M**edically **A**ccurate **G**eneration of **I**mages through AI-Expert **C**ollaboration), that synthesizes clinically accurate skin disease images for data augmentation. Our method creatively translates expert-defined criteria into actionable feedback for image synthesis of DMs, significantly improving clinical accuracy while reducing the direct human workload. Experiments demonstrate that our method greatly improves the clinical quality of synthesized skin disease images, with outputs aligning with dermatologist assessments. Additionally, augmenting training data with these synthesized images improves diagnostic accuracy by +9.02% on a challenging 20-condition skin disease classification task, and by +13.89% in the few-shot setting. Beyond image synthesis, MAGIC illustrates a task-centric alignment paradigm: instead of adapting MLLMs to niche medical tasks, it adapts tasks to the evaluative strengths of general-purpose MLLMs by decomposing domain knowledge into attribute-level checklists. This design offers a scalable and reliable path for leveraging foundation models in specialized domains.",
    "keywords": [
      "Synthetic Clinical Data",
      "Machine Learning for Healthcare",
      "Skin Imaging Analysis"
    ],
    "pdf_url": "https://openreview.net/pdf?id=IPxOoU8aqt",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper is highly relevant to Healthcare AI and Biomedicine AI as it explicitly addresses the generation of medically accurate skin disease images for diagnostic purposes and clinical data augmentation. Key phrases such as \"skin disease classification task,\" \"clinical accuracy,\" \"diagnostic accuracy,\" and \"dermatologist assessments\" demonstrate its focus on medical applications. Additionally, it describes aligning synthetic image generation with clinical standards to improve disease diagnosis, which is central to healthcare AI. The use of synthetic clinical data and its role in improving diagnostic models further supports its classification within Healthcare AI and Biomedicine AI domains.",
    "prompt_tokens": 22229,
    "completion_tokens": 215,
    "total_tokens": 22444,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Digital Pathology"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Diffusion Models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Diffusion model; Direct Preference Optimization; Expert Feedback Fine-Tuning",
    "application": "Synthetic dermatological image generation – skin disease classification",
    "code_link": "https://github.com/janet-sw/MAGIC.git",
    "dataset_name": [
      "Fitzpatrick17k",
      "SCIN",
      "PAD-UFES-20"
    ]
  },
  {
    "id": "Ekw6gjs5Y5",
    "title": "PathVQ: Reforming Computational Pathology Foundation Model for Whole Slide Image Analysis via Vector Quantization",
    "authors": [
      "Honglin Li",
      "Zhongyi Shui",
      "Yunlong Zhang",
      "Chenglu Zhu",
      "Lin Yang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Pathology whole slide image (WSI) analysis is vital for disease diagnosis and understanding. While foundation models (FMs) have driven recent advances, their scalability in pathology remains a key challenge. In particular, vision-language (VL) pathology FMs align visual features with language annotation for downstream tasks, but they rely heavily on large-scale image-text paired data, which is scarce thus limiting generalization. On the other hand, vision-only pathology FMs can leverage abundant unlabeled data via self-supervised learning (SSL). However, current approaches often use the [CLS] token from tile-level ViTs as slide-level input for efficiency (a tile with 224×224 pixels composed of 196 patches with 16×16 pixels). This SSL pretrained [CLS] token lacks alignment with downstream objectives, limiting effectiveness. We find that spatial patch tokens retain a wealth of informative features beneficial for downstream tasks, but utilizing all of them incurs up to 200× higher computation and storage costs compared [CLS] token only (e.g., 196 tokens per ViT$_{224}$). This highlights a fundamental trade-off between efficiency and representational richness to build scalable pathology FMs. To address this, we propose a feature distillation framework via vector-quantization (VQ) that compresses patch tokens into discrete indices and reconstructs them via a decoder, achieving 64× compression (1024 → 16 dimensions) while preserving fidelity. We further introduce a multi-scale VQ (MSVQ) strategy, enhancing both reconstruction and providing SSL supervision for slide-level pretraining. Built upon MSVQ features and supervision signals, we design a progressive convolutional module and a slide-level SSL objective to learn spatially rich representations for downstream WSI tasks. Extensive experiments across multiple datasets demonstrate that our approach achieves state-of-the-art performance, offering a scalable and effective solution for high-performing pathology FMs in WSI analysis.",
    "keywords": [
      "Computational Pathology",
      "Foundation Model",
      "Whole Slide Image",
      "Vector Quantization"
    ],
    "pdf_url": "https://openreview.net/pdf?id=Ekw6gjs5Y5",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper is directly related to \"pathology whole slide image (WSI) analysis,\" which is a vital component of disease diagnosis and medical understanding, both of which fall firmly into the domain of Healthcare AI and Biomedicine AI. Terms like \"disease diagnosis,\" \"computational pathology,\" and \"WSI analysis\" are clear indicators of a healthcare-related application. Additionally, the work focuses on building models designed to improve pathology workflows, which are critical in biomedical research and healthcare settings. Therefore, this research aligns well with the Biomedicine AI domain.",
    "prompt_tokens": 22492,
    "completion_tokens": 219,
    "total_tokens": 22711,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Digital Pathology"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Vector Quantization (VQ); Multi-scale VQ (MSVQ); SSL pretraining",
    "application": "Tumor classification – WSIs",
    "code_link": "N/A",
    "dataset_name": [
      "CRC-100K",
      "Camelyon-17 WILDS",
      "TCGA"
    ]
  },
  {
    "id": "qcdoHkkHcb",
    "title": "SPICED: A Synaptic Homeostasis-Inspired Framework for Unsupervised Continual EEG Decoding",
    "authors": [
      "Yangxuan Zhou",
      "Sha Zhao",
      "Jiquan Wang",
      "Haiteng Jiang",
      "Shijian Li",
      "Tao Li",
      "Gang Pan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Human brain achieves dynamic stability-plasticity balance through synaptic homeostasis, a self-regulatory mechanism that stabilizes critical memory traces while preserving optimal learning capacities. Inspired by this biological principle, we propose SPICED: a neuromorphic framework that integrates the synaptic homeostasis mechanism for unsupervised continual EEG decoding, particularly addressing practical scenarios where new individuals with inter-individual variability emerge continually. SPICED comprises a novel synaptic network that enables dynamic expansion during continual adaptation through three bio-inspired neural mechanisms: (1) critical memory reactivation, which mimics brain functional specificity, selectively activates task-relevant memories to facilitate adaptation; (2) synaptic consolidation, which strengthens these reactivated critical memory traces and enhances their replay prioritizations for further adaptations and (3) synaptic renormalization, which are periodically triggered to weaken global memory traces to preserve learning capacities. The interplay within synaptic homeostasis dynamically strengthens  task-discriminative memory traces and weakens detrimental memories. By integrating these mechanisms with continual learning system, SPICED preferentially replays task-discriminative memory traces that exhibit strong associations with newly emerging individuals, thereby achieving robust adaptations. Meanwhile, SPICED effectively mitigates catastrophic forgetting by suppressing the replay prioritization of detrimental memories during long-term continual learning. Validated on three EEG datasets, SPICED show its effectiveness. More importantly, SPICED bridges biological neural mechanisms and artificial intelligence through synaptic homeostasis, providing insights into the broader applicability of bio-inspired principles.",
    "keywords": [
      "Synaptic homeostasis; Brain-inspired; Continual EEG decoding"
    ],
    "pdf_url": "https://openreview.net/pdf?id=qcdoHkkHcb",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses SPICED, a framework for \"unsupervised continual EEG decoding.\" EEG (electroencephalogram) data is a type of health-related dataset commonly used in neurological and clinical research, falling under the domain of neuroscience and biomedical applications. The proposed method aims to address variability across individuals in a continual learning context, which aligns with applications in personalized medicine or patient-specific neural monitoring and diagnostics. Synaptic homeostasis, as a core mechanism of the framework, further ties the work to neurobiological modeling, reinforcing its relevance to Biomedicine AI. Even though the abstract does not explicitly mention clinical or healthcare tasks, the focus on EEG data and its implications in neurobiological and health-related contexts classify this work under Biomedicine AI.",
    "prompt_tokens": 22348,
    "completion_tokens": 221,
    "total_tokens": 22569,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Physiological Time Series Analysis"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Bio-inspired synaptic network; Synaptic consolidation; Synaptic renormalization",
    "application": "Continual EEG decoding",
    "code_link": "https://github.com/xiaobaben/SPICED",
    "dataset_name": [
      "ISRUC",
      "PhysioNet-MI",
      "FACED"
    ]
  },
  {
    "id": "3Sk8CaQWdv",
    "title": "Decoding Causal Structure: End-to-End Mediation Pathways Inference",
    "authors": [
      "Yulong Li",
      "Xiwei Liu",
      "Feilong Tang",
      "Ming Hu",
      "Jionglong Su",
      "Zongyuan Ge",
      "Imran Razzak",
      "Eran Segal"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Causal mediation analysis is crucial for deconstructing complex mechanisms of action. However, in current mediation analysis, complex structures derived from causal discovery lack direct interpretation of mediation pathways, while traditional mediation analysis and effect estimation are limited by the reliance on pre-specified pathways, leading to a disconnection between structure discovery and causal mechanism understanding. Therefore, a unified framework integrating structure discovery, pathway identification, and effect estimation systematically quantifies mediation pathways under structural uncertainty, enabling automated identification and inference of mediation pathways. To this end, we propose Structure-Informed Guided Mediation Analysis (SIGMA), which guides automated mediation pathway identification through probabilistic causal structure discovery and uncertainty quantification, enabling end-to-end propagation of structural uncertainty from structure learning to effect estimation. Specifically, SIGMA employs differentiable Flow-Structural Equation Models to learn structural posteriors, generating diverse Directed Acyclic Graphs (DAGs) to quantify structural uncertainty. Based on these DAGs, we introduce the Path Stability Score to evaluate the marginal probability of pathways, identifying high-confidence mediation paths. For identified mediation pathways, we integrate Efficient Influence Functions with Bayesian model averaging to fuse within-structure estimation uncertainty and between-structure effect variation, propagating uncertainty to the final effect estimates. In synthetic data experiments, SIGMA achieves state-of-the-art performance in pathway identification accuracy and effect quantification precision under structures uncertainty, concurrent multiple pathways, and nonlinear scenarios. In real-world applications using Human Phenotype Project data, SIGMA identifies mediation effects of sleep quality on cardiovascular health through inflammatory and metabolic pathways, uncovering previously unspecified multiple mediation paths.",
    "keywords": [
      "Mediation Pathways Inference"
    ],
    "pdf_url": "https://openreview.net/pdf?id=3Sk8CaQWdv",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract clearly indicates the paper's relevance to Biomedicine AI through its application of causal mediation analysis in a real-world healthcare context. Specifically, the study identifies mediation effects of sleep quality on cardiovascular health through inflammatory and metabolic pathways using Human Phenotype Project data. This indicates an integration of AI methodologies into biomedical research, focusing on health outcomes related to cardiovascular health, which aligns with the Biomedicine AI domain. Additionally, the use of health-related datasets and analysis of biological pathways further reinforces the classification.",
    "prompt_tokens": 22087,
    "completion_tokens": 216,
    "total_tokens": 22303,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Physiological Time Series Analysis"
    },
    "Topic Axis II": {
      "MainTopic": "Causal Inference & Reasoning",
      "SubTopic": "Causal Representation Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Inherently Interpretable Models"
    },
    "method": "Efficient Influence Functions; Bayesian Model Averaging; Variational Autoencoder for Imputation",
    "application": "mediation pathway inference – sleep quality and cardiovascular health",
    "code_link": "N/A",
    "dataset_name": [
      "Human Phenotype Project (HPP)"
    ]
  },
  {
    "id": "MoS4P8zieM",
    "title": "Learning to Zoom with Anatomical Relations for Medical Structure Detection",
    "authors": [
      "Bin Pu",
      "Liwen Wang",
      "Xingbo Dong",
      "Xingguo Lv",
      "Zhe Jin"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Accurate anatomical structure detection is a critical preliminary step for diagnosing diseases characterized by structural abnormalities. In clinical practice, medical experts frequently adjust the zoom level of medical images to obtain comprehensive views for diagnosis. This common interaction results in significant variations in the apparent scale of anatomical structures across different images or fields of view. However, the information embedded in these zoom-induced scale changes is often overlooked by existing detection algorithms. \nIn addition, human organs possess a priori, fixed topological knowledge. To overcome this limitation, we propose ZR-DETR, a zoom-aware probabilistic framework tailored for medical object detection. ZR-DETR uniquely incorporates scale-sensitive zoom embeddings, anatomical relation constraints, and a Gaussian Process-based detection head. This architecture enables the framework to jointly model semantic context, enforce anatomical plausibility, and quantify detection uncertainty. Empirical validation across three diverse medical imaging benchmarks demonstrates that ZR-DETR consistently outperforms strong baselines in both single-domain and unsupervised domain adaptation scenarios.",
    "keywords": [
      "Zoom Pattern;Anatomical Relation;Medical Structure Detection"
    ],
    "pdf_url": "https://openreview.net/pdf?id=MoS4P8zieM",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper clearly falls within the domain of Healthcare AI or Biomedicine AI because it focuses on \"medical structure detection,\" which is explicitly stated in both the title and abstract. The proposed framework, ZR-DETR, is tailored for detecting anatomical structures—a critical task in diagnosing diseases characterized by structural abnormalities. Furthermore, the abstract mentions clinical practices like adjusting zoom levels for medical image analysis, demonstrating direct relevance to healthcare applications. Keywords such as \"anatomical relation\" and \"medical structure detection\" further confirm the focus on healthcare and biomedicine contexts.",
    "prompt_tokens": 22200,
    "completion_tokens": 200,
    "total_tokens": 22400,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Radiology"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Gaussian Processes; Zoom Relation Encoding; Anatomical Relation Constraints",
    "application": "Anatomical object detection – radiology",
    "code_link": "N/A",
    "dataset_name": [
      "FCS",
      "EPV",
      "MM-WHS"
    ]
  },
  {
    "id": "waHF2ekuf2",
    "title": "Straight-Line Diffusion Model for Efficient 3D Molecular Generation",
    "authors": [
      "Yuyan Ni",
      "Shikun Feng",
      "Haohan Chi",
      "Bowen Zheng",
      "Huan-ang Gao",
      "Wei-Ying Ma",
      "Zhi-Ming Ma",
      "Yanyan Lan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Diffusion-based models have shown great promise in molecular generation but often require a large number of sampling steps to generate valid samples. In this paper, we introduce a novel Straight-Line Diffusion Model (SLDM) to tackle this problem, by formulating the diffusion process to follow a linear trajectory. The proposed process aligns well with the noise sensitivity characteristic of molecular structures and uniformly distributes reconstruction effort across the generative process, thus enhancing learning efficiency and efficacy. Consequently, SLDM achieves state-of-the-art performance on 3D molecule generation benchmarks, delivering a 100-fold improvement in sampling efficiency.",
    "keywords": [
      "Molecule generation; Diffusion model"
    ],
    "pdf_url": "https://openreview.net/pdf?id=waHF2ekuf2",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses the use of a Straight-Line Diffusion Model (SLDM) for 3D molecular generation, which is explicitly relevant to molecular design and generation tasks commonly used in biomedical research. Keywords like \"molecular generation\" and the mention of \"3D molecule generation benchmarks\" align strongly with applications such as drug discovery, protein modeling, and other biomedical contexts. While healthcare-specific applications are not mentioned directly, the focus on molecular structures and enhanced generative methods strongly suggests relevance to Biomedicine AI, particularly in areas such as chemical and pharmaceutical research.",
    "prompt_tokens": 22230,
    "completion_tokens": 222,
    "total_tokens": 22452,
    "Topic Axis I": {
      "MainTopic": "Drug Discovery & Development",
      "SubTopic": "De Novo Molecule Design"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Diffusion Models"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "new-Application of generative molecule models for user interpretability and enhanced insights"
    },
    "method": "Straight-Line Diffusion Model (SLDM)",
    "application": "Conditional molecule generation – 3D molecular structures with specific properties",
    "code_link": "https://github.com/fengshikun/SLDM",
    "dataset_name": [
      "QM9",
      "Geom-Drugs"
    ]
  },
  {
    "id": "ls5L4IMEwt",
    "title": "E2Former: An Efficient and Equivariant Transformer with Linear-Scaling Tensor Products",
    "authors": [
      "Yunyang Li",
      "Lin Huang",
      "Zhihao Ding",
      "Xinran Wei",
      "Chu Wang",
      "Han Yang",
      "Zun Wang",
      "Chang Liu",
      "Yu Shi",
      "Peiran Jin",
      "Tao Qin",
      "Mark Gerstein",
      "Jia Zhang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Equivariant Graph Neural Networks (EGNNs) have demonstrated significant success in modeling microscale systems, including those in chemistry, biology and materials science. However, EGNNs face substantial computational challenges due to the high cost of constructing edge features via spherical tensor products, making them almost impractical for large-scale systems. \nTo address this limitation, we introduce E2Former, an equivariant and efficient transformer architecture that incorporates a Wigner $6j$ convolution (Wigner $6j$ Conv). By shifting the computational burden from edges to nodes, Wigner $6j$ Conv reduces the complexity from $O(| \\mathcal{E}|)$ to  $O(| \\mathcal{V}|)$ while preserving both the model's expressive power and rotational equivariance.\nWe show that this approach achieves a 7x–30x speedup compared to conventional $\\mathrm{SO}(3)$ convolutions. Furthermore, our empirical results demonstrate that the derived E2Former mitigates the computational challenges of existing approaches without compromising the ability to capture detailed geometric information. This development could suggest a promising direction for scalable molecular modeling.",
    "keywords": [
      "Equivariant Neural network",
      "quantum chemistry"
    ],
    "pdf_url": "https://openreview.net/pdf?id=ls5L4IMEwt",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses the development of an \"Equivariant Graph Neural Network\" (EGNN) framework applied to microscale systems in fields including chemistry, biology, and materials science. It specifically targets \"molecular modeling,\" which is a critical aspect of biomedicine research, such as drug discovery and understanding molecular interactions. Although clinical or healthcare applications are not explicitly mentioned, the focus on modeling microscale biological systems strongly aligns with Biomedicine AI, particularly in areas like molecular and protein structure analysis, both of which are foundational for drug and therapeutic development.",
    "prompt_tokens": 22410,
    "completion_tokens": 213,
    "total_tokens": 22623,
    "Topic Axis I": {
      "MainTopic": "Drug Discovery & Development",
      "SubTopic": "Structure-to-Energy-and-Forces Prediction"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Graph Representation Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-Detailed spectral accuracy comparison with DFT methods"
    },
    "method": "Equivariant Attention Mechanism; Wigner 6j Convolution",
    "application": "Molecular force and energy prediction",
    "code_link": "N/A",
    "dataset_name": [
      "OC20",
      "OC22",
      "SPICE"
    ]
  },
  {
    "id": "tI04KmK27S",
    "title": "scMRDR: A scalable and flexible framework for unpaired single-cell multi-omics data integration",
    "authors": [
      "Jianle Sun",
      "Chaoqi Liang",
      "Ran Wei",
      "Peng Zheng",
      "LEI BAI",
      "Wanli Ouyang",
      "Hongliang Yan",
      "Peng Ye"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Advances in single-cell sequencing have enabled high-resolution profiling of diverse molecular modalities, while integrating unpaired multi-omics single-cell data remains challenging. Existing approaches either rely on pair information or prior correspondences, or require computing a global pairwise coupling matrix, limiting their scalability and flexibility. In this paper, we introduce a scalable and flexible generative framework called single-cell Multi-omics Regularized Disentangled Representations (scMRDR) for unpaired multi-omics integration. Specifically, we disentangle each cell’s latent representations into modality-shared and modality-specific components using a well-designed $\\beta$-VAE architecture, which are augmented with isometric regularization to preserve intra-omics biological heterogeneity, adversarial objective to encourage cross-modal alignment, and masked reconstruction loss strategy to address the issue of missing features across modalities. Our method achieves excellent performance on benchmark datasets in terms of batch correction, modality alignment, and biological signal preservation. Crucially, it scales effectively to large-level datasets and supports integration of more than two omics, offering a powerful and flexible solution for large-scale multi-omics data integration and downstream biological discovery.",
    "keywords": [
      "Single-cell omics",
      "Multi-omics integration",
      "Unpaired data",
      "Disentangled representation",
      "Variational inference",
      "Adversarial learning",
      "Isometric regularization",
      "Masked loss"
    ],
    "pdf_url": "https://openreview.net/pdf?id=tI04KmK27S",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses a framework for integrating unpaired single-cell multi-omics data, which is directly related to genomics and molecular-level research within biomedicine. Specifically, single-cell sequencing is a critical tool in biomedical applications such as understanding disease mechanisms, developing biomarkers, and advancing therapeutic research. The mention of \"biological signal preservation\" and \"downstream biological discovery\" further implies relevance to biomedical research, as these are common goals in studies seeking to improve knowledge of cellular and molecular processes underlying health and disease conditions. Keywords like \"Single-cell omics\" and \"Multi-omics integration\" strongly align with Biomedicine AI.",
    "prompt_tokens": 22322,
    "completion_tokens": 261,
    "total_tokens": 22583,
    "Topic Axis I": {
      "MainTopic": "Computational Genomics & Multi-Omics",
      "SubTopic": "Transcriptomics: Single-cell RNA-seq analysis, gene expression quantification, cell typing"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Other Generative Models: Variational Autoencoder (VAE)"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Disentangled generative modeling; Variational Autoencoders; Adversarial regularization; Masked reconstruction loss",
    "application": "Single-cell multi-omics data integration",
    "code_link": "https://github.com/sjl-sjtu/scMRDR",
    "dataset_name": [
      "scRNA-seq",
      "scATAC-seq",
      "CITE-seq",
      "merFISH"
    ]
  },
  {
    "id": "zb16xZ1NGB",
    "title": "scSplit: Bringing Severity Cognizance to Image Decomposition in Fluorescence Microscopy",
    "authors": [
      "Ashesh",
      "Florian Jug"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Fluorescence microscopy, while being a key driver for progress in the life sciences, is also subject to technical limitations. To overcome them, computational multiplexing techniques have recently been proposed, which allow multiple cellular structures to be captured in a single image and later be unmixed. Existing image decomposition methods are trained on a set of superimposed input images and the respective unmixed target images. It is critical to note that the relative strength (mixing ratio) of the superimposed images for a given input is a priori unknown. However, existing methods are trained on a fixed intensity ratio of superimposed inputs, making them not cognizant of the range of relative intensities that can occur in fluorescence microscopy. In this work, we propose a novel method called scSplit that is cognizant of the severity of the above-mentioned mixing ratio. Our idea is based on InDI, a popular iterative method for image restoration, and an ideal starting point to embrace the unknown mixing ratio in any given input. We introduce (i) a suitably trained regressor network that predicts the degradation level (mixing asymmetry) of a given input image and (ii) a degradation-specific normalization module, enabling degradation-aware inference across all mixing ratios. We show that this method solves two relevant tasks in fluorescence microscopy, namely image splitting and bleedthrough removal, and empirically demonstrate the applicability of scSplit on 5 public datasets. The source code with pre-trained models is hosted at https://github.com/juglab/scSplit/.",
    "keywords": [
      "semantic unmixing",
      "image decomposition",
      "Fluorescence microscopy",
      "Computer vision",
      "inverse problem"
    ],
    "pdf_url": "https://openreview.net/pdf?id=zb16xZ1NGB",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on image decomposition techniques in fluorescence microscopy, which is critical for analyzing cellular structures. Fluorescence microscopy is widely used in biomedical research, as it enables the study of biological processes at the cellular and molecular levels. Terms like \"cellular structures\" and \"fluorescence microscopy\" strongly link this work to Biomedicine AI, as the advancements proposed (e.g., image splitting and bleedthrough removal) support tasks related to biological and potentially medical imaging. Furthermore, the use of public datasets suggests applicability to real-world biomedical research scenarios. While it does not explicitly mention healthcare applications, its relevance to biomedical imaging places it within the Biomedicine AI domain.",
    "prompt_tokens": 22315,
    "completion_tokens": 223,
    "total_tokens": 22538,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Other Imaging Modalities"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Iterative Inference Methods"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Iterative inference; Severity Cognizant Input Normalization (SCIN); degradation-specific framework",
    "application": "Image decomposition – fluorescence microscopy",
    "code_link": "https://github.com/juglab/scSplit",
    "dataset_name": [
      "Hagen",
      "BioSR",
      "HTT24",
      "HTLIF24",
      "PaviaATN"
    ]
  },
  {
    "id": "FVtu7yC7fY",
    "title": "Can LLMs Reason Over Non-Text Modalities in a Training-Free Manner? A Case Study with In-Context Representation Learning",
    "authors": [
      "Tianle Zhang",
      "Wanlong Fang",
      "Jonathan Woo",
      "Paridhi Latawa",
      "Deepak A. Subramanian",
      "Alvin Chan"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The remarkable performance of Large Language Models (LLMs) can be enhanced with test-time computation, which relies on external tools and even other deep learning models.\nHowever, existing approaches for integrating non-text modality representations into LLMs typically require additional costly supervised training, restricting on-the-fly adaptation to new domains and modalities. \nIn this work, we explore the feasibility of integrating representations from non-text foundational models (FMs) into text-based LLMs in a training-free manner. We propose In-Context Representation Learning (ICRL) as a proof-of-concept to allow LLMs to adaptively utilize non-text modality representations with few-shot learning. \nUnlike traditional in-context learning, which incorporates text-label pairs, ICRL replaces text inputs with FM representations, enabling the LLM to perform multi-modal inference without fine-tuning. \nWe evaluate ICRL on a suite of tasks in the molecular domain, investigating three core research questions: (i) how to map FM representations into LLMs in a training-free manner, (ii) what factors influence ICRL performance, and (iii) what mechanisms underlie the effectiveness of ICRL. \nTo the best of our knowledge, ICRL is the first training-free framework for integrating non-text modality representations into text-based LLMs, presenting a promising direction for adaptable, multi-modal generalization.",
    "keywords": [
      "Large Language Models",
      "Training-Free Adaptation",
      "Foundation Models",
      "Multi-Modal Large Language Models",
      "In-Context Learning"
    ],
    "pdf_url": "https://openreview.net/pdf?id=FVtu7yC7fY",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract references tasks in the molecular domain, which is a strong indicator of relevance to Biomedicine AI. The mention of \"foundational models\" being used for \"multi-modal inference\" and the exploration of \"non-text modality representations\" aligns with biomedical research, particularly in areas such as molecular modeling, drug discovery, or genome analysis. Additionally, the evaluation of the framework on tasks in the molecular domain suggests possible applications in biomedical research and healthcare-related fields. Keywords like \"multi-modal large language models\" and \"molecular domain\" further support this categorization.",
    "prompt_tokens": 21782,
    "completion_tokens": 220,
    "total_tokens": 22002,
    "Topic Axis I": {
      "MainTopic": "Drug Discovery & Development",
      "SubTopic": "Virtual Screening & Hit Generation"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Other Generative Models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Optimal Transport alignment; PCA method; Representation injection",
    "application": "Molecular property prediction – drug-target domain",
    "code_link": "N/A",
    "dataset_name": [
      "ESOL",
      "Caco-2",
      "AqSolDB",
      "LD50Zhu",
      "AstraZeneca",
      "BindingDB"
    ]
  },
  {
    "id": "4P6Mployhf",
    "title": "Offline Guarded Safe Reinforcement Learning for Medical Treatment Optimization Strategies",
    "authors": [
      "Runze Yan",
      "Xun Shen",
      "Akifumi Wachi",
      "Sebastien Gros",
      "Anni Zhao",
      "Xiao Hu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "When applying offline reinforcement learning (RL) in healthcare scenarios, the out-of-distribution (OOD) issues pose significant risks, as inappropriate generalization beyond clinical expertise can result in potentially harmful recommendations. \nWhile existing methods like conservative Q-learning (CQL) attempt to address the OOD issue, their effectiveness is limited by only constraining action selection by suppressing uncertain actions. This action-only regularization imitates clinician actions that prioritize short-term rewards, but it fails to regulate downstream state trajectories, thereby limiting the discovery of improved long-term treatment strategies. To safely improve policy beyond clinician recommendations while ensuring that state-action trajectories remain in-distribution, we propose \\textit{Offline Guarded Safe Reinforcement Learning} ($\\mathsf{OGSRL}$), a theoretically grounded model-based offline RL framework. $\\mathsf{OGSRL}$ introduces a novel dual constraint mechanism for improving policy with reliability and safety. First, the OOD guardian is established to specify clinically validated regions for safe policy exploration. By constraining optimization within these regions, it enables the reliable exploration of treatment strategies that outperform clinician behavior by leveraging the full patient state history, without drifting into unsupported state-action trajectories. Second, we introduce a safety cost constraint that encodes medical knowledge about physiological safety boundaries, providing domain-specific safeguards even in areas where training data might contain potentially unsafe interventions. Notably, we provide theoretical guarantees on safety and near-optimality: policies that satisfy these constraints remain in safe and reliable regions and achieve performance close to the best possible policy supported by the data. When evaluated on the MIMIC-III sepsis treatment dataset, $\\mathsf{OGSRL}$ demonstrated significantly better OOD handling than baselines. $\\mathsf{OGSRL}$ achieved a 78\\% reduction in mortality estimates and a 51\\% increase in reward compared to clinician decisions.",
    "keywords": [
      "Health informatics; Offline reinforcement learning; Safe reinforcement learning; Mathematical optimization;"
    ],
    "pdf_url": "https://openreview.net/pdf?id=4P6Mployhf",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly addresses the use of offline reinforcement learning for optimizing medical treatment strategies, evidenced by its focus on healthcare scenarios and concepts like \"sepsis treatment dataset\" and \"clinical expertise.\" Additionally, it emphasizes safety and reliability in treatment decisions using \"clinically validated regions for safe policy exploration\" and \"safety cost constraints,\" grounding the work in healthcare applications while attempting to improve patient outcomes such as \"mortality estimates.\" The use of the MIMIC-III dataset, a well-known medical dataset, further underscores the paper's relevance to the Healthcare AI domain.",
    "prompt_tokens": 22056,
    "completion_tokens": 232,
    "total_tokens": 22288,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Physiological Time Series Analysis"
    },
    "Topic Axis II": {
      "MainTopic": "Sequential Decision Making & Reinforcement Learning",
      "SubTopic": "Dynamic Treatment Regimes"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Safety & Failure Detection"
    },
    "method": "Offline Guarded Safe Reinforcement Learning (OGSRL); Constrained Policy Optimization",
    "application": "Sepsis treatment optimization; Hypotension treatment optimization",
    "code_link": "https://github.com/Runz96/SafeRL-OGSRL",
    "dataset_name": [
      "MIMIC-III",
      "Synthetic Acute Hypotension Dataset"
    ]
  },
  {
    "id": "IwjkwtkPGb",
    "title": "SimSort: A Data-Driven Framework for Spike Sorting by Large-Scale Electrophysiology Simulation",
    "authors": [
      "Yimu Zhang",
      "Dongqi Han",
      "Yansen Wang",
      "Zhenning Lv",
      "Yu Gu",
      "Dongsheng Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Spike sorting is an essential process in neural recording, which identifies and separates electrical signals from individual neurons recorded by electrodes in the brain, enabling researchers to study how specific neurons communicate and process information. Although there exist a number of spike sorting methods which have contributed to significant neuroscientific breakthroughs, many are heuristically designed, making it challenging to verify their correctness due to the difficulty of obtaining ground truth labels from real-world neural recordings. In this work, we explore a data-driven, deep learning-based approach. We begin by creating a large-scale dataset through electrophysiology simulations using biologically realistic computational models. We then present SimSort, a pretraining framework for spike sorting. Trained solely on simulated data, SimSort demonstrates zero-shot generalizability to real-world spike sorting tasks, yielding consistent improvements over existing methods across multiple benchmarks. These results highlight the potential of simulation-driven pretraining to enhance the robustness and scalability of spike sorting in experimental neuroscience.",
    "keywords": [
      "Spike Sorting",
      "Neuroscience"
    ],
    "pdf_url": "https://openreview.net/pdf?id=IwjkwtkPGb",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper describes a framework for \"spike sorting,\" which involves identifying neural signals using electrophysiology simulations and biologically realistic models. This process is directly tied to neuroscience and neural recording, which are central to the field of biomedicine. The paper discusses how SimSort can enhance the understanding of neuronal communication and processing, making it relevant to biomedical research. The focus on a neural system (neurons, brain activity) aligns with the domain of Biomedicine AI, as it is related to neuroscience and neurobiological modeling.",
    "prompt_tokens": 22144,
    "completion_tokens": 209,
    "total_tokens": 22353,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Physiological Time Series Analysis"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Other Generative Models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-Embedding visualization for spike detection"
    },
    "method": "Contrastive learning; Deep neural networks; Embedding optimization",
    "application": "Spike sorting – Neural recordings",
    "code_link": "https://SimSortTool.github.io",
    "dataset_name": [
      "BBP L6 dataset",
      "Hybrid dataset"
    ]
  },
  {
    "id": "aXAkNlbnGa",
    "title": "Joint Velocity-Growth Flow Matching for Single-Cell Dynamics Modeling",
    "authors": [
      "Dongyi Wang",
      "Yuanwei Jiang",
      "Zhenyi Zhang",
      "Xiang Gu",
      "Peijie Zhou",
      "Jian Sun"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Learning the underlying dynamics of single cells from snapshot data has gained increasing attention in scientific and machine learning research. The destructive measurement technique and cell proliferation/death result in unpaired and unbalanced data between snapshots, making the learning of the underlying dynamics challenging. In this paper, we propose joint Velocity-Growth Flow Matching (VGFM), a novel paradigm that jointly learns state transition and mass growth of single-cell populations via flow matching. VGFM builds an ideal single-cell dynamics containing velocity of state and growth of mass, driven by a presented two-period dynamic understanding of the static semi-relaxed optimal transport, a mathematical tool that seeks the coupling between unpaired and unbalanced data. To enable practical usage, we approximate the ideal dynamics using neural networks, forming our joint velocity and growth matching framework. A distribution fitting loss is also employed in VGFM to further improve the fitting performance for snapshot data. Extensive experimental results on both synthetic and real datasets demonstrate that VGFM can capture the underlying biological dynamics accounting for mass and state variations over time, outperforming existing approaches for single-cell dynamics modeling.",
    "keywords": [
      "flow matching",
      "single-cell",
      "optimal transport",
      "dynamics modeling"
    ],
    "pdf_url": "https://openreview.net/pdf?id=aXAkNlbnGa",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on modeling single-cell dynamics, which involves understanding the state transition and mass growth of single-cell populations. Single-cell analysis is a key aspect of biomedical research, as it is widely used in areas like genomics, transcriptomics, and understanding cellular behavior in disease contexts (e.g., cancer progression or immune responses). The mention of \"single-cell populations\" and references to \"biological dynamics\" strongly indicate relevance to Biomedicine AI, as this methodology can contribute to advancements in disease understanding, drug discovery, and therapeutic development. Additionally, the use of models for unpaired and unbalanced snapshot data is highly applicable to biomedical scenarios involving destructive cell measurement techniques.",
    "prompt_tokens": 22305,
    "completion_tokens": 229,
    "total_tokens": 22534,
    "Topic Axis I": {
      "MainTopic": "Computational Genomics & Multi-Omics",
      "SubTopic": "Transcriptomics"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Other Generative Models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Inherently Interpretable Models"
    },
    "method": "Velocity-Growth Flow Matching; Semi-relaxed optimal transport",
    "application": "Single-cell dynamics modeling; Cellular trajectory reconstruction",
    "code_link": "https://github.com/DongyiWang-66/VGFM",
    "dataset_name": [
      "Dyngen Data",
      "Mouse Hematopoiesis Data",
      "EB Data"
    ]
  },
  {
    "id": "098tsRhmQ7",
    "title": "Uncover Governing Law of Pathology Propagation Mechanism Through A Mean-Field Game",
    "authors": [
      "Tingting Dan",
      "Zhihao Fan",
      "Guorong Wu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Alzheimer’s disease (AD) is marked by cognitive decline along with the widespread of tau aggregates across the brain cortex. Due to the challenges of imaging pathology spreading flows *in vivo*, however, quantitative analysis on the cortical pathways of tau propagation and its interaction with the cascade of amyloid-beta (A$\\beta$) plaques lags behind the experimental insights of underlying pathophysiological mechanisms. To address this challenge, we present a physics-informed neural network, empowered by mean-field theory, to uncover the biologically meaningful spreading pathways of tau aggregates between two longitudinal snapshots. Following the notion of `prion-like' mechanism in AD, we first formulate the dynamics of tau propagation as a mean-field game (MFG), where the spread of tau aggregate at each location (aka. agent) depends on the collective behavior of the surrounding agents as well as the potential field formed by amyloid burden. Given the governing equation of propagation dynamics, MFG reaches an equilibrium that allows us to model the evolution of tau aggregates as an optimal transport with the lowest cost in *Wasserstein* space. By leveraging the variational primal-dual structure in MFG, we propose a *Wasserstein*-1 Lagrangian generative adversarial network (GAN), in which a Lipschitz critic seeks the appropriate transport cost at the population level and a generator parameterizes the flow fields of optimal transport across individuals. Additionally, we incorporate a symbolic regression module to derive an explicit formulation capturing the A$\\beta$-tau crosstalk. Experimental results on public neuroimaging datasets demonstrate that our explainable deep model not only yields precise and reliable predictions of future tau progression for unseen new subjects but also provides a new window to uncover new understanding of pathology propagation in AD through learning-based approaches.",
    "keywords": [
      "physics-informed deep learning",
      "reaction–diffusion model",
      "mean field game",
      "symbolic regression",
      "Alzheimer’s disease"
    ],
    "pdf_url": "https://openreview.net/pdf?id=098tsRhmQ7",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper is centered on Alzheimer’s disease (AD), a neurodegenerative condition, which directly places it within the healthcare and biomedicine domain. Specifically, it proposes a physics-informed neural network to analyze the propagation of tau aggregates and their interaction with amyloid-beta plaques, both of which are hallmark biomarkers for AD. The focus on neuroimaging datasets and the ability to predict tau progression strongly ties the research to medical applications, emphasizing disease progression modeling. Furthermore, terms like \"pathology propagation,\" \"neuroimaging datasets,\" and \"new understanding of pathology in AD\" directly associate the work with Biomedicine AI. Thus, the paper's application in understanding and predicting disease dynamics in Alzheimer's corresponds to both Healthcare AI and Biomedicine AI domains.",
    "prompt_tokens": 22440,
    "completion_tokens": 217,
    "total_tokens": 22657,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Radiology"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Diffusion Models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-Symbolic regression for capturing biological interactions"
    },
    "method": "Wasserstein-1 Lagrangian GAN; Symbolic regression; Reaction–Diffusion modeling",
    "application": "Tau propagation modeling – Alzheimer’s Disease",
    "code_link": "https://github.com/Dandy5721/MFG4AD2025",
    "dataset_name": [
      "ADNI",
      "OASIS"
    ]
  },
  {
    "id": "I822ZIRtms",
    "title": "Characterizing control between interacting subsystems with deep Jacobian estimation",
    "authors": [
      "Adam Joseph Eisen",
      "Mitchell Ostrow",
      "Sarthak Chandra",
      "Leo Kozachkov",
      "Earl K Miller",
      "Ila R Fiete"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Biological function arises through the dynamical interactions of multiple subsystems, including those between brain areas, within gene regulatory networks, and more. A common approach to understanding these systems is to model the dynamics of each subsystem and characterize communication between them. An alternative approach is through the lens of control theory: how the subsystems control one another. This approach involves inferring the directionality, strength, and contextual modulation of control between subsystems. However, methods for understanding subsystem control are typically linear and cannot adequately describe the rich contextual effects enabled by nonlinear complex systems. To bridge this gap, we devise a data-driven nonlinear control-theoretic framework to characterize subsystem interactions via the Jacobian of the dynamics. We address the challenge of learning Jacobians from time-series data by proposing the JacobianODE, a deep learning method that leverages properties of the Jacobian to directly estimate it for arbitrary dynamical systems from data alone. We show that JacobianODE models outperform existing Jacobian estimation methods on challenging systems, including high-dimensional chaos. Applying our approach to a multi-area recurrent neural network (RNN) trained on a working memory selection task, we show that the “sensory” area gains greater control over the “cognitive” area over learning. Furthermore, we leverage the JacobianODE to directly control the trained RNN, enabling precise manipulation of its behavior. Our work lays the foundation for a theoretically grounded and data-driven understanding of interactions among biological subsystems.",
    "keywords": [
      "control theory",
      "dynamical systems",
      "neuroscience",
      "deep learning",
      "modular systems"
    ],
    "pdf_url": "https://openreview.net/pdf?id=I822ZIRtms",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper’s focus on characterizing interactions among biological subsystems, including brain areas and gene regulatory networks, strongly ties it to the Biomedicine AI domain. Specifically, the application of the developed framework to analyze neural dynamics in a multi-area recurrent neural network (RNN) trained on a cognitive task suggests connections to neuroscience and neurobiological modeling. Understanding subsystem control in biological systems can be relevant to advancing biomedicine through insights into brain function and gene regulation. The mention of these biological systems aligns with biomedicine-oriented research, even though clinical or therapeutic applications are not explicitly stated.",
    "prompt_tokens": 22449,
    "completion_tokens": 221,
    "total_tokens": 22670,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Physiological Time Series Analysis"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "JacobianODE; Deep learning for Jacobian estimation",
    "application": "Inference of control dynamics in biological subsystems",
    "code_link": "N/A",
    "dataset_name": [
      "Synthetic high-dimensional chaotic systems",
      "Task-trained RNN working memory dataset"
    ]
  },
  {
    "id": "fYSPRGmS6l",
    "title": "MoRE-Brain: Routed Mixture of Experts for Interpretable and Generalizable Cross-Subject fMRI Visual Decoding",
    "authors": [
      "YUXIANG WEI",
      "Yanteng Zhang",
      "Xi Xiao",
      "Tianyang Wang",
      "Xiao Wang",
      "Vince Calhoun"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Decoding visual experiences from fMRI offers a powerful avenue to understand human perception and develop advanced brain-computer interfaces. However, current progress often prioritizes maximizing reconstruction fidelity while overlooking interpretability, an essential aspect for deriving neuroscientific insight. To address this gap, we propose MoRE-Brain, a neuro-inspired framework designed for high-fidelity, adaptable, and interpretable visual reconstruction. MoRE-Brain uniquely employs a hierarchical Mixture-of-Experts architecture where distinct experts process fMRI signals from functionally related voxel groups, mimicking specialized brain networks. The experts are first trained to encode fMRI into the frozen CLIP space. A finetuned diffusion model then synthesizes images, guided by expert outputs through a novel dual-stage routing mechanism that dynamically weighs expert contributions across the diffusion process. MoRE-Brain offers three main advancements: First, it introduces a novel Mixture-of-Experts architecture grounded in brain network principles for neuro-decoding. Second, it achieves efficient cross-subject generalization by sharing core expert networks while adapting only subject-specific routers. Third, it provides enhanced mechanistic insight, as the explicit routing reveals precisely how different modeled brain regions shape the semantic and spatial attributes of the reconstructed image. Extensive experiments validate MoRE-Brain’s high reconstruction fidelity, with bottleneck analyses further demonstrating its effective utilization of fMRI signals, distinguishing genuine neural decoding from over-reliance on generative priors. Consequently, MoRE-Brain marks a substantial advance towards more generalizable and interpretable fMRI-based visual decoding.",
    "keywords": [
      "brain decoding; visual reconstruction; fMRI"
    ],
    "pdf_url": "https://openreview.net/pdf?id=fYSPRGmS6l",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper centers on decoding visual experiences from fMRI signals, involving neuroscientific and neurobiological modeling, which are strong indicators of relevance to the Biomedicine AI domain. Specifically, the methodology emphasizes interpreting brain activity (\"fMRI signals from functionally related voxel groups\" and \"neural decoding\"), which directly ties to neuroscience and biomedical research. Furthermore, tools such as fMRI are widely used in biomedical applications for studying brain function and disorders, making this research pertinent to the Biomedicine AI domain even though clinical applications are not explicitly mentioned.",
    "prompt_tokens": 22637,
    "completion_tokens": 210,
    "total_tokens": 22847,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Other Imaging Modalities"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Diffusion Models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Hierarchical Mixture of Experts (MoE) architecture; Diffusion models",
    "application": "Visual decoding – fMRI",
    "code_link": "https://github.com/yuxiangwei0808/MoRE-Brain",
    "dataset_name": [
      "NSD (Natural Scenes Dataset)",
      "COCO captions"
    ]
  },
  {
    "id": "kgjY80e1LF",
    "title": "Symmetry-Preserving Conformer Ensemble Networks for Molecular Representation Learning",
    "authors": [
      "Yanqiao Zhu",
      "Yidan Shi",
      "Yuanzhou Chen",
      "Fang Sun",
      "Yizhou Sun",
      "Wei Wang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Molecular representation learning has emerged as a promising approach for modeling molecules with deep learning in chemistry and beyond. While 3D geometric models effectively capture molecular structure, they typically process single static conformers, overlooking the inherent flexibility and dynamics of molecules. In reality, many molecular properties depend on distributions of thermodynamically accessible conformations rather than single structures. Recent works show that learning from conformer ensembles can improve molecular representations, but existing approaches either produce unphysical structures through averaging or require restrictive molecular alignment. In this paper, we propose SymmetryPreserving Conformer Ensemble networks (SPiCE), which introduces two key innovations: (1) geometric mixture-of-experts for selective processing of scalar and vector features, and (2) hierarchical ensemble encoding that combines ensemblelevel representation with cross-conformer integration. Crucially, SPiCE ensures physically meaningful representations by maintaining joint equivariance to geometric transformations of individual conformers and conformer permutations. Extensive experiments demonstrate that SPiCE consistently outperforms existing conformer ensemble methods and state-of-the-art structural aggregation models across quantum mechanical and biological property prediction tasks.",
    "keywords": [
      "Molecular Conformers",
      "Geometric Deep Learning",
      "Mixture-of-Experts"
    ],
    "pdf_url": "https://openreview.net/pdf?id=kgjY80e1LF",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explores molecular representation learning through SPiCE networks, which explicitly target improvements in quantum mechanical and biological property prediction tasks. The mention of \"biological property prediction\" aligns with Biomedicine AI as it pertains to understanding and modeling biomedically relevant molecular structures. Furthermore, the focus on molecular conformers and the implications for biological and drug-related research fits within the realm of biomedical applications, such as drug discovery or therapeutic development. These factors strongly suggest relevance to biomedicine AI.",
    "prompt_tokens": 22243,
    "completion_tokens": 236,
    "total_tokens": 22479,
    "Topic Axis I": {
      "MainTopic": "Drug Discovery & Development",
      "SubTopic": "Target Identification & Validation"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Graph Representation Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Geometric Mixture-of-Experts (GMoE); Equivariant 3D GNN",
    "application": "molecular property prediction",
    "code_link": "https://github.com/DannieSYD/SPiCE",
    "dataset_name": [
      "Drugs-7.5K",
      "Kraken",
      "CoV2",
      "CoV2-3CL"
    ]
  },
  {
    "id": "2PhVe7p9xD",
    "title": "Unsupervised Trajectory Optimization for 3D Registration in Serial Section Electron Microscopy using Neural ODEs",
    "authors": [
      "Zhenbang Zhang",
      "Jingtong Feng",
      "Hongjia Li",
      "Haythem El-Messiry",
      "zhiqiang xu",
      "Renmin Han"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Series Section Electron Microscopy (ssEM) has emerged as a pivotal technology for deciphering nanoscale biological architectures. Three-dimensional (3D) registration is a critical step in ssEM, tasked with rectifying axial misalignments and nonlinear distortions introduced during serial sectioning. The core scientific challenge lies in achieving distortion mitigation without erasing the natural morphological deformations of biological tissues, thereby enabling faithful reconstruction of 3D ultrastructural organization. In this study, we present a paradigm-shifting optimization framework that rethinks 3D registration through the lens of manifold trajectory optimization. We propose the first continuous trajectory dynamics formulation for 3D registration and introduce a novel optimization strategy. Specifically, we introduce a dual optimization objective that inherently balances global trajectory smoothness with local structural preservation, while developing a solver that combines Gauss-Seidel iteration with Neural ODEs to systematically integrate biophysical priors with data-driven deformation compensation. A key strength of our method is its fully unsupervised training, which avoids reliance on ground truth and suits ssEM scenarios where annotations are difficult to obtain. Extensive experiments on multiple datasets spanning diverse tissue types demonstrate our method's superior performance in structural restoration accuracy and cross-tissue robustness.",
    "keywords": [
      "computer vision",
      "biomedical image processing",
      "ai for science"
    ],
    "pdf_url": "https://openreview.net/pdf?id=2PhVe7p9xD",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on optimizing 3D registration for Serial Section Electron Microscopy (ssEM), which is explicitly stated to enable \"faithful reconstruction of 3D ultrastructural organization\" to study nanoscale biological tissues. This directly supports biomedical applications, such as understanding biological structures and processes critical in biomedicine. The abstract mentions its relevance to \"biophysical priors\" and \"nanoscale biological architectures,\" which are central to biomedical research. Though it may not target healthcare-specific outcomes like clinical data or patient monitoring, its focus on biomedical image processing to enhance structural analysis makes it highly relevant to the Biomedicine AI domain. Keywords such as \"biomedical image processing\" further confirm its classification.",
    "prompt_tokens": 22386,
    "completion_tokens": 232,
    "total_tokens": 22618,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Other Imaging Modalities"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Neural ordinary differential equations; Image registration models",
    "application": "3D registration and segmentation - Medical Imaging",
    "code_link": "N/A",
    "dataset_name": [
      "P7 Mouse Heart",
      "Mouse Kidney",
      "P7 Mouse Liver",
      "Mouse Liver",
      "P7 Mouse Pancreas",
      "P7 Mouse Skin",
      "FemFlyBrain",
      "FAFB",
      "Mouse Cortex"
    ]
  },
  {
    "id": "aXpbgG5z6I",
    "title": "AI Debate Aids Assessment of Controversial Claims",
    "authors": [
      "Salman Rahman",
      "Sheriff Issaka",
      "Ashima Suvarna",
      "Genglin Liu",
      "James Shiffer",
      "Jaeyoung Lee",
      "Md Rizwan Parvez",
      "Hamid Palangi",
      "Shi Feng",
      "Nanyun Peng",
      "Yejin Choi",
      "Julian Michael",
      "Liwei Jiang",
      "Saadia Gabriel"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "As AI grows more powerful, it will increasingly shape how we understand the world. But with this influence comes the risk of amplifying misinformation and deepening social divides—especially on consequential topics where factual accuracy directly impacts well-being. Scalable Oversight aims to ensure AI systems remain truthful even when their capabilities exceed those of their evaluators. Yet when humans serve as evaluators, their own beliefs and biases can impair judgment. We study whether AI debate can guide biased judges toward the truth by having two AI systems debate opposing sides of controversial factuality claims on COVID-19 and climate change where people hold strong prior beliefs. We conduct two studies. Study I recruits human judges with either mainstream or skeptical beliefs who evaluate claims through two protocols: debate (interaction with two AI advisors arguing opposing sides) or consultancy (interaction with a single AI advisor). Study II uses AI judges with and without human-like personas to evaluate the same protocols. In Study I, debate consistently improves human judgment accuracy and confidence calibration, outperforming consultancy by 4-10\\% across COVID-19 and climate change claims. The improvement is most significant for judges with mainstream beliefs (up to +15.2\\% accuracy on COVID-19 claims), though debate also helps skeptical judges who initially misjudge claims move toward accurate views (+4.7\\% accuracy). In Study II, AI judges with human-like personas achieve even higher accuracy (78.5\\%) than human judges (70.1\\%) and default AI judges without personas (69.8\\%), suggesting their potential for supervising frontier AI models. These findings highlight AI debate as a promising path toward scalable, bias-resilient oversight in contested domains.",
    "keywords": [
      "Scalable Oversight",
      "AI Debate",
      "Cognitive Bias",
      "Factuality"
    ],
    "pdf_url": "https://openreview.net/pdf?id=aXpbgG5z6I",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract discusses AI debate to evaluate controversial claims, including COVID-19—a prominent healthcare-related topic. COVID-19 is a global health concern with direct relevance to healthcare and public well-being, making the paper partially focused on a healthcare-related domain. While the paper primarily assesses ways to improve judgment accuracy through AI debate, the inclusion of COVID-19-specific claims ties it to Healthcare AI, as better understanding and evaluating factuality on this topic can shape clinical policies and public health strategies. Therefore, this paper partially engages with Healthcare AI.",
    "prompt_tokens": 22552,
    "completion_tokens": 204,
    "total_tokens": 22756,
    "Topic Axis I": {
      "MainTopic": "Population Health & Computational Epidemiology",
      "SubTopic": "Public Health Surveillance"
    },
    "Topic Axis II": {
      "MainTopic": "Causal Inference & Reasoning",
      "SubTopic": "Causal Representation Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "Clinician-in-the-loop Systems"
    },
    "method": "AI debate structure; Persona-conditioned LLM judges",
    "application": "Factuality judgment accuracy improvement",
    "code_link": "https://github.com/salman-lui/ai-debate",
    "dataset_name": [
      "Climate-Fever",
      "CORD-19"
    ]
  },
  {
    "id": "7wdi1LaocD",
    "title": "AlphaFold Database Debiasing for Robust Inverse Folding",
    "authors": [
      "Cheng Tan",
      "Zhenxiao Cao",
      "Zhangyang Gao",
      "Siyuan Li",
      "Yufei Huang",
      "Stan Z. Li"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The AlphaFold Protein Structure Database (AFDB) offers unparalleled structural coverage at near-experimental accuracy, positioning it as a valuable resource for data-driven protein design. However, its direct use in training deep models that are sensitive to fine-grained atomic geometry—such as inverse folding—exposes a critical limitation. Comparative analysis of structural feature distributions reveals that AFDB structures exhibit distinct statistical regularities, reflecting a systematic geometric bias that deviates from the conformational diversity found in experimentally determined structures from the Protein Data Bank (PDB). While AFDB structures are cleaner and more idealized, PDB structures capture the intrinsic variability and physical realism essential for generalization in downstream tasks. To address this discrepancy, we introduce a Debiasing Structure AutoEncoder (DeSAE) that learns to reconstruct native-like conformations from intentionally corrupted backbone geometries. By training the model to recover plausible structural states, DeSAE implicitly captures a more robust and natural structural manifold. At inference, applying DeSAE to AFDB structures produces debiased structures that significantly improve inverse folding performance across multiple benchmarks. This work highlights the critical impact of subtle systematic biases in predicted structures and presents a principled framework for debiasing, significantly boosting the performance of structure-based learning tasks like inverse folding.",
    "keywords": [
      "protein structure; protein design; AlphaFold"
    ],
    "pdf_url": "https://openreview.net/pdf?id=7wdi1LaocD",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on protein structure prediction and design, which are highly relevant to Biomedicine AI due to their applications in drug discovery, molecular modeling, and synthetic biology. The abstract explicitly mentions the use of the AlphaFold Protein Structure Database in protein design and describes methods for improving structural modeling for downstream tasks. Protein design and inverse folding are critical areas in biomedical research, often contributing to understanding molecular interactions and developing therapeutics, which aligns well with the Biomedicine AI domain. Keywords such as \"protein structure\" and \"protein design\" further support this classification.",
    "prompt_tokens": 21958,
    "completion_tokens": 233,
    "total_tokens": 22191,
    "Topic Axis I": {
      "MainTopic": "Computational Genomics & Multi-Omics",
      "SubTopic": "Proteomics & Protein Structure"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Disentangled Representation Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-Structural Debiasing"
    },
    "method": "Geometric vector perceptrons; Graph-based protein modeling; Structural debiasing autoencoder",
    "application": "Protein inverse folding — structural design",
    "code_link": "N/A",
    "dataset_name": [
      "AFDB",
      "PDB",
      "Debiased AFDB",
      "CATH 4.2",
      "TS50",
      "TS500",
      "CATH 4.3"
    ]
  },
  {
    "id": "ZC2rbIYWfy",
    "title": "Few-Shot Learning from Gigapixel Images via Hierarchical Vision-Language Alignment and Modeling",
    "authors": [
      "Bryan Wong",
      "Jong woo kim",
      "Huazhu Fu",
      "Mun Yong Yi"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Vision-language models (VLMs) have recently been integrated into multiple instance learning (MIL) frameworks to address the challenge of few-shot, weakly supervised classification of whole slide images (WSIs). A key trend involves leveraging multi-scale information to better represent hierarchical tissue structures. However, existing methods often face two key limitations: (1) insufficient modeling of interactions within the same modalities across scales (e.g., 5x and 20x) and (2) inadequate alignment between visual and textual modalities on the same scale. To address these gaps, we propose HiVE-MIL, a hierarchical vision-language framework that constructs a unified graph consisting of (1) parent–child links between coarse (5x) and fine (20x) visual/textual nodes to capture hierarchical relationships, and (2) heterogeneous intra-scale edges linking visual and textual nodes on the same scale. To further enhance semantic consistency, HiVE-MIL incorporates a two-stage, text-guided dynamic filtering mechanism that removes weakly correlated patch–text pairs, and introduces a hierarchical contrastive loss to align textual semantics across scales. Extensive experiments on TCGA breast, lung, and kidney cancer datasets demonstrate that HiVE-MIL consistently outperforms both traditional MIL and recent VLM-based MIL approaches, achieving gains of up to 4.1% in macro F1 under 16-shot settings. Our results demonstrate the value of jointly modeling hierarchical structure and multimodal alignment for efficient and scalable learning from limited pathology data. The code is available at https://github.com/bryanwong17/HiVE-MIL.",
    "keywords": [
      "computational pathology",
      "whole slide image",
      "multiple instance learning",
      "vision-language model",
      "multimodal learning",
      "few-shot learning"
    ],
    "pdf_url": "https://openreview.net/pdf?id=ZC2rbIYWfy",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly focuses on the classification of whole slide images (WSIs), which are integral to computational pathology—a key area of biomedicine. It describes methods for analyzing tissue structures and pathology data to enhance cancer diagnosis in datasets such as TCGA breast, lung, and kidney cancer. This is a clear health-related application involving biomedical imaging and few-shot learning techniques applied directly to cancer research, solidly placing the paper in the domain of Healthcare AI or Biomedicine AI. Keywords like \"clinical pathology,\" \"whole slide image,\" and \"cancer datasets\" further emphasize its relevance.",
    "prompt_tokens": 21936,
    "completion_tokens": 218,
    "total_tokens": 22154,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Digital Pathology"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Vision Foundation Models (VFMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Hierarchical vision-language modeling; Contrastive loss",
    "application": "Cancer subtype classification",
    "code_link": "https://github.com/bryanwong17/HiVE-MIL",
    "dataset_name": [
      "TCGA-NSCLC",
      "TCGA-BRCA",
      "TCGA-RCC"
    ]
  },
  {
    "id": "2uKVyGq5zK",
    "title": "ProtInvTree: Deliberate Protein Inverse Folding with Reward-guided Tree Search",
    "authors": [
      "Mengdi Liu",
      "Xiaoxue Cheng",
      "Zhangyang Gao",
      "Hong Chang",
      "Cheng Tan",
      "Shiguang Shan",
      "Xilin Chen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Designing protein sequences that fold into a target 3D structure—known as protein inverse folding—is a fundamental challenge in protein engineering. While recent deep learning methods have achieved impressive performance by recovering native sequences, they often overlook the one-to-many nature of the problem: multiple diverse sequences can fold into the same structure. This motivates the need for a generative model capable of designing diverse sequences while preserving structural consistency. To address this trade-off, we introduce ProtInvTree, the first reward-guided tree-search framework for protein inverse folding. ProtInvTree reformulates sequence generation as a deliberate, step-wise decision-making process, enabling the exploration of multiple design paths and exploitation of promising candidates through self-evaluation, lookahead, and backtracking. We propose a two-stage focus-and-grounding action mechanism that decouples position selection and residue generation. To efficiently evaluate intermediate states, we introduce a jumpy denoising strategy that avoids full rollouts. Built upon pretrained protein language models, ProtInvTree supports flexible test-time scaling by adjusting the search depth and breadth without retraining. Empirically, ProtInvTree outperforms state-of-the-art baselines across multiple benchmarks, generating structurally consistent yet diverse sequences, including those far from the native ground truth. The code is available at https://github.com/A4Bio/ProteinInvBench/.",
    "keywords": [
      "protein design"
    ],
    "pdf_url": "https://openreview.net/pdf?id=2uKVyGq5zK",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on protein inverse folding, a fundamental task in protein engineering. Protein design is explicitly mentioned in the abstract, which is a key aspect of biomedical research, particularly important in areas such as drug discovery and therapeutic development. The methods described aim to generate diverse protein sequences that are structurally consistent, which could have applications in designing proteins for therapeutic or other biomedical uses. Terms like \"protein design\" and \"structurally consistent sequences\" strongly align with Biomedicine AI. Although the paper does not explicitly frame its work within a therapeutic context, the relevance to synthetic biology and potential for applications in drug discovery makes this fall under Biomedicine AI.",
    "prompt_tokens": 22473,
    "completion_tokens": 237,
    "total_tokens": 22710,
    "Topic Axis I": {
      "MainTopic": "Computational Genomics & Multi-Omics",
      "SubTopic": "Protein folding prediction"
    },
    "Topic Axis II": {
      "MainTopic": "Sequential Decision Making & Reinforcement Learning",
      "SubTopic": "Monte Carlo Tree Search (MCTS)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-Tree-based design explained using structural metrics"
    },
    "method": "Monte Carlo Tree Search; Jumpy Denoising; Focus-and-Grounding Action",
    "application": "Protein sequence design – structure consistency and diversity",
    "code_link": "https://github.com/A4Bio/ProteinInvBench",
    "dataset_name": [
      "CATH v4.2",
      "CATH v4.3",
      "TS45"
    ]
  },
  {
    "id": "P37GIj4wB7",
    "title": "Jacobian-Based Interpretation of Nonlinear Neural Encoding Model",
    "authors": [
      "Xiaohui Gao",
      "Haoran Yang",
      "Yue Cheng",
      "Mengfei Zuo",
      "Yiheng Liu",
      "Peiyang Li",
      "Xintao Hu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In recent years, the alignment between artificial neural network (ANN) embeddings and blood oxygenation level dependent (BOLD) responses in functional magnetic resonance imaging (fMRI) via neural encoding models has significantly advanced research on neural representation mechanisms and interpretability in the brain. However, these approaches remain limited in characterizing the brain’s inherently nonlinear response properties. To address this, we propose the Jacobian-based Nonlinearity Evaluation (JNE), an interpretability metric for nonlinear neural encoding models. JNE quantifies nonlinearity by statistically measuring the dispersion of local linear mappings (Jacobians) from model representations to predicted BOLD responses, thereby approximating the nonlinearity of BOLD signals. Centered on proposing JNE as a novel interpretability metric, we validated its effectiveness through controlled simulation experiments on various activation functions and network architectures, and further verified it on real fMRI data, demonstrating a hierarchical progression of nonlinear characteristics from primary to higher-order visual cortices, consistent with established cortical organization. We further extended JNE with Sample-Specificity (JNE-SS), revealing stimulus-selective nonlinear response patterns in functionally specialized brain regions. As the first interpretability metric for quantifying nonlinear responses, JNE provides new insights into brain information processing. Code available at https://github.com/Gaitxh/JNE.",
    "keywords": [
      "fMRI",
      "neural encoding model",
      "nonlinearity",
      "Jacobian matrix"
    ],
    "pdf_url": "https://openreview.net/pdf?id=P37GIj4wB7",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses a novel interpretability metric (JNE) for analyzing nonlinear neural encoding models used to understand BOLD responses in fMRI data, which is directly related to studying neural representation mechanisms in the brain. fMRI is a widely used imaging modality in neuroscience and clinical research for brain function analysis, which falls under the scope of biomedicine. Additionally, the paper validates its approach using real fMRI data, emphasizing its utility for investigating brain functions and cortical structures. This strongly associates the research with Biomedicine AI, as it targets understanding brain information processing, which has implications for neuroscience and potentially clinical applications.",
    "prompt_tokens": 22348,
    "completion_tokens": 203,
    "total_tokens": 22551,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Other Imaging Modalities"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Jacobian-based Nonlinearity Evaluation (JNE); Neural Encoding Models",
    "application": "Nonlinearity quantification – visual cortex fMRI signals",
    "code_link": "N/A",
    "dataset_name": [
      "Natural Scenes Dataset (NSD)"
    ]
  },
  {
    "id": "JPoQca8CSg",
    "title": "MoleBridge: Synthetic Space Projecting with Discrete Markov Bridges",
    "authors": [
      "Rongchao Zhang",
      "Yu Huang",
      "Yongzhi Cao",
      "Hanpin Wang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Molecular synthetic space projecting is a critical technique in de novo molecular design, which aims to rectify molecules without synthesizability guarantee by converting them into synthetic postfix notations. However, the vast synthesizable chemical space and the discrete data modalities involved pose significant challenges to postfix notation conversion benchmarking. In this paper, we exploit conditional probability transitions in discrete state space and introduce MoleBridge, a deep generative model built on the Markov bridge approach for designing postfix notations of molecular synthesis pathways. MoleBridge consists of two iterative optimizations: i) Autoregressive extending of notation tokens from molecular graphs, and ii) generation of discrete reaction postfix notations through Markov bridge, where noisy token blocks are progressively denoised over multi-step iterations. For the challenging second iteration, which demands sensitivity to incorrect generative probability paths within intricate chemical spaces, we employ a thinking and denoising separation approach to denoise. Empirically, we find that MoleBridge is capable of accurately predicting synthesis pathways while exhibiting excellent performance in a variety of application scenarios.",
    "keywords": [
      "Markov Bridges",
      "Diffusion Models",
      "AIGC",
      "Generation"
    ],
    "pdf_url": "https://openreview.net/pdf?id=JPoQca8CSg",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses \"Molecular synthetic space projecting\" and introduces the MoleBridge model for designing synthesis pathways of molecules. Molecular synthesis and pathways are strongly associated with drug discovery and related biomedical applications because they often involve the creation or optimization of molecules for therapeutic purposes. Phrases like \"molecular synthetic space projecting,\" \"de novo molecular design,\" and \"synthetic pathways\" align with tasks in Biomedicine AI, particularly under the domain of computational drug discovery or molecular therapeutics. Additionally, the mention of \"reaction postfix notations\" and the exploration of chemical spaces supports the relevance to synthetic biology or chemistry-focused biomedical research. While the paper does not explicitly state healthcare or biomedicine contexts, its focus is highly indicative of relevance to biomedical research involving molecular modeling and design.",
    "prompt_tokens": 22518,
    "completion_tokens": 221,
    "total_tokens": 22739,
    "Topic Axis I": {
      "MainTopic": "Drug Discovery & Development",
      "SubTopic": "Structure-Based Drug Design"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Diffusion Models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Markov Bridge Process; Semi-Autoregressive Molecular Design; Cross-Attention Mechanisms",
    "application": "Drug Target Generation; Synthetic Path Projection",
    "code_link": "https://github.com/MoleBridgeProject",
    "dataset_name": [
      "SynNet",
      "Enamine US Stock Catalog",
      "ChEMBL"
    ]
  },
  {
    "id": "agcXjEHmyW",
    "title": "CSBrain: A Cross-scale Spatiotemporal Brain Foundation Model for EEG Decoding",
    "authors": [
      "Yuchen Zhou",
      "Jiamin Wu",
      "Zichen Ren",
      "Zhouheng Yao",
      "Weiheng Lu",
      "Kunyu Peng",
      "Qihao Zheng",
      "Chunfeng Song",
      "Wanli Ouyang",
      "Chao Gou"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Understanding and decoding human brain activity from electroencephalography (EEG) signals is a fundamental problem in neuroscience and artificial intelligence, with applications ranging from cognition and emotion recognition to clinical diagnosis and brain–computer interfaces. While recent EEG foundation models have made progress in generalized brain decoding by leveraging unified architectures and large-scale pretraining, they inherit a scale-agnostic dense modeling paradigm from NLP and vision. This design overlooks an intrinsic property of neural activity—cross-scale spatiotemporal structure. Different EEG task patterns span a broad range of temporal and spatial scales, from brief neural activations to slow-varying rhythms, and from localized cortical activations to large-scale distributed interactions. Ignoring this diversity may lead to suboptimal representations and weakened generalization ability. To address these limitations, we propose CSBrain, a Cross-scale Spatiotemporal Brain foundation model for generalized EEG decoding. CSBrain introduces two key components: (i) Cross-scale Spatiotemporal Tokenization (CST), which aggregates multi-scale features within localized temporal windows and anatomical brain regions into compact scale-aware token representations; and (ii) Structured Sparse Attention (SSA), which models cross-window and cross-region dependencies for diverse decoding tasks, further enriching scale diversities while eliminating the spurious dependencies. CST and SSA are alternately stacked to progressively integrate cross-scale spatiotemporal dependencies. Extensive experiments across 11 representative EEG tasks and 16 datasets demonstrate that CSBrain consistently outperforms both task-specific models and strong foundation baselines. These results establish cross-scale modeling as a key inductive bias for generalized EEG decoding and highlight CSBrain as a robust backbone for future brain–AI research.",
    "keywords": [
      "Brain Foundation Model",
      "Cross-scale",
      "Generalized EEG Decoding"
    ],
    "pdf_url": "https://openreview.net/pdf?id=agcXjEHmyW",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly focuses on decoding human brain activity using EEG signals, which are widely used in neuroscience and healthcare-related applications such as cognition recognition, emotion recognition, clinical diagnosis, and brain–computer interfaces. These applications strongly align with the domain of Biomedicine AI, as EEG decoding is a critical tool for understanding neural behaviors relevant to medical and therapeutic contexts. Additionally, the paper mentions its utility for generalized EEG decoding across multiple tasks, which could include clinical and diagnostic tasks. The focus on brain activity analysis and its relevance to neuroscience further supports classification within this domain.",
    "prompt_tokens": 22075,
    "completion_tokens": 227,
    "total_tokens": 22302,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Physiological Time Series Analysis"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-Inherent interpretability for EEG signals"
    },
    "method": "Cross-scale Spatiotemporal Tokenization; Masked Autoencoder; Structured Sparse Attention",
    "application": "Seizure detection – EEG; Emotion recognition – EEG",
    "code_link": "N/A",
    "dataset_name": [
      "CHB-MIT",
      "Siena",
      "SEED-V",
      "FACED"
    ]
  },
  {
    "id": "lovTDtbsdZ",
    "title": "Towards a General Attention Framework on Gyrovector Spaces for Matrix Manifolds",
    "authors": [
      "Rui Wang",
      "Chen Hu",
      "Xiaoning Song",
      "Xiaojun Wu",
      "Nicu Sebe",
      "Ziheng Chen"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Deep neural networks operating on non-Euclidean geometries have recently demonstrated impressive performance across various machine-learning applications. Several studies have extended the attention mechanism to different manifolds. However, most existing non-Euclidean attention models are tailored to specific geometries, limiting their applicability. On the other hand, recent studies show that several matrix manifolds, such as Symmetric Positive Definite (SPD), Symmetric Positive Semi-Definite (SPSD), and Grassmannian manifolds, admit gyrovector structures, which extend vector addition and scalar product into manifolds. Leveraging these properties, we propose a Gyro Attention (GyroAtt) framework over general gyrovector spaces, applicable to various matrix geometries. Empirically, we manifest GyroAtt on three gyro structures on the SPD manifold, three on the SPSD manifold, and one on the Grassmannian manifold. Extensive experiments on four electroencephalography (EEG) datasets demonstrate the effectiveness of our framework.",
    "keywords": [
      "Manifold Learning",
      "Gyrovector Space",
      "Attention Mechanism",
      "Riemannian Manifold",
      "Signal Classification"
    ],
    "pdf_url": "https://openreview.net/pdf?id=lovTDtbsdZ",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper describes a framework leveraging gyrovector spaces for manifold learning, specifically applied to electroencephalography (EEG) datasets. EEG is a common neurobiological data modality used in healthcare and biomedicine for diagnosing and monitoring neurological disorders, brain activity-related conditions, or cognitive states. Therefore, the paper is highly relevant to the Biomedicine AI domain due to the explicit experimental application to EEG datasets, which are frequently used in health-related contexts and neuroscience research.",
    "prompt_tokens": 21971,
    "completion_tokens": 235,
    "total_tokens": 22206,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Physiological Time Series Analysis"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Gyro Attention Framework; Riemannian neural networks",
    "application": "EEG decoding – Inter-session and inter-subject evaluations",
    "code_link": "https://github.com/ChenHu-ML/GyroAtt",
    "dataset_name": [
      "BNCI2014001",
      "BNCI2015001",
      "MAMEM-SSVEP-II",
      "BCI-ERN"
    ]
  },
  {
    "id": "ugOn7Pohxv",
    "title": "Towards Prospective Medical Image Reconstruction via Knowledge-Informed Dynamic Optimal Transport",
    "authors": [
      "Taoran Zheng",
      "Yan Yang",
      "Xing Li",
      "Xiang Gu",
      "Jian Sun",
      "Zongben Xu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Medical image reconstruction from measurement data is a vital but challenging inverse problem. Deep learning approaches have achieved promising results, but often requires paired measurement and high-quality images, which is typically simulated through a forward model, i.e., retrospective reconstruction. However, training on simulated pairs commonly leads to performance degradation on real prospective data due to the retrospective-to-prospective gap caused by incomplete imaging knowledge in simulation. To address this challenge, this paper introduces imaging Knowledge-Informed Dynamic Optimal Transport (KIDOT), a novel dynamic optimal transport framework with optimality in the sense of preserving consistency with imaging physics in transport, that conceptualizes reconstruction as finding a dynamic transport path. KIDOT learns from unpaired data by modeling reconstruction as a continuous evolution path from measurements to images, guided by an imaging knowledge-informed cost function and transport equation. This dynamic and knowledge-aware approach enhances robustness and better leverages unpaired data while respecting acquisition physics. Theoretically, we demonstrate that KIDOT naturally generalizes dynamic optimal transport, ensuring its mathematical rationale and solution existence. Extensive experiments on MRI and CT reconstruction demonstrate KIDOT's superior performance. Code is available at https://github.com/TaoranZheng717/KIDOT.",
    "keywords": [
      "prospective medical image reconstruction",
      "dynamic optimal transport",
      "inverse problem",
      "imaging knowledge-informed"
    ],
    "pdf_url": "https://openreview.net/pdf?id=ugOn7Pohxv",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly focuses on \"medical image reconstruction,\" which is a direct application of AI within the healthcare domain. It addresses challenges in reconstructing MRI and CT images, which are vital tools for clinical diagnosis and treatment planning. The mention of imaging physics and acquisition systems further underscores its relevance to healthcare and medical imaging applications. This ties closely to Healthcare AI as the methods described aim to improve medical imaging quality and adaptability to real-world clinical data.",
    "prompt_tokens": 22360,
    "completion_tokens": 226,
    "total_tokens": 22586,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Other Imaging Modalities"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Dynamic Optimal Transport; E2E-VarNet backbone",
    "application": "Reconstruction of MRI and CT images",
    "code_link": "N/A",
    "dataset_name": [
      "fastMRI",
      "Prospective MRI Dataset",
      "Clinical Prospective CT Dataset"
    ]
  },
  {
    "id": "XQIa0vGIum",
    "title": "Explore In-Context Message Passing Operator for Graph Neural Networks in A Mean Field Game",
    "authors": [
      "Tingting Dan",
      "Xinwei Huang",
      "Won Hwa Kim",
      "Guorong Wu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "In typical graph neural networks (GNNs), feature representation learning naturally evolves through iteratively updating node features and exchanging information based on graph topology. In this context, we conceptualize that the learning process in GNNs is a mean-field game (MFG), where each graph node is an agent, interacting with its topologically connected neighbors.  However, current GNNs often employ the identical MFG strategy across different graph datasets, regardless of whether the graph exhibits homophilic or heterophilic characteristics. To address this challenge, we propose to formulate the learning mechanism into a variational framework of the MFG inverse problem, introducing an in-context selective message passing paradigm for each agent, which promotes the best overall outcome for the graph. Specifically, we seek for the application-adaptive transportation function (controlling information exchange throughout the graph) and reaction function (controlling feature representation learning on each agent), *on the fly*, which allows us to uncover the most suitable selective mechanism of message passing by solving an MFG variational problem through the lens of Hamiltonian flows. Taken together, our variational framework unifies existing GNN models into various mean-field games with distinct equilibrium states, each characterized by the learned in-context message passing operators. Furthermore, we present an agnostic end-to-end deep model, coined *Game-of-GNN*, to jointly identify the message passing mechanism and fine-tune the GNN hyper-parameters on top of the elucidated message passing operators. *Game-of-GNN* has achieved SOTA performance on diverse graph data, including popular benchmark datasets and human connectomes. More importantly, the mathematical insight of MFG framework provides a new window to understand the foundational principles of graph learning as an interactive dynamical system, which allows us to reshape the idea of designing next-generation GNN models.",
    "keywords": [
      "Graph neural network",
      "mean-field game",
      "reaction diffusion model",
      "partial differential equation"
    ],
    "pdf_url": "https://openreview.net/pdf?id=XQIa0vGIum",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract mentions the use of \"human connectomes\" as one of the graph data types for evaluating the proposed model, *Game-of-GNN*. Human connectomes are directly relevant to neuroscience and neurobiological modeling, which are integral components of Biomedicine AI. The exploration of graph neural networks (GNNs) in this context, coupled with a mean-field game formulation, provides insights into brain dynamics and feature representation learning, pertinent to understanding neural systems. Thus, the paper's methods and applications suggest relevance to Biomedicine AI.",
    "prompt_tokens": 22241,
    "completion_tokens": 256,
    "total_tokens": 22497,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Physiological Time Series Analysis"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Graph Representation Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Graph neural networks (GNN); ICNN backbone; Hamiltonian flows",
    "application": "Disease diagnosis – Neurological disorders",
    "code_link": "https://github.com/Dandy5721/Game-of-GNN",
    "dataset_name": [
      "MUTAGE",
      "NCI1",
      "ENZYMES",
      "D&D",
      "PTC_FM",
      "IMDB",
      "PROTEINS",
      "ABIDE",
      "ADNI",
      "OASIS",
      "PPMI"
    ]
  },
  {
    "id": "idtZwmjakN",
    "title": "GEM: Empowering MLLM for Grounded ECG Understanding with Time Series and Images",
    "authors": [
      "Xiang Lan",
      "Feng Wu",
      "Kai He",
      "Qinghao Zhao",
      "Shenda Hong",
      "Mengling Feng"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "While recent multimodal large language models (MLLMs) have advanced automated ECG interpretation, they still face two key limitations: (1) insufficient multimodal synergy between ECG time series and ECG images, and (2) limited explainability in linking diagnoses to granular waveform evidence. We introduce GEM, the first MLLM unifying ECG time series, 12-lead ECG images and text for grounded and clinician-aligned ECG interpretation. GEM enables feature-grounded analysis, evidence-driven reasoning, and a clinician-like diagnostic process through three core innovations: a dual-encoder framework extracting complementary time series and image features, cross-modal alignment for effective multimodal understanding, and knowledge-guided instruction data generation for generating high-granularity grounding data (ECG-Grounding) linking diagnoses to measurable parameters ($e.g.$, QRS/PR Intervals). Additionally, we propose the Grounded ECG Understanding task, a clinically motivated benchmark designed to comprehensively assess the MLLM's capability in grounded ECG understanding. Experimental results on both existing and our proposed benchmarks show GEM significantly improves predictive performance (CSN $7.4\\%$ $\\uparrow$), explainability ($22.7\\%$ $\\uparrow$), and grounding ($25.3\\%$ $\\uparrow$), making it a promising approach for real-world clinical applications. Codes, model, and data are available at https://github.com/lanxiang1017/GEM.",
    "keywords": [
      "Multimodal Large Language Model",
      "ECG",
      "Time Series",
      "Medical AI"
    ],
    "pdf_url": "https://openreview.net/pdf?id=idtZwmjakN",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on the development of a multimodal large language model (MLLM), GEM, which is specifically designed for “grounded and clinician-aligned ECG interpretation.” The use of ECG time series and images, as well as the emphasis on linking diagnoses to measurable parameters (e.g., QRS/PR intervals), indicates its direct application in clinical settings and tasks related to patient diagnosis and monitoring. Additionally, the introduction of the \"Grounded ECG Understanding\" task highlights the paper’s relevance to healthcare and the improvement of medical AI systems. The abstract references concepts such as predictive performance, explainability, and grounding in the context of real-world clinical applications, which strongly align with healthcare AI. Keywords like \"ECG,\" \"Medical AI,\" and \"clinician-like diagnostic process\" further reinforce the paper’s relevance to this domain.",
    "prompt_tokens": 22131,
    "completion_tokens": 226,
    "total_tokens": 22357,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Physiological Time Series Analysis"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Vision Foundation Models (VFMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Multimodal Encoding; Cross-modal Alignment Learning; Knowledge-guided Instruction Data Generation",
    "application": "ECG analysis and interpretation",
    "code_link": "https://github.com/lanxiang1017/GEM",
    "dataset_name": [
      "ECG-Grounding",
      "MIMIC-IV-ECG",
      "PTB-XL"
    ]
  },
  {
    "id": "gUbQZ7AtaZ",
    "title": "Chiron-o1: Igniting Multimodal Large Language Models towards Generalizable Medical Reasoning via Mentor-Intern Collaborative Search",
    "authors": [
      "Haoran Sun",
      "Yankai Jiang",
      "Wenjie Lou",
      "Yujie Zhang",
      "Wenjie Li",
      "Lilong Wang",
      "Mianxin Liu",
      "Lei Liu",
      "Xiaosong Wang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Multimodal large language models (MLLMs) have begun to demonstrate robust reasoning capabilities on general tasks, yet their application in the medical domain remains in its early stages. Constructing chain-of-thought (CoT) training data is essential for bolstering the reasoning abilities of medical MLLMs. However, existing approaches exhibit a deficiency in offering a comprehensive framework for searching and evaluating effective reasoning paths towards critical diagnosis. To address this challenge, we propose Mentor-Intern Collaborative Search (MICS), a novel reasoning-path searching scheme to generate rigorous and effective medical CoT data. MICS first leverages mentor models to initialize the reasoning, one step at a time, then prompts each intern model to continue the thinking along those initiated paths, and finally selects the optimal reasoning path according to the overall reasoning performance of multiple intern models. The reasoning performance is determined by an MICS-Score, which assesses the quality of generated reasoning paths. Eventually, we construct MMRP, a multi-task medical reasoning dataset with ranked difficulty, and Chiron-o1,  a new medical MLLM devised via a curriculum learning strategy, with robust visual question-answering and generalizable reasoning capabilities. Extensive experiments demonstrate that Chiron-o1, trained on our CoT dataset constructed using MICS, achieves state-of-the-art performance across a list of medical visual question answering and reasoning benchmarks. Codes are available at https://github.com/Yankai96/Chiron-o1",
    "keywords": [
      "Multimodal Large Language Models",
      "Medical Reasoning",
      "Chain-of-Thought"
    ],
    "pdf_url": "https://openreview.net/pdf?id=gUbQZ7AtaZ",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly focuses on developing multimodal large language models for medical reasoning tasks, which fall under Healthcare AI and Biomedicine AI. The abstract references \"critical diagnosis,\" \"medical reasoning dataset,\" and \"medical visual question answering\" benchmarks, all of which are strongly indicative of healthcare-specific applications. Furthermore, the creation of a medical reasoning dataset and the emphasis on improving diagnosis and reasoning capabilities ties directly to clinical and healthcare relevance.",
    "prompt_tokens": 22437,
    "completion_tokens": 234,
    "total_tokens": 22671,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Radiology"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Vision Foundation Models (VFMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Mentor-Intern Collaborative Search; Curriculum Learning; Chain-of-Thought (CoT) reasoning",
    "application": "Medical visual question answering and reasoning",
    "code_link": "https://github.com/Yankai96/Chiron-o1",
    "dataset_name": [
      "MMRP",
      "VQA_RAD",
      "SLAKE",
      "PATH_VQA",
      "PMC_VQA",
      "MMMU(H&M)"
    ]
  },
  {
    "id": "867TaCMfCj",
    "title": "A Cautionary Tale on Integrating Studies with Disparate Outcome Measures for Causal Inference",
    "authors": [
      "Harsh Parikh",
      "Trang Quynh Nguyen",
      "Elizabeth Stuart",
      "Kara E. Rudolph",
      "Caleb H Miles"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Data integration approaches are increasingly used to enhance the efficiency and generalizability of studies. However, a key limitation of these methods is the assumption that outcome measures are identical across datasets -- an assumption that often does not hold in practice. Consider the following opioid use disorder (OUD) studies: the XBOT trial and the POAT study, both evaluating the effect of medications for OUD on withdrawal symptom severity (not the primary outcome of either trial). While XBOT measures withdrawal severity using the subjective opiate withdrawal scale, POAT uses the clinical opiate withdrawal scale. We analyze this realistic yet challenging setting where outcome measures differ across studies and where neither study records both types of outcomes. Our paper studies whether and when integrating studies with disparate outcome measures leads to efficiency gains. We introduce three sets of assumptions -- with varying degrees of strength -- linking both outcome measures. Our theoretical and empirical results highlight a cautionary tale: integration can improve asymptotic efficiency only under the strongest assumption linking the outcomes. However, misspecification of this assumption leads to bias. In contrast, a milder assumption may yield finite-sample efficiency gains, yet these benefits diminish as sample size increases. We illustrate these trade-offs via a case study integrating the XBOT and POAT datasets to estimate the comparative effect of two medications for opioid use disorder on withdrawal symptoms. By systematically varying the assumptions linking the SOW and COW scales, we show potential efficiency gains and the risks of bias. Our findings emphasize the need for careful assumption selection when fusing datasets with differing outcome measures, offering guidance for researchers navigating this common challenge in modern data integration.",
    "keywords": [
      "causal inference",
      "data integration",
      "semiparametric statistics",
      "double robustness"
    ],
    "pdf_url": "https://openreview.net/pdf?id=867TaCMfCj",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly addresses the integration of datasets from studies that focus on opioid use disorder (OUD) and outcome measures like withdrawal symptom severity, which are directly linked to health outcomes. The context of the research falls within healthcare as it involves the estimation of treatment effects of medications for OUD, a public health issue. Additionally, terms like \"clinical opiate withdrawal scale\" and \"medications for OUD\" indicate a focus on health-related outcomes, making this highly relevant to the Healthcare AI/Biomedicine AI domain. The use of causal inference methods in a clinical setting further supports its classification in this domain.",
    "prompt_tokens": 22113,
    "completion_tokens": 212,
    "total_tokens": 22325,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Clinical Natural Language Processing"
    },
    "Topic Axis II": {
      "MainTopic": "Causal Inference & Reasoning",
      "SubTopic": "Individualized Treatment Effect Estimation"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Semiparametric estimation; Bayesian meta-analytical modeling",
    "application": "Treatment effect estimation – opioid use disorder",
    "code_link": "N/A",
    "dataset_name": [
      "XBOT",
      "POAT"
    ]
  },
  {
    "id": "aTqfufujj7",
    "title": "From Indicators to Insights: Diversity-Optimized for Medical Series-Text Decoding via LLMs",
    "authors": [
      "Xiyuan Jin",
      "Jing Wang",
      "Ziwei Lin",
      "Qianru Jia",
      "Yuqing Huang",
      "Xiaojun Ning",
      "Zhonghua Shi",
      "Youfang Lin"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Medical time-series analysis differs fundamentally from general ones by requiring specialized domain knowledge to interpret complex signals and clinical context.\nLarge language models (LLMs) hold great promise for augmenting medical time-series analysis by complementing raw series with rich contextual knowledge drawn from biomedical literature and clinical guidelines.\nHowever, realizing this potential depends on precise and meaningful prompts that guide the LLM to key information.\nYet, determining what constitutes effective prompt content remains non-trivial—especially in medical settings where signal interpretation often hinges on subtle, expert-defined decision-making indicators. \nTo this end, we propose InDiGO, a knowledge-aware evolutionary learning framework that integrates clinical signals and decision-making indicators through iterative optimization.\nAcross four medical benchmarks, InDiGO consistently outperforms prior methods. \nThe code is available at: https://github.com/jinxyBJTU/InDiGO.",
    "keywords": [
      "biomedical signal analysis",
      "medical time series",
      "knowledge-guided learning"
    ],
    "pdf_url": "https://openreview.net/pdf?id=aTqfufujj7",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses a framework, InDiGO, for medical time-series analysis, which integrates clinical signals and decision-making indicators. It explicitly focuses on using large language models (LLMs) to interpret complex medical signals in contexts like those found in biomedical literature and clinical guidelines. The tasks involve medical benchmarks and references to clinical signal interpretation, which are clearly tied to both healthcare and biomedical AI applications. Additionally, the keywords “biomedical signal analysis” and “medical time series” strongly suggest relevance to these domains.",
    "prompt_tokens": 22698,
    "completion_tokens": 226,
    "total_tokens": 22924,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Physiological Time Series Analysis"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Large Language Models (LLMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Masked Monte Carlo importance sampling; match alignment and diversity optimization; series-text joint decoding",
    "application": "Medical prognosis and diagnosis – physiological time series",
    "code_link": "https://github.com/jinxyBJTU/InDiGO",
    "dataset_name": [
      "Sleep-EDF-20",
      "Sleep-EDF-78",
      "PTB-XL",
      "HAR"
    ]
  },
  {
    "id": "7L4NvUtZY3",
    "title": "FlashBias: Fast Computation of Attention with Bias",
    "authors": [
      "Haixu Wu",
      "Minghao Guo",
      "Yuezhou Ma",
      "Yuanxu Sun",
      "Jianmin Wang",
      "Wojciech Matusik",
      "Mingsheng Long"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Attention with bias, which extends standard attention by introducing prior knowledge as an additive bias matrix to the query-key scores, has been widely deployed in vision, language, protein-folding and other advanced scientific models, underscoring its status as a key evolution of this foundational module. However, introducing bias terms creates a severe efficiency bottleneck in attention computation. It disrupts the tightly fused memory-compute pipeline that underlies the speed of accelerators like FlashAttention, thereby stripping away most of their performance gains and leaving biased attention computationally expensive. Surprisingly, despite its common usage, targeted efficiency optimization for attention with bias remains absent, which seriously hinders its application in complex tasks. Diving into the computation of FlashAttention, we prove that its optimal efficiency is determined by the rank of the attention weight matrix. Inspired by this theoretical result, this paper presents FlashBias based on the low-rank compressed sensing theory, which can provide fast-exact computation for many widely used attention biases and a fast-accurate approximation for biases in general formalizations. FlashBias can fully take advantage of the extremely optimized matrix multiplication operation in modern GPUs, achieving 1.5$\\times$ speedup for Pairformer in AlphaFold 3, and over 2$\\times$ speedup for attention with bias in vision and language models without loss of accuracy. Code is available at this repository: https://github.com/thuml/FlashBias.",
    "keywords": [
      "FlashAttention",
      "Efficient Attention"
    ],
    "pdf_url": "https://openreview.net/pdf?id=7L4NvUtZY3",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper mentions \"Pairformer in AlphaFold 3\" as one of the applications of FlashBias. AlphaFold is a well-known tool in the domain of protein folding, which is highly relevant to biomedicine, as it aids in understanding protein structures critical for drug discovery and molecular biology. Protein folding models are typically utilized in biomedical research to advance knowledge about molecular mechanisms underlying diseases and therapies. Although the focus of the paper is on computational efficiency improvements for biased attention, its application to AlphaFold strongly ties it to Biomedicine AI.",
    "prompt_tokens": 22405,
    "completion_tokens": 204,
    "total_tokens": 22609,
    "Topic Axis I": {
      "MainTopic": "Computational Genomics & Multi-Omics",
      "SubTopic": "Proteomics & Protein Structure"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Transformer-based models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "N/A"
    },
    "method": "Transformer-based models; Neural decomposition techniques",
    "application": "Protein structure prediction",
    "code_link": "https://github.com/thuml/FlashBias",
    "dataset_name": [
      "weightedPDB_before2109_wopb_nometalc_0925",
      "recentPDB_1536_sample384_0925"
    ]
  },
  {
    "id": "OiqQGjNvyJ",
    "title": "OMiSO: Adaptive optimization of state-dependent brain stimulation to shape neural population states",
    "authors": [
      "Yuki Minai",
      "Joana Soldado-Magraner",
      "Byron M. Yu",
      "Matthew A. Smith"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The coordinated activity of neural populations underlies myriad brain functions. Manipulating this activity using brain stimulation techniques has great potential for scientific and clinical applications, as it provides a tool to causally influence brain function. To improve the accuracy by which one can manipulate neural activity, it is important to (1) take into account the pre-stimulation brain state, which can influence the brain’s response to stimulation, and (2) adaptively update stimulation parameters over time to compensate for changes in the brain’s response to stimulation. In this work, we propose Online MicroStimulation Optimization (OMiSO), a brain stimulation framework that leverages brain state information to find stimulation parameters that can drive neural population activity toward specified states. OMiSO includes two key advances: i) training a stimulation-response model that leverages the pre-stimulation brain state, and inverting this model to choose the stimulation parameters, and ii) updating this inverse model online using newly-observed responses to stimulation. We tested OMiSO using intracortical microstimulation with a ``Utah'' array and found that it outperformed competing methods that do not incorporate these advances. Taken together, OMiSO provides greater accuracy in achieving specified activity states, thereby advancing neuromodulation technologies for understanding the brain and for treating brain disorders.",
    "keywords": [
      "closed-loop optimization",
      "microstimulation",
      "neural population activity",
      "dimensionality reduction",
      "latent variable models",
      "reinforcement learning",
      "behavior cloning",
      "proximal policy optimization"
    ],
    "pdf_url": "https://openreview.net/pdf?id=OiqQGjNvyJ",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on the \"manipulation of neural population activity\" through adaptive brain stimulation techniques, specifically using intracortical microstimulation, which is closely tied to neuroscience and neurobiology. It mentions potential applications for \"understanding the brain and treating brain disorders,\" indicating relevance to Biomedicine AI. Techniques discussed, such as reinforcement learning within the context of brain stimulation optimization, aim to advance neuromodulation technologies, which are often applied to therapeutic interventions for neurological or psychiatric conditions. Furthermore, the inclusion of terms like \"state-dependent brain stimulation\" strongly suggests relevance to biomedical research aimed at improving health-related outcomes through precise neural modulation.",
    "prompt_tokens": 22163,
    "completion_tokens": 196,
    "total_tokens": 22359,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Physiological Time Series Analysis"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "Clinician-in-the-loop Systems"
    },
    "method": "PPO-inspired adaptive optimization; inverse model updating",
    "application": "Brain state modulation – neural activity prediction",
    "code_link": "https://github.com/yuumii-san/OMiSO.git",
    "dataset_name": [
      "N/A"
    ]
  },
  {
    "id": "3p4272zl7q",
    "title": "Rationalized All-Atom Protein Design with Unified Multi-Modal Bayesian Flow",
    "authors": [
      "Hanlin Wu",
      "Yuxuan Song",
      "Zhe Zhang",
      "Zhilong Zhang",
      "Hao Zhou",
      "Wei-Ying Ma",
      "Jingjing Liu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Designing functional proteins is a critical yet challenging problem due to the intricate interplay between backbone structures, sequences, and side-chains. Current approaches often decompose protein design into separate tasks, which can lead to accumulated errors, while recent efforts increasingly focus on all-atom protein design. However, we observe that existing all-atom generation approaches suffering from an information shortcut issue, where models inadvertently infer sequences from side-chain information, compromising their ability to accurately learn sequence distributions. To address this, we introduce a novel rationalized information flow strategy to eliminate the information shortcut. Furthermore, motivated by the advantages of Bayesian flows over differential equation–based methods, we propose the first Bayesian flow formulation for protein backbone orientations by recasting orientation modeling as an equivalent hyperspherical generation problem with antipodal symmetry. To validate, our method delivers consistently exceptional performance in both peptide and antibody design tasks.",
    "keywords": [
      "Bayesian Flow Networks",
      "Protein Generation"
    ],
    "pdf_url": "https://openreview.net/pdf?id=3p4272zl7q",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper is described as focusing on \"all-atom protein design\" and introduces novel methods for designing functional proteins. Protein design and modeling are highly relevant to the Biomedicine AI domain, as proteins are fundamental components in biological systems and have diverse applications in drug discovery and therapeutic development. The mention of \"peptide and antibody design tasks,\" which have clear implications in biomedical research and healthcare (e.g., the development of therapeutic antibodies), further reinforces the connection to Biomedicine AI. The introduction of advanced machine learning techniques, such as Bayesian flow networks, to address these challenges aligns with the domain's goals to leverage AI for biomedical and therapeutic advancements.",
    "prompt_tokens": 22679,
    "completion_tokens": 216,
    "total_tokens": 22895,
    "Topic Axis I": {
      "MainTopic": "Computational Genomics & Multi-Omics",
      "SubTopic": "Proteomics & Protein Structure"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Diffusion Models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Bayesian flow networks; rationalized information flow;",
    "application": "antibody design; peptide structure prediction",
    "code_link": "https://github.com/GenSI-THUAIR/ProBayes",
    "dataset_name": [
      "PepBench",
      "PepBD"
    ]
  },
  {
    "id": "AHjspi4R22",
    "title": "GLID$^2$E: A Gradient-Free Lightweight Fine-tune Approach for Discrete Biological Sequence Design",
    "authors": [
      "Hanqun Cao",
      "Haosen Shi",
      "Chenyu Wang",
      "Sinno Jialin Pan",
      "Pheng-Ann Heng"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The design of biological sequences is essential for engineering functional biomolecules that contribute to advancements in human health and biotechnology. Recent advances in diffusion models, with their generative power and efficient conditional sampling, have made them a promising approach for sequence generation. To enhance model performance on limited data and enable multi-objective design and optimization, reinforcement learning (RL)-based fine-tuning has shown great potential. However, existing post-sampling and fine-tuning methods either lack stability in discrete optimization when avoiding gradients or incur high computational costs when employing gradient-based approaches, creating significant challenges for achieving both control and stability in the tuning process.\nTo address these limitations, we propose GLID$^2$E, a gradient-free RL-based tuning approach for discrete diffusion models. Our method introduces a clipped likelihood constraint to regulate the exploration space and implements reward shaping to better align the generative process with design objectives, ensuring a more stable and efficient tuning process. \nBy integrating these techniques, GLID$^2$E mitigates training instabilities commonly encountered in RL and diffusion-based frameworks, enabling robust optimization even in challenging biological design tasks. In the DNA sequence and protein sequence design systems, GLID$^2$E achieves competitive performance in function-based design while maintaining computational efficiency and a flexible tuning mechanism.",
    "keywords": [
      "Deep learning",
      "Protein design",
      "Diffusion Model",
      "Reinforcement learning",
      "DNA design",
      "Protein inverse folding"
    ],
    "pdf_url": "https://openreview.net/pdf?id=AHjspi4R22",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly focuses on biological sequence design, including DNA and protein sequence optimization, which are essential components of biomedical research. By addressing function-based design for biomolecules and presenting novel methods for sequence generation, the research supports advancements in areas like genomics and protein engineering, which are critical for understanding and treating diseases, drug discovery, and therapeutic development. Keywords such as \"Protein design,\" \"DNA design,\" and \"Protein inverse folding\" further indicate relevance to biomedicine AI. These applications are directly tied to developing technologies for healthcare and biotechnology, making the paper fall under Biomedicine AI.",
    "prompt_tokens": 21990,
    "completion_tokens": 220,
    "total_tokens": 22210,
    "Topic Axis I": {
      "MainTopic": "Computational Genomics & Multi-Omics",
      "SubTopic": "Transcriptomics"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Diffusion Models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-effect of design bias in biological modeling"
    },
    "method": "Reinforcement Learning; Diffusion models; PPO-based optimization",
    "application": "DNA enhancer design; thermostable protein optimization",
    "code_link": "https://github.com/chq1155/GLID2E",
    "dataset_name": [
      "700,000 enhancer sequences",
      "PDB single-chain structures"
    ]
  },
  {
    "id": "VkSd42HWil",
    "title": "Dual-Res Tandem Mamba-3D: Bilateral Breast Lesion Detection and Classification on Non-contrast Chest CT",
    "authors": [
      "Jiaheng Zhou",
      "Wei Fang",
      "Luyuan Xie",
      "Yanfeng Zhou",
      "Lianyan Xu",
      "Minfeng Xu",
      "Ge Yang",
      "Yuxing Tang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Breast cancer remains a leading cause of death among women, with early detection significantly improving prognosis. Non-contrast computed tomography (NCCT) scans of the chest, routinely acquired for thoracic assessments, often capture the breast region incidentally, presenting an underexplored opportunity for opportunistic breast lesion detection without additional imaging cost or radiation. However, the subtle appearance of lesions in NCCT and the difficulty of jointly modeling lesion detection and malignancy classification pose unique challenges.\nIn this work, we propose Dual-Res Tandem Mamba-3D (DRT-M3D), a novel multitask framework for opportunistic breast cancer analysis on NCCT scans. DRT-M3D introduces a dual-resolution architecture, which captures fine-grained spatial details for segmentation-based lesion detection and global contextual features for breast-level cancer classification. It further incorporates a tandem input mechanism that models bilateral breast regions jointly through Mamba-3D blocks, enabling cross-breast feature interaction by leveraging subtle asymmetries between the two sides. \nOur approach achieves state-of-the-art performance in both tasks across multi-institutional NCCT datasets spanning four medical centers. Extensive experiments and ablation studies validate the effectiveness of each key component.",
    "keywords": [
      "Opportunistic Bilateral Breast Cancer Analysis",
      "Non-contrast Chest CT",
      "Joint Detection and Classification",
      "State Space Models"
    ],
    "pdf_url": "https://openreview.net/pdf?id=VkSd42HWil",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper focuses on \"opportunistic breast cancer analysis\" using non-contrast chest CT scans, which are frequently utilized in medical diagnostics. Keywords and phrases like \"breast cancer,\" \"lesion detection,\" \"malignancy classification,\" and the mention of \"multi-institutional NCCT datasets\" suggest that the research directly pertains to healthcare applications, specifically early breast cancer detection, a clinical and diagnostic task. Additionally, the framework involves AI techniques for medical imaging analysis, aligning it with the Healthcare AI and Biomedicine AI domains.",
    "prompt_tokens": 22249,
    "completion_tokens": 213,
    "total_tokens": 22462,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Other Imaging Modalities"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "Human-AI Collaborative Performance"
    },
    "method": "Selective State Space Models; Mamba-3D; Tandem Input Mechanism",
    "application": "Lesion segmentation and malignancy classification – NCCT",
    "code_link": "N/A",
    "dataset_name": [
      "Internal Institution 1",
      "Internal Institution 2",
      "Internal Institution 3",
      "External Institution"
    ]
  },
  {
    "id": "pzPyxXjHrT",
    "title": "Interpretable Next-token Prediction via the Generalized Induction Head",
    "authors": [
      "Eunji Kim",
      "Sriya Mantena",
      "Weiwei Yang",
      "Chandan Singh",
      "Sungroh Yoon",
      "Jianfeng Gao"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "While large transformer models excel in predictive performance, their lack of interpretability restricts their usefulness in high-stakes domains. To remedy this, we propose the Generalized Induction-Head Model (GIM), an interpretable model for next-token prediction inspired by the observation of “induction heads” in LLMs. GIM is a retrieval-based module that identifies similar sequences in the input context by combining exact n-gram matching and fuzzy matching based on a neural similarity metric. We evaluate GIM in two settings: language modeling and fMRI response prediction. In language modeling, GIM improves next-token prediction by up to 25%p over interpretable baselines, significantly narrowing the gap with black-box LLMs. In an fMRI setting, GIM improves neural response prediction by 20% and offers insights into the language selectivity of the brain. GIM represents a significant step toward uniting interpretability and performance across domains. The code is available at https://github.com/ejkim47/generalized-induction-head.",
    "keywords": [
      "interpretability",
      "ngram",
      "language modeling",
      "fmri",
      "neuroscience"
    ],
    "pdf_url": "https://openreview.net/pdf?id=pzPyxXjHrT",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses the application of the proposed Generalized Induction-Head Model (GIM) to an fMRI setting, specifically improving \"neural response prediction\" and offering insights into the \"language selectivity of the brain.\" fMRI is a neuroimaging technique used in neuroscience and healthcare contexts to study brain functions and often has relevance to medical and biomedical research. Improving neural response prediction and understanding brain activity are directly tied to healthcare and neuroscience applications, placing the paper squarely within the Biomedicine AI domain.",
    "prompt_tokens": 22419,
    "completion_tokens": 210,
    "total_tokens": 22629,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Digital Health & Wearable Sensor Data"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Vision Foundation Models (VFMs)"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Fuzzy Matching Model; Generalized Induction Head; Language Model",
    "application": "Next-token prediction; fMRI response prediction",
    "code_link": "https://github.com/AlexWan0/infini-gram/tree/main",
    "dataset_name": [
      "BabyLM",
      "OpenWebText",
      "Pile",
      "FineWeb"
    ]
  },
  {
    "id": "7yOl9qiLWd",
    "title": "BrainODE: Neural Shape Dynamics for Age- and Disease-aware Brain Trajectories",
    "authors": [
      "Wonjung Park",
      "Suhyun Ahn",
      "Maria C. Valdes Hernandez",
      "Susana Muñoz Maniega",
      "Jinah Park"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We present BrainODE, a neural ordinary differential equation (ODE)-based framework for modeling continuous longitudinal deformations of brain shapes. BrainODE learns a deformation space over anatomically meaningful brain regions to facilitate early prediction of neurodegenerative disease progression. Addressing inherent challenges of longitudinal neuroimaging data-such as limited sample sizes, irregular temporal sampling, and substantial inter-subject variability-we propose a conditional neural ODE architecture that models shape dynamics with subject-specific age and cognitive status. To enable autoregressive forecasting of brain morphology from a single observation, we propose a pseudo-cognitive status embedding that allows progressive shape prediction across intermediate time points with predicted cognitive decline. Experiments show that BrainODE outperforms time-aware baselines in predicting future brain shapes, demonstrating strong generalization across longitudinal datasets with both regular and irregular time intervals.",
    "keywords": [
      "Shape analysis",
      "Medical application",
      "Prediagnosis"
    ],
    "pdf_url": "https://openreview.net/pdf?id=7yOl9qiLWd",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper \"BrainODE: Neural Shape Dynamics for Age- and Disease-aware Brain Trajectories\" discusses a framework specifically designed for the longitudinal study of brain shape deformations in relation to age and neurodegenerative diseases. References to \"early prediction of neurodegenerative disease progression,\" \"brain morphology,\" as well as terms such as \"age-aware\" and \"cognitive status\" highlight its relevance to Healthcare AI and Biomedicine AI. The focus on modeling changes in brain structures for predicting health outcomes related to diseases firmly situates this work in the domain of medical applications and neuroscience research. Additionally, the use of neuroimaging, an important tool in health-related diagnostics and monitoring, further supports this classification.",
    "prompt_tokens": 22475,
    "completion_tokens": 217,
    "total_tokens": 22692,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Radiology"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Diffusion Models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Neural Ordinary Differential Equations; Pseudo-Cognitive Status Embedding",
    "application": "Prediction of longitudinal brain shape deformation – Alzheimer's Disease",
    "code_link": "https://github.com/PWonjung/BrainODE",
    "dataset_name": [
      "ADNI",
      "OASIS",
      "AIBL",
      "LBC1936"
    ]
  },
  {
    "id": "3aNvX9TQTo",
    "title": "Disentangling Superpositions: Interpretable Brain Encoding Model with Sparse Concept Atoms",
    "authors": [
      "Alicia Zeng",
      "Jack L. Gallant"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Encoding models based on word embeddings or artificial neural network (ANN) features reliably predict brain responses to naturalistic stimuli but remain difficult to interpret. A central limitation is superposition—the entanglement of distinct semantic features along correlated directions in dense embeddings, which arises when latent features outnumber the embedding dimensions. This entanglement renders regression weights non-identifiable: different combinations of semantic directions can produce identical predicted brain activity, preventing principled interpretation of voxel selectivity. To overcome this, we introduce the Sparse Concept Encoding Model, which transforms dense embeddings into a higher-dimensional, sparse, and non-negative space of learned concept atoms. This transformation yields an axis-aligned semantic basis where each dimension corresponds to an interpretable concept, enabling direct readout of conceptual selectivity from voxel weights. When applied to fMRI data collected during story listening, our model matches the prediction performance of conventional dense models while substantially enhancing interpretability. It enables novel neuroscientific analyses such as disentangling overlapping cortical representations of time, space, and number, and revealing structured similarity among distributed conceptual maps. This framework offers a scalable and interpretable bridge between ANN-derived features and human conceptual representations in the brain.",
    "keywords": [
      "Interpretability",
      "Neuroscience",
      "fMRI",
      "Encoding Models",
      "Superposition"
    ],
    "pdf_url": "https://openreview.net/pdf?id=3aNvX9TQTo",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses the development of an interpretable brain encoding model applied to fMRI data, which is a neuroimaging technique extensively used in neuroscience and biomedical research. The reference to fMRI indicates relevance to biomedicine, as this technology is commonly employed to study brain activity and its relationship with behavior, cognition, and potentially clinical conditions. Additionally, the model’s application in understanding cortical representations of concepts such as time, space, and number aligns with biomedicine, as it could have implications for advancing our understanding of brain function. Thus, the work is relevant to Biomedicine AI.",
    "prompt_tokens": -1,
    "completion_tokens": -1,
    "total_tokens": -1,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Neuroimaging – fMRI encoding models"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Disentangled Representation Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "Method": "Sparse dictionary learning; Non-negative sparse coding; Vector Norm Reparameterization; Banded ridge regression",
    "Application": "Brain encoding and semantic representation mapping – fMRI",
    "Code Link": "https://github.com/alicialitrtwe/sparseconcept",
    "Dataset Name": ["Gallant Lab story listening fMRI dataset", "OSF preprocessed fMRI data"]
  
  },
  {
    "id": "hWtvsL51hO",
    "title": "SpiderSolver: A Geometry-Aware Transformer for Solving PDEs on Complex Geometries",
    "authors": [
      "Kai Qi",
      "Fan Wang",
      "Zhewen Dong",
      "Jian Sun"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Transformers have demonstrated effectiveness in solving partial differential equations (PDEs). However, extending them to solve PDEs on complex geometries remains a challenge. In this work, we propose SpiderSolver, a geometry-aware transformer that introduces spiderweb tokenization for handling complex domain geometry and irregularly discretized points. Our method partitions the irregular spatial domain into spiderweb-like patches, guided by the domain boundary geometry. SpiderSolver leverages a coarse-grained attention mechanism to capture global interactions across spiderweb tokens and a fine-grained attention mechanism to refine feature interactions between the domain boundary and its neighboring interior points. We evaluate SpiderSolver on PDEs with diverse domain geometries across seven datasets, including cars, airfoils, blood flow in the human thoracic aorta, as well as canonical cases governed by the Navier-Stokes, Darcy flow, elasticity, and plasticity equations. Experimental results demonstrate that SpiderSolver consistently achieves state-of-the-art performance across different datasets and metrics, with better generalization ability in the OOD setting. The code is available at https://github.com/Kai-Qi/SpiderSolver.",
    "keywords": [
      "Machine learning in PDE; Transformer architecture; PDE on complex geometry; Tokenization;"
    ],
    "pdf_url": "https://openreview.net/pdf?id=hWtvsL51hO",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract mentions evaluating the SpiderSolver model on \"blood flow in the human thoracic aorta,\" which is directly relevant to biomedicine as it pertains to understanding physiological processes and potential applications in medical research or healthcare, such as cardiovascular modeling or diagnosis. While the paper primarily focuses on solving PDEs in complex geometries, the inclusion of a health-related dataset strongly suggests relevance to Biomedicine AI, as it could aid in biomedical research or healthcare simulation tasks.",
    "prompt_tokens": 22242,
    "completion_tokens": 203,
    "total_tokens": 22445,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Other Imaging Modalities"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Transformer-based models; Spiderweb Tokenization",
    "application": "Blood flow dynamics prediction",
    "code_link": "N/A",
    "dataset_name": [
      "Blood Flow",
      "Bounded Navier-Stokes",
      "Darcy Flow"
    ]
  },
  {
    "id": "wTBhWbCRpN",
    "title": "Multi-scale Temporal Prediction via Incremental Generation and Multi-agent Collaboration",
    "authors": [
      "Zhitao Zeng",
      "Guojian Yuan",
      "Junyuan Mao",
      "Yuxuan Wang",
      "Xiaoshuang Jia",
      "Yueming Jin"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Accurate temporal prediction is the bridge between comprehensive scene understanding and embodied artificial intelligence. However, predicting multiple fine-grained states of scene at multiple temporal scales is difficult for vision-language models.\nWe formalize the Multi‐Scale Temporal Prediction (MSTP) task in general and surgical scene by decomposing multi‐scale into two orthogonal dimensions: the temporal scale, forecasting states of human and surgery at varying look‐ahead intervals, and the state scale, modeling a hierarchy of states in general and surgical scene. For instance in general scene, states of contacting relationship are finer-grained than states of spatial relationship. For instance in surgical scene, medium‐level steps are finer‐grained than high‐level phases yet remain constrained by their encompassing phase. \nTo support this unified task, we introduce the first MSTP Benchmark, featuring synchronized annotations across multiple state scales and temporal scales. We further propose a novel method, Incremental Generation and Multi‐agent Collaboration (IG-MC), which integrates two key innovations. Firstly, we propose an plug-and-play incremental generation to keep high-quality temporal prediction that continuously synthesizes up-to-date visual previews at expanding temporal scales to inform multiple decision-making agents, ensuring decision content and generated visuals remain synchronized and preventing performance degradation as look‐ahead intervals lengthen.\nSecondly, we propose a decision‐driven multi‐agent collaboration framework for multiple states prediction, comprising generation, initiation, and multi‐state assessment agents that dynamically triggers and evaluates prediction cycles to balance global coherence and local fidelity. Extensive experiments on the MSTP Benchmark in general and surgical scene show that IG‐MC is a generalizable plug-and-play method for MSTP, demonstrating the effectiveness of incremental generation and the stability of decision‐driven multi‐agent collaboration.",
    "keywords": [
      "Multi-scale Temporal Prediction",
      "Incremental Generation",
      "Multi-agent Collaboration"
    ],
    "pdf_url": "https://openreview.net/pdf?id=wTBhWbCRpN",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper references applications in the \"surgical scene,\" which explicitly ties the research to a healthcare domain. Surgical scene understanding and prediction inherently involve healthcare AI considerations, as they contribute to optimizing surgical procedures and enhancing embodied intelligence for medical applications. The focus on temporal prediction of surgical phases, steps, and states suggests a direct connection to improving outcomes in surgical contexts. Additionally, the method introduced could potentially be used to support decision-making in surgeries, which is a healthcare-specific task.",
    "prompt_tokens": 22401,
    "completion_tokens": 203,
    "total_tokens": 22604,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Physiological Time Series Analysis"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Diffusion Models"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Incremental generation; Multi-agent collaboration",
    "application": "Surgical workflow prediction",
    "code_link": "N/A",
    "dataset_name": [
      "MSTP Benchmark",
      "Action Genome"
    ]
  },
  {
    "id": "cdgVrsu7T5",
    "title": "RETRO SYNFLOW: Discrete Flow-Matching for Accurate and Diverse Single-Step Retrosynthesis",
    "authors": [
      "Robin Yadav",
      "Qi Yan",
      "Guy Wolf",
      "Joey Bose",
      "Renjie Liao"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "A fundamental challenge in organic chemistry is identifying and predicting the sequence of reactions that synthesize a desired target molecule. Due to the combinatorial nature of the chemical search space, single-step reactant prediction—i.e., single-step retrosynthesis—remains difficult, even for state-of-the-art template-free generative methods. These models often struggle to produce an accurate yet diverse set of feasible reactions in a chemically rational manner. In this paper, we propose RETRO SYNFLOW (RSF), a discrete flow-matching framework that formulates single-step retrosynthesis as a Markov bridge between a given product molecule and its corresponding reactants. Unlike prior approaches, RSF introduces a reaction center identification step to extract intermediate structures, or synthons, which serve as a more informative and structured source distribution for the discrete flow model. To further improve the diversity and chemical feasibility of generated samples, RSF incorporates Feynman-Kac (FK) steering with Sequential Monte Carlo (SMC) resampling at inference time. This approach leverages a learned forward-synthesis reward oracle to guide the generation process toward more promising reactant candidates. Empirically, RSF substantially outperforms the previous state-of-the-art methods in top-1 accuracy. In addition, FK-steering significantly improves round-trip accuracy, demonstrating stronger chemical validity and synthetic feasibility, all while maintaining competitive top-k performance. These results establish RSF as a new leading approach for single-step retrosynthesis prediction.",
    "keywords": [
      "retrosynthesis",
      "flow matching",
      "discrete data"
    ],
    "pdf_url": "https://openreview.net/pdf?id=cdgVrsu7T5",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses a novel framework for single-step retrosynthesis and emphasizes its application to organic chemistry. Retrosynthesis is a critical aspect of drug discovery as it involves predicting reactants and reaction pathways to synthesize target molecules, including pharmaceutical compounds. The concepts of identifying reaction centers and leveraging forward-synthesis reward oracles align closely with biomedical research tasks, particularly in computational drug design. Although the paper does not explicitly mention healthcare or clinical applications, the fundamental role of retrosynthesis in improving molecular synthesis and drug development situates it firmly within the Biomedicine AI domain. Keywords like \"reaction prediction\" and \"synthetic feasibility\" support this inference.",
    "prompt_tokens": 22518,
    "completion_tokens": 205,
    "total_tokens": 22723,
    "Topic Axis I": {
      "MainTopic": "Drug Discovery & Development",
      "SubTopic": "De Novo Molecule Design"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Diffusion Models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-Round-trip consistency and reactant scoring"
    },
    "method": "Discrete Flow Matching; Feynman-Kac Steering",
    "application": "Retrosynthesis prediction – molecular graphs",
    "code_link": "https://github.com/DSL-Lab/RetroSynFlow",
    "dataset_name": [
      "USPTO-50k"
    ]
  },
  {
    "id": "TtHvmhjNui",
    "title": "Self-Calibrating BCIs: Ranking and Recovery of Mental Targets Without Labels",
    "authors": [
      "Jonathan Grizou",
      "Carlos De la Torre-Ortiz",
      "Tuukka Ruotsalo"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "We consider the problem of recovering a mental target (e.g., an image of a face) that a participant has in mind from paired EEG (i.e., brain responses) and image (i.e., perceived faces) data collected during interactive sessions without access to labeled information. The problem has been previously explored with labeled data but not via self-calibration, where labeled data is unavailable. Here, we present the first framework and an algorithm, CURSOR, that learns to recover unknown mental targets without access to labeled data or pre-trained decoders. Our experiments on naturalistic images of faces demonstrate that CURSOR can (1) predict image similarity scores that correlate with human perceptual judgments without any label information, (2) use these scores to rank stimuli against an unknown mental target, and (3) generate new stimuli indistinguishable from the unknown mental target (validated via a user study, N=53). We release the brain response data set (N=29), associated face images used as stimuli data, and a codebase to initiate further research on this novel task.",
    "keywords": [
      "EEG",
      "brain-computer interfacing",
      "calibration-free"
    ],
    "pdf_url": "https://openreview.net/pdf?id=TtHvmhjNui",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses brain-computer interfacing (BCI), specifically using EEG data, which is a common neuroscientific technique often employed in medical and biomedicine contexts for understanding brain activity, mental states, or neurobiological functions. Although the focus is on self-calibration and mental targets (images of faces in this case), EEG data as a context is strongly associated with applications like neurological health monitoring, cognitive condition assessment, and potentially therapeutic interventions in neuroscience. Therefore, the paper aligns with Biomedicine AI due to its use of EEG and emphasis on brain response computation, which is a domain-relevant topic for understanding brain function or mental health dynamics.",
    "prompt_tokens": 22247,
    "completion_tokens": 204,
    "total_tokens": 22451,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Other Imaging Modalities"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-Explainable SC-BCI Methodologies"
    },
    "method": "CURSOR algorithm; EEGNet embeddings; Linear Regression",
    "application": "Image reconstruction – EEG embedding space",
    "code_link": "N/A",
    "dataset_name": [
      "new-EEG responses with face images"
    ]
  },
  {
    "id": "PhHrlDKcx1",
    "title": "Discovering Latent Graphs with GFlowNets for Diverse Conditional Image Generation",
    "authors": [
      "Bailey Trang",
      "Parham Saremi",
      "Alan Q. Wang",
      "Fangrui Huang",
      "Zahra TehraniNasab",
      "Amar Kumar",
      "Tal Arbel",
      "Li Fei-Fei",
      "Ehsan Adeli"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Capturing diversity is crucial in conditional and prompt-based image generation, particularly when conditions contain uncertainty that can lead to multiple plausible outputs. To generate diverse images reflecting this diversity, traditional methods often modify random seeds, making it difficult to discern meaningful differences between samples, or diversify the input prompt, which is limited in verbally interpretable diversity. We propose \\modelnamenospace, a novel conditional image generation framework, applicable to any pretrained conditional generative model, that addresses inherent condition/prompt uncertainty and generates diverse plausible images. \\modelname is based on a simple yet effective idea: decomposing the input condition into diverse latent representations, each capturing an aspect of the uncertainty and generating a distinct image. First, we integrate a latent graph, parameterized by Generative Flow Networks (GFlowNets), into the prompt representation computation. Second, leveraging GFlowNets' advanced graph sampling capabilities to capture uncertainty and output diverse trajectories over the graph, we produce multiple trajectories that collectively represent the input condition, leading to diverse condition representations and corresponding output images. Evaluations on natural image and medical image datasets demonstrate \\modelnamenospace’s improvement in both diversity and fidelity across image synthesis, image generation, and counterfactual generation tasks.",
    "keywords": [
      "generative models",
      "diffusion model",
      "diversity",
      "gflownet."
    ],
    "pdf_url": "https://openreview.net/pdf?id=PhHrlDKcx1",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract mentions the application of the proposed framework to medical image datasets, which strongly suggests relevance to healthcare AI or biomedicine AI. Medical imaging is often used in tasks such as disease diagnosis, treatment planning, and counterfactual generation for clinical reasoning. Additionally, the use of \"medical image datasets\" implies direct applicability to healthcare-related tasks or systems. While the majority of the framework focuses on general diversity in conditional image generation, the explicit reference to medical imaging is a key indicator of relevance to the domain.",
    "prompt_tokens": 22568,
    "completion_tokens": 211,
    "total_tokens": 22779,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Radiology"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Diffusion Models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Generative diffusion model; GFlowNets",
    "application": "Image generation – Chest X-Ray",
    "code_link": "https://github.com/mseitzer/pytorch-fid",
    "dataset_name": [
      "MIMIC-CXR",
      "NIH-CXR",
      "CheXpert"
    ]
  },
  {
    "id": "feLdTALuq3",
    "title": "Evaluating and Learning Optimal Dynamic Treatment Regimes under Truncation by Death",
    "authors": [
      "Sihyung Park",
      "Wenbin Lu",
      "Shu Yang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Truncation by death, a prevalent challenge in critical care, renders traditional dynamic treatment regime (DTR) evaluation inapplicable due to ill-defined potential outcomes. We introduce a principal stratification-based method, focusing on the always-survivor value function. We derive a semiparametrically efficient, multiply robust estimator for multi-stage DTRs, demonstrating its robustness and efficiency. Empirical validation and an application to electronic health records showcase its utility for personalized treatment optimization.",
    "keywords": [
      "Dynamic Treatment Regimes",
      "Panel Data",
      "Principal Stratification",
      "Truncation by Death",
      "Multiple Robustness",
      "Nonparametric Efficiency",
      "Personalized Medicine"
    ],
    "pdf_url": "https://openreview.net/pdf?id=feLdTALuq3",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper addresses the optimization of dynamic treatment regimes (DTRs) under a specific healthcare-related challenge, \"truncation by death,\" which is common in critical care settings. It explicitly involves methods for evaluating treatment strategies using electronic health records (EHRs), which are central to healthcare applications. The keywords such as \"personalized medicine,\" \"health records,\" and \"critical care\" strongly indicate relevance to Healthcare AI. Furthermore, the focus on personalized treatment optimization situates this paper firmly within the domain of Healthcare AI as it seeks to improve clinical decision-making and patient outcomes.",
    "prompt_tokens": 22364,
    "completion_tokens": 216,
    "total_tokens": 22580,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Physiological Time Series Analysis"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Trustworthy AI: Fairness, Robustness & Safety",
      "SubTopic": "Model Robustness & Uncertainty Quantification"
    },
    "method": "Multiply robust estimation; Principal stratification",
    "application": "Dynamic treatment regime optimization – Sepsis cases",
    "code_link": "N/A",
    "dataset_name": [
      "MIMIC-III"
    ]
  },
  {
    "id": "yh1t1yFtXG",
    "title": "Prior-Guided Flow Matching for Target-Aware Molecule Design with Learnable Atom Number",
    "authors": [
      "Jingyuan Zhou",
      "Hao Qian",
      "Shikui Tu",
      "Lei Xu"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Structure-based drug design (SBDD), aiming to generate 3D molecules with high binding affinity toward target proteins, is a vital approach in novel drug discovery. Although recent generative models have shown great potential, they suffer from unstable probability dynamics and mismatch between generated molecule size and the protein pockets geometry, resulting in inconsistent quality and off-target effects. We propose PAFlow, a novel target-aware molecular generation model featuring prior interaction guidance and a learnable atom number predictor. PAFlow adopts the efficient flow matching framework to model the generation process and constructs a new form of conditional flow matching for discrete atom types. A protein–ligand interaction predictor is incorporated to guide the vector field toward higher-affinity regions during generation, while an atom number predictor based on protein pocket information is designed to better align generated molecule size with target geometry. Extensive experiments on the CrossDocked2020 benchmark show that PAFlow achieves a new state-of-the-art in binding affinity (up to -8.31 Avg. Vina Score), simultaneously maintains favorable molecular properties.",
    "keywords": [
      "Structure-based drug design",
      "Molecule Generation",
      "Generative models",
      "Flow Matching",
      "Computational Biology"
    ],
    "pdf_url": "https://openreview.net/pdf?id=yh1t1yFtXG",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly focuses on target-aware molecule design for structure-based drug discovery, which is a critical aspect of biomedical research and therapeutic development. Terms such as \"drug discovery,\" \"binding affinity,\" \"protein–ligand interaction,\" and \"CrossDocked2020 benchmark\" are strongly indicative of Biomedicine AI applications. While the focus is on generative models and flow matching frameworks, these methods are directly applied to molecular modeling in the context of developing drugs, thereby aligning with biomedical AI goals.",
    "prompt_tokens": 22526,
    "completion_tokens": 209,
    "total_tokens": 22735,
    "Topic Axis I": {
      "MainTopic": "Drug Discovery & Development",
      "SubTopic": "De Novo Molecule Design"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Diffusion Models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-Prior-guided molecule generation"
    },
    "method": "Conditional Flow Matching; SE(3)-Equivariant Neural Networks",
    "application": "De Novo Molecule Design – Structure-Based Drug Discovery",
    "code_link": "N/A",
    "dataset_name": [
      "CrossDocked2020",
      "Binding MOAD"
    ]
  },
  {
    "id": "IWEc6kpy8O",
    "title": "ELDET: Early-Learning Distillation with Noisy Labels for Object Detection",
    "authors": [
      "Dongmin Choi",
      "Sangbin Lee",
      "EungGu Yun",
      "Jonghyuk Baek",
      "Frank C. Park"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "The performance of learning-based object detection algorithms, which attempt to both classify and locate objects within images, is determined largely by the quality of the annotated dataset used for training. Two types of labelling noises are prevalent: objects that are incorrectly classified (categorization noise) and inaccurate bounding boxes (localization noise); both noises typically occur together in large-scale datasets. In this paper we propose a distillation-based method to train object detectors that takes into account both categorization and localization noise. The key insight underpinning our method is that the early-learning phenomenon - in which models trained on noisy data with mixed clean and false labels tend to first fit to the clean data, and memorize the false labels later -- manifests earlier for localization noise than for categorization noise. We propose a method that uses models from the early-learning phase (before overfitting to noisy data occurs) as a teacher network. A plug-in module implementation compatible with general object detection architectures is developed, and its performance is validated against the state-of-the-art using PASCAL VOC, MS COCO and VinDr-CXR medical detection datasets.",
    "keywords": [
      "object detection",
      "noisy label",
      "early learning"
    ],
    "pdf_url": "https://openreview.net/pdf?id=IWEc6kpy8O",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The abstract mentions the use of the VinDr-CXR medical detection dataset, which points to a clear application of the proposed method in a healthcare or biomedical context. Specifically, \"VinDr-CXR\" is a dataset related to medical imaging for chest X-rays, typically used for tasks like detecting diseases or abnormalities. While the paper discusses a general object detection method, its validation on this medical dataset suggests relevance to medical imaging and healthcare AI applications. This aligns with the domains of Healthcare AI and Biomedicine AI due to the application of the method in analyzing health-related imaging data.",
    "prompt_tokens": 21993,
    "completion_tokens": 209,
    "total_tokens": 22202,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Radiology"
    },
    "Topic Axis II": {
      "MainTopic": "Data-Centric & Privacy-Enhancing AI",
      "SubTopic": "Self-Supervised & Unsupervised Learning"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Post-hoc Explanation Methods"
    },
    "method": "Self-knowledge distillation; Exponential moving average; Task-specific guidance mechanism",
    "application": "Object detection – medical imaging",
    "code_link": "N/A",
    "dataset_name": [
      "PASCAL VOC",
      "MS COCO",
      "VinDr-CXR"
    ]
  },
  {
    "id": "L3aEdxJMHl",
    "title": "NEED: Cross-Subject and Cross-Task Generalization for Video and Image Reconstruction from EEG Signals",
    "authors": [
      "Shuai Huang",
      "Huan Luo",
      "Haodong Jing",
      "Qixian Zhang",
      "Litao Chang",
      "Yating Feng",
      "Xiao Lin",
      "Chendong Qin",
      "Han Chen",
      "Shuwen Jia",
      "Siyi Sun",
      "Yongxiong Wang"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Translating brain activity into meaningful visual content has long been recognized as a fundamental challenge in neuroscience and brain-computer interface research. Recent advances in EEG-based neural decoding have shown promise, yet two critical limitations remain in this area: poor generalization across subjects and constraints to specific visual tasks. We introduce NEED, the first unified framework achieving zero-shot cross-subject and cross-task generalization for EEG-based visual reconstruction. Our approach addresses three fundamental challenges: (1) cross-subject variability through an Individual Adaptation Module pretrained on multiple EEG datasets to normalize subject-specific patterns, (2) limited spatial resolution and complex temporal dynamics via a dual-pathway architecture capturing both low-level visual dynamics and high-level semantics, and (3) task specificity constraints through a unified inference mechanism adaptable to different visual domains. For video reconstruction, NEED achieves better performance than existing methods. Importantly, Our model maintains 93.7% of within-subject classification performance and 92.4% of visual reconstruction quality when generalizing to unseen subjects, while achieving an SSIM of 0.352 when transferring directly to static image reconstruction without fine-tuning, demonstrating how neural decoding can move beyond subject and task boundaries toward truly generalizable brain-computer interfaces.",
    "keywords": [
      "EEG",
      "Cross-Subject",
      "Cross-Task",
      "Video Reconstruction",
      "Image Reconstruction"
    ],
    "pdf_url": "https://openreview.net/pdf?id=L3aEdxJMHl",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses using EEG signals for visual reconstruction, which is directly linked to neuroscience, a biomedical field. EEG (Electroencephalogram) is a health-related dataset often used in clinical and neuroscience research to study brain activity and neurological conditions. The focus on neural decoding and cross-subject generalization implies potential applications in brain-computer interfaces that can be used for medical purposes, such as assisting individuals with neurological impairments. While the abstract does not explicitly mention clinical applications, the use of EEG and its connection to neuroscience strongly aligns with the Biomedicine AI domain.",
    "prompt_tokens": 22449,
    "completion_tokens": 216,
    "total_tokens": 22665,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Physiological Time Series Analysis"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Human-AI Interaction & Collaboration",
      "SubTopic": "Clinician-in-the-loop Systems"
    },
    "method": "Hierarchical Individual Adaptation; Dual-pathway architecture; Unified inference mechanism",
    "application": "Visual reconstruction from EEG signals",
    "code_link": "https://hharr1son.github.io/",
    "dataset_name": [
      "SEED-DV",
      "THINGS-EEG"
    ]
  },
  {
    "id": "NY3LzmUXl7",
    "title": "Riemannian Flow Matching for Brain Connectivity Matrices via Pullback Geometry",
    "authors": [
      "Antoine Collas",
      "Ce Ju",
      "Nicolas Salvy",
      "Bertrand Thirion"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Generating realistic brain connectivity matrices is key to analyzing population heterogeneity in brain organization, understanding disease, and augmenting data in challenging classification problems. Functional connectivity matrices lie in constrained spaces—such as the set of symmetric positive definite or correlation matrices—that can be modeled as Riemannian manifolds. However, using Riemannian tools typically requires redefining core operations (geodesics, norms, integration), making generative modeling computationally inefficient. In this work, we propose DiffeoCFM, an approach that enables conditional flow matching (CFM) on matrix manifolds by exploiting pullback metrics induced by global diffeomorphisms on Euclidean spaces. We show that Riemannian CFM with such metrics is equivalent to applying standard CFM after data transformation. This equivalence allows efficient vector field learning, and fast sampling with standard ODE solvers. We instantiate DiffeoCFM with two different settings: the matrix logarithm for covariance matrices and the normalized Cholesky decomposition for correlation matrices. We evaluate DiffeoCFM on three large-scale fMRI datasets with more than $4600$ scans from $2800$ subjects (ADNI, ABIDE, OASIS‑3) and two EEG motor imagery datasets with over $30000$ trials from $26$ subjects (BNCI2014‑002 and BNCI2015‑001). It enables fast training and achieves state-of-the-art performance, all while preserving manifold constraints.\nCode: https://github.com/antoinecollas/DiffeoCFM",
    "keywords": [
      "brain connectivity",
      "Riemannian geometry",
      "covariance matrix",
      "fmri",
      "diffeomorphism",
      "generative model"
    ],
    "pdf_url": "https://openreview.net/pdf?id=NY3LzmUXl7",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper discusses generating realistic brain connectivity matrices (functional connectivity and correlation matrices) and evaluates the method on large-scale neuroimaging datasets (fMRI) and EEG motor imagery datasets. These datasets are strongly associated with understanding brain organization and disease (e.g., neurodegenerative disorders in ADNI, autism in ABIDE, and aging-related brain health in OASIS‑3) and neural activity patterns related to health outcomes. The focus on analyzing population heterogeneity and disease-specific brain patterns directly connects to Biomedicine AI, as it supports biomedical research and healthcare applications related to neurological and cognitive disorders. Additionally, the use of computational methods in neuroscience, a critical area of Biomedicine AI, further supports the classification under this domain.",
    "prompt_tokens": 22061,
    "completion_tokens": 237,
    "total_tokens": 22298,
    "Topic Axis I": {
      "MainTopic": "Clinical Data Science & Informatics",
      "SubTopic": "Physiological Time Series Analysis"
    },
    "Topic Axis II": {
      "MainTopic": "Generative & Foundation Models",
      "SubTopic": "Diffusion Models"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "Concept-based Explanations"
    },
    "method": "Flow matching on Riemannian manifolds; Diffeomorphic embeddings",
    "application": "Generative modeling – neuroimaging connectivity matrices",
    "code_link": "https://github.com/antoinecollas/DiffeoCFM",
    "dataset_name": [
      "ADNI",
      "ABIDE",
      "OASIS-3",
      "BNCI2014-002",
      "BNCI2015-001"
    ]
  },
  {
    "id": "pOJBw1YQgL",
    "title": "Towards Dynamic 3D Reconstruction of Hand-Instrument Interaction in Ophthalmic Surgery",
    "authors": [
      "Ming Hu",
      "Zhengdi Yu",
      "Feilong Tang",
      "Kaiwen Chen",
      "Yulong Li",
      "Imran Razzak",
      "Junjun He",
      "Tolga Birdal",
      "Kaijing Zhou",
      "Zongyuan Ge"
    ],
    "institutes": "N/A",
    "authors/institutes": "N/A",
    "abstract": "Accurate 3D reconstruction of hands and instruments is critical for vision-based analysis of ophthalmic microsurgery, yet progress has been hampered by the lack of realistic, large-scale datasets and reliable annotation tools. In this work, we introduce OphNet-3D, the first extensive RGB-D dynamic 3D reconstruction dataset for ophthalmic surgery, comprising 41 sequences from 40 surgeons and totaling 7.1 million frames, with fine-grained annotations of 12 surgical phases, 10 instrument categories, dense MANO hand meshes, and full 6-DoF instrument poses. To scalably produce high-fidelity labels, we design a multi-stage automatic annotation pipeline that integrates multi-view data observation, data-driven motion prior with cross-view geometric consistency and biomechanical constraints, along with a combination of collision-aware interaction constraints for instrument interactions. Building upon OphNet-3D, we establish two challenging benchmarks—bimanual hand pose estimation and hand–instrument interaction reconstruction—and propose two dedicated architectures: H-Net for dual-hand mesh recovery and OH-Net for joint reconstruction of two-hand–two-instrument interactions. These models leverage a novel spatial reasoning module with weak-perspective camera modeling and collision-aware center-based representation. Both architectures outperform existing methods by substantial margins, achieving improvements of over 2mm in Mean Per Joint Position Error (MPJPE) and up to 23\\% in ADD-S metrics for hand and instrument reconstruction, respectively.",
    "keywords": [
      "3D Reconstruction",
      "Ophthalmic Surgery",
      "Hand–Instrument Interaction",
      "Surgical Vision"
    ],
    "pdf_url": "https://openreview.net/pdf?id=pOJBw1YQgL",
    "is_healthcare": "Yes",
    "reasoning": "**Reasoning**: The paper explicitly focuses on a medical application—ophthalmic surgery, which is a domain within healthcare. It discusses the development of 3D reconstruction models for analyzing hand-instrument interaction during microsurgical procedures, which has direct relevance to healthcare and surgical practice. The creation of an extensive RGB-D dataset, \"OphNet-3D,\" containing annotations for surgical phases and instrument categories, along with benchmarks for bimanual hand pose estimation and hand–instrument interaction reconstruction, further ties the work to healthcare AI. Moreover, terms such as \"instrument interactions,\" \"surgical vision,\" and \"6-DoF instrument poses\" solidify the link to applications in surgical healthcare. Therefore, the paper aligns closely with the Healthcare AI domain.",
    "prompt_tokens": 22122,
    "completion_tokens": 213,
    "total_tokens": 22335,
    "Topic Axis I": {
      "MainTopic": "Medical Imaging Analysis",
      "SubTopic": "Ophthalmology"
    },
    "Topic Axis II": {
      "MainTopic": "Advanced Supervised & Representation Learning",
      "SubTopic": "Novel Architectures for Time Series"
    },
    "Topic Axis III": {
      "MainTopic": "Explainability & Interpretability (XAI)",
      "SubTopic": "new-Benchmarking hand-instrument interaction reconstruction"
    },
    "method": "Monocular reconstruction; MANO model parameters; Hand-instrument joint optimization",
    "application": "Bimanual surgical hand pose estimation; Hand-instrument interactions reconstruction",
    "code_link": "N/A",
    "dataset_name": [
      "OphNet-3D"
    ]
  }
]